[
  {
    "number": 11097,
    "title": "How to get pcm data during video playing?",
    "created_at": "2023-04-04T06:07:20Z",
    "closed_at": "2023-04-04T09:10:36Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/11097",
    "body": "How to get pcm data during video playing? The exoplayer version used is 2.18.5.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/11097/comments",
    "author": "GreenVegetables",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2023-04-04T08:14:58Z",
        "body": "You can add a `TeeAudioProcessor` to `DefaultAudioSink` (by overriding `DefaultRenderersFactory.buildAudioSink`). In there, you can specify an `AudioBufferSink` to write your pcm data to. You can also use the predefined `WavFileAudioBufferSink` to write to a wav file if needed. Alternatively, you can write your own `AudioProcessor` to modify the pcm audio as needed."
      },
      {
        "user": "GreenVegetables",
        "created_at": "2023-04-04T09:08:41Z",
        "body": "> You can add a `TeeAudioProcessor` to `DefaultAudioSink` (by overriding `DefaultRenderersFactory.buildAudioSink`). In there, you can specify an `AudioBufferSink` to write your pcm data to. You can also use the predefined `WavFileAudioBufferSink` to write to a wav file if needed. Alternatively, you can write your own `AudioProcessor` to modify the pcm audio as needed.\r\n\r\nThank you. Following these steps, I successfully obtained the pcm data."
      }
    ],
    "satisfaction_conditions": [
      "Demonstrates how to intercept raw PCM audio data during ExoPlayer playback",
      "Utilizes ExoPlayer's audio processing architecture without requiring playback modification",
      "Supports both direct PCM access and standardized file output formats",
      "Maintains compatibility with ExoPlayer 2.x extensibility patterns"
    ]
  },
  {
    "number": 10900,
    "title": "how i can set the startup bitrate in exo player?",
    "created_at": "2023-01-03T14:29:50Z",
    "closed_at": "2023-01-05T15:59:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/10900",
    "body": "how i can set the startup bitrate in exo player?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/10900/comments",
    "author": "Lilsax",
    "comments": [
      {
        "user": "pradeepvernekarzee",
        "created_at": "2023-01-04T06:22:51Z",
        "body": " Please try the below code to set the initial bitrate\r\n DefaultBandwidthMeter.Builder(context).apply {\r\n                setInitialBitrateEstimate(bitrate)\r\n            }\r\n  }.build()"
      },
      {
        "user": "Lilsax",
        "created_at": "2023-01-04T08:14:06Z",
        "body": "that does not actually set the initial bitrate becasue it only work when\r\n\r\n_Sets the initial bitrate estimate in bits per second that should be assumed when a bandwidth estimate is unavailable_\r\n\r\nand the bandwidth estimate determined by the player so as long as that value is set that function is useless that's why it only work the first time u lunch the app \r\n\r\nso the real question in here is is there a way to set **bandwidth estimate** ??"
      },
      {
        "user": "tonihei",
        "created_at": "2023-01-05T09:26:39Z",
        "body": "I assume your intention is not to set the bandwidth estimate (=the actual network speed), but rather to force a maximum selected bitrate for the first segment of each playback. If that's not the case, please clarify what you want to achieve. \r\n\r\nYou can dynamically filter which formats can be selected by providing custom `AdaptiveTrackSelection` classes that override the `canSelectFormat` method with your custom filtering logic:\r\n\r\nYou can provide a custom `ExoTrackSelection.Factory` to `DefaultTrackSelector` (which can be set via `ExoPlayer.Builder.setTrackSelector`). This custom `ExoTrackSelection.Factory` can be a subclass of `AdaptiveTrackSelection.Factory` where you override `createAdaptiveTrackSelection`. In there you can return a subclass of `AdaptiveTrackSelection` where you override `canSelectFormat`. This method can return `false` for the first selection if the bitrate exceeds a certain value. "
      },
      {
        "user": "Lilsax",
        "created_at": "2023-01-05T16:00:30Z",
        "body": "Thank you @tonihei  it worked <3"
      }
    ],
    "satisfaction_conditions": [
      "Solution must allow enforcing a maximum bitrate for the first segment of playback",
      "Approach must work when bandwidth estimates are already available",
      "Mechanism should dynamically filter selectable formats during initial track selection",
      "Solution must not depend solely on initial bitrate estimation configuration"
    ]
  },
  {
    "number": 10897,
    "title": "Identify onPlaybackStatsReady callbacks for Ads playback",
    "created_at": "2023-01-02T13:18:42Z",
    "closed_at": "2023-01-07T11:44:25Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/10897",
    "body": "As mentioned in docs for `PlaybackStatsListener`, `onPlaybackStatsReady` callback is called separately for main playback item and all of the inserted ads (e.g. pre-roll ads). Since `PlaybackStats` for ad playbacks are not important for me, I only want to log stats for the main media item. Is there a way to identify the type of media item for which the  `PlaybackStats` is prepared?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/10897/comments",
    "author": "MBakhshi96",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2023-01-05T09:13:28Z",
        "body": "The `eventTime` parameter of `onPlaybackStatsReady` tells you about which playback the stats belong to. In particular, the `EventTime` contains a `Timeline` with the full playlist and ad information and the `mediaPeriodId` field that tells you about the current ad group index and ad index. "
      },
      {
        "user": "MBakhshi96",
        "created_at": "2023-01-07T11:43:42Z",
        "body": "I'm now using `eventTime.mediaPeriodId.isAd()` to filter ad playbacks and it seems to work. Thank you for your help."
      }
    ],
    "satisfaction_conditions": [
      "Provides a way to distinguish between main media playback and ad playback using parameters available in the onPlaybackStatsReady callback",
      "Identifies the media type through metadata available in the PlaybackStatsListener callback parameters"
    ]
  },
  {
    "number": 10834,
    "title": "SimplePool for Exoplayer",
    "created_at": "2022-12-05T15:56:40Z",
    "closed_at": "2023-01-16T14:34:18Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/10834",
    "body": "Describe your question in detail:\r\n\r\nHello, my application use extensively Exoplayer and I wanted to make some improvement for my users ( ~440 000 users with phone from API 21 to API 26).\r\n\r\nFor context my app is just like Youtube, so users browse between pages which result in an ever-ending cycle of:\r\n1. creating Exoplayer\r\n2. setting mediaSource + listeners\r\n3. playing/pausing\r\n4. removing listener + releasing Exoplayer\r\n\r\nI was wondering if creating/releasing player is more resource-consuming than creating a Pool with 2 instances of Exoplayer? What's your opinion about using a `SimplePool<Exoplayer>(2)` ?\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/10834/comments",
    "author": "yoobi",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2022-12-06T13:33:00Z",
        "body": "Using a pool of player can make sense for some use cases. I wouldn't think about performance in the sense opf resources required to create the players. It is certainly needs a bit more resources to recreate new instances, but I would focus on performance only in the sense of user experience. That is, if you want to play two videos in a `RecyclerView` or a `ViewPager` and the surfaces on which the video is rendered are visible at the same time, then you possibly need two players to be able to have at least one frame rendered on each of the surfaces. In general, if your app needs to decode two videos at the same time, you need multiple instances.\r\n\r\nHowever, if you do that you need to take care of some low-level devices possibly do not support multiple instances of the video codec being used at the same time. So it gets a bit more complicated.\r\n\r\nIn general I would say if there is no need in terms of user experience I would stick with a single instance for simplicity. But I think in your case it can make sense to use a pool.\r\n\r\nThis is an advanced problem to solve properly and people asked question around this quite a lot. So it also makes sense to search the existing issues a bit to learn how other users solved this problem. An example issue about how to use the player in a `RecyclerView` is #867. \r\n\r\n"
      },
      {
        "user": "yoobi",
        "created_at": "2023-01-16T09:29:54Z",
        "body": "Thank you for your detailed answer ! My issue is not really caused by a `RecyclerView` or `ViewPager` albeit it can relate in a sense.\r\n\r\nLet's say we have `VideoPageFragment` which creates a new `Exoplayer` instance in `fun onStart()` and destroy the instance in `onStop()`. Therefore there is only one instance of Exoplayer at a time.\r\n \r\n1. User browse to`VideoPageFragment` to watch a video called: \"Building Exoplayer Part 1\"\r\n2. User clicks on button \"Next\", hence destroying the last `VideoPageFragment` and creating a new `VideoPageFragment` with data of the next video.\r\n3. User close the app\r\n\r\nWith this simple 3-step example, the user has created and destroyed 2 instance of `Exoplayer`. Would using a Pool make sense for such a case ?\n\n---\n\nDo you have some advice ?"
      },
      {
        "user": "marcbaechinger",
        "created_at": "2023-01-16T10:46:54Z",
        "body": "I understand there is only one fragment active and  only one instance playing at a time that can be shared by these fragments.  I think in this case I would just have a single instance that is created in the activity, that you can use from the fragment by using `((ExoPlayerHostingActivity)getActivity()).getPlayer()`. The fragments lifecycle methods can then be used to set media sources, prepare the player and start playback. Afterwards the player is pause, stopped and released. For such a use case without overlapping playback a single instance sounds sufficient.  "
      },
      {
        "user": "yoobi",
        "created_at": "2023-01-16T11:09:44Z",
        "body": "I'm ashamed to say I didn't think of that because this is simple and brilliant. I'll go with that instead of doing a pool.\r\n\r\nThanks"
      }
    ],
    "satisfaction_conditions": [
      "Addresses resource efficiency of ExoPlayer instance management",
      "Considers single-instance vs multi-instance requirements based on playback concurrency",
      "Provides lifecycle management strategy that avoids redundant initialization",
      "Balances complexity against performance benefits"
    ]
  },
  {
    "number": 10543,
    "title": "Intercepting notification events",
    "created_at": "2022-08-22T18:02:13Z",
    "closed_at": "2022-09-01T15:31:10Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/10543",
    "body": "I would like to intercept the notification events, so I can implement custom functionality when they are fired. Currently, they are being handled in this `NotificationBroadcastReceiver`:\r\n\r\n```java\r\n @Override\r\n    public void onReceive(Context context, Intent intent) {\r\n      Player player = PlayerNotificationManager.this.player;\r\n      if (player == null\r\n          || !isNotificationStarted\r\n          || intent.getIntExtra(EXTRA_INSTANCE_ID, instanceId) != instanceId) {\r\n        return;\r\n      }\r\n      String action = intent.getAction();\r\n      if (ACTION_PLAY.equals(action)) {\r\n        if (player.getPlaybackState() == Player.STATE_IDLE) {\r\n          player.prepare();\r\n        } else if (player.getPlaybackState() == Player.STATE_ENDED) {\r\n          player.seekToDefaultPosition(player.getCurrentMediaItemIndex());\r\n        }\r\n        player.play();\r\n      } else if (ACTION_PAUSE.equals(action)) {\r\n        player.pause();\r\n      } else if (ACTION_PREVIOUS.equals(action)) {\r\n        player.seekToPrevious();\r\n      } else if (ACTION_REWIND.equals(action)) {\r\n        player.seekBack();\r\n      } else if (ACTION_FAST_FORWARD.equals(action)) {\r\n        player.seekForward();\r\n      } else if (ACTION_NEXT.equals(action)) {\r\n        player.seekToNext();\r\n      } else if (ACTION_STOP.equals(action)) {\r\n        player.stop(/* reset= */ true);\r\n      } else if (ACTION_DISMISS.equals(action)) {\r\n        stopNotification(/* dismissedByUser= */ true);\r\n      } else if (action != null\r\n          && customActionReceiver != null\r\n          && customActions.containsKey(action)) {\r\n        customActionReceiver.onCustomAction(player, action, intent);\r\n      }\r\n    }\r\n```\r\n\r\nSadly, I can't replace the receiver with my own, since it's private:\r\n\r\n`  private final NotificationBroadcastReceiver notificationBroadcastReceiver;`\r\n\r\nI was thinking of maybe overriding `getActions` and `getActionIndicesForCompactView` and make my own custom actions, but the original actions are used in so many cases in functions that are not overridable that I don't think it's possible to mimic when they are called. \r\n\r\nMy final solution is to just make my own notification manager from scratch, but I hope it doesn't come to that.\r\n\r\nIs there a way that I haven't found to intercept those events?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/10543/comments",
    "author": "mpivchev",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2022-08-22T22:12:38Z",
        "body": "You can use a `ForwardingPlayer` to intercept the method calls done in `onReceive`. Issue #10212 has some more detail. Please let me know if this helps for your use case."
      },
      {
        "user": "mpivchev",
        "created_at": "2022-09-01T15:31:03Z",
        "body": "`ForwardingPlayer` did the trick, thank you."
      }
    ],
    "satisfaction_conditions": [
      "Provides a way to intercept notification events without replacing the private NotificationBroadcastReceiver",
      "Allows adding custom functionality when notification actions are triggered",
      "Works with existing PlayerNotificationManager architecture",
      "Doesn't require overriding non-overridable methods"
    ]
  },
  {
    "number": 10533,
    "title": "Do not Deprecate Player.Listener.onPlayerStateChanged()",
    "created_at": "2022-08-17T16:56:36Z",
    "closed_at": "2022-08-17T17:36:12Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/10533",
    "body": "### [REQUIRED] Use case description\r\n\r\nI need to listen for a state where the video is playing. The only way to do that right now is using `Player.Listener.onPlayerStateChanged()`.\r\n\r\n```\r\nexoPlayer.addListener(object : Player.Listener {\r\n            override fun onPlayerStateChanged(playWhenReady: Boolean, playbackState: Int) {\r\n                if (playWhenReady && playbackState == ExoPlayer.STATE_READY) {\r\n                    // The video is playing\r\n                }\r\n            }\r\n        })\r\n```\r\n\r\nHowever, this method is marked as deprecated. `onPlaybackStateChanged(int)` and `onPlayWhenReadyChanged(boolean, int)` are being recommended. However, none of them provides the state that the video is actually playing.\r\n\r\n`onPlaybackStateChanged()` could means it's still loading and `onPlayWhenReadyChanged` could means it's loaded but still paused.\r\n\r\n\r\n\r\n### Proposed solution\r\nWe should un-deprecate `onPlayerStateChanged`\r\n\r\n\r\n\r\n### Alternatives considered\r\nOr adde a new state: `STATE_PLAYING`\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/10533/comments",
    "author": "GC-Xi",
    "comments": [
      {
        "user": "rohitjoins",
        "created_at": "2022-08-17T17:36:12Z",
        "body": "@GC-Xi You can use either of the options below to know if the video is playing:\r\n\r\n1.  `onEvents(Player player, Events events)` callback which has a reference to player and check\r\n```\r\nif (events.contains(Player.EVENT_PLAY_WHEN_READY_CHANGED) && player.getPlaybackState() == ExoPlayer.STATE_READY) {\r\n    // The video is playing\r\n}\r\n```\r\n2. `Player.isPlaying()` which returns whether the player is playing."
      },
      {
        "user": "GC-Xi",
        "created_at": "2022-08-18T10:22:18Z",
        "body": "@rohitjoins That worked. Thanks!"
      }
    ],
    "satisfaction_conditions": [
      "Provides a way to detect when the video is actively playing (not just ready or paused)",
      "Works with non-deprecated APIs",
      "Doesn't require manual state tracking across multiple callbacks",
      "Matches the simplicity of their original implementation"
    ]
  },
  {
    "number": 10452,
    "title": "How to configure forward and rewind time values for player notification manager?",
    "created_at": "2022-07-19T09:31:41Z",
    "closed_at": "2022-07-19T10:49:03Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/10452",
    "body": "By default rewind button in the notification seeking player time by 5 seconds but forward button seeking player by 15 seconds. Can't find any direct functions in the player notification manager javadoc.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/10452/comments",
    "author": "shaiksalam9182",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2022-07-19T10:02:28Z",
        "body": "When you build your player you can set the `seekBackIncrements` or the `seekForwardIncrement` by using the setters of the `ExoPlayer.Builder`. This sets the seek increments generally for all `Player.seekBack()` and `Player.seekForward()` calls on that player instance.\r\n\r\nIf you want to have the behaviour specific for commands coming from the notification, you can use a `ForwardingPlayer` with which you wrap the player. Then you set the forwarding player to the `PlayerNotificationManager.setPlayer(forwardingPlayer)` and you can override the `seekBack()` and `seekForward()` methods on the forwarding player to customize it to fit your requirements.\r\n\r\n"
      },
      {
        "user": "shaiksalam9182",
        "created_at": "2022-07-19T10:49:03Z",
        "body": "Thanks @marcbaechinger . It's working now"
      }
    ],
    "satisfaction_conditions": [
      "Allows separate configuration of forward and rewind seek increments",
      "Applies specifically to notification-triggered seek commands",
      "Doesn't require direct modification of PlayerNotificationManager internals",
      "Maintains compatibility with ExoPlayer's architecture"
    ]
  },
  {
    "number": 10396,
    "title": "Intercepting DAI stream URL using the ExoPlayer IMA extension",
    "created_at": "2022-07-01T14:02:13Z",
    "closed_at": "2022-07-13T08:31:36Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/10396",
    "body": "Hi, \r\n\r\nwe are currently trying out the ExoPlayer IMA extension for IMA server side inserted ad streams in our android app, by using `ImaServerSideAdInsertionMediaSource`. We encountered the following problem and would like to ask you how to best handle it.\r\n\r\nWe have been using the trick to have a placeholder @TOKEN@ configured in ad manager and replace it in our client with the proper auth token. The hook to do this seems to be missing from the IMA extension.\r\nWith a previous IMA SDK integration, the IMA SDK functionality was implemented by our client app, resolving the media URL dynamically in order to get the stitched stream. This allowed us to manipulate the loaded media URL of the stitched stream (via `VideoStreamPlayer.loadUrl(...` callback), so we could replace a stream token placeholder for authorisation, before passing the stitched stream url to the player. \r\n\r\nBy using `ImaServerSideAdInsertionMediaSource`, the stitched stream URL seems to be passed to the player internally, and we were not yet able to find any way to intercept this stitched stream media URL over the new IMA extension API.\r\n\r\nDo you have any suggestions as to how to best handle stream authorisation in the given context?\r\n\r\nThanks in advance!\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/10396/comments",
    "author": "amiantoch",
    "comments": [
      {
        "user": "amiantoch",
        "created_at": "2022-07-11T12:50:33Z",
        "body": "Hi,\r\n\r\nare there any updates on this issue?\r\nIs any additional information required from our side to further clarify?\r\n\r\nThanks\r\n"
      },
      {
        "user": "marcbaechinger",
        "created_at": "2022-07-11T18:04:31Z",
        "body": "I'm not quite sure whether I understand all your requirements and what manipulations you want to do at what moment in time of the SDK/Player interaction. But I think there are some hooks that are useful for you to know about.\r\n\r\nThe `ImaServerSideAdInsertionMediaSource.Factory` allows app to set their `MediaSourceFactory` by passing it to the constructor. By default apps want this to be the `DefaultMediaSourceFactory` to support HLS and DASH. In your case you may want to take advantage of this flexibility:\r\n\r\n1) You can inject your own custom `DataSource.Factory` into the constructor of the `DefaultMediaSourceFactory` and then inject that into the constructor of the `ImaServerSideAdInsertionMediaSource.Factory`. The custom `DataSource.Factory` would then create a `ResolvingDataSource` that wraps the concrete `DataSource` that you are using. The `ResolvingDataSource` allows you to replace the `DataSpec` with your modified version by providing a `Resolver` and overriding its\r\n\r\n```\r\nDataSpec resolveDataSpec(DataSpec dataSpec) throws IOException;\r\n```\r\n\r\nThe `DataSpec` passed in is what you would have seen in `loadUrl` (I think) and you can create a new `DataSpec` replacing that with whatever you like in the resolver. \r\n\r\nNote: If I'm not mistaken then the `Resolver` will be called for any requests manifest/playlist and any media (video/audio/text).\r\n\r\n2) An alternative would be to implement your own `MediaSource.Factory` and pass it to the constructor of `ImaServerSideAdInsertionMediaSource.Factory`. Your implementation is a composition that delegates everything to an instance of `DefaultMediaSourceFactory` that you hold as a member field. Then when `MediaSource.Factory.createMediaSource(MediaItem)` is called your wrapper source receives the `MediaItem` and can `buildUpon()` to inject the modified URI before delegating to `createMediaSource` of the actual source and pass the new `MediaItem`.\r\n\r\nNote: This approach does only manipulate the initial URI that is used to load the manifest/playlist initially. After that, media and the like is requested as without this change.\r\n\r\nI hope one or the other approach may work for you. Please let me know in either case. :)"
      },
      {
        "user": "amiantoch",
        "created_at": "2022-07-13T08:31:36Z",
        "body": "Very useful tips!:)\r\nThe second solution seems to be working perfectly for our needs.\r\n\r\nThank you!"
      }
    ],
    "satisfaction_conditions": [
      "Provides a supported method to modify the stitched stream URL before it's loaded by the player",
      "Works with the ImaServerSideAdInsertionMediaSource architecture without internal modifications",
      "Allows URI manipulation at the initial media loading stage",
      "Maintains compatibility with standard media formats (HLS/DASH)"
    ]
  },
  {
    "number": 10268,
    "title": "ForwardingPlayer.setPlayWhenReady is not being called",
    "created_at": "2022-05-17T21:56:44Z",
    "closed_at": "2022-05-24T10:49:32Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/10268",
    "body": "From migrating a `DefaultControlDispatcher` to `ForwardingPlayer`, do I need to implement something else besides only creating an instance of the `ForwardingPlayer` class? Because I'm not getting called the method `setPlayWhenReady` from the `ForwardingPlayer` but other methods are called as `getPlayWhenReady` and `isPlaying`, for example.\r\n\r\nThis is reproducible in the ExoPlayer Demo app v2.17.1 by just passing a `ForwardingPlayer` object to the `playerView` object through the method `setPlayer()`\r\n\r\nThank you!\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/10268/comments",
    "author": "nandovelazquez",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2022-05-17T22:07:42Z",
        "body": "The `PlayerControlView` is using `player.play()` and `player.pause()` which is delegated by the `ForwardingPlayer` to the wrapped `Player`. Then the wrapped player is calling `setPlayWhenReady(true|false)` but not on the `ForwardingPlayer` but internally on itself.\r\n\r\nSo you can intercept these calls by overriding `play()` and `pause()` of your `ForwardingPlayer`."
      },
      {
        "user": "nandovelazquez",
        "created_at": "2022-05-20T17:17:09Z",
        "body": "Thanks for the quick response!\r\n\r\nThe methods `play()` and `pause()` work. It might be helpful if that behavior is somewhere in the documentation for future references.\r\n\r\nThanks again."
      },
      {
        "user": "marcbaechinger",
        "created_at": "2022-05-24T10:49:32Z",
        "body": "We added a section about 'ForwardingPlayer' to the developer guide that will be published with the next release."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why setPlayWhenReady isn't called when using ForwardingPlayer",
      "Clarification of which methods to override for intercepting play/pause state changes",
      "Documentation of ForwardingPlayer's interaction patterns with PlayerControlView",
      "Guidance on proper ForwardingPlayer implementation requirements beyond instantiation"
    ]
  },
  {
    "number": 10262,
    "title": "Method to disable sequential playback on MediaSource level",
    "created_at": "2022-05-16T09:53:15Z",
    "closed_at": "2022-05-17T09:22:01Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/10262",
    "body": "I am looking for a way to disable sequential playback of mp3s on `MediaSource` level (of course, the MediaSource in my case is a `ConcatenatingMediaSource`). I know about the method `setPauseAtEndOfMediaItems` on exoplayer level. But this disables sequential playback for ALL media sources used by exoplayer. I would like to disable sequential playback on one `MediaSource` while enable it on another `MediaSource`. Is there something like `MediaSource.setPauseAtEndOfMediaItems` ? Thank you!",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/10262/comments",
    "author": "tosam144",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2022-05-16T21:02:24Z",
        "body": "There is no API for this I'm afraid, but I think implementing this with the existing API is straightforward.\r\n\r\nYou can listen to `Player.Listener.onMediaItemTransition(mediaItem, reason)` then look at the media item and set `pauseAtEndOfMediaItems` accordingly.\r\n\r\nWould that work?"
      },
      {
        "user": "tosam144",
        "created_at": "2022-05-17T09:10:18Z",
        "body": "Excellent, @marcbaechinger: thank you. That works perfectly indeed."
      }
    ],
    "satisfaction_conditions": [
      "Allows per-MediaSource control of sequential playback behavior",
      "Provides dynamic adjustment of playback behavior during media transitions",
      "Maintains isolation between MediaSource instances"
    ]
  },
  {
    "number": 10128,
    "title": "Ffmpeg extension quesion",
    "created_at": "2022-03-30T05:25:24Z",
    "closed_at": "2022-03-30T14:19:17Z",
    "labels": [
      "question",
      "needs triage"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/10128",
    "body": "I'm able to build the ffmpeg extension and use it in the demo app and my own app. But I want to just have the armeabi-v7a and arm64-v8a libraries generated only to reduce the apk size. When I build the demo project, it seems  x86 and x64_64 libraries needs to be in  the ANDROID-LIBS folder. I build the ffmpeg extension in  the Linux machine and  copy the ffmpeg directory to Windows 10  where Android Studio is resided. What needs to be done to achieve this? Thanks.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/10128/comments",
    "author": "tpuserhp",
    "comments": [
      {
        "user": "vovan888",
        "created_at": "2022-03-30T10:58:23Z",
        "body": "app/build.gradle:\r\n\r\n```\r\nandroid {\r\n        ndk {\r\n            abiFilters \"armeabi-v7a\", \"arm64-v8a\"\r\n        }\r\n}\r\n\r\n```"
      },
      {
        "user": "tpuserhp",
        "created_at": "2022-03-30T14:19:16Z",
        "body": "Yes, the suggested changes resulted in a smaller size of the apk  generated. Thank you very much  for your help. This issue can be closed now."
      }
    ],
    "satisfaction_conditions": [
      "Provides a way to exclude x86 and x86_64 architectures from the final APK",
      "Works with Android Studio's build system when using prebuilt libraries",
      "Maintains functionality of the FFmpeg extension after architecture filtering",
      "Doesn't require maintaining multiple library sets for different architectures"
    ]
  },
  {
    "number": 10023,
    "title": "Custom controller layout not recognizing play and pause buttons.",
    "created_at": "2022-03-03T14:33:23Z",
    "closed_at": "2022-03-04T08:39:18Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/10023",
    "body": "Hi, I think there is a bug with the custom controller layout.\r\n\r\nI tried to add a custom controller layout to StyledPlayerView on the demo app and it is loaded, but when I override the exo_play and exo_pause buttons they don't work. \r\nWeird thing is that exo_ffwd and exo_rew work as expected (I didn't try others).\r\n\r\nPlayer Activity contains StyledPlayerView\r\n\r\n```\r\n    <com.google.android.exoplayer2.ui.StyledPlayerView\r\n          android:id=\"@+id/player_view\"\r\n          android:layout_width=\"match_parent\"\r\n          android:layout_height=\"match_parent\"\r\n          app:controller_layout_id=\"@layout/exo_player_layout\"/>\r\n```\r\n\r\n\r\nAnd this is exo_player_layout\r\n\r\n\r\n```\r\n     <LinearLayout\r\n            android:id=\"@+id/play_controls\"\r\n            android:layout_width=\"wrap_content\"\r\n            android:layout_height=\"wrap_content\"\r\n            android:gravity=\"center\">\r\n\r\n            <ImageButton\r\n                android:id=\"@id/exo_play\"\r\n                android:layout_width=\"wrap_content\"\r\n                android:layout_height=\"wrap_content\"\r\n                app:srcCompat=\"@drawable/ic_exo_play\" />\r\n\r\n            <ImageButton\r\n                android:id=\"@id/exo_pause\"\r\n                android:layout_width=\"wrap_content\"\r\n                android:layout_height=\"wrap_content\"\r\n                app:srcCompat=\"@drawable/ic_exo_pause\"/>\r\n\r\n        </LinearLayout>\r\n\r\n```\r\n\r\nDoes anyone have any ideas?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/10023/comments",
    "author": "mdurokov",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2022-03-03T15:00:21Z",
        "body": "I think the `StyledPlayerView` is using `@id/exo_play_pause` rather than `@id/exo_play` and `@id/exo_pause`.\r\n\r\nIf you want to provide your custom layout you should use a single button with `@+id/exo_play_pause`. The styled control view does not hide/show one or the other of these buttons, but instead change the drawable of the icon. If you want to change these icons you can do so by adding a `drawables.xml` in the `values` folder of the app module to override the drawables used by default:\r\n\r\n```\r\n<resources>\r\n  <drawable name=\"exo_styled_controls_play\">@drawable/custom_controls_play</drawable>\r\n  <drawable name=\"exo_styled_controls_pause\">@drawable/custom_controls_pause</drawable>\r\n</resources>\r\n``` \r\n\r\nPlease see #10008 also which is about a similar issue.\r\n\r\nThere were quite some changes in the ui components, so if the above does not help, please let us know the exact ExoPlayer version you are depending to with your app."
      },
      {
        "user": "mdurokov",
        "created_at": "2022-03-04T08:39:18Z",
        "body": "That does the trick, thank you! \r\nI didn't see it documented anywhere.\r\nAs a matter of fact, I did use PlayerView before and it worked with exo_play and exo_pause. "
      },
      {
        "user": "draganstojanov",
        "created_at": "2022-03-10T12:10:51Z",
        "body": "It works. But, i have two sets of icons, one for vertical oriented video and other for horizontal oriented. Is there any way to programmatically override drawables?"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of the required UI component IDs for play/pause functionality in StyledPlayerView",
      "Clarification on how to properly customize play/pause button icons",
      "Differentiation between StyledPlayerView and legacy PlayerView component handling",
      "Identification of version-specific requirements"
    ]
  },
  {
    "number": 9945,
    "title": "Allow LoadControl to prevent loading indefinitely",
    "created_at": "2022-02-07T13:00:18Z",
    "closed_at": "2022-06-09T12:26:05Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/9945",
    "body": "My use case here is that I would like to prevent loading by overriding DefaultLoadControl if the user switches to a mobile data connection. Due to data caps not everybody wants to use their data towards video streaming. I would like to offer a setting to opt in using mobile data (just like you need to explicitly allow automatic app updates when not on wifi).\r\n\r\nYou can easily reproduce this by overriding `shouldContinueLoading` and always returning `false`.\r\n\r\nApparently there are some legitimate cases where the player could get stuck which is why there is a check for this in `ExoPlayerImplInternal`:\r\n\r\n```\r\nif (!playbackInfo.isLoading\r\n    && playbackInfo.totalBufferedDurationUs < 500_000\r\n    && isLoadingPossible()) {\r\n  // Throw if the LoadControl prevents loading even if the buffer is empty or almost empty. We\r\n  // can't compare against 0 to account for small differences between the renderer position\r\n  // and buffered position in the media at the point where playback gets stuck.\r\n  throw new IllegalStateException(\"Playback stuck buffering and not loading\");\r\n}\r\n```\r\n\r\nIs there a better way to achieve this without running into an Exception? I would like this to be fully recoverable: if the user connects to wifi again streaming should continue without having to prepare the player again.\r\n\r\nIf not I would like to request a configuration flag to override this for my use case. I cannot imagine that I am the only one facing this.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/9945/comments",
    "author": "wkarl",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2022-05-17T15:34:08Z",
        "body": ">  I would like this to be fully recoverable: if the user connects to wifi again streaming should continue without having to prepare the player again.\r\n\r\nThis is an interesting request in that the player is technically doing the right thing: it detects the playback as being stuck and fails. The issue is that you actually want the player to be stuck forever (or until the WiFi connection comes back). I think it would make more sense to let the player fail, display an appropriate message to the user (\"no internet connection / waiting for WiFi\") and just call `player.prepare()` once the Wifi is available again. There isn't a big cost involved in calling `prepare` again (other than recreating the decoder) because there is no already downloaded data left to play anyway, so it's unclear why you want to avoid re-preparation. \r\n\r\nTwo further thoughts on general setup:\r\n - It's not too unlikely that the user will stay on the mobile data connection for a considerable amount of time, so they might not expect playback to continue anyway? \r\n - To create a consistent user experience, you likely need to implement the same logic for a client that goes offline completely. However, that's not easily possible because sudden switches to offline will almost certainly result in network-related playback errors instead of a stuck-buffering exception, so it's unlikely you can prevent the player from going into an error state when the connection is lost completely. "
      },
      {
        "user": "wkarl",
        "created_at": "2022-05-18T05:05:00Z",
        "body": "Thank you for your detailed response @tonihei \r\nAbout the two further thoughts you mentioned:\r\n> It's not too unlikely that the user will stay on the mobile data connection for a considerable amount of time, so they might not expect playback to continue anyway?\r\n\r\nThis only applies to users with a very limited data plan. Many users will want to continue playing on mobile data. That's why there is a \"allow mobile data playback\" button in the dialog we display: it will dismiss the message and continue playing immediately (in addition to a switch in the app settings).\r\n\r\n> To create a consistent user experience, you likely need to implement the same logic for a client that goes offline completely. However, that's not easily possible because sudden switches to offline will almost certainly result in network-related playback errors instead of a stuck-buffering exception, so it's unlikely you can prevent the player from going into an error state when the connection is lost completely.\r\n\r\nYou'd be surprised how well this works. I modified `DefaultLoadErrorHandlingPolicy` to keep retrying playback for this case. As soon as a connection is restored the stream continues playing without fail.\r\n\r\nAs you suggested I currently just call `player.prepare()` again but there are a few downsides:\r\n- The error must be suppressed for this specific case when reporting errors to Firebase etc. to avoid inflating playback errors.\r\n- Semantics: I see this specific case as more of a prompt than an actual error. Handling in the app is very different to regular errors.\r\n- Recovery would be simpler: just unblock `LoadControl` instead of specialised error handling.\r\n- To make sure the video is resumed at the correct position, I either need to remember the position where the error occurred or skip setting the media item again (or use `player.setMediaItem(mediaItem, false)` to keep the position).\r\n\r\nDespite the successful workaround this would definitely be a nice-to-have for me."
      },
      {
        "user": "tonihei",
        "created_at": "2022-05-18T11:20:13Z",
        "body": "> To make sure the video is resumed at the correct position, I either need to remember the position where the error occurred or skip setting the media item again (or use player.setMediaItem(mediaItem, false) to keep the position).\r\n\r\nI believe this should just work without any special workarounds? If you just call `prepare()` after the error and nothing else, playback should continue from where it left off and the whole playlist should still be intact.\r\n\r\n>  You'd be surprised how well this works. I modified DefaultLoadErrorHandlingPolicy to keep retrying playback for this case. As soon as a connection is restored the stream continues playing without fail.\r\n\r\nThis is certainly possible (although I think not the original intention of the `LoadErrorHandlingPolicy`). If you handle network errors in this way anyway, I believe you can achieve your goal with the mobile data connection via the same path by using a `DataSource` wrapper that throws a custom exception when Wifi is lost.\r\n\r\nSomething like (pseudo-code):\r\n```\r\nclass NetworkAwareDataSource implements DataSource {\r\n\r\n   private DataSource actualDataSource;\r\n\r\n   @Override \r\n   public void allDataSourceMethods(...) {\r\n      actualDataSource.method(...);\r\n    }\r\n\r\n   @Override \r\n   public int read(....) throws IOException {\r\n      if (networkLost) {\r\n        throw new CustomNetworkLostIOException();\r\n      }\r\n      return actualDataSource.read(...);\r\n   }\r\n}\r\n```\r\nand you can then pass this `DataSource` to the `DefaultMediaSourceFactory` in the `ExoPlayer.Builder` (or your more specific `MediaSource.Factory` depending on your setup)."
      },
      {
        "user": "wkarl",
        "created_at": "2022-05-18T19:24:54Z",
        "body": "That looks like a good approach, thank you for the suggestion!"
      },
      {
        "user": "tonihei",
        "created_at": "2022-06-09T12:26:05Z",
        "body": "Closing the issue, because the question was answered. "
      }
    ],
    "satisfaction_conditions": [
      "Dynamic control over playback loading based on network conditions without triggering fatal errors",
      "Differentiation between intentional loading blocks and error states",
      "State preservation across network condition changes"
    ]
  },
  {
    "number": 9870,
    "title": "Unable to fetch the Chunk Size and Latency during playing the video",
    "created_at": "2022-01-18T11:24:15Z",
    "closed_at": "2022-01-21T14:21:12Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/9870",
    "body": "Hi Team,\r\n\r\nCurrently, I am using the 2.12.1 version and trying to fetch the Chunk Size and Latency by calling the MediaSourceEventListener but I didn't get a call inside the onLoadCompleted Override method.\r\n\r\nPlease find the onLoadCompleted method logic\r\n\r\n@Override\r\n    public void onLoadCompleted(int windowIndex, @Nullable MediaSource.MediaPeriodId mediaPeriodId, LoadEventInfo loadEventInfo, MediaLoadData mediaLoadData) {\r\n        mLatestChunkLatency = loadEventInfo.loadDurationMs;\r\n        mLatestChunkSize = (int) ((mediaLoadData.mediaEndTimeMs - mediaLoadData.mediaStartTimeMs) / 1000);\r\n    }\r\n    \r\n    How to find the Chunk Size and Latency without updating the version?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/9870/comments",
    "author": "satishkumar-tudip",
    "comments": [
      {
        "user": "christosts",
        "created_at": "2022-01-21T14:12:19Z",
        "body": "I don't know how you are creating MediaSources and attaching listeners to them in your app, however can you try attaching an `AnalyticsListener` to the player and override its `onLoadCompleted()`?\r\n\r\nLet me know if that worked."
      },
      {
        "user": "satishkumar-tudip",
        "created_at": "2022-01-21T14:15:20Z",
        "body": "Hi @christosts \r\nThank you for the reply, I have already attached the AnalyticsListener and it's working now."
      }
    ],
    "satisfaction_conditions": [
      "Solution must work with ExoPlayer 2.12.1 without requiring version updates",
      "Mechanism to capture chunk size and latency metrics during video playback",
      "Event listener implementation that reliably triggers onLoadCompleted callbacks"
    ]
  },
  {
    "number": 9818,
    "title": "Get ad information from DASH manifest where ad is SSAI.",
    "created_at": "2021-12-28T12:34:14Z",
    "closed_at": "2021-12-28T13:55:02Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/9818",
    "body": "From my dash manifest I need to get some advt information which is part of event stream objects.\r\nThe ads are being inserted on server side via SSAI.\r\nI am using the function `onTimelineChanged` but it gets called multiple times. And I am unable to get when the ad is being started or completed.\r\nIs there any other method or callback for SSAI ads on DASH? \r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/9818/comments",
    "author": "wishygupta",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2021-12-28T12:52:04Z",
        "body": "There is a list of `EventStream` objects in the `Period` of the `DashManifest`. You can access the manifest as soon as you receive a timeline update for a reason of `TIMELINE_CHANGE_REASON_SOURCE_UPDATE`. If the dash stream is the only media item that is in the playlist, the code below show how you can access the manifest with `player.getCurrentManifest()` and the `EventStream` information that is in the manifest.\r\n\r\n```\r\n    @Override\r\n    public void onTimelineChanged(Timeline timeline, @Player.TimelineChangeReason int reason) {\r\n      if (reason == Player.TIMELINE_CHANGE_REASON_SOURCE_UPDATE) {\r\n        // assuming the stream in question is the only media item in the playlist\r\n        DashManifest manifest = (DashManifest) player.getCurrentManifest();\r\n        for (int i = 0; i < manifest.getPeriodCount(); i++) {\r\n          for (int j = 0; j < manifest.getPeriod(i).eventStreams.size(); j++) {\r\n            // Here we go.\r\n          }\r\n        }\r\n      }\r\n    }\r\n```\r\n\r\nI'm not sure whether you also need information of timed metadata that may be delivered as in-band metadata. In such a case you should be able to listen to the arrival of timed metadata by using the `onMetadata` callback of the `Player.Listener`. \r\n\r\n```\r\n    @Override\r\n    public void onMetadata(Metadata metadata) {\r\n        // timed metadata arrived...\r\n    }\r\n```"
      },
      {
        "user": "wishygupta",
        "created_at": "2021-12-28T13:55:02Z",
        "body": "Thank you for the response. I can get started with this."
      }
    ],
    "satisfaction_conditions": [
      "Identifies a method to access SSAI ad timing information from DASH manifests",
      "Provides a reliable callback mechanism for ad-related timeline changes",
      "Differentiates between general timeline updates and ad-specific events",
      "Handles both manifest-based event streams and in-band metadata"
    ]
  },
  {
    "number": 9751,
    "title": "seekToPrevious() in PlayerControlView can't change to the previous mediaItem",
    "created_at": "2021-12-02T10:18:02Z",
    "closed_at": "2021-12-02T12:25:54Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/9751",
    "body": "I'm used PlayeControlView in the xml layout, when I clicked previous button, it's just seek to the start of current mediaItem.\r\n\r\nI find that there is a method `seekToPreviousMediaItem()` , but in PlayeControlView, it's called `seekToPrevious()`, then it's will get the current playing position and judge is change to previous or seek to 0 of current item.\r\n\r\nI just want to change the previous item, but I can't control it if I use PlayeControlView ,since I can't override the onClick()\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/9751/comments",
    "author": "lizebinbin",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2021-12-02T12:25:54Z",
        "body": "You can achieve this by wrapping the player in a `ForwardingPlayer`, and overriding the `seekToPrevious()` behavior:\r\n\r\n```\r\nPlayer forwardingPlayer = new ForwardingPlayer(player) {\r\n  @Override\r\n  public long getMaxSeekToPreviousPosition() {\r\n      return 0;\r\n  }\r\n  @Override\r\n  public final void seekToPrevious() {\r\n    seekToPreviousMediaItem();\r\n  }\r\n};\r\nplayerView.setPlayer(forwardingPlayer);\r\n``` "
      },
      {
        "user": "lizebinbin",
        "created_at": "2021-12-03T03:29:02Z",
        "body": "than\r\n\r\n> You can achieve this by wrapping the player in a `ForwardingPlayer`, and overriding the `seekToPrevious()` behavior:\r\n> \r\n> ```\r\n> Player forwardingPlayer = new ForwardingPlayer(player) {\r\n>   @Override\r\n>   public long getMaxSeekToPreviousPosition() {\r\n>       return 0;\r\n>   }\r\n>   @Override\r\n>   public final void seekToPrevious() {\r\n>     seekToPreviousMediaItem();\r\n>   }\r\n> };\r\n> playerView.setPlayer(forwardingPlayer);\r\n> ```\r\n\r\nThanks\uff5e"
      }
    ],
    "satisfaction_conditions": [
      "Solution must enable switching to previous media item instead of seeking within current item",
      "Implementation must work with PlayerControlView's existing click handlers",
      "Approach should modify player behavior rather than view behavior",
      "Must override default position-based navigation logic"
    ]
  },
  {
    "number": 9693,
    "title": "Custom DataSource.Factory with different headers",
    "created_at": "2021-11-16T05:18:27Z",
    "closed_at": "2021-11-22T15:16:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/9693",
    "body": "Hi Team,\r\n\r\nWe are using a Custom DataSource.Factory for playing the encrypted HLS content where we pass a Token in headers.\r\n\r\nBut when we are sideloading the Subtitles. The subtitles are not working because of the Header Token which we added for HLS content. \r\n\r\nIs there a way to overcome this situation?\r\nwhere we can exclude the header for subtitles through Custom DataSource.Factory.\r\n\r\nBelow is the Custom DataSpurce.Factory\r\n```\r\nclass CustomDataSourcesFactory\r\n/**\r\n * Constructs a DefaultHttpDataSourceFactory. Sets [ ][DefaultHttpDataSource.DEFAULT_CONNECT_TIMEOUT_MILLIS] as the connection timeout, [ ][DefaultHttpDataSource.DEFAULT_READ_TIMEOUT_MILLIS] as the read timeout and disables\r\n * cross-protocol redirects.\r\n *\r\n * @param userAgent The User-Agent string that should be used.\r\n */ @JvmOverloads constructor(\r\n    private val userAgent: String?,\r\n    private val token: String?,\r\n    @field:Nullable @param:Nullable private val listener: TransferListener? = null,\r\n    private val connectTimeoutMillis: Int = DefaultHttpDataSource.DEFAULT_CONNECT_TIMEOUT_MILLIS,\r\n    private val readTimeoutMillis: Int =\r\n        DefaultHttpDataSource.DEFAULT_READ_TIMEOUT_MILLIS,\r\n    private val allowCrossProtocolRedirects: Boolean = false\r\n) : BaseFactory() {\r\n\r\n    override fun createDataSourceInternal(\r\n        defaultRequestProperties: RequestProperties\r\n    ): HttpDataSource {\r\n        val defaultHttpDataSource = DefaultHttpDataSource(\r\n            userAgent, connectTimeoutMillis, readTimeoutMillis,\r\n            allowCrossProtocolRedirects, defaultRequestProperties\r\n        )\r\n        defaultHttpDataSource.setRequestProperty(AUTHORIZATION,\r\n            \"$BEARER$token\"\r\n        )\r\n        return defaultHttpDataSource\r\n    }\r\n}\r\n```\r\n\r\nPlease do let us know if any feasibility available.\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/9693/comments",
    "author": "SashiWork",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2021-11-16T13:46:24Z",
        "body": "I'm not entirely sure how you are achieving what you do  from the information you provided. So I assume you are injecting your `CustomDataSourceFactory` to the `DefaultMediaSourrceFactory` which you then use for building your player. You then define the subtitles in a `MediaItem` which you pass to `player.setMediaItem(mediaItem)` or another media item based method.\r\n\r\nIf this is the case then the `DataSourceFactory` that you inject is used by the `DefaultMediaSourcefactory` for the content and the subtitles requests. So the token is sent to the server that serves the subtitle files as well as to the server that serves the HLS playlist and media files.\r\n\r\nThe `DefaultMediaSourceFactory` currently does not offer an API to set different `DataSourceFactory` for different request. I think you could solve this by using a `ResolvingDataSource.Factory` and implement a custom `Resolver`. This resolver would check whether it is a subtitle or an HLS request and then add the bearer token to HLS requests by modifiyng the `DataSpec`.\r\n\r\nAs an alternative, you can also create a custom `MediaSourceFactory` and use thiat factory when you build the player, but this would require you to kind of build all the features that are in `DefaultMediaSourceFactory` again (you can do a composite and delegate to an instance of the `DefaultMediaSourceFactory`, but you have to create a `MergedMediaSource` yourself and such things). Seems this is more complicated, so I'd look into the resolver first."
      },
      {
        "user": "SashiWork",
        "created_at": "2021-11-22T15:16:49Z",
        "body": "@marcbaechinger  thank you, the ```ResolvingDataSource.Factory```  worked for me. Cheers Mate"
      }
    ],
    "satisfaction_conditions": [
      "Differentiates between HLS content requests and subtitle requests when applying headers",
      "Provides a way to conditionally modify request properties based on request type",
      "Maintains existing media source handling functionality while customizing data sources",
      "Offers a centralized way to handle multiple data source requirements"
    ]
  },
  {
    "number": 9683,
    "title": "How to reset the back/forward increments on 2.16.0?",
    "created_at": "2021-11-11T11:08:53Z",
    "closed_at": "2021-11-12T12:29:40Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/9683",
    "body": "I need to implement **multi-speed** fast-forward/backward when the user multi-tap the forward/backward button. \r\n\r\n> Remove ControlDispatcher and DefaultControlDispatcher. Operations can be customized by using a ForwardingPlayer, or when configuring the player (for example by using ExoPlayer.Builder.setSeekBackIncrementMs).\r\n\r\nThe above is written at the release note for 2.16.0\r\nwe were using the `DefaultControlDispatcher(long fastForwardIncrementMs, long rewindIncrementMs)` or `playerView.setFastForwardIncrementMs(positionOffset)`/`playerView.setRewindIncrementMs(positionOffset)`.\r\n\r\nbut this class is already removed. we should using `ExoPlayer.Builder.setSeekBackIncrementMs` according to the release note. but I can't see how we can reset the increments after the player is built.\r\n\r\nCould you guys please help to figure out it? maybe I am missing sth.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/9683/comments",
    "author": "MiaJiaXa",
    "comments": [
      {
        "user": "christosts",
        "created_at": "2021-11-12T12:12:12Z",
        "body": "Let me confirm I understood the question, I also read your comments on #9492: In your app, when the user changes the player speed, you would re-construct the `DefaultControlDispatcher` with the updated `fastForwardIncrementMs` and  `rewindIncrementMs`, is this correct?\r\n\r\nIf my understanding is correct, you can achieve the same by using the `ForwardingPlayer`: wrap the `Player` in a `ForwardingPlayer` and override the `ForwardingPlayer``s `seekForward` and `seekBack` . Your implementation of these two methods can take the player's forward or backward increment values, multiply them by a factor (2x for double speed?) and then call `Player.seekTo` accordingly, for example\r\n\r\n```\r\nForwardingPlayer forwardingPlayer = new ForwardingPlayer(player) {\r\n      @Override\r\n      public void seekForward() {        \r\n        // Double the forward increment.\r\n        long seekForwardIncrement = player.getSeekForwardIncrement() * 2;\r\n        seekToOffset(seekForwardIncrement);\r\n      }\r\n\r\n      // Copied from DefaultContorlDispatcher implementation.\r\n      private void seekToOffset(long offsetMs) {\r\n        long positionMs = player.getCurrentPosition() + offsetMs;\r\n        long durationMs = player.getDuration();\r\n        if (durationMs != C.TIME_UNSET) {\r\n          positionMs = min(positionMs, durationMs);\r\n        }\r\n        positionMs = max(positionMs, 0);\r\n        player.seekTo(positionMs);\r\n      }\r\n    };\r\n```\r\n\r\nYou'll need of course to find a way to update the multiplication factors in your `ForwardingPlayer`, but that's a general programming task (e.g., you can subclass `ForwardingPlayer` and add additional setters). Please let me know if that works for your app, so we can close this issue."
      }
    ],
    "satisfaction_conditions": [
      "Dynamic adjustment of seek increments after player initialization",
      "Support for multiple speed multipliers in seek operations",
      "Compatibility with ExoPlayer 2.16.0 architecture",
      "State-aware seek calculation"
    ]
  },
  {
    "number": 9614,
    "title": "How can i play RTSP stream without audio codecs?",
    "created_at": "2021-10-27T12:09:20Z",
    "closed_at": "2021-11-10T14:10:23Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/9614",
    "body": "How can i play RTSP stream without audio codecs? I need only video?I can't start watch stream because camera using g.711 for audio.\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/9614/comments",
    "author": "LostInAbyss",
    "comments": [
      {
        "user": "claincly",
        "created_at": "2021-11-01T10:40:27Z",
        "body": "The player drops the formats that it cannot play and plays the playable formats only. In your case, G711 will be automatically dropped and the player should start playing video only.\r\n\r\nPlease comment if that's not the case."
      },
      {
        "user": "LostInAbyss",
        "created_at": "2021-11-10T13:54:38Z",
        "body": "Thanks for answer!"
      },
      {
        "user": "claincly",
        "created_at": "2021-11-10T14:10:23Z",
        "body": "I'm closing it for now, please feel free to re-open."
      }
    ],
    "satisfaction_conditions": [
      "Solution must allow video playback from RTSP stream even when unsupported audio codecs are present",
      "Approach should automatically handle/ignore unsupported audio formats without user intervention",
      "Method must maintain video stream functionality when audio is unavailable"
    ]
  },
  {
    "number": 9343,
    "title": "Play audio and video at the same time. (However, post-processing must be possible in the AudioProcessor)",
    "created_at": "2021-08-26T17:07:09Z",
    "closed_at": "2021-08-26T17:33:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/9343",
    "body": "Hi \r\n\r\nCurrently, we are using two exoplayer instances to play audio and video at the same time.\r\n(This audio was extracted from the video and then processed by our solution.\r\nSo, Audio is 5.1 channels and video is stereo)\r\nHowever, of course, if i repeat seek, play, and pause, the synchronization will gradually become out of sync.\r\nTherefore, I want to play audio and video files with one Exoplayer Instance. \r\n\r\nsum up\r\n- play audio and video at the same time\r\n  ( video is stereo, audio is 5.1 )\r\n- post-processing must be possible (AudioProcessor)\r\n- NO out of sync\r\n\r\nIs it possible?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/9343/comments",
    "author": "hotstone1993",
    "comments": [
      {
        "user": "icbaker",
        "created_at": "2021-08-26T17:12:49Z",
        "body": "Have you tried using MergingMediaSource?"
      },
      {
        "user": "hotstone1993",
        "created_at": "2021-08-26T17:33:36Z",
        "body": "Thank you for quick response.\r\nI use MergingMediaSource and it works perfectly.\r\n(It didn't work when I used MergingMediaSource in the past, but I guess I was used it wrong then.)\r\n"
      }
    ],
    "satisfaction_conditions": [
      "Synchronized playback of separate audio and video streams without gradual desynchronization",
      "Single player instance handling both audio and video",
      "Support for custom audio post-processing via AudioProcessor",
      "Compatibility with different audio channel configurations (5.1 vs stereo)"
    ]
  },
  {
    "number": 9302,
    "title": "How to get Proper AdprogressInfo using Exoplayer extension of IMA",
    "created_at": "2021-08-16T08:25:47Z",
    "closed_at": "2021-08-18T14:48:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/9302",
    "body": "How I will get ad player current position when ad is playing. Am able to get ad duration but am not getting ad current position means that how much second being played. Am working on custom ad controller using exoplayer ima extension,  so I required this information. Please help.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/9302/comments",
    "author": "adityaroutandroid",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2021-08-16T16:26:58Z",
        "body": "Just calling `getCurrentPosition` on the player should give you the playback position within the ad. If you're interested in the position within the content (i.e., the position from which playback of the content will resume after the ad has finished playing), then you can call `getContentPosition`."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to retrieve the current playback position within an ad during playback",
      "Clarification on the distinction between ad playback position and content playback position"
    ]
  },
  {
    "number": 9148,
    "title": "How to clear the view and the buffer?",
    "created_at": "2021-07-04T13:31:44Z",
    "closed_at": "2021-09-06T13:41:45Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/9148",
    "body": "My app is focusing on downloading videos and then playing them with Exoplayer. And obviously Downloading comes together with deleting the file.\r\n\r\nSo the downloading/playing parts work but then I want to be able to clear the player when the user is deleting the video he/she is playing. So I have:\r\n\r\n```\r\nvideoView.player?.stop()\r\nvideoView.player?.release()\r\n```\r\n\r\nHowever, the videoview still shows the image that it was last playing and I'm also guessing that the buffer is still there because when I delete and redownload the same video just after I cannot play it, it gives me this error:\r\n\r\n```\r\nE/ExoPlayerImplInternal: Playback error\r\n      com.google.android.exoplayer2.ExoPlaybackException: Source error\r\n        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:580)\r\n        at android.os.Handler.dispatchMessage(Handler.java:102)\r\n        at android.os.Looper.loop(Looper.java:246)\r\n        at android.os.HandlerThread.run(HandlerThread.java:67)\r\n     Caused by: com.google.android.exoplayer2.source.UnrecognizedInputFormatException: None of the available extractors (Mp4Extractor, AdtsExtractor) could read the stream.\r\n        at com.google.android.exoplayer2.source.BundledExtractorsAdapter.init(BundledExtractorsAdapter.java:92)\r\n        at com.google.android.exoplayer2.source.ProgressiveMediaPeriod$ExtractingLoadable.load(ProgressiveMediaPeriod.java:1027)\r\n        at com.google.android.exoplayer2.upstream.Loader$LoadTask.run(Loader.java:417)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\r\n        at java.lang.Thread.run(Thread.java:923)\r\n```\r\n\r\n(i tried to use all the possible exrtractors)\r\n\r\nHow can I clear view and buffer in this case and then still being able to play the new downloaded video?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/9148/comments",
    "author": "Clement-Jean",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2021-07-05T12:00:55Z",
        "body": "Can you give some more details what you do after calling `release`? Because I'd say that after releasing you have to recreate the player to restart playback with a new stream.\r\n\r\nI don't think it has something to do with the buffer because data in the buffer isn't read by the extractor. For my understanding the data in the buffer has been extracted by an extractor already and is then buffered before it is sent to the codec.\r\n\r\nCan you give some more details in how you release and then recreate the player in your code?"
      },
      {
        "user": "Clement-Jean",
        "created_at": "2021-07-05T23:21:39Z",
        "body": "I was not recreating the player but yesterday I saw that the `release` documentation says something like `don't use the player after calling this`.\n\nSo I recreated it and it works. However, I wonder if there is a less \"heavy\" way of doing this because I have a player with a Playlist (ConcatenatingMediaSource) and I need to reinitialize everything each time this event happens.\n\nWhat do you think ?"
      },
      {
        "user": "marcbaechinger",
        "created_at": "2021-07-07T09:51:59Z",
        "body": "I think it should be enough to just remove the `MediaSource` for the given stream to the download that have been removed. Then you can create a new `MediaSource` and add it to the `ConcatentaingMediaSource` again. When the user then seeks to that item in the playlist (or playback transitions to it automatically), the new source will be prepared.\r\n\r\n```\r\nconcatenatingMediaSource.removeMediaSource(index);\r\nconcatenatingMediaSource.addMediaSource(index, newMediaSource);\r\n```\r\n\r\nAs an aside, we support playlist with a top level API since a while (2.12). So you could move from the concatenating media source to `player.addMediaSource()`. \r\n\r\n```\r\nplayer.removeMediaSource(index);\r\nplayer.addMediaSource(index, newMediaSource);\r\n```"
      }
    ],
    "satisfaction_conditions": [
      "Solution must fully reset player state to prevent residual UI elements",
      "Must handle media source replacement without file conflicts",
      "Should maintain playlist integrity during media source updates",
      "Must explain proper player lifecycle management for resource reuse"
    ]
  },
  {
    "number": 9008,
    "title": "Issue with wrap_content in ExoPlayerView. ExoPlayerView height remain 0 at run-time if it set to wrap_content",
    "created_at": "2021-06-02T11:46:32Z",
    "closed_at": "2021-06-02T17:14:09Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/9008",
    "body": "[Condition]\r\n - video url only available\r\n\r\nThe title of this issue was on Stack Overflow but there was no answer.\r\n\r\nI was trying to set exoplayers to recyclerview with multiple media source.\r\n\r\nAutomatic video playback takes up space appropriately. Also, if the height value is given as an absolute value, thumbnail can be seen through the \"use_artwork\" option even if no replay is made('But it's not fit to the given layout).\r\n\r\nSo I brought a thumbnail separately through Glide, but it was too slow.\r\n\r\nIs there a way to automatically set the height value without playing the EXO player automatically or setting an absolute value?\r\n\r\n```\r\n<com.google.android.exoplayer2.ui.PlayerView\r\n                android:layout_width=\"match_parent\"\r\n                android:layout_height=\"wrap_content\"\r\n                app:use_artwork=\"true\"\r\n                app:resize_mode=\"fit\"\r\n                app:show_buffering=\"when_playing\"\r\n                />\r\n```",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/9008/comments",
    "author": "JiyongYang",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2021-06-02T14:12:57Z",
        "body": "If you are trying to set the height of the player view such that it matches the shape of the video but without actually loading the video I don't think there is a way to do that. You can `pause()` the player before preparing it if you want to load the media (and acquire resources for buffering and decoders) but not actually start playback. I'm not sure I follow the question though, so perhaps you could rephrase?"
      },
      {
        "user": "JiyongYang",
        "created_at": "2021-06-02T17:14:09Z",
        "body": "Thank you. It really helped. I think calling `pause()` is way more effective than using other lib."
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to determine video dimensions without full playback",
      "Avoid absolute height values while maintaining layout integrity",
      "Efficient media metadata loading",
      "Integration with ExoPlayer's native capabilities"
    ]
  },
  {
    "number": 8950,
    "title": "Exoplayer download service unable to download different HLS videos with different cookie value for authentication ",
    "created_at": "2021-05-17T12:02:05Z",
    "closed_at": "2021-06-09T13:31:44Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/8950",
    "body": "I have implemented a download service and it is working fine with normal HLS URL's....but when i try download a HLS URL which usses some cookie value for authentication...my download fails because download manager initializes only once in download service of exoplayer. Is there any way to restart the service every time or change the instance of download manager every time for each video or to stop the download service if one video has been completed and start service again for another video as that would solve my issue. ",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/8950/comments",
    "author": "anandsingh2903",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2021-05-27T14:57:31Z",
        "body": "When you subclass the `DownloadService` you need to implement the `getDownloadManager` method. So you can construct the `DownloadManager` yourself.  So your app can determine what `DataSource.Factory` is passed to the constructor of `DownloadManager`. If you pass a `ResolvingDataSource.Factory` you can change the request at the moment when the request is issued. This seems to be a flexible way to change your request.\r\n\r\n>  restart the service every time or change the instance of download manager every time\r\n\r\nWould the apporach above help for this? Instead of creating a new service or download manager you would be able to change the request you are doing with the `ResolvingDataSource` that modifies the `DataSpec` passed to the upstream data source by consulting the `ResolvingDataSource.Resolver` that you implement.\r\n\r\nPlease let me know if this helps.\r\n\r\nIf not, can you clarify a bit how the request to the server needs to be changed for successfully downloading with authentication?\r\n\r\n"
      },
      {
        "user": "anandsingh2903",
        "created_at": "2021-06-09T13:31:44Z",
        "body": "Alright will try your suggested implementation and will get back to you.\n\n---\n\nThis is working great....thanks"
      }
    ],
    "satisfaction_conditions": [
      "Supports dynamic cookie-based authentication per download request",
      "Enables request modification at download execution time",
      "Avoids service/dependency manager restarts for new downloads"
    ]
  },
  {
    "number": 8833,
    "title": "Equivalent callback for onTimelineChanged with reason TIMELINE_CHANGE_REASON_PREPARED, on versiosn 2.12+",
    "created_at": "2021-04-20T10:32:13Z",
    "closed_at": "2021-04-29T08:37:46Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/8833",
    "body": "Hi,\r\n\r\nOn my project, when playing a live stream, i need to make a seek to a specific time of the day, when starting playing a new stream. \r\nTo do that, on ExoPlayer 2.11.x i relied the callback for `onTimelineChanged `with reason `TIMELINE_CHANGE_REASON_PREPARED`. \r\nWhen that callback was called, i could get the media duration, and with the offset from the currentTime, calculate the position to pass to the `seekTo `method (`player.duration - System.currentTime - timeOfTheDayToSeekTo`).\r\n\r\nAfter version 2.12.0, `TIMELINE_CHANGE_REASON_PREPARED `was removed, and when the callback is called with reason `TIMELINE_CHANGE_REASON_PLAYLIST_CHANGED`, the player duration still undefined.\r\n\r\nI could rely on the callback being called with `TIMELINE_CHANGE_REASON_SOURCE_UPDATE`, but since that is called multiple times, i need to make extra checks to be sure i only make the seek on the first call after the media is changed, and the `timeOfTheDayToSeekTo `is set.\r\n\r\n\r\nMy question is:\r\nOn versions 2.12.+ is there any equivalent callback to `onTimelineChanged`, with reason `TIMELINE_CHANGE_REASON_PREPARED `on 2.11.x (Only called once, before the first the first frame is rendered, and after the media duration is known) ? \r\n\r\nIs there any way make a relative seek, like seek to 30000ms before the live edge/default position (something like seekTo(-30000) so i can set the seek position right after calling prepare without knowing the media duration?\r\n\r\nThanks in advance",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/8833/comments",
    "author": "jrocharodrigues",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2021-04-21T13:50:27Z",
        "body": "For 2.12. the equivalent is the first call with `TIMELINE_CHANGE_REASON_SOURCE_UPDATE` like you mention. For non-live sources this commonly is called only once. To answer your question, there is no alternative that is called only once for live streams I'm afraid.\r\n\r\nFor the second question you may want to use the extended live support we added with 2.13 where you can set the target offset from the live edge. So you could calculate the offset for the time to which you want to seek \r\n\r\n```\r\nMediaItem mediaItem = new MediaItem.Builder()\r\n        .setUri(uri)\r\n        .setLiveTargetOffsetMs(10 * 60_000)\r\n        .build();\r\n```\r\n\r\nYou probably want to look into issue #8218 that is about a similar topic for HLS, there is a proposal for adding a new property (not HLS specific) to the live configuration that lets you set the requested live unix start time. I think that would be most precisely what you want. Please drop a comment of interest in that issue if that would be something you'd like to have in a future release.\r\n\r\n```\r\nMediaItem mediaItem = new MediaItem.Builder()\r\n        .setUri(uri)\r\n        .setRequestedLiveUnixStartTimeMs(unixStartTimeMs)\r\n        .build();\r\n```"
      },
      {
        "user": "jrocharodrigues",
        "created_at": "2021-04-21T14:40:02Z",
        "body": "Hi, thanks for your answer.\r\n\r\nFor now i'll use you suggestion:\r\n`MediaItem mediaItem = new MediaItem.Builder()\r\n        .setUri(uri)\r\n        .setLiveTargetOffsetMs(10 * 60_000)\r\n        .build();`\r\n\r\nAs for the new property `setRequestedLiveUnixStartTimeMs` tracked on #8218  , i think it's a good idea, i'll drop a comment suggesting it to be implmented also for Dash.\r\n\r\nbest regards"
      }
    ],
    "satisfaction_conditions": [
      "Provides a way to trigger a seek operation exactly once when new media is prepared and duration is known",
      "Enables setting a seek position relative to live edge without requiring media duration",
      "Offers a solution compatible with ExoPlayer's evolving live stream features",
      "Avoids race conditions between media preparation and seek execution"
    ]
  },
  {
    "number": 8813,
    "title": "Generating Relation Between Offline License and Downloaded Content",
    "created_at": "2021-04-12T23:49:48Z",
    "closed_at": "2021-04-13T11:06:26Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/8813",
    "body": "Hi,\r\n\r\nI am trying to understand how to create the downloaded license's keySetId and downloaded track. Normally If I am on the latest release that's not an issue. Because we can create a relation between keySetId and download request during the request generation. But since I am on 2.11.4 (due to some other dependencies in the project) I can not find a way to create the relation. \r\n\r\nShould I save the keyset id with the related content id in local storage or some place like that ? Or is there a supportive utility that can manage the keysetId and content relation ? ",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/8813/comments",
    "author": "olgunkaya",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2021-04-13T11:06:26Z",
        "body": "`DownloadRequest.data` is available in 2.11.4, and can be used to hold arbitrary application defined data. So you can use that. Note that if you're serializing multiple pieces of data into that field, it's your responsibility to handle versioning and compatibility of the data across different versions of your application.\r\n\r\nAs you've noted, you can also persist the mapping with your own application code."
      },
      {
        "user": "olgunkaya",
        "created_at": "2021-04-13T14:21:12Z",
        "body": "Thanks @ojw28, I was using that field to hold metadata like title etc.. But, now I will add my piece of keySetId array there too. "
      }
    ],
    "satisfaction_conditions": [
      "A mechanism to associate offline license keySetId with downloaded content in version 2.11.4",
      "Utilization of existing framework capabilities for data persistence",
      "Support for custom data versioning and compatibility management",
      "Avoidance of external storage unless necessary"
    ]
  },
  {
    "number": 8775,
    "title": "add MediaSourceListener using DataSource.Factory ",
    "created_at": "2021-03-29T13:47:23Z",
    "closed_at": "2021-03-31T08:42:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/8775",
    "body": "Hi, since i've migrated to MediaSourceFactory pattern, how can i add a MediaSourceListener if i can't access MediaSource?\r\n\r\ni was able to add listener using the mediaSource.addEventListener(handler, listener) methon and then, prepare the player passing the mediasource: player.prepare(MediaSource mediaSource, boolean resetPosition, boolean resetState)\r\n\r\nBut now, building the player like this, i can't figure out how to listen the mediasource events\r\n```\r\nSimpleExoPlayer player = new SimpleExoPlayer.Builder(context)\r\n    .setMediaSourceFactory(mediaSourceFactory)\r\n    .build();\r\n```\r\n\r\nThank you",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/8775/comments",
    "author": "GrilloLuca",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2021-03-30T09:27:26Z",
        "body": "Can you instead use the `AnalyticsListener` that you can add globally to `SimpleExoPlayer`? The events from the `MediaSourceEventListener` are delegated to the `AnalyticsListener`.\r\n\r\n```\r\nSimpleExoPlayer player = new SimpleExoPlayer.Builder(context)\r\n    .setMediaSourceFactory(mediaSourceFactory)\r\n    .build();\r\n\r\nplayer.addAnalyticsListener(new MyAnalyticsListener() {\r\n    public void onLoadStarted(\r\n      EventTime eventTime, LoadEventInfo loadEventInfo, MediaLoadData mediaLoadData) {\r\n          // your implementation\r\n     }\r\n})'\r\n```"
      },
      {
        "user": "GrilloLuca",
        "created_at": "2021-03-31T08:42:39Z",
        "body": "> Can you instead use the `AnalyticsListener` that you can add globally to `SimpleExoPlayer`? The events from the `MediaSourceEventListener` are delegated to the `AnalyticsListener`.\r\n> \r\n> ```\r\n> SimpleExoPlayer player = new SimpleExoPlayer.Builder(context)\r\n>     .setMediaSourceFactory(mediaSourceFactory)\r\n>     .build();\r\n> \r\n> player.addAnalyticsListener(new MyAnalyticsListener() {\r\n>     public void onLoadStarted(\r\n>       EventTime eventTime, LoadEventInfo loadEventInfo, MediaLoadData mediaLoadData) {\r\n>           // your implementation\r\n>      }\r\n> })'\r\n> ```\r\n\r\nthank you, it worked !"
      }
    ],
    "satisfaction_conditions": [
      "Provides a way to listen to media source events when using MediaSourceFactory pattern",
      "Solution must integrate with the player's existing builder configuration",
      "Alternative event monitoring approach that doesn't require direct MediaSource access",
      "Maintains access to equivalent media loading event data"
    ]
  },
  {
    "number": 8769,
    "title": "How to enableDecoderFallback for ExoPlayerFactory.newSimpleInstance() ?",
    "created_at": "2021-03-29T06:47:22Z",
    "closed_at": "2021-04-01T16:29:45Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/8769",
    "body": "Let's say there is an app which uses two third-party media players each one internally implemented using ExoPlayer.\r\nLet's refer to the first player as the \"main\" and the second one as \"aux\".\r\n\r\nThe main player plays content and when the user pauses playback it the application starts the \"aux\" player.\r\nThe aux player plays some special \"pause\" content.\r\n\r\nWhen we were using this scenario with ExoPlayer 2.9.4 this worked with a caveat that the aux player was using the software video decoder while the main player was holding on to the hardware video decoder (it is just paused and not stopped or released). \r\n\r\nWhen we switched to ExoPlayer 2.12.3 this stopped working -- the \"aux\" player now fails with an exception that it cannot allocate the _hardware_ video decoder.\r\n\r\nIn ExoPlayer 2.12.3 there is a way to enable decoder fallback, when it is enabled the behavior is similar to what we used to have with 2.9.4.\r\nThe problem however is that \"aux\" player is using ExoPlayerFactory.newSimpleInstance() and there is no way to enable decoder fallback from this level of API (and decoder fallback is disabled by default).\r\n\r\nDo you have any recommendation on how to work around this issue (without asking the \"main\" player vendor to change the player behavior significantly during pause or asking the \"aux\" player vendor to use different API level for ExoPlayer)?\r\n\r\nAny plans to allow enableDecoderFallback with ExoPlayerFactory.newSimpleInstance() ?\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/8769/comments",
    "author": "sruditsky",
    "comments": [
      {
        "user": "lcf87",
        "created_at": "2021-03-29T13:28:05Z",
        "body": "I don't think supporting `enableDecoderFallback` in `newSimpleInstance` is on our agenda. If you don't have direct influence on the implementations on the two players you are using, I doubt there's a \"workaround\" to enabling that. \r\n\r\nOlly, could you confirm?"
      },
      {
        "user": "ojw28",
        "created_at": "2021-04-01T16:29:45Z",
        "body": "I'm not sure exactly what was in `2.12.3`, but certainly from `2.13.0` you can do:\r\n\r\n```\r\nDefaultRenderersFactory renderersFactory =\r\n    new DefaultRenderersFactory(this).setEnableDecoderFallback(true);\r\nSimpleExoPlayer player =\r\n    new SimpleExoPlayer.Builder(/* context= */ this, renderersFactory)\r\n        ...\r\n        .build();\r\n```"
      },
      {
        "user": "sruditsky",
        "created_at": "2021-04-02T14:31:42Z",
        "body": "Oh, yeah, this should work.\r\nThanks!"
      }
    ],
    "satisfaction_conditions": [
      "Enable decoder fallback for the auxiliary player without requiring third-party vendors to modify their player implementations",
      "Provide a method to configure decoder fallback through ExoPlayer's public API",
      "Maintain compatibility with ExoPlayer 2.12.x or newer versions",
      "Avoid requiring fundamental changes to player lifecycle management (pause/release behavior)"
    ]
  },
  {
    "number": 8607,
    "title": "[Question] Previous button is going to the beginning of the stream instead of the previous item in the playlist",
    "created_at": "2021-02-19T08:37:10Z",
    "closed_at": "2021-02-19T10:48:44Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/8607",
    "body": "I am using the exoplayer to play live streams in a playlist.\r\n\r\nThe previous button instead of going to the previous item in the playlist, it returns to the beginning of the stream of the current item.\r\n\r\nThis happens when I let it play the stream for few seconds then click on the previous button.\r\nIn that case, I need to click twice on the previous button to have it switch to the previous item in the playlist.\r\n\r\nWhat do I need to do in order to force the previous button to ignore the current item's live window and go to the previous item in the playlist?\r\n\r\nThanks",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/8607/comments",
    "author": "amahouachi",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2021-02-19T10:17:16Z",
        "body": "This behaviour is defined by the `DefaultControlDispatcher`.  You can create a subclass of `DefaultControlDispatcher`, override `dispatchPrevious` and set the control dispatcher with `PlayerView.setControlDispatcher` or `StyledPlayerView.setControlDispatcher` respectively."
      },
      {
        "user": "amahouachi",
        "created_at": "2021-02-19T10:48:44Z",
        "body": "Works great thanks !\r\n\r\n```kotlin\r\nplayerView.setControlDispatcher(object : DefaultControlDispatcher() {\r\n          override fun dispatchPrevious(player: Player): Boolean {\r\n            player.seekTo(0)\r\n            return super.dispatchPrevious(player)\r\n          }\r\n        })\r\n```"
      }
    ],
    "satisfaction_conditions": [
      "Solution must override default previous button behavior to prioritize playlist navigation over current stream position",
      "Must handle live stream window management appropriately during navigation",
      "Solution should maintain standard player controls functionality where not conflicting with playlist navigation"
    ]
  },
  {
    "number": 8509,
    "title": "MediaCodecVideoRenderer error, index=0, format=Format(1, null, null, video/avc, null, -1, null, [720, 1280, 29.969316], [-1, -1]), format_supported=YES",
    "created_at": "2021-01-26T08:51:15Z",
    "closed_at": "2021-01-26T10:59:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/8509",
    "body": "To be honest, it is the first I use the ExoPlayer. And, a problem happened!\r\nwhen the SimpleExoPlayer.stop() invoked, I want the screen(the SurfaceView) is pur black color, So, I did this.\r\n\r\n      stopBtn.setOnClickListener(new View.OnClickListener() {\r\n            @Override\r\n            public void onClick(View v) {\r\n                simpleExoPlayer.stop(true);\r\n                simpleExoPlayer.clearVideoSurfaceHolder(surfaceView.getHolder());\r\n\r\n                SurfaceHolder holder = surfaceView.getHolder();\r\n                Canvas canvas = holder.lockCanvas();\r\n                canvas.drawColor(Color.BLACK);\r\n                holder.unlockCanvasAndPost(canvas);\r\n\r\n                simpleExoPlayer.setVideoSurfaceHolder(surfaceView.getHolder());\r\n            }\r\n        });\r\n        nextBtn.setOnClickListener(new View.OnClickListener() {\r\n            @Override\r\n            public void onClick(View v) {\r\n                MediaItem mediaItem = MediaItem.fromUri(getString(R.string.media_url_mp4));\r\n                simpleExoPlayer.setMediaItem(mediaItem);\r\n                simpleExoPlayer.prepare();\r\n            }\r\n        });` \r\nI click stop button, it running well.\r\nwhen I click the button what name is nextVideo, Yes\uff0cit is Error.\r\nGuys,please tell me WTF?\r\n\r\n`2021-01-26 16:22:37.780 E/SurfaceUtils: Failed to connect to surface 0x71e8f79010, err -22\r\n2021-01-26 16:22:37.780 E/MediaCodec: nativeWindowConnect returned an error: Invalid argument (-22)\r\n2021-01-26 16:22:37.780 E/MediaCodec: configure failed with err 0xffffffea, resetting...\r\n2021-01-26 16:22:37.788 I/OMXClient: IOmx service obtained\r\n2021-01-26 16:22:37.816 W/MediaCodecRenderer: Failed to initialize decoder: OMX.qcom.video.decoder.avc\r\n      java.lang.IllegalArgumentException\r\n        at android.media.MediaCodec.native_configure(Native Method)\r\n        at android.media.MediaCodec.configure(MediaCodec.java:2023)\r\n        at android.media.MediaCodec.configure(MediaCodec.java:1951)\r\n        at com.google.android.exoplayer2.mediacodec.SynchronousMediaCodecAdapter.configure(SynchronousMediaCodecAdapter.java:43)\r\n        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.configureCodec(MediaCodecVideoRenderer.java:580)\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.initCodec(MediaCodecRenderer.java:1143)\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.maybeInitCodecWithFallback(MediaCodecRenderer.java:1040)\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.maybeInitCodecOrBypass(MediaCodecRenderer.java:604)\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onInputFormatChanged(MediaCodecRenderer.java:1470)\r\n        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onInputFormatChanged(MediaCodecVideoRenderer.java:640)\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.readToFlagsOnlyBuffer(MediaCodecRenderer.java:994)\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:844)\r\n        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:892)\r\n        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:467)\r\n        at android.os.Handler.dispatchMessage(Handler.java:103)\r\n        at android.os.Looper.loop(Looper.java:224)\r\n        at android.os.HandlerThread.run(HandlerThread.java:67)\r\n2021-01-26 16:22:37.820 E/ExoPlayerImplInternal: Playback error\r\n      com.google.android.exoplayer2.ExoPlaybackException: MediaCodecVideoRenderer error, index=0, format=Format(1, null, null, video/avc, null, -1, null, [720, 1280, 29.969316], [-1, -1]), format_supported=YES\r\n        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:542)\r\n        at android.os.Handler.dispatchMessage(Handler.java:103)\r\n        at android.os.Looper.loop(Looper.java:224)\r\n        at android.os.HandlerThread.run(HandlerThread.java:67)\r\n     Caused by: com.google.android.exoplayer2.mediacodec.MediaCodecRenderer$DecoderInitializationException: Decoder init failed: OMX.qcom.video.decoder.avc, Format(1, null, null, video/avc, null, -1, null, [720, 1280, 29.969316], [-1, -1])\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.maybeInitCodecWithFallback(MediaCodecRenderer.java:1047)\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.maybeInitCodecOrBypass(MediaCodecRenderer.java:604)\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onInputFormatChanged(MediaCodecRenderer.java:1470)\r\n        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onInputFormatChanged(MediaCodecVideoRenderer.java:640)\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.readToFlagsOnlyBuffer(MediaCodecRenderer.java:994)\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:844)\r\n        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:892)\r\n        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:467)\r\n        at android.os.Handler.dispatchMessage(Handler.java:103)\u00a0\r\n        at android.os.Looper.loop(Looper.java:224)\u00a0\r\n        at android.os.HandlerThread.run(HandlerThread.java:67)\u00a0\r\n     Caused by: java.lang.IllegalArgumentException\r\n        at android.media.MediaCodec.native_configure(Native Method)\r\n        at android.media.MediaCodec.configure(MediaCodec.java:2023)\r\n        at android.media.MediaCodec.configure(MediaCodec.java:1951)\r\n        at com.google.android.exoplayer2.mediacodec.SynchronousMediaCodecAdapter.configure(SynchronousMediaCodecAdapter.java:43)\r\n        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.configureCodec(MediaCodecVideoRenderer.java:580)\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.initCodec(MediaCodecRenderer.java:1143)\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.maybeInitCodecWithFallback(MediaCodecRenderer.java:1040)\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.maybeInitCodecOrBypass(MediaCodecRenderer.java:604)\u00a0\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.onInputFormatChanged(MediaCodecRenderer.java:1470)\u00a0\r\n        at com.google.android.exoplayer2.video.MediaCodecVideoRenderer.onInputFormatChanged(MediaCodecVideoRenderer.java:640)\u00a0\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.readToFlagsOnlyBuffer(MediaCodecRenderer.java:994)\u00a0\r\n        at com.google.android.exoplayer2.mediacodec.MediaCodecRenderer.render(MediaCodecRenderer.java:844)\u00a0\r\n        at com.google.android.exoplayer2.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:892)\u00a0\r\n        at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:467)\u00a0\r\n        at android.os.Handler.dispatchMessage(Handler.java:103)\u00a0\r\n        at android.os.Looper.loop(Looper.java:224)\u00a0\r\n        at android.os.HandlerThread.run(HandlerThread.java:67)\u00a0`\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/8509/comments",
    "author": "Kimiar",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2021-01-26T10:59:11Z",
        "body": "I think there's an Android platform limitation that once you've used a `Surface` for drawing from the CPU like this it can't be used as the output surface for a video decoder. See also #6454.\r\n\r\nYour best bet is have a separate view with the background color. This can go on top of the surface view to obscure it until you want to show the video output (when the player triggers the `onRenderedFirstFrame` event). If you don't want to write your own code to do this you could just use the ExoPlayer UI module `StyledPlayerView`, which takes care of this for you."
      },
      {
        "user": "Kimiar",
        "created_at": "2021-01-27T01:46:46Z",
        "body": "Buddy, thanks. You are really great!"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of Android platform limitations when reusing a Surface after CPU drawing operations",
      "Solution for maintaining black screen after stop() without breaking Surface reuse",
      "Guidance on proper Surface lifecycle management with ExoPlayer",
      "Alternative approach for obscuring video output without Surface manipulation"
    ]
  },
  {
    "number": 8258,
    "title": "Why does ExoPlayer call updateSelectedTrack() many times when I modify determineIdealSelectedIndex()?",
    "created_at": "2020-11-20T10:44:55Z",
    "closed_at": "2020-11-22T10:53:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/8258",
    "body": "Hi,\r\nWhen I run your **demo** configuration and watch `Google Play H264 (MP4)`, the `AdaptiveTrackSelection.updateSelectedTrack()` is called 15 times, and the selected qualities are recorded as follows:\r\n_Note_: \r\n```java\r\nThe QualityIdx is determined as `length - newSelectedIndex`\r\npublic static final int DEFAULT_MIN_BUFFER_MS = 20_000;\r\npublic static final int DEFAULT_MAX_BUFFER_MS = 20_000; \r\n```\r\n```\r\n2020-11-20 11:17:23.105 5588-5588/com.google.android.exoplayer2.demo I/MINH: Id\tTime\tEstThroughput\tQualityIdx\tBitrate\tBuffer\r\n2020-11-20 11:17:23.105 5588-5588/com.google.android.exoplayer2.demo I/MINH: 1\t989\t4.139778\t6\t1.834968\t0.0\t\r\n2020-11-20 11:17:23.105 5588-5588/com.google.android.exoplayer2.demo I/MINH: 2\t990\t4.139778\t6\t1.834968\t0.0\t\r\n2020-11-20 11:17:23.106 5588-5588/com.google.android.exoplayer2.demo I/MINH: 3\t990\t23.515743\t6\t1.834968\t5.213468\t\r\n2020-11-20 11:17:23.106 5588-5588/com.google.android.exoplayer2.demo I/MINH: 4\t990\t32.762936\t6\t1.834968\t9.359454\t\r\n2020-11-20 11:17:23.106 5588-5588/com.google.android.exoplayer2.demo I/MINH: 5\t990\t32.762936\t6\t1.834968\t13.740843\t\r\n2020-11-20 11:17:23.107 5588-5588/com.google.android.exoplayer2.demo I/MINH: 6\t991\t28.8144\t\t6\t1.834968\t17.874817\t\r\n2020-11-20 11:17:23.107 5588-5588/com.google.android.exoplayer2.demo I/MINH: 7\t993\t28.8144\t\t6\t1.834968\t19.99352\t\r\n2020-11-20 11:17:23.108 5588-5588/com.google.android.exoplayer2.demo I/MINH: 8\t998\t28.8144\t\t6\t1.834968\t19.996836\t\r\n2020-11-20 11:17:23.108 5588-5588/com.google.android.exoplayer2.demo I/MINH: 9\t1003\t27.448479\t6\t1.834968\t19.99776\t\r\n2020-11-20 11:17:23.109 5588-5588/com.google.android.exoplayer2.demo I/MINH: 10\t1008\t31.993544\t6\t1.834968\t19.997576\t\r\n2020-11-20 11:17:23.109 5588-5588/com.google.android.exoplayer2.demo I/MINH: 11\t1012\t31.993544\t6\t1.834968\t19.995329\t\r\n2020-11-20 11:17:23.109 5588-5588/com.google.android.exoplayer2.demo I/MINH: 12\t1017\t31.585793\t6\t1.834968\t19.999952\t\r\n2020-11-20 11:17:23.110 5588-5588/com.google.android.exoplayer2.demo I/MINH: 13\t1023\t51.726105\t6\t1.834968\t19.996777\t\r\n2020-11-20 11:17:23.110 5588-5588/com.google.android.exoplayer2.demo I/MINH: 14\t1027\t51.726105\t6\t1.834968\t19.990929\t\r\n2020-11-20 11:17:23.110 5588-5588/com.google.android.exoplayer2.demo I/MINH: 15\t1029\t51.726105\t6\t1.834968\t19.996412\t\r\n```\r\n\r\nHowever, when I modify the function `determineIdealSelectedIndex()`\r\n\r\n```java\r\n...\r\nprivate static int minh_count = 0;\r\n...\r\nprivate int determineIdealSelectedIndex(long nowMs) {\r\n    long effectiveBitrate = bandwidthProvider.getAllocatedBandwidth();\r\n    int lowestBitrateAllowedIndex = 0;\r\n    for (int i = 0; i < length; i++) {\r\n      if (nowMs == Long.MIN_VALUE || !isBlacklisted(i, nowMs)) {\r\n        Format format = getFormat(i);\r\n        if (canSelectFormat(format, format.bitrate, playbackSpeed, effectiveBitrate)) { //throughput-based\r\n          // Modify for test - START\r\n          //  return  i;\r\n          minh_count ++;\r\n          return minh_count%length;\r\n          // Modify for test - END\r\n        } else {\r\n          lowestBitrateAllowedIndex = i;\r\n        }\r\n      }\r\n    }\r\n\r\n    return lowestBitrateAllowedIndex;\r\n  }\r\n```\r\nThe `AdaptiveTrackSelection.updateSelectedTrack()` is called 20 times as follows:\r\n```\r\n2020-11-20 11:20:25.514 5744-5744/com.google.android.exoplayer2.demo I/MINH: Id\tTime\tEstThroughput\tQualityIdx\tBitrate\tBuffer\r\n2020-11-20 11:20:25.514 5744-5744/com.google.android.exoplayer2.demo I/MINH: 1\t1172\t4.139778\t5\t1.006977\t0.0\t\r\n2020-11-20 11:20:25.514 5744-5744/com.google.android.exoplayer2.demo I/MINH: 2\t1172\t4.139778\t4\t0.499978\t0.0\t\r\n2020-11-20 11:20:25.514 5744-5744/com.google.android.exoplayer2.demo I/MINH: 3\t1172\t4.139778\t3\t0.257246\t0.0\t\r\n2020-11-20 11:20:25.514 5744-5744/com.google.android.exoplayer2.demo I/MINH: 4\t1172\t4.139778\t2\t0.147097\t0.0\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 5\t1172\t4.139778\t1\t0.075814\t0.0\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 6\t1172\t4.139778\t1\t0.075814\t0.0\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 7\t1172\t4.139778\t1\t0.075814\t5.214\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 8\t1172\t4.139778\t1\t0.075814\t9.522873\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 9\t1172\t4.139778\t3\t0.257246\t14.114865\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 10\t1172\t15.159876\t2\t0.147097\t18.749332\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 11\t1175\t15.932693\t1\t0.075814\t19.99592\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 12\t1180\t15.932693\t6\t1.834968\t19.999607\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 13\t1180\t15.932693\t5\t1.006977\t19.87662\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 14\t1185\t16.497812\t4\t0.499978\t19.998589\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 15\t1190\t15.932693\t3\t0.257246\t19.999405\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 16\t1195\t19.41076\t2\t0.147097\t19.99306\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 17\t1200\t19.41076\t1\t0.075814\t19.991512\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 18\t1205\t18.738419\t6\t1.834968\t19.993235\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 19\t1209\t19.41076\t5\t1.006977\t19.998152\t\r\n2020-11-20 11:20:25.515 5744-5744/com.google.android.exoplayer2.demo I/MINH: 20\t1211\t18.738419\t4\t0.499978\t19.99512\t\r\n```\r\nEspecially, the segment `Id`s: 2, 3, 4, 5 and 12 have the `chunk.getDurationUs() = 0.0` in the function `DefaultDashChunkSource.onChunkLoadCompleted()`, and theses segments are not played on the screen.\r\n\r\nWhy does this happen?\r\nHow can I enforce the ExoPlayer to send requests and plays exactly what `updateSelectedTrack()` determines?\r\n\r\nThank you.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/8258/comments",
    "author": "minhkstn",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2020-11-20T13:25:33Z",
        "body": "ExoPlayer calls `updateSelectedTrack` whenever we need to load something new. Depending on your `selectedIndex`, ExoPlayer may need to load non-media data first though. \r\n\r\nIn the example stream we need to load the initialization data for the selected format the first time you try to select it. After we loaded the initialization data, we call `updateSelectedTrack` again to see if we still want to continue with this format. So the chunks with `chunk.getDurationUs() = 0.0` are most likely the initialization chunk loads you see. The second example contains more of them because you force the player to load the initialization data for all formats before even starting playback."
      },
      {
        "user": "minhkstn",
        "created_at": "2020-11-20T14:01:15Z",
        "body": " @tonihei Thank you for your response. So I guess to avoid additional calls, I need to keep the same format in the `updateSelectedTrack` by choosing the same quality index before starting playback. Is it correct?"
      },
      {
        "user": "tonihei",
        "created_at": "2020-11-20T15:55:25Z",
        "body": "Yes, but there is generally no need to avoid them because the initialization data is really small compared to the actual media data."
      },
      {
        "user": "minhkstn",
        "created_at": "2020-11-22T10:53:09Z",
        "body": "Thank you so much."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why ExoPlayer triggers multiple updateSelectedTrack() calls when track selection logic is modified",
      "Clarification on how track selection interacts with chunk loading behavior",
      "Guidance on ensuring track selection consistency during playback initialization",
      "Explanation of ExoPlayer's adaptive loading mechanism for different formats"
    ]
  },
  {
    "number": 8185,
    "title": "Why the DefaultRenderersFactory's enableDecoderFallback is false by default?",
    "created_at": "2020-11-09T07:21:48Z",
    "closed_at": "2020-11-10T06:35:32Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/8185",
    "body": "### [REQUIRED] Question\r\nHello. Is there a reason why the DefaultRenderersFactory's setEnableDecoderFallback is set to false by default?\r\n\r\nI have AB tested and analyzed the Boolean values at 50/50 and it doesn't seem to have any effect on JoinTime or anything else. Does it have a negative impact on performance?\r\n\r\nApart from that, interestingly enough, AndroidTV improved 99.9% of sessions on AndroidTV.\r\n\r\nI was curious, so I felt free to ask about it. Best regards.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/8185/comments",
    "author": "Gumio",
    "comments": [
      {
        "user": "kim-vde",
        "created_at": "2020-11-09T15:59:25Z",
        "body": "Using a lower-priority decoder if the best suited decoder initialization fails is not an expected default behaviour. Playback will continue without throwing any error, while there was something wrong in the decoder initialization.\r\n\r\nAs for performance, it depends on what you do if the decoder fails (and on what you mean exactly by performance):\r\n- If you retry, then it is probably best not to fallback on a lower-priority decoder because your retry might succeed.\r\n- If you don't retry, then it is probably best to fallback on a lower-priority decoder because it will allow you to continue playback.\r\n\r\nFrom a time and space complexity point of view, performance shouldn't be affected by this parameter. Enabling it will just try the next decoder instead of throwing."
      },
      {
        "user": "Gumio",
        "created_at": "2020-11-10T06:35:32Z",
        "body": "Thank u! I understand."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of the design rationale for the default value",
      "Clarification of potential negative impacts when enabling decoder fallback",
      "Identification of scenarios where enabling decoder fallback would be beneficial"
    ]
  },
  {
    "number": 8137,
    "title": "How to get the entire content Duration of a MediaItem, not just the clip length? ",
    "created_at": "2020-10-29T17:04:48Z",
    "closed_at": "2020-11-03T13:36:47Z",
    "labels": [
      "duplicate",
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/8137",
    "body": "### [REQUIRED] Question\r\nI have a list of `MediaItem`s with different start positions. \r\n```java\r\nMediaItem mediaItem = new MediaItem.Builder()\r\n    .setUri(trackUri)\r\n    .setClipStartPositionMs(startPos)\r\n    .setClipEndPositionMs(C.TIME_END_OF_SOURCE)\r\n    .build();\r\n```\r\nWhen a particular MediaItem is being played, the Player is just returning the duration of the clip, not the total length of the track. \r\nIs there a way where I can get the total length of the track, not just the clip length? ",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/8137/comments",
    "author": "pavan245",
    "comments": [
      {
        "user": "pavan245",
        "created_at": "2020-11-02T18:28:01Z",
        "body": "Hi\r\n\r\nI have to do quite a bit of work if the Player can't give the entire duration of the MediaItem. And I'm not sure if this is a bug or the intended behavior. \r\nCan I get an update here? Do I need to provide some more details for this question? \r\n\r\nThanks"
      },
      {
        "user": "ojw28",
        "created_at": "2020-11-02T19:49:51Z",
        "body": "If you're only changing the start clip position then I think you can retrieve the entire content duration like:\r\n```\r\n@Override\r\npublic void onTimelineChanged(Timeline timeline, @TimelineChangeReason int reason) {\r\n  if (!timeline.isEmpty()) {\r\n    long durationMs = timeline.getPeriod(0, new Period()).getDurationMs();\r\n  }\r\n}\r\n```\r\nNote that you can also retrieve the timeline from `Player.getCurrentTimeline`. @pavan245 - Does that work for you?\r\n\r\nThe same trick does not work if you set an end clip position, however. This may not be relevant to your use case, but is something we should think about. @tonihei - Do you understand why that's not the case? If both start and end are clipped, I think I'd expect the period and window to look like:\r\n```\r\n<----------- original content ----------->\r\n<-------------- period ------------------>\r\n            <----- window ----->\r\n```\r\nwhere-as it seems they look like:\r\n```\r\n<----------- original content ----------->\r\n<-------------- period -------->\r\n            <----- window ----->\r\n```\r\nI tried changing `ClippingTimeline.getPeriod` to do what I expected, but then playback doesn't transition to the ended state once the clip end point is reached. Which also seems unexpected to me."
      },
      {
        "user": "tonihei",
        "created_at": "2020-11-03T13:03:21Z",
        "body": "> If both start and end are clipped, I think I'd expect the period and window to look like ... where-as it seems they look like ...\r\n\r\nThis is because the clipping is not properly integrated in every `MediaPeriod` and thus the player (without knowing `ClippingMediaSource`) has no concept of a period ending early. That's why we need to shorten the period so that the player knows when it ends and that it can transition to the next item. \r\n\r\nThe pending work for #3163 will change this by making clipping a first-class citizen in `MediaPeriod` and `Timeline.Period`. This will solve this issue, but also #3163 that is currently blocked on correctly discarding buffer when the end clip position changes.  "
      },
      {
        "user": "ojw28",
        "created_at": "2020-11-03T13:36:47Z",
        "body": "@pavan245 - For only changing the start clip position, my solution posted above will work. For the end position, marking this as a duplicate of #3163 as per Toni's response above."
      },
      {
        "user": "pavan245",
        "created_at": "2020-11-09T15:01:13Z",
        "body": "@ojw28 Thanks for your solution. For the time being, I'm only using the start clip position so your solution works. \r\n\r\nIs there any way I can get the current playing position in the window from the Player/Timeline APIs? \r\nI tried `Period.getPositionInWindowMs` and it's returning a negative of `startPosition`. \r\nI can add the `startPosition` and `Player.getCurrentPosition`, but prefer to rely on the Player. "
      },
      {
        "user": "tonihei",
        "created_at": "2020-11-09T15:09:04Z",
        "body": "`Player.getCurrentPosition` returns the position in the window actually. If you want to convert to a period position you can use `Timeline.getPeriodPosition(window, period, windowIndex, windowPositionUs)` that gives you both the `periodUid` and the period position. The uid is only relevant for cases where you have multiple periods per window. As `ClippingMediaSource` doesn't support multi-period windows at all, you can probably ignore this part of the return value."
      },
      {
        "user": "pavan245",
        "created_at": "2020-11-09T15:36:08Z",
        "body": "Hi @tonihei \r\nIf the MediaItem's `setClipStartPositionMs` is 300000ms, I need the `Player.getCurrentPosition` to start from 300000. Is this the expected behaviour? \r\n\r\nFrom the below source code, I can see `Player.getCurrentPosition` internally calling `periodPositionUsToWindowPositionMs` method. But as mentioned in the above comment, `Period.getPositionInWindowMs()` is returning `-300000`\r\n\r\n```java\r\n\r\n@Override\r\npublic long getCurrentPosition() {\r\n    if (playbackInfo.timeline.isEmpty()) {\r\n      return maskingWindowPositionMs;\r\n    } else if (playbackInfo.periodId.isAd()) {\r\n      return C.usToMs(playbackInfo.positionUs);\r\n    } else {\r\n      return periodPositionUsToWindowPositionMs(playbackInfo.periodId, playbackInfo.positionUs);\r\n    }\r\n }\r\n\r\nprivate long periodPositionUsToWindowPositionMs(MediaPeriodId periodId, long positionUs) {\r\n    long positionMs = C.usToMs(positionUs);\r\n    playbackInfo.timeline.getPeriodByUid(periodId.periodUid, period);\r\n    positionMs += period.getPositionInWindowMs();\r\n    return positionMs;\r\n}\r\n\r\n```"
      },
      {
        "user": "tonihei",
        "created_at": "2020-11-09T15:39:04Z",
        "body": "If you want the position to start at `300000`, then you want to know the period position if I understand you correctly. Have you tried using `Timeline.getPeriodPosition` as proposed above?"
      },
      {
        "user": "pavan245",
        "created_at": "2020-11-09T16:22:09Z",
        "body": "Sorry, you're right. I need the period position.\r\nThis is how I got it working:\r\n\r\n```java\r\n    public long getCurrentPosition() {\r\n\r\n        if (player == null || player.getPlaybackState() == Player.STATE_IDLE)\r\n            return 0;\r\n\r\n        Timeline timeline = player.getCurrentTimeline();\r\n        if (timeline == null || timeline.isEmpty())\r\n            return 0;\r\n\r\n        Timeline.Period period = timeline.getPeriod(0, new Timeline.Period());\r\n\r\n        Timeline.Window window = timeline.getWindow(period.windowIndex, new Timeline.Window());\r\n\r\n        long windowPosition = player.getCurrentPosition();\r\n\r\n        Pair<Object, Long> periodPosition = timeline.getPeriodPosition(window, period, period.windowIndex, C.msToUs(windowPosition));\r\n\r\n        return periodPosition != null ? C.usToMs(periodPosition.second) : 0;\r\n    }\r\n```"
      }
    ],
    "satisfaction_conditions": [
      "Ability to retrieve original media content duration when using clipped MediaItems",
      "Clear distinction between clip-relative and original-content-relative positions",
      "Solution must work with official ExoPlayer APIs without internal hacks"
    ]
  },
  {
    "number": 8118,
    "title": "can't get duration of audio file which  extension is .aac",
    "created_at": "2020-10-27T03:10:20Z",
    "closed_at": "2020-10-29T08:56:36Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/8118",
    "body": "[No information provided]",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/8118/comments",
    "author": "l20160606sy",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2020-10-28T17:20:47Z",
        "body": "This is a known limitation. You should consider using a more appropriate container format for your audio, such as MP4, which will not have this problem."
      },
      {
        "user": "l20160606sy",
        "created_at": "2020-10-29T02:02:26Z",
        "body": "But I found that sometimes the audio of AAC files can get the total duration, and sometimes it can't"
      },
      {
        "user": "ojw28",
        "created_at": "2020-10-29T08:46:55Z",
        "body": "I think the duration might become known once the player has buffered to the end of the stream, so you may find that duration is determined quickly for short AAC files (which are fully buffered up-front), and toward the end of the playback for longer AAC files (where this is not possible).\r\n\r\nThe problem is that the player doesn't have an efficient way to determine the duration of the content from only the start of the file. Processing the entire file is clearly a very inefficient way of determining duration, and so we opt not to do this. If this is a requirement you should use a modern container format such as MP4, which specifies its duration directly at the start of the file in a way that the player can easily read."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why AAC file duration detection is inconsistent",
      "Comparison of container format limitations",
      "Guidance on when duration becomes available in AAC playback"
    ]
  },
  {
    "number": 8116,
    "title": "Widevine license renewal using azure media services",
    "created_at": "2020-10-26T14:11:06Z",
    "closed_at": "2020-11-09T11:42:52Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/8116",
    "body": "hello, \r\n\r\nI'm trying to renew my widevine offline license for playback, I'm not able to do so with azure media services because it provides a dynamic license server URL that is included in the manifest.\r\n\r\na bug report was opened for a variant of this issue #3393  and was fixed. ( when the player doesn't parse incoming data in the manifest and now that it is fixed , the parser reads directly from the manifest and parses the azure license URL without a problem.)   \r\n\r\nmy issue comes at hand when I'm trying to renew my license using a dynamic license URL because I can't include it in my widevine license template in the field renewal_server_url since it's not static, and azure media services does not provide a commun url for their license server.\r\n\r\nwhat can i do to retreive the license url in order to ask for a renewal?\r\n\r\nVersion of ExoPlayer being used\r\n2.12.0\r\n\r\nHUAWEI P30 LITE\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/8116/comments",
    "author": "AnassHmida",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2020-10-27T19:06:17Z",
        "body": "If the URL is included in the manifest then I think you'll need to request and parse the manifest, and then retrieve the URL from it. You can load and parse the manifest with `DashUtil.loadManifest`. Once you have it, you can dig around inside the `DashManifest` to retrieve the license URL. I didn't test this, but it's probably retrievable via:\r\n```\r\ndashManifest.getPeriod(0).adaptationSets.get(0).representations.get(0).format.drmInitData.get(0).licenseServerUrl\r\n```\r\nIf not, try attaching a debugger and exploring in the `DashManifest` object. "
      },
      {
        "user": "AnassHmida",
        "created_at": "2020-10-27T19:22:34Z",
        "body": "Good evening @ojw28,\r\nThank you for your detailed response, i will get back to you after i test this. \r\nI do have one last question tho,\r\nafter renewing my license for offline playback , do i need to replace the generated keysetid response from offlinelicencehelper.renewlicense with the one that is linked to the download so i can playback my downloaded content with the new license or is there an other step to it?\r\n\r\n"
      },
      {
        "user": "ojw28",
        "created_at": "2020-11-02T11:20:40Z",
        "body": "If you're using `OfflineLicenseHelper.renewLicense`, was your initial question about getting a `defaultLicenseUrl` to build a `HttpMediaDrmCallback`? I'm not sure, but it might be possible for you to set it to any dummy value for your media, if it's always specifying a URL internally. That would avoid you needing to look inside the DASH manifest. In future releases we will allow this parameter to be `null`.\r\n\r\n> after renewing my license for offline playback , do i need to replace the generated keysetid response from offlinelicencehelper.renewlicense with the one that is linked to the download so i can playback my downloaded content with the new license or is there an other step to it?\r\n\r\nI'm not entirely sure what you're asking here. Is the `keySetId` returned by `renewLicense` _different_ to the one when the license was originally obtained, or is it the same? If the `keySetId` has changed, you'll need to use the one returned by `renewLicense` for successful playback after renewal. We should probably look at an easy way to update the download database in this case."
      },
      {
        "user": "AnassHmida",
        "created_at": "2020-11-02T14:06:31Z",
        "body": "@ojw28 yes that's exactly what I meant, and by setting that value to `null` will that mean it will use a license URL if it has one and `null` if it doesn't?\r\n\r\nas for the download part, that is what I meant precisely, I use the `newkeySetId `generated from the `OfflineLicenseHelper.renewLicense` function using my old `keySetId` like this : \r\n\r\n```\r\n        keySetId = mediaItem.playbackProperties.drmConfiguration.getKeySetId();\r\n        android.util.Log.d(TAG, \"doInBackground: Old key : \"+ Arrays.toString(keySetId));\r\n        newkeySetId = offlineLicenseHelper.renewLicense(keySetId);\r\n        android.util.Log.d(TAG, \"doInBackground: new key : \"+Arrays.toString(newkeySetId));\r\n```\r\n\r\nThen afterwards , i'm creating a new downloadRequest  using the same data from the old DownloadRequest and only replacing my old `keySetId ` with the new `newkeySetId` and adding that request to a new download and replacing that download with the one in the `downloads` list, here's the function that i'm using to do so : \r\n\r\n`updateDownloadwithKeySetId(mediaItem, newkeySetId);`\r\n\r\nHere's how it works.\r\n\r\n```\r\n private void  updateDownloadwithKeySetId(MediaItem mediaItem,byte[] KeysetId) {\r\n\r\n//Adding a new download request using previous data from my stored download Request.\r\n//Here i'm using my uri for the ID.\r\n\r\n  DownloadRequest downloadRequest = downloadHelper.getDownloadRequest(Util.getUtf8Bytes(checkNotNull(mediaItem.mediaMetadata.title))).copyWithKeySetId(keySetId);\r\n\r\n    DownloadRequest newDownloadRequest =\r\n            new DownloadRequest.Builder(downloadRequest.id, downloadRequest.uri)\r\n                    .setStreamKeys(downloadRequest.streamKeys)\r\n                    .setCustomCacheKey(downloadRequest.customCacheKey)\r\n//Changing the keysetId here\r\n                    .setKeySetId(keySetId)\r\n                    .setData(downloadRequest.data)\r\n                    .setMimeType(downloadRequest.mimeType)\r\n                    .build();\r\n\r\n\r\n//creating a new download based on the stored download (Updating Download Request).\r\n\r\n    Download download = downloads.get(checkNotNull(mediaItem.playbackProperties).uri);\r\n\r\n    Download download1 = new Download(\r\n            newDownloadRequest,\r\n            download.state,\r\n            download.startTimeMs,\r\n            download.updateTimeMs,\r\n            download.contentLength,\r\n            download.stopReason,\r\n            download.failureReason);\r\n\r\n//Replacing the old download with the new modified one.\r\n\r\n    downloads.put(mediaItem.playbackProperties.uri,download1);\r\n    Download justDownloaded = downloads.get(checkNotNull(mediaItem.playbackProperties).uri);\r\n\r\n    /*Checking */\r\n\r\n    String justDown = new String(justDownloaded.request.keySetId);\r\n    String oldDown = new String(download.request.keySetId);\r\n\r\n    if(justDown.equals(oldDown)){\r\n      android.util.Log.d(TAG, \"onPostExecute: License renew error.\");\r\n    }else{\r\n      android.util.Log.d(TAG, \"onPostExecute: License has been renewed.\");\r\n    }\r\n\r\n  }\r\n```\r\nNot sure if this is the correct approach to achieve license renewal.\r\nthis function is not tested because I'm not able to receive a new `keySetID` from the azure license URL ( for some reason )  , but I wrote it based on the logic of what will happen when my license is renewed."
      },
      {
        "user": "ojw28",
        "created_at": "2020-11-09T11:20:07Z",
        "body": "> We should probably look at an easy way to update the download database in this case.\r\n\r\nAha, it looks like you've figured out how to do this, just by adding the same download request again with an updated `keySetId`. Nice one :)! It looks like that should work fine, although we can optimize it slightly to not moving the download out of the `STATE_COMPLETED` state.\r\n\r\nI think everything else you've written looks sensible/correct. Can I close this issue as answered?"
      },
      {
        "user": "AnassHmida",
        "created_at": "2020-11-09T11:42:49Z",
        "body": "> > We should probably look at an easy way to update the download database in this case.\r\n> \r\n> Aha, it looks like you've figured out how to do this, just by adding the same download request again with an updated `keySetId`. Nice one :)! It looks like that should work fine, although we can optimize it slightly to not moving the download out of the `STATE_COMPLETED` state.\r\n> \r\n> I think everything else you've written looks sensible/correct. Can I close this issue as answered?\r\n\r\n\r\nYes, I believe you can, my problem is now with azure, since everything works as intended in here. \r\nThank you for your guidance! \r\n"
      }
    ],
    "satisfaction_conditions": [
      "A method to dynamically retrieve the Widevine license server URL from the Azure Media Services manifest",
      "Clear guidance on associating renewed licenses with offline content",
      "Validation of the license renewal workflow with dynamic URLs",
      "Compatibility with Azure Media Services' license delivery mechanism"
    ]
  },
  {
    "number": 8084,
    "title": "The custom render can only play for 52 seconds. Is there anything that needs special treatment?",
    "created_at": "2020-10-18T10:34:35Z",
    "closed_at": "2020-10-19T09:31:58Z",
    "labels": [
      "question",
      "need more info"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/8084",
    "body": "I customized the audio and video render, processed the data in the processOutputBuffer method, and then released the outputbuffer, but each time it can only be played for 52 seconds, the processOutputBuffer stops outputting. Is there anything that needs special treatment?\r\n\r\n--------------------------\r\n\r\nThanks for answering\r\n--------------------------\r\ncode\uff1a\r\n\r\nplayer\r\n```\r\nRtmpDataSourceFactory rtmpDataSourceFactory = new RtmpDataSourceFactory();\r\n        MediaSource videoSource = new ProgressiveMediaSource.Factory(rtmpDataSourceFactory)\r\n                .createMediaSource(MediaItem.fromUri(Uri.parse(mRtmpUrl)));\r\n        TrackSelection.Factory trackSelectionFactory = new AdaptiveTrackSelection.Factory();\r\n        DefaultTrackSelector trackSelector = new DefaultTrackSelector(AppContext.get(), trackSelectionFactory);\r\n        mExoPlayer = new SimpleExoPlayer.Builder(AppContext.get(), new RenderersFactory() {\r\n            @Override\r\n            public Renderer[] createRenderers(Handler eventHandler, VideoRendererEventListener videoRendererEventListener, AudioRendererEventListener audioRendererEventListener, TextOutput textRendererOutput, MetadataOutput metadataRendererOutput) {\r\n                Renderer [] renderers = new Renderer[2];\r\n                renderers[0]= new CustomMediaCodecAudioRenderer(AppContext.get(), MediaCodecSelector.DEFAULT);\r\n                renderers[1]= new CustomMediaCodecVideoRenderer(AppContext.get(), MediaCodecSelector.DEFAULT);\r\n                return renderers;\r\n            }\r\n        }).setTrackSelector(trackSelector).build();\r\n mExoPlayer.addListener(new Player.EventListener() {\r\n ...\r\n@Override\r\n   public void onIsLoadingChanged(boolean isLoading) {\r\n      Log.info(TAG,\"onIsLoadingChanged == \"+ isLoading);\r\n               \r\n     }\r\n}\r\nmExoPlayer.setMediaSource(videoSource);\r\nmExoPlayer.prepare();\r\nmExoPlayer.setPlayWhenReady(true);\r\n```\r\n\r\nrender:\r\n\r\n```\r\npublic class CustomMediaCodecVideoRenderer extends MediaCodecVideoRenderer {\r\n ...\r\n @Override\r\n    protected boolean processOutputBuffer(long positionUs, long elapsedRealtimeUs, @Nullable MediaCodec codec, @Nullable ByteBuffer buffer, int bufferIndex, int bufferFlags, int sampleCount, long bufferPresentationTimeUs, boolean isDecodeOnlyBuffer, boolean isLastBuffer, Format format) throws ExoPlaybackException {\r\n        ByteBuffer byteBuffer = codec.getOutputBuffer(bufferIndex);\r\n        CPHAgent.instance().submitI420(byteBuffer);\r\n       codec.releaseOutputBuffer(bufferIndex,false);\r\n        return true;\r\n\r\n    }\r\n}\r\n```\r\n\r\n```\r\npublic class CustomMediaCodecAudioRenderer extends MediaCodecAudioRenderer {\r\n @Override\r\n    protected boolean processOutputBuffer(long positionUs, long elapsedRealtimeUs, @Nullable MediaCodec codec, @Nullable ByteBuffer buffer, int bufferIndex, int bufferFlags, int sampleCount, long bufferPresentationTimeUs, boolean isDecodeOnlyBuffer, boolean isLastBuffer, Format format) throws ExoPlaybackException {\r\n         ByteBuffer byteBuffer = codec.getOutputBuffer(bufferIndex);\r\n        CPHAgent.instance().submitPCM(byteBuffer);\r\n        codec.releaseOutputBuffer(bufferIndex,false);\r\n        return true;\r\n    }\r\n}\r\n```\r\nLog\uff1a(Every time the processOutputBuffer stops outputting after 52 seconds of playback, I use other players to see that the data stream is working)\r\n```\r\n2020-10-18 18:12:04.517 60205-60222/? I/[bs-java][RtmpFilter]: [RtmpDecodeFilter.java:62:setup()] -- setup() -- \r\n2020-10-18 18:12:04.517 60205-60222/? I/[bs-java][RtmpFilter]: [RtmpDecodeFilter.java:87:connect()] ==========connect=========\r\n2020-10-18 18:12:04.540 60205-60222/? I/[bs-java][RtmpFilter]: [RtmpDecodeFilter.java:163:onPlaybackStateChanged()] onPlaybackStateChanged == 2\r\n2020-10-18 18:12:04.541 60205-60222/? I/[bs-java][RtmpFilter]: [RtmpDecodeFilter.java:142:onIsLoadingChanged()] onIsLoadingChanged == true\r\n2020-10-18 18:12:04.541 60205-60222/? I/[bs-java][RtmpFilter]: [RtmpDecodeFilter.java:121:onTimelineChanged()] onTracksChanged == com.google.android.exoplayer2.PlaylistTimeline@c1eb3f82,1\r\n2020-10-18 18:12:04.648 60205-60222/? I/[bs-java][RtmpFilter]: [RtmpDecodeFilter.java:121:onTimelineChanged()] onTracksChanged == com.google.android.exoplayer2.PlaylistTimeline@ee4e81a4,1\r\n2020-10-18 18:12:04.664 60205-60222/? I/[bs-java][RtmpFilter]: [RtmpDecodeFilter.java:137:onTracksChanged()] onTracksChanged == com.google.android.exoplayer2.trackselection.TrackSelectionArray@ea0764a7\r\n2020-10-18 18:12:56.375 60205-60222/? I/[bs-java][RtmpFilter]: [RtmpDecodeFilter.java:142:onIsLoadingChanged()] onIsLoadingChanged == false\r\n```\r\n\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/8084/comments",
    "author": "luohaohaha",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2020-10-19T08:47:53Z",
        "body": "Based on the information provided, I'd guess that the player position is stuck at zero because the `CustomMediaCodecAudioRenderer` is not writing data to the `AudioTrack`, whose position is normally used to determine the player position. You can verify this hypothesis by checking whether the position passed to `render` is advancing.\r\n\r\nIf you actually want to play the audio, you could try calling `super.processOutputBuffer` in your subclass. If you don't want to play the audio, I'd suggest overriding `MediaCodecAudioRenderer.getPositionUs` and making it return an advancing position (probably best to use the microsecond time associated with the latest sample you've handled). Or it might give a cleaner design to implement a custom `AudioSink` that does the audio processing you need, and just use the normal `MediaCodecAudioRenderer` instead of subclassing it.\r\n\r\nIf that doesn't help, I think we'll need a minimal sample project that reproduces the issue, or you'll need to do some investigation on your side to check whether/why the source is not ready (`MediaCodecRenderer`'s call to `readSource` in `feedInputBuffer` is not getting any data), or whether data flow is stuck somewhere else."
      },
      {
        "user": "luohaohaha",
        "created_at": "2020-10-19T09:31:58Z",
        "body": "As you said, I override the getPositionUs method and it's fine, thank you for your answer."
      }
    ],
    "satisfaction_conditions": [
      "Ensures proper advancement of player position when using custom renderers",
      "Addresses synchronization between custom processing and player state management",
      "Provides mechanism to handle media timeline progression without standard rendering"
    ]
  },
  {
    "number": 7955,
    "title": "With v2.12.0 playlist api, how do I know which source causes the onPlayerError",
    "created_at": "2020-09-21T08:30:29Z",
    "closed_at": "2020-09-21T15:03:28Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/7955",
    "body": "### [REQUIRED] Searched documentation and issues\r\nLooked at StackOverflow and other issues. Could not find anything related\r\n\r\n### [REQUIRED] Question\r\nI using the new playlist API provided with v2.12.0 and loading multiple `MediaItem`s into the player. One of the sources throws an `ExoPlaybackException` of `ExoPlaybackException.TYPE_SOURCE` type.\r\n\r\nHow do I know which media item this relates to?\r\n\r\n### A full bug report captured from the device\r\nNo specific bug is referred to.\r\n\r\n### Link to test content\r\nGeneral question that does not relate to a specific source.\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/7955/comments",
    "author": "strangesource",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2020-09-21T12:53:18Z",
        "body": "I think in this case the field `ExoPlaybackException.mediaPeriodId` has a media period id assigned (it is not null). If so you can do something like this:\r\n\r\n```\r\nMediaSource.MediaPeriodId mediaPeriodId = playbackException.mediaPeriodId;\r\nint windowIndex = player.getCurrentTimeline()\r\n   .getPeriodByUid(mediaPeriodId.periodUid, new Timeline.Period()).windowIndex;\r\nplayer.removeMediaItem(windowIndex);\r\n```\r\n\r\nPlease note, that the above assumes that you are having a 1:1 relationship between media items and windows in the timeline. This means you are not using a `ConcatenatingMediaSource`. In case you are only using the new API with `MediaItem` you are fine. \r\n\r\nPlease let me know whether that works for you."
      },
      {
        "user": "tonihei",
        "created_at": "2020-09-21T13:03:41Z",
        "body": "You can also use `AnalyticsListener` and listen to `onPlayerError` which has an `EventTime` argument with a `windowIndex` field. This is essentially equivalent to the proposal above, but easier to read in code:\r\n```\r\n@Override\r\n public void onPlayerError(EventTime eventTime, ExoPlaybackException e) {\r\n    Log.e(\"ERROR\", \"Media item number \" + eventTime.windowIndex + \" failed.\");\r\n }\r\n```"
      },
      {
        "user": "strangesource",
        "created_at": "2020-09-21T13:36:49Z",
        "body": "Thanks a lot for the fast answers, this solves my problem. \ud83d\ude42  \ud83d\ude47 "
      },
      {
        "user": "marcbaechinger",
        "created_at": "2020-09-21T15:03:28Z",
        "body": "Cool, thanks for letting us know. I'm closing this issue. Please re-open if you think it is needed."
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to map an ExoPlaybackException to the specific MediaItem in a playlist",
      "Clear association between error events and playlist position/index",
      "Solution works without ConcatenatingMediaSource assumptions",
      "Error tracking compatible with AnalyticsListener patterns"
    ]
  },
  {
    "number": 7915,
    "title": "MediaItem.Builder() doesn't contain StreamType in ExoPlayer 2.12.0",
    "created_at": "2020-09-15T10:55:40Z",
    "closed_at": "2020-09-15T22:30:40Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/7915",
    "body": "Hello,\r\n\r\nUntil ExoPlayer 2.12.0 i used `MediaInfo.Builder()` where i could set media stream type, for example: `.setStreamType(MediaInfo.STREAM_TYPE_LIVE)` and then i passed all information to the `MediaQueueItem.Builder()` to cast video to Google Chromecast.\r\n\r\nIn the new ExoPlayer 2.12.0 version i have to use `MediaItem.Builder()` now. And it is impossible to set media stream type now.\r\nOr maybe i'm missing something?\r\n\r\nThank you.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/7915/comments",
    "author": "menscikov",
    "comments": [
      {
        "user": "menscikov",
        "created_at": "2020-09-15T11:29:14Z",
        "body": "There is also a problem with `com.google.android.exoplayer2.MediaMetadata` class.\r\nIt's only accepting \"title\" now.\r\n\r\nEarlier i used `com.google.android.gms.cast.MediaMetadata` class, and i could set \"title\", \"subtitle\", \"image\" and other options to metadata with `MediaInfo.Builder()`.\r\n\r\nBut now `MediaItem.Builder()` is only accepting `MediaMetadata` class from `com.google.android.exoplayer2`.\n\n---\n\nMaybe it's better to leave `MediaQueueItem.Builder()` and make `CastPlayer.loadItem()` method not deprecated for Google Chromecast?"
      },
      {
        "user": "marcbaechinger",
        "created_at": "2020-09-15T11:59:14Z",
        "body": "You can pass a `MediaItemConverter` to the constructor of the `CastPlayer`. This lets you convert the `MediaItem` to a `MediaQueueItem` which is then sent to `RemoteMediaClient`.\r\n\r\nIf you want to transport custom data with the `MediaItem` you can do so by using `new MediaItem.Builder().setTag(object)`. This can be retrieved in the converter by using `mediaItem.playbackProperties.tag` and then converted to the `MediaQueueItem` ."
      },
      {
        "user": "menscikov",
        "created_at": "2020-09-15T17:00:58Z",
        "body": "> You can pass a `MediaItemConverter` to the constructor of the `CastPlayer`. This lets you convert the `MediaItem` to a `MediaQueueItem` which is then sent to `RemoteMediaClient`.\r\n> \r\n> If you want to transport custom data with the `MediaItem` you can do so by using `new MediaItem.Builder().setTag(object)`. This can be retrieved in the converter by using `mediaItem.playbackProperties.tag` and then converted to the `MediaQueueItem` .\r\n\r\nCould you please give an example how to do that?\r\nI can't understand how can i convert `MediaQueueItem` to `MediaItem` with all options, like \"streamType\" and `MediaMetadata` \"title\", \"subtitle\", \"image\"?\r\nCastPlayer is accepting only `MediaItem` now in ExoPlayer 2.12.0 version.\r\n\r\n`DefaultMediaItemConverter().toMediaItem` class doesn't allow to do this."
      },
      {
        "user": "marcbaechinger",
        "created_at": "2020-09-15T17:39:47Z",
        "body": "Sorry to not give you enough details. You are right it's confusing. Specifically because the conversion back which confused you is currently unused. Please accept my apologies of not being clear here.\r\n\r\nOn the bright side, this should make things easier for you. You said above that your app is building a `MediaQueueItem` with `MediaQueueItem.Builder()`. If you aim for doing this with the least possible changes in you code it would probably be something like the following:\r\n\r\nImplement your custom `MediaItemConverter`:\r\n\r\n```\r\npublic class CustomConverter implements MediaItemConverter {\r\n  public MediaQueueItem toMediaQueueItem(MediaItem mediaItem) {\r\n       // The MediaQueueItem you build is expected to be in the tag.\r\n       return (MediaQueueItem)mediaItem.playbackProperties.getTag();\r\n  }\r\n  public MediaItem toMediaItem(MediaQueueItem Item) {\r\n      // This should give the same as when you build your media item to be passed to ExoPlayer.\r\n      return new MediaItem.Builder()\r\n          .setUri(item.getMedia().getContentUrl())\r\n          .setTag(item)\r\n          .build();\r\n  }\r\n}\r\n\r\n// The custom converter is used to create the cast player.\r\nCastPlayer castPlayer = CastPlayer(castContext, new CustomConverter());\r\n\r\n// You code builds a MediaQueueItem\r\nMediaQueueItem queueItem = MediaQueueItem.Builder().setXyz().build();\r\n// and ads it as the tag of the media item\r\nMediaItem mediaItem = new MediaItem.Build().setUri(uri).setTag(queueItem).build();\r\n\r\n// Add the item to the cast player which uses the converter internally.\r\ncastPlayer.addMediaItem(mediaItem);\r\nsimpleExoPlayer.addMediaItem(mediaItem);\r\n```\r\n\r\nYou could use any object as the tag. But given your code builds the media queue item already it's probably easiest to just use this.\r\n\r\nYour app can now use the same API like `addMediaItem` on both, the `CastPlayer` and `SimpleExoPlayer` because both implement the `Player` interface. ExoPlayer will just ignore the tag which you only need to create the queue item."
      },
      {
        "user": "menscikov",
        "created_at": "2020-09-15T18:07:11Z",
        "body": "Thank you very much for the explanation. It's working now!"
      },
      {
        "user": "marcbaechinger",
        "created_at": "2020-09-15T22:30:40Z",
        "body": "Cool. I'm glad it works :) \r\n\r\nI close this issue for now. Please re-open if you have further questions. Happy to help!"
      }
    ],
    "satisfaction_conditions": [
      "Ability to specify stream type (e.g. STREAM_TYPE_LIVE) when casting to Chromecast",
      "Support for full media metadata including title, subtitle, and images",
      "Compatibility with both CastPlayer and SimpleExoPlayer interfaces",
      "Clear migration path from deprecated MediaQueueItem.Builder API",
      "Mechanism to transport custom playback parameters through MediaItem"
    ]
  },
  {
    "number": 7782,
    "title": "Switch between video and view at given times",
    "created_at": "2020-08-19T05:15:33Z",
    "closed_at": "2020-08-21T12:41:48Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/7782",
    "body": "I'm looking for a way to stop the video at, let's say 10s, pause the video switch to another view and when the user is finished with that view, start back the video display.\r\n\r\nAfter looking at the dev website, I was wondering if this could be done with IMA ads but I guess it can't be done because I need indefinite time for the in-middle view. \r\n\r\nIs there any way I can do this? Then is there a way to display little vertical yellow bars (at switching position) in the seekbar as you do for ads ?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/7782/comments",
    "author": "Clement-Jean",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2020-08-19T11:56:41Z",
        "body": "You can use ad markers for marking positions and fire player messages at the given playback positions to run your code:\r\n\r\n```\r\nlong[] extraAdGroupTimesMs = new long[]{20_000, 40_000};\r\nplayerView.setExtraAdGroupMarkers(extraAdGroupTimesMs, new boolean[] { false, false});\r\n```\r\n\r\nThe first argument is an array holding the positions on the timebar of the `PlayerControlView`. The second argument is an array of flags whether these markers should be shown or not.\r\n\r\nYou can customize the color of the markers by customizing the `player_control_view.xml` layout file and replacing the placeholder with id `exo_progress_placeholder` with a DefaultTimeBar element with id `exo_progress`:\r\n\r\n```  \r\n  <com.google.android.exoplayer2.ui.DefaultTimeBar\r\n    android:id=\"@id/exo_progress\"\r\n    android:layout_width=\"match_parent\"\r\n    android:layout_gravity=\"bottom\"\r\n    app:ad_marker_color=\"@color/customAdMarkerColor\" />\r\n```\r\n\r\nAnd finally you can add player messages which can execute custom code at a given position:\r\n\r\n```\r\nfor (int i = 0; i < extraAdGroupTimesMs.length; i++) {\r\n  long positionMs = extraAdGroupTimesMs[i];\r\n  PlayerMessage playerMessage = player.createMessage(\r\n      (messageType, payload) -> {\r\n        Log.d(\"player message\", \"message at position: \" + positionMs);\r\n        // do what you need to do\r\n        player.setPlayWhenReady(false);\r\n        switchToAnotherView();\r\n      });\r\n\r\n  playerMessage\r\n      .setPosition(positionMs) // the playback position according to the markers\r\n      .setDeleteAfterDelivery(false) \r\n      .setHandler(new Handler())\r\n      .send();\r\n}\r\n```"
      },
      {
        "user": "Clement-Jean",
        "created_at": "2020-08-19T14:13:28Z",
        "body": "Thank you @marcbaechinger, very helpful.\r\n\r\nJust one thing to add here, I needed to use activity.runOnUiThread in the lambda or I would have an error saying that you need to be in the same thread for changing the player and the view."
      },
      {
        "user": "marcbaechinger",
        "created_at": "2020-08-21T12:41:48Z",
        "body": "Oh, yes, sorry. I forgot to add the `setHandler(new Handler())` call. I added it to the snippet above. If you pass the handler, the message is executed on the thread on which the `Handler` has been created. Assuming you send the message on the UI thread this would do what you want.\n\n---\n\nI close this for now. Please re-open if you have any further question."
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to trigger actions at specific video timestamps",
      "Support for custom view switching during playback interruptions",
      "Visual indicators for switch points in seekbar",
      "Thread-safe execution of UI changes"
    ]
  },
  {
    "number": 7754,
    "title": "Reading the TsExtractor code and see its methods `sniff(ExtractorInput input)`\uff0c some problems ",
    "created_at": "2020-08-14T09:57:09Z",
    "closed_at": "2020-08-14T10:42:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/7754",
    "body": "Reading the TsExtractor code and see its methods `sniff(ExtractorInput input)`\uff0c some problems behind it\uff1a\r\n\r\n```\r\npublic static final int TS_PACKET_SIZE = 188; // why it is 188\uff1f\r\nprivate static final int SNIFF_TS_PACKET_COUNT = 5; // why it is 5\uff1f\r\nprivate static final int SNIFF_TS_PACKET_COUNT = 5; // why it is 5\uff1f\r\n\r\npublic boolean sniff(ExtractorInput input) throws IOException, InterruptedException {\r\n    byte[] buffer = tsPacketBuffer.data;\r\n    input.peekFully(buffer, 0, TS_PACKET_SIZE * SNIFF_TS_PACKET_COUNT);\r\n    for (int startPosCandidate = 0; startPosCandidate < TS_PACKET_SIZE; startPosCandidate++) {\r\n      // Try to identify at least SNIFF_TS_PACKET_COUNT packets starting with TS_SYNC_BYTE.\r\n      boolean isSyncBytePatternCorrect = true;\r\n      for (int i = 0; i < SNIFF_TS_PACKET_COUNT; i++) {\r\n        if (buffer[startPosCandidate + i * TS_PACKET_SIZE] != TS_SYNC_BYTE) {\r\n          isSyncBytePatternCorrect = false;\r\n          break;\r\n        }\r\n      }\r\n      if (isSyncBytePatternCorrect) {\r\n        input.skipFully(startPosCandidate);\r\n        return true;\r\n      }\r\n    }\r\n    return false;\r\n  }\r\n```\r\nI wonder why loops inside don't start with i =0 and end at buffer.length, but it's a complicated calculation. What is the principle? Thank you!",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/7754/comments",
    "author": "JaredLees",
    "comments": [
      {
        "user": "AquilesCanta",
        "created_at": "2020-08-14T10:42:11Z",
        "body": "I suggest you have a look at ISO/IEC 13818-1 for some context on what a Transport stream looks like (packets are 188 bytes) and what the spec expects from the Transport Stream receiving end (e.g. synchronisation guidelines: try to find 5 consecutive packets). Also keep in mind that Transport stream is a stream to which clients need to synchronise, which means packet boundaries are not necessarily aligned with file boundaries therefor the complicated loop. Hope this helps!"
      },
      {
        "user": "JaredLees",
        "created_at": "2020-08-14T10:49:33Z",
        "body": "thanks!"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of the Transport Stream (TS) packet structure standard",
      "Clarification of synchronization requirements for TS packet detection",
      "Description of packet boundary alignment challenges in stream processing",
      "Connection between implementation details and MPEG-TS specification requirements"
    ]
  },
  {
    "number": 7525,
    "title": "Accessing active datasource in onPositionDiscontinuity",
    "created_at": "2020-06-18T18:31:36Z",
    "closed_at": "2020-09-22T16:17:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/7525",
    "body": "### [REQUIRED] Searched documentation and issues\r\n\r\nI did :)\r\n\r\n### [REQUIRED] Question\r\nI'm having an hard time to get the active datasource when the media change in a ```ConcatenatingMediaSource```.\r\n\r\nI use a specific ```DataSourceFactory``` that extends ```HttpDataSource.BaseFactory``` and prepare the media in the ```open(dataSpec)```.\r\nDuring this preparation the media can be transcoded or not and depending on many factor the resulting may support some things like seeking or not.\r\nI need to be able to access this information to do things like not calling normal seek but restart the transcoding at the new position.\r\n\r\nThe problem is that in ```ConcatenatingMediaSource``` ```open``` can be called to prepare the next media while the active media is still not closed.\r\n\r\nSo the question is how can I access the datasource from the player ```onPositionDiscontinuity``` callback. Or how can I access the ```MediaSource``` from the ```DataSource``` to be able to modify the tag?\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/7525/comments",
    "author": "Tolriq",
    "comments": [
      {
        "user": "AquilesCanta",
        "created_at": "2020-06-19T15:01:31Z",
        "body": "Why don't you assign a specific `DataSourceFactory` to each `MediaSource` so that each `DataSourceFactory` knows to which MediaSource they are assigned?\r\n\r\nSo when the media source calls `open(...)` for preparation (or whatever), you know which is the calling MediaSource, since the `DataSourceFactory` knows the corresponding `MediaSource`."
      },
      {
        "user": "Tolriq",
        "created_at": "2020-06-19T15:23:04Z",
        "body": "Isn't that highly inefficient to create a DefaultDataSourceFactory and my factory for every single items for very large playlists?"
      },
      {
        "user": "tonihei",
        "created_at": "2020-09-22T14:41:11Z",
        "body": "`DefaultDataSourceFactory` is just a thin wrapper creating other `DataSource` instances, so there should be no issue with creating multiple factories if needed.\r\n\r\nNot sure about your exact use case, but you can also consider one of the following:\r\n - Use `ResolvingDataSource` to add additional loading steps based on the `DataSpec`. You could detect whatever you need from the `DataSpec` URL, custom header key-value pairs or from using the `customData` object. Whether this is easily possible depends on the details of what you need and what you are trying to achieve.\r\n - Set a `tag` on each `MediaSource` (or `MediaItem`) that can be retrieved by `Player.getCurrentTag()` in `onPositionDiscontinuity`."
      },
      {
        "user": "Tolriq",
        "created_at": "2020-09-22T14:56:49Z",
        "body": "@tonihei  Ok so let me try to better explain the need that is.\r\n\r\nThe player can play media from many different sources and some of them can transcode the media on the fly.\r\nThe transcoding or not decision is made at the ```DataSource.open``` to avoid wasting server resources.\r\nWhen transcoding some server for some media type and transcoded media can generate non seekable media via normal player seek functions.\r\nI can detect and know this only when transcoding start so in ```DataSource.open```\r\n\r\nBut I need to know this at the player / UI side to either disable the seek functions or intercept the seek to be actual restart of the media at the proper new starting point.\r\n\r\nThe problem is that with gapless / ConcateningMediaSource the ```DataSource.open``` is called independently of the active media.\r\n\r\nAnd from ```DataSource.open``` I can't access the corresponding MediaItem/MediaSource to update the tag that I could then use in ```onPositionDiscontinuity```\r\n\r\nSo TL;DR I need to access the MediaSource/MediaItem from the ```DataSource.open``` not sure ```ResolvingDataSource``` brings anything here as it's before the open."
      },
      {
        "user": "tonihei",
        "created_at": "2020-09-22T15:06:29Z",
        "body": "`ResolvingDataSource` is essentially just an easy wrapper to intercept the `DataSpec` to the `DataSource`. If the actual information you need is only available afterwards, you would probably need to follow @AquilesCanta's advice and use a `DataSource.Factory` for each of your `DataSources` that has access to your tag object:\r\n\r\n```\r\nMediaSource mediaSource = \r\n    new ProgressiveMediaSource.Factory(() -> new MyCustomDataSource(tag))\r\n      .setTag(tag)\r\n      .createMediaSource(MediaItem.forUri(uri));\r\n```\r\n\r\nAside: If you make the `tag` object mutable be aware that the loading takes place on another thread, so you need additional thread safety around the updates."
      },
      {
        "user": "Tolriq",
        "created_at": "2020-09-22T15:36:03Z",
        "body": "Thanks that's what I do, but the new playlist api is all about MediaItem directly no? Or I can use MediaSources directly and still use the new playlist api instead of concateningmediasource?"
      },
      {
        "user": "tonihei",
        "created_at": "2020-09-22T15:43:49Z",
        "body": "Yes, you can. The `ExoPlayer` interface defines all relevant methods for that (e.g. `setMediaSource`, `addMediaSource` etc)"
      },
      {
        "user": "Tolriq",
        "created_at": "2020-09-22T16:17:58Z",
        "body": "Ok thanks, closing this one too as there's no other way and factory are small :)"
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to associate DataSource instances with their corresponding MediaSource/MediaItem",
      "Thread-safe way to propagate dynamic metadata from DataSource to player callbacks",
      "Access to media source identification without performance penalties for large playlists",
      "Compatibility with ExoPlayer's MediaSource tagging system",
      "Support for mutable MediaSource metadata during playback"
    ]
  },
  {
    "number": 7450,
    "title": "How to remove ICY header request",
    "created_at": "2020-05-31T13:53:32Z",
    "closed_at": "2020-06-01T10:21:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/7450",
    "body": "Hi,\r\n\r\nI was trying to find a way on how to remove the ICY header from the header request. I'm expecting it is causing some issues with certein hosting server.\r\n\r\ni have been trying many things without success e.g. \r\n\r\n```\r\nfinal HttpDataSource.RequestProperties s = dataSourceFactory.getDefaultRequestProperties();\r\ns.remove(IcyHeaders.REQUEST_HEADER_ENABLE_METADATA_NAME);\r\n```\r\n\r\nOR \r\n\r\n```\r\nfinal ProgressiveMediaSource audioSource2 =\r\nnew ProgressiveMediaSource.Factory(() -> {\r\n\tfinal HttpDataSource dataSource = new DefaultHttpDataSource(Util.getUserAgent(this, getString(R.string.app_name)))\r\n\t{\r\n\t\t@Override\r\n\t\tpublic long open(DataSpec dataSpec) throws HttpDataSourceException\r\n\t\t{\r\n\t\t\tdataSpec.httpRequestHeaders.remove(IcyHeaders.REQUEST_HEADER_ENABLE_METADATA_NAME);\r\n\t\t\treturn super.open(dataSpec);\r\n\t\t}\r\n\t};\r\n\t//dataSource.clearRequestProperty(IcyHeaders.REQUEST_HEADER_ENABLE_METADATA_NAME);\r\n\treturn dataSource;\r\n}).createMediaSource(Uri.parse(url));\r\n```\r\n\r\nthe last one throws:\r\n```\r\n2020-05-31 17:45:56.863 9747-10339/com.myapp.audiocataloger E/LoadTask: Unexpected exception loading stream\r\n      java.lang.UnsupportedOperationException\r\n        at java.util.Collections$UnmodifiableMap.remove(Collections.java:1502)\r\n        at com.myapp.audiocataloger.MediaService$4.open(MediaService.java:813)\r\n        at com.google.android.exoplayer2.upstream.StatsDataSource.open(StatsDataSource.java:83)\r\n        at com.google.android.exoplayer2.source.ProgressiveMediaPeriod$ExtractingLoadable.load(ProgressiveMediaPeriod.java:956)\r\n        at com.google.android.exoplayer2.upstream.Loader$LoadTask.run(Loader.java:391)\r\n        at java.util.concurrent.ThreadPoolExecutor.processTask(ThreadPoolExecutor.java:1187)\r\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1152)\r\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\r\n        at java.lang.Thread.run(Thread.java:784)\r\n```\r\n\r\nI tried as well to override it in TransferListener without success as well\r\n\r\n```\r\nfinal TransferListener transferListener = new TransferListener()\r\n{\r\n\t@Override\r\n\tpublic void onTransferInitializing(DataSource dataSource, DataSpec dataSpec, boolean isNetwork)\r\n\t{\r\n\t\t// Override it here\r\n\t}\r\n\r\n\t@Override\r\n\tpublic void onTransferStart(DataSource dataSource, DataSpec dataSpec, boolean b){}\r\n\r\n\t@Override\r\n\tpublic void onBytesTransferred(DataSource dataSource, DataSpec dataSpec, boolean b, int i){}\r\n\r\n\t@Override\r\n\tpublic void onTransferEnd(DataSource dataSource, DataSpec dataSpec, boolean b){}\r\n};\r\n```\r\n\r\nPlease advise the proper way to do this.\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/7450/comments",
    "author": "Abu-Abdullah",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2020-06-01T08:04:06Z",
        "body": "In the option where you override `open`, could you try instantiating a new `DataSpec` based on values from the old one but without the ICY header?"
      },
      {
        "user": "Abu-Abdullah",
        "created_at": "2020-06-01T10:21:49Z",
        "body": "thank you @andrewlewis for the hint. it is working as you suggest:\r\n```\r\n@Override\r\npublic long open(DataSpec dataSpec) throws HttpDataSourceException\r\n{\r\n\tfinal Map<String, String> m1 = dataSpec.httpRequestHeaders;\r\n\tfinal Map<String, String> m2 = new HashMap<>();\r\n\tfor (Map.Entry<String, String> entry : m1.entrySet())\r\n\t\tif(!entry.getKey().equals(IcyHeaders.REQUEST_HEADER_ENABLE_METADATA_NAME))\r\n\t\t\tm2.put(entry.getKey(), entry.getValue());\r\n\t\r\n\treturn super.open(dataSpec.withRequestHeaders(m2));\r\n}\r\n```\r\nAnd thankfully the web server behavior is correct now. I'm not facing the same issues that i faced in #7353 which indicates that setting ICY_Metadata in the header by default is not the correct way. Many web servers might be affected by this (at least in my case which i have it on bluehost, one of the leaders in this market).\r\n\r\nI think we should have an easy way to configure the dataspec.httpRequestHeaders\r\n\r\nthank you again"
      }
    ],
    "satisfaction_conditions": [
      "Solution must remove ICY metadata header from HTTP requests",
      "Approach must handle unmodifiable request header maps safely",
      "Method should allow configuration of request headers before connection establishment",
      "Implementation must avoid runtime exceptions during header manipulation",
      "Solution should work with ExoPlayer's data source architecture"
    ]
  },
  {
    "number": 7366,
    "title": "Is it possible to change video duration after changing video speed?",
    "created_at": "2020-05-12T13:28:41Z",
    "closed_at": "2020-05-21T08:33:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/7366",
    "body": "I have used `setPlaybackParameters` method to change speed of video. Player keep same duration when I increased or decreased speed. But if we apply process on video then if speed increased, video duration decreased and speed decreased, video duration increased. I want to show that in preview using exoplayer. \r\n\r\nPlease guide me.\r\n\r\nThanks",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/7366/comments",
    "author": "ghost",
    "comments": [
      {
        "user": "krocard",
        "created_at": "2020-05-13T19:20:45Z",
        "body": "I'm not sure to understand the question. What type of video processing are you talking about?\r\n\r\nDo you want the video duration in the UI to decrease with the speed as if\r\n`UI_video_duration = real_video_duration / speed`)\r\n\r\nOr is the UI video duration you want to display related to your app _processing on video_, so not proportional to the speed?"
      },
      {
        "user": "ghost",
        "created_at": "2020-05-14T04:59:47Z",
        "body": "Hi @krocard Thank you for quick response.\r\nI have applied above formula. But video will complete on it's actual time.\r\nLet's say I have choose video of `144639` Millisecond. set speed 5. As per your formula `144639/5 = 28927.8`. So now video duration is `28927.8`. But when I play video in exoplayer with speed `5` it will complete in `144639` Millisecond not `28927.8`. \r\nSo how can I play complete video in updated duration?\r\nI hope for your response.\r\nThank you."
      },
      {
        "user": "krocard",
        "created_at": "2020-05-14T10:26:55Z",
        "body": "> But when I play video in exoplayer with speed 5 it will complete in 144639 Millisecond not 28927.8.\r\n\r\nIf you play a video with speed 5, the real elapse time to play the video will be 5\u00a0time less.\r\nAka if you start a stopwatch at the beginning of the video, and stop the timewatch when it is finished playing, the stopwatch will show around 28927.8. You will also see and hear the video playing 5 time faster.\r\n\r\nOn the other hand, the timestamps reported by ExoPlayer (for example `Player.getCurrentPosition()`), are independent of the speed and refer to the position in the video as if it was played at speed 1.\r\n\r\nIf what you want is the real time ExoPlayer has played the current video (like the stopwatch would give you in my previous thought experiment), I'm afraid ExoPlayer does not keep track of it.\r\nNevertheless, assuming you always play the video at the same speed, you can divide the position that ExoPlayer returns by the playback speed to get the \"stopwatch\" position.\r\n\r\nDoes this answers your question?"
      },
      {
        "user": "ghost",
        "created_at": "2020-05-20T07:22:44Z",
        "body": "Thanks for your help.\r\n\r\nI have implemented as per you told. I calculated updated video duration and video will complete within updated duration with speed changes.\r\n\r\nLet say `29568` Millisecond video, `0.6` speed set then updated video duration is `49280(29568 / 0.6).` So I sat that update duration and display in my screen.\r\n\r\nBut now I will seek manually and `seekTo` `24640` millisecond means `50%` of updated video duration. But player seek video almost till end because video actual duration is `29568`.\r\nIn That case what should I do to seek video to `50%`\r\n\r\nPlease guide me.\r\n\r\nThank you."
      },
      {
        "user": "krocard",
        "created_at": "2020-05-20T08:47:36Z",
        "body": "Does doing the inverse transformation when controlling the player fixes your issue. Aka\r\n`player.seekTo(TimestampFromTheUI*videoSpeed)`.\r\n\r\nIn your example that would be: `player.seekTo(24640*0.6)`. As `24640*0.6 = 14784` which is 50% of the actual video duration (`29568/2`).\r\n"
      },
      {
        "user": "ghost",
        "created_at": "2020-05-21T04:24:15Z",
        "body": "Yes, It is working.\r\nThank you so much for help and support."
      },
      {
        "user": "krocard",
        "created_at": "2020-05-21T08:33:47Z",
        "body": "You're welcome!\r\nI'm closing this issue as your questions are answered."
      }
    ],
    "satisfaction_conditions": [
      "Display adjusted video duration in the UI based on playback speed",
      "Handle seek operations proportionally to the adjusted duration",
      "Maintain synchronization between UI timeline and playback behavior"
    ]
  },
  {
    "number": 7365,
    "title": "Seeking did not work proper with ConcatenatingMediaSource.",
    "created_at": "2020-05-12T13:21:24Z",
    "closed_at": "2020-05-21T14:32:10Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/7365",
    "body": "ExoPlayer 2.11.4\r\nPixel 2 \r\nAndroid 10\r\n\r\nI use a `ConcatenatingMediaSource`. When I call `seekTo` with the current `windowIndex` and the `positionMs`, At that time `onPositionDiscontinuity` called with reason `DISCONTINUITY_REASON_PERIOD_TRANSITION` and it will not seek to the proper position but `windowIndex` will increased. \r\n\r\nLet's say take 3 videos(10000, 20000, 30000 MS) and add source in `ConcatenatingMediaSource`. Current first video is playing and seek to `windowIndex` = 1 and `positionMs` = 12000 MS. `windowIndex` will change to 2 and 3rd video will start from it's default position.\r\n\r\nI have used seekbar to seek to particular position.\r\n\r\nPlease guide me.\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/7365/comments",
    "author": "ghost",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2020-05-14T12:05:33Z",
        "body": "Are you saying that when you call `player.seekTo(1, 12000)` from inside the onPositionDiscontinuity() callback, then it starts window 2 at default position instead of window 1 at 12000?\r\n\r\nCan you please provide me with the code you are executing in the `onPositionDiscontinuity()` callback? To see what is going on in the player, can you please add `EventLogger` to the player of your app and take a bug report just after you have experienced the behaviour above?\r\n\r\nThis would allow me to look into your problem and give you some guidance on what is going on (or recognize a bug on our side if that's the case)."
      },
      {
        "user": "ghost",
        "created_at": "2020-05-15T04:51:02Z",
        "body": "Thank you for your response.\r\nNo I am not calling `player.seekTo(1, 12000)` from Inside the onPositionDiscontinuity() callback.\r\n\r\nPlease see code.\r\n\r\n```\r\nvideoSeekBar.setOnSeekChangeListener(object : OnSeekChangeListener {\r\n        override fun onSeeking(seekBar: VideoSeekBar?) {\r\n            try {\r\n                if(isSeeking)\r\n                   player.seekTo(currentWindowIndex, seekBar.position)\r\n            } catch (e: Exception) {\r\n                e.printStackTrace()\r\n            }\r\n        }\r\n\r\n        override fun onStartSeeking(seekBar: VideoSeekBar?) {\r\n            isSeeking = true\r\n        }\r\n\r\n        override fun onStopSeeking(seekBar: VideoSeekBar?) {\r\n                try {\r\n                    isSeeking = false\r\n                    player.seekTo(currentWindowIndex, seekBar.position)\r\n                } catch (e: Exception) {\r\n                    e.printStackTrace()\r\n                }\r\n        }\r\n    })\r\n\r\nobject : Player.EventListener {\r\n        override fun onPositionDiscontinuity(reason: Int) {\r\n            when (reason) {\r\n                Player.DISCONTINUITY_REASON_PERIOD_TRANSITION -> {\r\n                   Log.e(\"onPositionDiscontinuity\",\"DISCONTINUITY_REASON_PERIOD_TRANSITION\")\r\n                    Log.e( \"onPositionDiscontinuity\", \"player.currentWindowIndex ${player.currentWindowIndex}\" )\r\n                }\r\n                Player.DISCONTINUITY_REASON_INTERNAL -> {\r\n                    Log.e(\"onPositionDiscontinuity\", \"DISCONTINUITY_REASON_INTERNAL\")\r\n                }\r\n                Player.DISCONTINUITY_REASON_SEEK -> {\r\n                }\r\n                Player.TIMELINE_CHANGE_REASON_DYNAMIC -> {\r\n                    if (selectedFunction != ON_PROGRESS && selectedFunction != TRIM && selectedFunction != SPLIT && selectedFunction != SPEED_VIEW) {\r\n                        Log.e(\"onPlayerStateChanged\", \"TIMELINE_CHANGE_REASON_DYNAMIC\")\r\n                        updateCurrentPosition()\r\n                    }\r\n                }\r\n            }\r\n        }\r\n```\r\nWhen Call player.seekTo(1, 12000) from seekbar listener and then I get callback in onPositionDiscontinuity() with DISCONTINUITY_REASON_PERIOD_TRANSITION reason and windewIndex increased and it will be 2. And next video will play from it's default position means 0 Millisecond.\r\n\r\nThank you."
      },
      {
        "user": "marcbaechinger",
        "created_at": "2020-05-15T15:37:44Z",
        "body": "Many thanks for further information.\r\n\r\nA first observation is that you can remove the section with `Player.TIMELINE_CHANGE_REASON_DYNAMIC` because that is relevant for `onTimelineChanged(timeline, reason)` only. It may have the same value as a reason of discontinuity but you don't want to check for `Player.TIMELINE_CHANGE_REASON_DYNAMIC` in this callback.\r\n\r\nNow, just to make sure I understand everything correctly, let me describe what I understand you are doing. Please correct me if I understood wrongly:\r\n\r\n1. Prepare player with 3 media sources (10000ms, 20000ms, 30000ms)\r\n   -> `player.prepare(concatenatingMediaSource);`\r\n2. Start playback at windowIndex=0\r\n   -> `player.setPlayWhenReady(true);`\r\n3. You wait until playback transition to the second media with windowIndex=1\r\n4. Use the seekBar to get the new position and then seek to that position in the current window\r\n  -> player.seekTo(currentWindowIndex, seekBar.position);\r\n5. Playback continues and eventually transition to the third media item\r\n\r\nI would expect this results in three calls of `onPositionDiscontinuity` with different reasons:\r\n\r\n3. -> when transitioning to the second item there is a `Player.DISCONTINUITY_REASON_PERIOD_TRANSITION`. At the time you receive the callback the currentWindowIndex is already 1 for the second item and the currentPosition close to or equal to 0 (zero).\r\n\r\n4. -> when you seek there is a `Player.DISCONTINUITY_REASON_SEEK`. You don't have log output in your code for this which can be a source of confusion. Probably add this when you check again. WHen this callback call arrives you should have a `currentWindowIndex` of 1 again. That's the result of the user seek.\r\n\r\n5. -> Finally you again receive a callback call with `Player.DISCONTINUITY_REASON_PERIOD_TRANSITION` for the transition to the third item. Now `currentWindowIndex` is 2 and the `currentPosition` close to or equal to 0 (zero).\r\n\r\nI'm pretty sure that works. People would have told us since a while, if that would not work as expected. I still tested that on a device for illustration of what log statement you can expect. I recommend to add the `EventLogger` to the player if you haven't done this already. I see the following logs which match to what I wrote above:\r\n\r\n```\r\nEventLogger: positionDiscontinuity [eventTime=28.97, mediaPos=0.02, window=1, period=1, PERIOD_TRANSITION]\r\nEventLogger: positionDiscontinuity [eventTime=33.77, mediaPos=120.87, window=1, period=1, SEEK]\r\nEventLogger: positionDiscontinuity [eventTime=43.26, mediaPos=0.02, window=2, period=2, PERIOD_TRANSITION]\r\n```\r\n\r\nCan you check this and verify? If you see something else please add the 'EventLogger' to your player and then take a bug report right after you've seen the erroneous behaviour. Upload the bug report here so I can see what is going on internally."
      },
      {
        "user": "ghost",
        "created_at": "2020-05-21T05:59:20Z",
        "body": "There are 5 videos in `ConcatenatingMediaSource`. And play them with `ClippingMediaSource` \r\nI have used like below:\r\n```\r\n1) 0 - 7392\r\n2) 7392 - 14784\r\n3) 22176 - 29568\r\n4) 14784 - 22176\r\n5) 0 - 29168\r\n```\r\n\r\nHere I have choose 2 videos of `29568` and `29168` milliseconds. But I have split 1st video in 4 section and use `ClippingMediaSource` to play specific duration.\r\nI am seeking seekbar to 5th video means `currentWindowIndex = 4`.\r\nThen player start 1st video means `currentWindowIndex` will be `0`.\r\nSo it will be issue for me.\r\nI have added `EvenLogger`. Please check below logs.\r\n```\r\nVideoSeekBar: currentVideoPosition 4\r\nVideoSeekBar: progress 36666.79\r\nonBindViewHolder: arrVideo[holder.adapterPosition].isSelected 4 true\r\nEventLogger: mediaPeriodReleased [eventTime=664.82, mediaPos=36.67, window=4, period=4]\r\nEventLogger: seekProcessed [eventTime=664.82, mediaPos=36.67, window=4]\r\nEventLogger: mediaPeriodCreated [eventTime=664.82, mediaPos=36.67, window=4, period=4]\r\nEventLogger: timeline [eventTime=664.82, mediaPos=36.67, window=4, period=4, periodCount=5, windowCount=5, reason=DYNAMIC\r\nEventLogger:   period [7.39]\r\nEventLogger:   period [14.78]\r\nEventLogger:   period [29.57]\r\nEventLogger:   ...\r\nEventLogger:   window [7.39, true, false]\r\nchatty: uid=10143(com.howto.demo) identical 1 line\r\nEventLogger:   window [7.39, true, false]\r\nEventLogger:   ...\r\nEventLogger: ]\r\nMediaCodecInfo: AssumedSupport [sizeAndRate.rotated, 640x1136x55.964298248291016] [OMX.google.h264.decoder, video/avc] [generic_x86, Android SDK built for x86, Google, 29]\r\nMediaCodecInfo: AssumedSupport [sizeAndRate.rotated, 640x1136x55.964298248291016] [OMX.google.h264.decoder, video/avc] [generic_x86, Android SDK built for x86, Google, 29]\r\nEventLogger: decoderEnabled [eventTime=664.85, mediaPos=36.67, window=4, period=4, video]\r\nEventLogger: decoderEnabled [eventTime=664.86, mediaPos=36.67, window=4, period=4, audio]\r\nEventLogger: tracks [eventTime=664.86, mediaPos=36.67, window=4, period=4, []]\r\nEventLogger: loading [eventTime=664.86, mediaPos=36.67, window=4, period=4, false]\r\nEventLogger: mediaPeriodReadingStarted [eventTime=664.86, mediaPos=36.67, window=4, period=4]\r\nEventLogger: state [eventTime=664.88, mediaPos=36.67, window=4, period=4, false, ENDED]\r\nonPlayerStateChanged: STATE_ENDED\r\nEventLogger: seekStarted [eventTime=664.88, mediaPos=36.67, window=4, period=4]\r\nEventLogger: positionDiscontinuity [eventTime=664.88, mediaPos=0.00, window=0, SEEK]\r\nonBindViewHolder: arrVideo[holder.adapterPosition].isSelected 4 false\r\nEventLogger: mediaPeriodReleased [eventTime=664.90, mediaPos=0.00, window=4, period=4]\r\nEventLogger: decoderDisabled [eventTime=664.90, mediaPos=0.00, window=4, period=4, video]\r\nEventLogger: decoderDisabled [eventTime=664.90, mediaPos=0.00, window=4, period=4, audio]\r\nEventLogger: positionDiscontinuity [eventTime=664.90, mediaPos=0.00, window=0, SEEK_ADJUSTMENT]\r\nonPlayerStateChanged: TIMELINE_CHANGE_REASON_DYNAMIC\r\nEventLogger: tracks [eventTime=664.90, mediaPos=0.00, window=0, []]\r\nEventLogger: state [eventTime=664.90, mediaPos=0.00, window=0, false, BUFFERING]\r\nEventLogger: seekProcessed [eventTime=664.90, mediaPos=0.00, window=0]\r\nEventLogger: mediaPeriodCreated [eventTime=664.90, mediaPos=0.00, window=0, period=0]\r\nEventLogger: loading [eventTime=664.90, mediaPos=0.00, window=0, period=0, true]\r\nEventLogger: timeline [eventTime=664.90, mediaPos=0.00, window=0, period=0, periodCount=5, windowCount=5, reason=DYNAMIC\r\nEventLogger:   period [7.39]\r\nEventLogger:   period [14.78]\r\nEventLogger:   period [29.57]\r\nEventLogger:   ...\r\nEventLogger:   window [7.39, true, false]\r\nchatty: uid=10143(com.howto.demo) identical 1 line\r\nEventLogger:   window [7.39, true, false]\r\nEventLogger:   ...\r\nEventLogger: ]\r\nEventLogger: decoderEnabled [eventTime=664.93, mediaPos=0.00, window=0, period=0, video]\r\nEventLogger: decoderEnabled [eventTime=664.93, mediaPos=0.00, window=0, period=0, audio]\r\nEventLogger: tracks [eventTime=664.93, mediaPos=0.00, window=0, period=0, []]\r\nEventLogger: mediaPeriodReadingStarted [eventTime=664.93, mediaPos=0.00, window=0, period=0]\r\nEventLogger: downstreamFormat [eventTime=664.94, mediaPos=0.00, window=0, period=0, id=1, mimeType=video/avc, res=1280x720, fps=25.0]\r\nEventLogger: decoderInputFormat [eventTime=664.94, mediaPos=0.00, window=0, period=0, video, id=1, mimeType=video/avc, res=1280x720, fps=25.0]\r\nEventLogger: downstreamFormat [eventTime=664.94, mediaPos=0.00, window=0, period=0, id=2, mimeType=audio/mp4a-latm, channels=6, sample_rate=48000, language=und]\r\nEventLogger: decoderInputFormat [eventTime=664.94, mediaPos=0.00, window=0, period=0, audio, id=2, mimeType=audio/mp4a-latm, channels=6, sample_rate=48000, language=und]\r\nEventLogger: mediaPeriodCreated [eventTime=664.96, mediaPos=0.00, window=1, period=1]\r\nEventLogger: videoSize [eventTime=665.05, mediaPos=0.00, window=0, period=0, 1280, 720]\r\nEventLogger: renderedFirstFrame [eventTime=665.06, mediaPos=0.00, window=0, period=0, Surface(name=null)/@0x56c8793]\r\nEventLogger: state [eventTime=665.06, mediaPos=0.00, window=0, period=0, false, READY]\r\nonPlayerStateChanged: STATE_READY updateProgressBar called\r\nEventLogger: loading [eventTime=665.10, mediaPos=0.00, window=0, period=0, false]\r\nOnTouchEvent: MotionEvent.ACTION_UP on draw will call\r\nonStopTrackingTouch: Called\r\nVideoSeekBar: currentVideoPosition 4\r\nVideoSeekBar: progress 36666.79\r\nEventLogger: seekStarted [eventTime=665.32, mediaPos=0.00, window=0, period=0]\r\nEventLogger: positionDiscontinuity [eventTime=665.34, mediaPos=36.67, window=4, SEEK]\r\nEventLogger: state [eventTime=665.34, mediaPos=36.67, window=4, true, READY]\r\nEventLogger: isPlaying [eventTime=665.34, mediaPos=36.67, window=4, true]\r\nonPlayerStateChanged: STATE_READY updateProgressBar called\r\nonBindViewHolder: arrVideo[holder.adapterPosition].isSelected 4 true\r\nEventLogger: mediaPeriodReleased [eventTime=665.36, mediaPos=36.67, window=0, period=0]\r\nEventLogger: mediaPeriodReleased [eventTime=665.36, mediaPos=36.67, window=1, period=1]\r\nEventLogger: decoderDisabled [eventTime=665.36, mediaPos=36.67, window=0, period=0, video]\r\nEventLogger: decoderDisabled [eventTime=665.36, mediaPos=36.67, window=0, period=0, audio]\r\nEventLogger: tracks [eventTime=665.36, mediaPos=36.67, window=4, []]\r\nEventLogger: state [eventTime=665.36, mediaPos=36.67, window=4, true, BUFFERING]\r\nEventLogger: isPlaying [eventTime=665.36, mediaPos=36.67, window=4, false]\r\nEventLogger: seekProcessed [eventTime=665.36, mediaPos=36.67, window=4]\r\nEventLogger: mediaPeriodCreated [eventTime=665.36, mediaPos=36.67, window=4, period=4]\r\nEventLogger: loading [eventTime=665.36, mediaPos=36.67, window=4, period=4, true]\r\nEventLogger: timeline [eventTime=665.36, mediaPos=36.67, window=4, period=4, periodCount=5, windowCount=5, reason=DYNAMIC\r\nEventLogger:   period [7.39]\r\nEventLogger:   period [14.78]\r\nEventLogger:   period [29.57]\r\nEventLogger:   ...\r\nEventLogger:   window [7.39, true, false]\r\nchatty: uid=10143(com.howto.demo) identical 1 line\r\nEventLogger:   window [7.39, true, false]\r\nEventLogger:   ...\r\nEventLogger: ]\r\nMediaCodecInfo: AssumedSupport [sizeAndRate.rotated, 640x1136x55.964298248291016] [OMX.google.h264.decoder, video/avc] [generic_x86, Android SDK built for x86, Google, 29]\r\nMediaCodecInfo: AssumedSupport [sizeAndRate.rotated, 640x1136x55.964298248291016] [OMX.google.h264.decoder, video/avc] [generic_x86, Android SDK built for x86, Google, 29]\r\nEventLogger: decoderEnabled [eventTime=665.40, mediaPos=36.67, window=4, period=4, video]\r\nEventLogger: decoderEnabled [eventTime=665.40, mediaPos=36.67, window=4, period=4, audio]\r\nEventLogger: tracks [eventTime=665.40, mediaPos=36.67, window=4, period=4, []]\r\nEventLogger: loading [eventTime=665.41, mediaPos=36.67, window=4, period=4, false]\r\nEventLogger: mediaPeriodReadingStarted [eventTime=665.41, mediaPos=36.67, window=4, period=4]\r\nEventLogger: state [eventTime=665.42, mediaPos=36.67, window=4, period=4, true, ENDED]\r\nonPlayerStateChanged: STATE_ENDED\r\nEventLogger: seekStarted [eventTime=665.42, mediaPos=36.67, window=4, period=4]\r\nEventLogger: positionDiscontinuity [eventTime=665.42, mediaPos=0.00, window=0, SEEK]\r\nonBindViewHolder: arrVideo[holder.adapterPosition].isSelected 4 false\r\nEventLogger: mediaPeriodReleased [eventTime=665.44, mediaPos=0.00, window=4, period=4]\r\nEventLogger: decoderDisabled [eventTime=665.44, mediaPos=0.00, window=4, period=4, video]\r\nEventLogger: decoderDisabled [eventTime=665.44, mediaPos=0.00, window=4, period=4, audio]\r\nEventLogger: positionDiscontinuity [eventTime=665.44, mediaPos=0.00, window=0, SEEK_ADJUSTMENT]\r\nonPlayerStateChanged: TIMELINE_CHANGE_REASON_DYNAMIC\r\nEventLogger: tracks [eventTime=665.44, mediaPos=0.00, window=0, []]\r\nEventLogger: state [eventTime=665.44, mediaPos=0.00, window=0, true, BUFFERING]\r\nEventLogger: seekProcessed [eventTime=665.44, mediaPos=0.00, window=0]\r\nEventLogger: mediaPeriodCreated [eventTime=665.44, mediaPos=0.00, window=0, period=0]\r\nEventLogger: loading [eventTime=665.44, mediaPos=0.00, window=0, period=0, true]\r\nEventLogger: timeline [eventTime=665.44, mediaPos=0.00, window=0, period=0, periodCount=5, windowCount=5, reason=DYNAMIC\r\nEventLogger:   period [7.39]\r\nEventLogger:   period [14.78]\r\nEventLogger:   period [29.57]\r\nEventLogger:   ...\r\nEventLogger:   window [7.39, true, false]\r\nchatty: uid=10143(com.howto.demo) identical 1 line\r\nEventLogger:   window [7.39, true, false]\r\nEventLogger:   ...\r\nEventLogger: ]\r\nEventLogger: decoderEnabled [eventTime=665.47, mediaPos=0.00, window=0, period=0, video]\r\nEventLogger: decoderEnabled [eventTime=665.47, mediaPos=0.00, window=0, period=0, audio]\r\nEventLogger: tracks [eventTime=665.47, mediaPos=0.00, window=0, period=0, []]\r\nEventLogger: mediaPeriodReadingStarted [eventTime=665.47, mediaPos=0.00, window=0, period=0]\r\nEventLogger: downstreamFormat [eventTime=665.47, mediaPos=0.00, window=0, period=0, id=1, mimeType=video/avc, res=1280x720, fps=25.0]\r\nEventLogger: decoderInputFormat [eventTime=665.47, mediaPos=0.00, window=0, period=0, video, id=1, mimeType=video/avc, res=1280x720, fps=25.0]\r\nEventLogger: downstreamFormat [eventTime=665.47, mediaPos=0.00, window=0, period=0, id=2, mimeType=audio/mp4a-latm, channels=6, sample_rate=48000, language=und]\r\nEventLogger: decoderInputFormat [eventTime=665.47, mediaPos=0.00, window=0, period=0, audio, id=2, mimeType=audio/mp4a-latm, channels=6, sample_rate=48000, language=und]\r\nEventLogger: mediaPeriodCreated [eventTime=665.48, mediaPos=0.00, window=1, period=1]\r\nEventLogger: videoSize [eventTime=665.53, mediaPos=0.00, window=0, period=0, 1280, 720]\r\nEventLogger: renderedFirstFrame [eventTime=665.55, mediaPos=0.00, window=0, period=0, Surface(name=null)/@0x56c8793]\r\nEventLogger: state [eventTime=665.55, mediaPos=0.00, window=0, period=0, true, READY]\r\nonPlayerStateChanged: STATE_READY updateProgressBar called\r\nEventLogger: isPlaying [eventTime=665.55, mediaPos=0.00, window=0, period=0, true]\r\n```\r\nThank you."
      },
      {
        "user": "marcbaechinger",
        "created_at": "2020-05-21T12:01:31Z",
        "body": "I think it happens when the player has finished playing and transition to `STATE_ENDED`. You log something to the console so you probably have more event listeners than you showed in the code snippet above. \r\n\r\nFirstly, I'd recommend again to remove the case `TIMELINE_CHANGE_REASON_DYNAMIC` from `onPositionDiscontinuity`. That might be confusing. Then I'd look what the code does in `onPlayerStateChanged()` when the state transitions to `STATE_ENDED` (see log snippet below). \r\n\r\nThe log says that there is a seek right when the player falls into `STATE_ENDED`. After that seek, the player is on position 0 in window 0. Can you look for the source of this seek?\r\n\r\n```\r\nEventLogger: state [eventTime=664.88, mediaPos=36.67, window=4, period=4, false, ENDED]\r\nonPlayerStateChanged: STATE_ENDED\r\nEventLogger: seekStarted [eventTime=664.88, mediaPos=36.67, window=4, period=4]\r\nEventLogger: positionDiscontinuity [eventTime=664.88, mediaPos=0.00, window=0, SEEK]\r\nonBindViewHolder: arrVideo[holder.adapterPosition].isSelected 4 false\r\nEventLogger: mediaPeriodReleased [eventTime=664.90, mediaPos=0.00, window=4, period=4]\r\nEventLogger: decoderDisabled [eventTime=664.90, mediaPos=0.00, window=4, period=4, video]\r\nEventLogger: decoderDisabled [eventTime=664.90, mediaPos=0.00, window=4, period=4, audio]\r\nEventLogger: positionDiscontinuity [eventTime=664.90, mediaPos=0.00, window=0, SEEK_ADJUSTMENT]\r\nonPlayerStateChanged: TIMELINE_CHANGE_REASON_DYNAMIC\r\n```"
      },
      {
        "user": "ghost",
        "created_at": "2020-05-21T14:12:57Z",
        "body": "Yes, I have checked seek position and changed it.\r\nNow it is working.\r\nThank you so much for your help and support."
      },
      {
        "user": "marcbaechinger",
        "created_at": "2020-05-21T14:32:10Z",
        "body": "Cool. Thanks for letting me know. I close the issue. Please re-open if required."
      }
    ],
    "satisfaction_conditions": [
      "Ensure proper handling of player state transitions when seeking within ConcatenatingMediaSource",
      "Maintain accurate window index mapping during seek operations",
      "Handle position discontinuities caused by both user seeks and automatic transitions",
      "Ensure timeline consistency when using dynamic media source modifications",
      "Proper synchronization between seekbar position and actual media source windows"
    ]
  },
  {
    "number": 7343,
    "title": "vp8 decode error",
    "created_at": "2020-05-07T09:36:56Z",
    "closed_at": "2020-05-07T10:02:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/7343",
    "body": "Hello, may I ask if I added the adaptation of vp8 in the vp9 extension, added vp8 decoding in generate_libvpx_android_configs.sh, the compilation shows that it passed, and the vp8 module has been integrated, but when running, the vp8 decoding error Decode error: Bitstream not supported by this decoder\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/7343/comments",
    "author": "kuailedeadai",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2020-05-07T10:02:57Z",
        "body": "It's difficult to know the cause based on the information you've provided, but one thing to note is that in `vpx_jni.cc` in the VP9 extension you will need to initialize the right codec in the call to `vpx_codec_dec_init` (you can use `get_vpx_decoder_by_name` to get the right codec interface to pass into that method). Caveat: last time I did this was in 2016 so the APIs may have changed!\r\n\r\nAs this is not something we support at the moment, and it seems unlikely we would add support given it hasn't been requested and the codec has been superseded, I will close this for now."
      },
      {
        "user": "kuailedeadai",
        "created_at": "2020-05-07T11:45:13Z",
        "body": "Thanks, your suggestion has solved my problem"
      }
    ],
    "satisfaction_conditions": [
      "Identifies the correct codec initialization method for VP8 decoding integration",
      "Addresses decoder configuration mismatch between integration and runtime execution",
      "Provides guidance for decoder interface selection in the codebase architecture"
    ]
  },
  {
    "number": 7276,
    "title": "PlayerNotificationManager event onNotificationCanceled is never called",
    "created_at": "2020-04-21T18:08:56Z",
    "closed_at": "2020-04-22T12:50:16Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/7276",
    "body": "### [REQUIRED] Issue description\r\nHi everyone, \r\n\r\nNotification cannot be swiped and onNotificationCanceled is never called.\r\n\r\n### [REQUIRED] Reproduction steps\r\n```\r\n`\r\n@Override\r\npublic void onCreate() {\r\nsuper.onCreate();\r\n\r\nfinal Context context = this;\r\n\r\nplayer = ExoPlayerFactory.newSimpleInstance(context, new DefaultTrackSelector());\r\n\r\n// playlist preparation\r\n\r\n// player.prepare(concatenatedSource, false, false);\r\nplayer.prepare(playlist);\r\nplayer.setPlayWhenReady(true);\r\n\r\nPlayerNotificationManager.MediaDescriptionAdapter notificationAdapter = new PlayerNotificationManager.MediaDescriptionAdapter() {\r\n    // implementation\r\n};\r\n\r\nPlayerNotificationManager.NotificationListener notificationListener = new PlayerNotificationManager.NotificationListener() {\r\n\r\n    @Override\r\n    public void onNotificationCancelled(int notificationId, boolean dismissedByUser) {\r\n        System.out.println(\"onNotificationCancelled dismissedByUser \"+dismissedByUser);\r\n        stopForeground(true);\r\n    }\r\n\r\n    @Override\r\n    public void onNotificationPosted(int notificationId, Notification notification, boolean ongoing) {\r\n        startForeground(notificationId, notification);\r\n    }\r\n};\r\n\r\nIntent dialogIntent = new Intent(this, PlayerActivity.class);\r\ndialogIntent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK);\r\n\r\nstartActivity(dialogIntent);\r\nplayerNotificationManager = PlayerNotificationManager.createWithNotificationChannel(\r\n        context, \"channelId\", R.string.player_activity_name, R.string.player_activity_description, 1, notificationAdapter, notificationListener );\r\nplayerNotificationManager.setPlayer(player);\r\n```\r\n`\r\n\r\n### [REQUIRED] Version of ExoPlayer being used\r\ncom.google.android.exoplayer:exoplayer-core:2.10.5\r\n\r\n### [REQUIRED] Device(s) and version(s) of Android being used\r\n    compileSdkVersion 29\r\n    defaultConfig {\r\n        minSdkVersion 16\r\n        targetSdkVersion 29\r\n\r\nMany thanks !!",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/7276/comments",
    "author": "ghost",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2020-04-22T12:25:04Z",
        "body": "The notification can only be swiped when not assigned to a foreground service. So it requires you to stop the foreground service, when the notification is not ongoing anymore (that is when the player is paused).\r\n\r\nYou are pretty close to that already with the code you show above.  You need to change `onNotificationPosted()` and check wether the notification is still ongoing. If paused `isOngoing` is false and you should stop the foreground service. Now the notification can be swiped, because it's not tied to a foreground service anymore.\r\n\r\nWhen you receive the cancellation event after swipe, you can totally destroy your service. The user needs to restart in the app UI without notification. That's when you can start the cycle again and start your foreground service again.\r\n\r\nThat could probably look like this:\r\n\r\n```\r\n@Override\r\npublic void onNotificationPosted(\r\n    int notificationId, Notification notification, boolean ongoing) {\r\n  if (ongoing) {\r\n    startForeground(notificationId, notification);\r\n   } else {\r\n     stopForeground(/* removeNotification= */ false);\r\n   }\r\n}\r\n\r\n@Override\r\npublic void onNotificationCancelled(int notificationId, boolean dismissedByUser) {\r\n   stopSelf();\r\n}\r\n``` \r\n\r\nPlease let me know if this help."
      },
      {
        "user": "ghost",
        "created_at": "2020-04-22T12:50:16Z",
        "body": "I understand perfectly I think, it works as expected. Thank you so much!"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of foreground service binding requirements for notification swipeability",
      "Guidance on handling notification ongoing state transitions",
      "Mechanism to trigger service termination on notification dismissal",
      "Clear lifecycle management between notifications and playback service"
    ]
  },
  {
    "number": 7175,
    "title": "IndexOutOfBoundsException - while checking if media isLive",
    "created_at": "2020-04-02T15:16:45Z",
    "closed_at": "2020-04-03T12:52:44Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/7175",
    "body": "Hi,\r\n\r\nWhile checking the isLive new API  \r\nin the Demo app in v2.11.3 version I get this exception after executing the below code.\r\nrunning this on Pixel 3 android 10\r\n\r\nNo sure what is the best approach here but I was expecting to get false\r\nunless it should be called only after player is READY\r\n\r\nis there a way to add api that checks is there is a window  before calling get, so this  case can be checked before accessing the window?\r\n\r\ndo you think I should stick to our current logic that uses -  `player.isCurrentWindowDynamic()`\r\n```\r\n     player.prepare(mediaSource, !haveStartPosition, false);\r\n    boolean isLive = false;\r\n    \r\n    if (player.getCurrentTimeline() != null) {\r\n      isLive = player.getCurrentTimeline().getWindow(player.getCurrentWindowIndex(), new Timeline.Window()).isLive;\r\n    }\r\n```\r\n\r\n\r\n10x\r\nGilad.\r\n\r\n2020-04-02 18:02:19.419 13123-13123/com.google.android.exoplayer2.demo E/AndroidRuntime: FATAL EXCEPTION: main\r\n    Process: com.google.android.exoplayer2.demo, PID: 13123\r\n    java.lang.IndexOutOfBoundsException\r\n        at com.google.android.exoplayer2.Timeline$1.getWindow(Timeline.java:550)\r\n        at com.google.android.exoplayer2.Timeline.getWindow(Timeline.java:668)\r\n        at com.google.android.exoplayer2.demo.PlayerActivity.initializePlayer(PlayerActivity.java:412)\r\n        at com.google.android.exoplayer2.demo.PlayerActivity.onStart(PlayerActivity.java:240)\r\n        at android.app.Instrumentation.callActivityOnStart(Instrumentation.java:1432)\r\n        at android.app.Activity.performStart(Activity.java:7848)\r\n        at android.app.ActivityThread.handleStartActivity(ActivityThread.java:3294)\r\n        at android.app.servertransaction.TransactionExecutor.performLifecycleSequence(TransactionExecutor.java:221)\r\n        at android.app.servertransaction.TransactionExecutor.cycleToPath(TransactionExecutor.java:201)\r\n        at android.app.servertransaction.TransactionExecutor.executeLifecycleState(TransactionExecutor.java:173)\r\n        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:97)\r\n        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2016)\r\n        at android.os.Handler.dispatchMessage(Handler.java:107)\r\n        at android.os.Looper.loop(Looper.java:214)\r\n        at android.app.ActivityThread.main(ActivityThread.java:7356)\r\n        at java.lang.reflect.Method.invoke(Native Method)\r\n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/7175/comments",
    "author": "giladna",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2020-04-03T12:52:44Z",
        "body": "You can check `timeline.getWindowCount()` or `timeline.isEmpty()`."
      },
      {
        "user": "tonihei",
        "created_at": "2020-04-03T12:57:40Z",
        "body": "Actually, the preferred way to check if media is live is to use `player.isCurrentWindowLive()`.  This already includes the check Andrew mentioned above."
      },
      {
        "user": "giladna",
        "created_at": "2020-04-05T10:13:19Z",
        "body": "thanks!"
      }
    ],
    "satisfaction_conditions": [
      "Ensure safe timeline/window access before checking liveness",
      "Provide API-compatible method for liveness checks",
      "Handle player state readiness requirements",
      "Maintain equivalent functionality to isCurrentWindowDynamic()"
    ]
  },
  {
    "number": 6979,
    "title": "different mimeType between FlacExtractor and LibflacAudioRenderer",
    "created_at": "2020-02-15T04:13:10Z",
    "closed_at": "2020-02-17T14:28:56Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/6979",
    "body": "Hello, I don't figure out that the mimeType is \"audio/raw\" in FlacExtractor of FLAC extension. However, the specific mimeType is \"audio/flac\" in LibflacAudioRenderer. As s result, LibflacAudioRenderer couldn't work for FlacExtractor.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/6979/comments",
    "author": "xufuji456",
    "comments": [
      {
        "user": "kim-vde",
        "created_at": "2020-02-17T10:29:21Z",
        "body": "The `FlacExtractor` from the FLAC extension is not intended to be used with the `LibflacAudioRenderer` because the frames are decoded directly in the extractor and PCM data is therefore outputted. You have 2 possibilities:\r\n- use the `FlacExtractor` from the FLAC extension and render with `MediaCodecAudioRenderer`, or\r\n- use the (newly-released) `FlacExtractor` from the core library and render with any renderer able to decode FLAC frames (`MediaCodecAudioRenderer` from API 27+, `LibflacAudioRenderer`, `FfmpegAudioRenderer`)."
      },
      {
        "user": "xufuji456",
        "created_at": "2020-02-17T14:28:41Z",
        "body": "@kim-vde Thank you very much. I got it."
      }
    ],
    "satisfaction_conditions": [
      "Clarify compatibility requirements between FlacExtractor implementations and audio renderers",
      "Provide valid component pairing options that ensure matching mimeType handling",
      "Explain the fundamental difference between raw PCM output vs encoded FLAC frame processing"
    ]
  },
  {
    "number": 6959,
    "title": "Calculating total playback time of a media.",
    "created_at": "2020-02-10T11:25:57Z",
    "closed_at": "2020-02-11T11:05:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/6959",
    "body": "**Scenario**: \r\nI want to calculate the total playback time for a media until the user switches to a different media by going to the next or previous media. \r\n\r\n**Problem**:\r\nI have covered all the possible scenarios except one, when the user switches to the next track/media after playing the media for a while, I'm not able to get the **playbackEndTime**. \r\nWhere **playbackEndTime** is the last known position from where the media was discontinued.\r\n\r\nIn this case the `EventTime.currentPlaybackPositionMs` is always 0 in every Callbacks of the AnalyticsListener. \r\n\r\nPlease correct me if my approach is not appropriate. ",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/6959/comments",
    "author": "VivekBhalodiya",
    "comments": [
      {
        "user": "kim-vde",
        "created_at": "2020-02-10T15:15:05Z",
        "body": "What implementation of `AnalyticsListener` are you using? Please provide the code if it is a custom one."
      },
      {
        "user": "VivekBhalodiya",
        "created_at": "2020-02-11T08:48:50Z",
        "body": "```\r\nclass ExoPlayerAnalyticsListener : AnalyticsListener, EventListener {\r\n  private var isSeekStarted: Boolean = false\r\n  private var hasTracksChanged: Boolean = false\r\n  private var playbackStartTime: Long = 0L\r\n  private var playbackEndTime: Long = 0L\r\n  private var isPlayingTime: Long = 0L\r\n  private var totalPlayBack: Long = 0L\r\n  private var currentMediaId: String? = null\r\n  private var window = Window()\r\n\r\n  override fun onPositionDiscontinuity(\r\n    eventTime: EventTime,\r\n    reason: Int\r\n  ) {\r\n    playbackStartTime = eventTime.currentPlaybackPositionMs\r\n  }\r\n\r\n  override fun onTracksChanged(\r\n    eventTime: EventTime,\r\n    trackGroups: TrackGroupArray,\r\n    trackSelections: TrackSelectionArray\r\n  ) {\r\n    hasTracksChanged = true\r\n    // I want the currentPlaybackPositionMs here \r\n  }\r\n\r\n  override fun onSeekStarted(eventTime: EventTime) {\r\n    isSeekStarted = true\r\n    playbackEndTime = eventTime.currentPlaybackPositionMs\r\n    calculatePlayback()\r\n    isSeekStarted = false\r\n  }\r\n\r\n  override fun onPlayerStateChanged(\r\n    eventTime: EventTime,\r\n    playWhenReady: Boolean,\r\n    playbackState: Int\r\n  ) {\r\n     // eventTime.currentPlaybackPositionMs is 0 when track is changed\r\n  }\r\n\r\n  override fun onIsPlayingChanged(\r\n    eventTime: EventTime,\r\n    isPlaying: Boolean\r\n  ) {\r\n    isPlayingTime = eventTime.currentPlaybackPositionMs\r\n    when {\r\n      isPlaying -> playbackStartTime = isPlayingTime\r\n      else -> playbackEndTime = isPlayingTime\r\n    }\r\n    if (isSeekStarted.not())\r\n      calculatePlayback()\r\n  }\r\n\r\n  private fun calculatePlayback() {\r\n    if (hasTracksChanged) {\r\n      hasTracksChanged = false\r\n      resetTrackers()\r\n      return\r\n    }\r\n\r\n    if (playbackStartTime == 0L) {\r\n      //Media is being played from start\r\n      totalPlayBack += playbackEndTime\r\n    } else if (playbackEndTime > playbackStartTime) {\r\n      totalPlayBack += abs(playbackEndTime - playbackStartTime)\r\n    }\r\n  }\r\n\r\n  private fun resetTrackers() { //.. }\r\n}\r\n```"
      },
      {
        "user": "tonihei",
        "created_at": "2020-02-11T09:47:17Z",
        "body": "In case you are using ExoPlayer 2.11, you can use add `PlaybackStatsListener` to retrieve `PlaybackStats` for each playlist item that has a method called `getTotalPlayTimeMs()`. Sounds as if you are trying to calculate this value. "
      },
      {
        "user": "VivekBhalodiya",
        "created_at": "2020-02-11T11:05:47Z",
        "body": "God bless `PlaybackStatsListener`\r\n`getTotalPlayTimeMs()` This is what exactly I've been looking for.\r\nThank you @tonihei  and @kim-vde  for your support. Really appreciate your time. "
      }
    ],
    "satisfaction_conditions": [
      "Provides a way to accurately capture playback end time when switching tracks",
      "Works with ExoPlayer's event system without manual position tracking",
      "Offers built-in playback duration tracking functionality",
      "Handles media transitions automatically"
    ]
  },
  {
    "number": 6847,
    "title": "Blank screen while switching video from portrait to landscape full screen for DRM enabled videos in DASH format",
    "created_at": "2020-01-08T07:37:27Z",
    "closed_at": "2020-01-09T10:22:32Z",
    "labels": [
      "question",
      "documentation candidate"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/6847",
    "body": "Issue description:\r\nWhile switching a video from portrait to landscape mode a blank black screen is visible for a sec before showing the video frame.This happens while switching from landscape to portrait also.This is occuring only for the videos which are DRM protected.This is seen only in few devices.It appears in the exoplayer demo app as well.\r\n\r\nReproduction steps:\r\n1.In the exoplayer demo app play the video with DASH+DRM\r\n2.Enable auto rotate option in settings.\r\n3.Rotate the phone to landscape.\r\n4.A blank screen is shown for a sec before the video frame shows up.\r\n5.Switch to portrait again and see the same blank screen\r\n\r\nLink to test content\r\nYou can check any drm enabled video from the demo app for dash stream.\r\n\r\nVersion of ExoPlayer being used\r\n2.9.0\r\n\r\nDevice(s) and version(s) of Android being used\r\n1.Mi Note 7 Pro Android version:9.0--Issue arises\r\n2.Asus Zenfone Max Pro M2. Android version:8.0--Issue arises\r\n3.Real Me 2 Pro. Android version 9.0--No issue\r\n4.Lenovo K5 note. Android Version 6.0--Issue Arises\r\n5.Samsung Galaxy J2 Pro. Andorid version 6.0--No Issue\r\n6.Mi A2. Android Version 9.0--No issue\r\n7.Redmi Note 3. Android Version 6.0--No issue \r\n\r\nCould you please check into this issue.\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/6847/comments",
    "author": "meenukrishnamurthy",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2020-01-08T07:45:10Z",
        "body": "This is a limitation in the underlying platform. The fact that the output path is secure means that the video buffers aren't available to be composited into the rotation animation when the display orientation changes, so for the duration of the animation the surface appears as though it is black. You will observe the issue in all applications that play DRM protected content."
      },
      {
        "user": "meenukrishnamurthy",
        "created_at": "2020-01-08T07:49:02Z",
        "body": "Can you be more specific as to which underlying platform the issue arises.Because i dont see this issue in all the devices."
      },
      {
        "user": "ojw28",
        "created_at": "2020-01-08T08:01:47Z",
        "body": "As above:\r\n\r\n> The fact that the output path is secure means that the video buffers aren't available to be composited into the rotation animation when the display orientation changes, so for the duration of the animation the surface appears as though it is black.\r\n\r\nI'm not sure why you don't see the issue on all devices, but my best guess would be that your content doesn't require a secure output path in the license policy, and that the devices where you don't see the issue only support L3 Widevine. If that's the case then you could try forcing L3 Widevine on all devices, to see if that resolves the problem.\r\n\r\nAlternatively, is it possible the devices where you don't see the issue simply don't animate orientation changes?"
      },
      {
        "user": "meenukrishnamurthy",
        "created_at": "2020-01-09T07:07:45Z",
        "body": "Thanks a lot @ojw28 . Forcing to L3 on all devices worked for me."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why DRM security level affects screen rotation transitions",
      "Solution that prevents secure output path interference during orientation changes",
      "Clarification of device-specific behavior variations",
      "Workaround that maintains DRM protection while avoiding visual glitches"
    ]
  },
  {
    "number": 6759,
    "title": "How to get BufferInfo in ExoPlayer 2?",
    "created_at": "2019-12-12T14:27:12Z",
    "closed_at": "2019-12-12T19:01:21Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/6759",
    "body": "Hi,\r\n**BufferInfo** was available in ExoPlayer 1 in the **processOutputBuffer** method, But in curently veresion bufferInfo not exist in **processOutputBuffer**\r\nIn version 1 I had access to **BufferInfo** by extending **MediaCodecAudioRenderer** Class and implementing **processOutputBuffer**\r\nAs you can see below\r\n\r\nVersion 1:\r\n```\r\n@Override\r\nprotected boolean processOutputBuffer(long positionUs,\r\n                                      long elapsedRealtimeUs,\r\n                                      MediaCodec codec,\r\n                                      ByteBuffer buffer,\r\n                                      MediaCodec.BufferInfo bufferInfo, //TODO: BufferInfo\r\n                                      int bufferIndex,\r\n                                      boolean shouldSkip)\r\n        throws com.google.android.exoplayer.ExoPlaybackException {\r\n\r\n    //using bufferInfo\r\n\r\n    return super.processOutputBuffer(positionUs,\r\n            elapsedRealtimeUs,\r\n            codec,\r\n            buffer,\r\n            bufferInfo,\r\n            bufferIndex,\r\n            shouldSkip);\r\n}\r\n```\r\nLast Version:\r\n```\r\n    protected boolean processOutputBuffer(long positionUs,\r\n                                          long elapsedRealtimeUs,\r\n                                          MediaCodec codec,\r\n                                          ByteBuffer buffer,\r\n                                          int bufferIndex,\r\n                                          int bufferFlags,\r\n                                          long bufferPresentationTimeUs,\r\n                                          boolean isDecodeOnlyBuffer,\r\n                                          boolean isLastBuffer,\r\n                                          Format format) throws ExoPlaybackException {\r\n\r\n        return super.processOutputBuffer(positionUs,\r\n                elapsedRealtimeUs,\r\n                codec,\r\n                buffer,\r\n                bufferIndex,\r\n                bufferFlags,\r\n                bufferPresentationTimeUs,\r\n                isDecodeOnlyBuffer,\r\n                isLastBuffer,\r\n                format);\r\n    }\r\n```\r\nAs you can see there is no **BufferInfo** inside **processOutputBuffer** method in the last version\r\nI need to get BufferInfo for read '**size**' and '**offset**' and '**presentationTimeUs**', How to do this in the latest version?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/6759/comments",
    "author": "saleh-gholamian",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2019-12-12T19:01:21Z",
        "body": "All the information is still there. It's just in slightly different places:\r\n* `bufferFlags` in V2 is the same as `bufferInfo.flags` in V1\r\n* `bufferPresentationTimeUs` in V2 is the same as `bufferInfo.presentationTimeUs` in V1\r\n* `buffer.position()` in V2 is the same as `bufferInfo.offset` in V1\r\n* `buffer.limit() - buffer.position()` in V2 is the same as `bufferInfo.size` in V1"
      },
      {
        "user": "saleh-gholamian",
        "created_at": "2019-12-13T08:54:39Z",
        "body": "> All the information is still there. It's just in slightly different places:\r\n\r\n    bufferFlags in V2 is the same as bufferInfo.flags in V1\r\n    bufferPresentationTimeUs in V2 is the same as bufferInfo.presentationTimeUs in V1\r\n    buffer.position() in V2 is the same as bufferInfo.offset in V1\r\n    buffer.limit() - buffer.position() in V2 is the same as bufferInfo.size in V1\r\n\r\nVery Thanks"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to retrieve buffer size, offset, and presentation time equivalents in ExoPlayer 2",
      "Mapping between legacy BufferInfo fields and current ExoPlayer 2 API parameters",
      "Clarification of parameter relationships in processOutputBuffer method",
      "Solution must work within ExoPlayer 2's renderer architecture"
    ]
  },
  {
    "number": 6718,
    "title": "Where is the code that hide a subtitle since being elapsed a given time?",
    "created_at": "2019-12-02T14:41:37Z",
    "closed_at": "2019-12-03T01:54:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/6718",
    "body": "### Problem.\r\n  I have searched Cue.java, Subtitle.java, SimpleExoPlayer.java and so on  for the codes that hide a subtitle since being elapsed a given time. But I couldn't at this moment.\r\n\r\nPlease Let me know where the codes are.\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/6718/comments",
    "author": "tuxxon",
    "comments": [
      {
        "user": "kim-vde",
        "created_at": "2019-12-02T16:33:08Z",
        "body": "The display of cues is based on events, as you can see in class `Subtitle`. A cue disappears when a new event (containing an empty cue or another cue to display) starts.\r\n\r\nThe display of subtitles is handled in `SubtitleView`. If you want to implement your own display, you will need to write a new class that implements interface `TextOutput`.\r\n\r\nDoes that answer your question? If not, could you be more specific about what you are looking for exactly and about what you want to achieve?"
      },
      {
        "user": "tuxxon",
        "created_at": "2019-12-03T01:54:30Z",
        "body": "Thank you for your commenting. \r\n\r\nWith your comment when I have checked out ***onCues()*** including ***cues.size(), player.getCurrentPostion()***, I got an empty cue and current position.\r\n\r\nI am really appreciated for this.\r\n"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of the event-driven mechanism controlling subtitle visibility",
      "Identification of key methods/classes involved in subtitle lifecycle management",
      "Clarification of how empty cues signal subtitle removal",
      "Guidance on tracking playback timing relationships"
    ]
  },
  {
    "number": 6710,
    "title": "Exoplayer releases itself when in background",
    "created_at": "2019-11-29T09:55:01Z",
    "closed_at": "2019-11-30T15:26:17Z",
    "labels": [
      "question",
      "need more info"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/6710",
    "body": "#6386 # [REQUIRED] Searched documentation and issues\r\n\r\nTried searching on Google but didn't find anything relevant.\r\n\r\n### [REQUIRED] Question\r\nI have an app that can play videos. I use a single instance of exoplayer that i initialize in a service so that the user can listen and control the video in background. The problem is that when a video is playing, the user goes into background and then pauses the player for 1-2 minutes exoplayer releases itself. So when the app comes back to the foreground all i have is a black screen playerView with no video in it.\r\n\r\n### A full bug report captured from the device\r\n```\r\n2019-11-29 10:26:51.715 23697-26444/app  D/FA: Application backgrounded\r\n2019-11-29 10:26:51.738 23697-26444/app  D/FA: Logging event (FE): app_background(_ab), Bundle[{ga_event_origin(_o)=auto}]\r\n2019-11-29 10:28:13.053 23697-23697/app  I/ExoPlayerImpl: Release 192e8c2 [ExoPlayerLib/2.10.4] [HWSTK-HF, STK-LX1, HUAWEI, 28] [goog.exo.core, goog.exo.ui, goog.exo.hls]\r\n2019-11-29 10:28:13.080 23697-26655/app  D/android.media.AudioTrack: [HSM] AudioTrace stop() uid: 10308, pid: 23697\r\n2019-11-29 10:28:13.084 23697-25116/app W/ACodec: forcing OMX state to Idle when received shutdown in ExecutingState\r\n2019-11-29 10:28:13.136 23697-25115/app  D/SurfaceUtils: disconnecting from surface 0x723f653010, reason disconnectFromSurface\r\n2019-11-29 10:28:13.167 23697-25127/app  W/ACodec: forcing OMX state to Idle when received shutdown in ExecutingState\r\n```\r\n\r\nAs you can see i backgrounded the video and then pause it. After 1.5 minutes without touching the phone  exoplayer released itself. \r\nI can see how this could be done on purpose to free some resources but is there any way to override this?\r\n\r\nThis is what happens when i bring the app to the foreground:\r\n```\r\n2019-11-29 10:58:47.192 23697-23697/app D/ZrHung.AppEyeUiProbe: notify runnable to start.\r\n2019-11-29 10:58:47.192 23697-23750/app D/ZrHung.AppEyeUiProbe: restart watching\r\n2019-11-29 10:58:47.220 23697-27978/app D/FA: Setting user property (FE): _sid, 1575021527\r\n2019-11-29 10:58:47.278 23697-23768/app D/mali_winsys: EGLint new_window_surface(egl_winsys_display *, void *, EGLSurface, EGLConfig, egl_winsys_surface **, EGLBoolean) returns 0x3000\r\n2019-11-29 10:58:47.289 23697-23697/app I/ExoPlayerImpl: Init aaeb70c [ExoPlayerLib/2.10.4] [HWSTK-HF, STK-LX1, HUAWEI, 28]\r\n2019-11-29 10:58:47.296 23697-27978/app D/FA: Logging event (FE): session_start(_s), Bundle[{ga_event_origin(_o)=auto, ga_session_id(_sid)=1575021527}]\r\n2019-11-29 10:58:47.330 23697-27978/app D/FA: Logging event (FE): app_start, Bundle[{method=app_start, ga_event_origin(_o)=app, ga_screen_class(_sc)=MainActivity, ga_screen_id(_si)=5911828178843061323}]\r\n2019-11-29 10:58:47.454 23697-23697/app I/ViewRootImpl: jank_removeInvalidNode all the node in jank list is out of time\r\n2019-11-29 10:58:47.465 23697-23697/app W/InputMethodManager: startInputReason = 1\r\n2019-11-29 10:58:47.500 23697-27978/app D/FA: Connected to remote service\r\n```\r\n\r\nI'm pretty new at this so i don't really understand what all this means or if it's useful at all.\r\nThanks in advance for your time!\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/6710/comments",
    "author": "Cosminnv",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2019-11-30T15:10:16Z",
        "body": "I don't think ExoPlayer does release itself automatically after a given time. But probably the service does release the player when it is destroyed, which would be the correct behaviour of the service.\r\n\r\nWith the available information that sounds like you may call stopForeground(boolean) when the user pauses the player. With this the service is not running in the foreground anymore and the system may remove/destroy the service after a given amount of time (the 2 minutes you are reporting seems reasonable). \r\n\r\nIf this is the case then the service is behaving correctly and according to what the recommendation is for having the player in a foreground service. If you want to override this, then you should not call stopForeground(boolean) for your service.\r\n\r\nMy recommendation would be to remove the service from the foreground as you do, but then. When the app comes to foreground again you have to restart the service and then resume playback from where it was paused.\r\n\r\nAside: is there a specific reason why you have the player in a service for playing a video? Usually this is required for audio, when playback should continue when the player is in background. In case of video you could have the player living in the activity instead."
      },
      {
        "user": "Cosminnv",
        "created_at": "2019-11-30T15:26:17Z",
        "body": "Hi, thanks for the reply.\r\n\r\nYou're right, i do call stopForeground when the player is paused ,but i only do that because i want the user to be able to swipe the notification away without killing the video ( kinda like spotify does). I'll try to do it like you recommended.\r\n\r\nAlso, i kinda need the player to be in a service because i have video of a guy talking. So you can watch him while he is speaking but you can also only listen to him.\r\n\r\nI think i got everything i needed, thank you very much!"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to prevent ExoPlayer from releasing itself when the app is backgrounded",
      "Guidance on maintaining service lifecycle for persistent video playback control",
      "Strategy for handling system cleanup of background services without losing playback state",
      "Mechanism to restore player state when returning to foreground"
    ]
  },
  {
    "number": 6651,
    "title": "PlayerNotificationManager not cancellable ",
    "created_at": "2019-11-14T09:06:30Z",
    "closed_at": "2019-11-24T15:02:15Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/6651",
    "body": "I am using PlayerNotificationManager and attaching it to Exoplayer.\r\nI want to make the notification as cancellable when the video/audio is paused.\r\n\r\nI am using stopForeground(false) when my video is paused but still the notification is non cancellable.\r\n\r\n```\r\n  class MediaConsumptionService : Service(), Player.EventListener {\r\n\r\n    private var player: SimpleExoPlayer? = null\r\n    var image: Bitmap? = null\r\n    private lateinit var playerNotificationManager: PlayerNotificationManager\r\n\r\n    private val NOTIFICATION_CHANNEL_ID = \"playback_channel\"\r\n    private val NOTIFICATION_ID = 2\r\n    private var additionalJson: String? = null\r\n    private var trackId = 0L\r\n    private var trackTitle = \"\"\r\n    private var trackThumbUrl = \"\"\r\n\r\n    override fun onBind(intent: Intent?): IBinder? {\r\n        return null\r\n    }\r\n\r\n    override fun onCreate() {\r\n        super.onCreate()\r\n    }\r\n\r\n    override fun onStartCommand(intent: Intent?, flags: Int, startId: Int): Int {\r\n\r\n        player = VideoPlayer.getInstance().player\r\n        player?.addListener(this)\r\n        val context = this\r\n\r\n        val bundle = intent?.extras\r\n        if (bundle != null) {\r\n            trackId = bundle.getLong(MVConstants.PLAYBACK_TRACK_ID, 0)\r\n            trackTitle = bundle.getString(MVConstants.PLAYBACK_TRACK_TITLE, \"\")\r\n            trackThumbUrl = bundle.getString(MVConstants.PLAYBACK_TRACK_THUMB, \"\")\r\n            additionalJson = bundle.getString(MVConstants.MEDIA_JSON, \"\")\r\n            Glide.with(context)\r\n                    .asBitmap()\r\n                    .load(trackThumbUrl)\r\n                    .into(object : CustomTarget<Bitmap>() {\r\n\r\n                        override fun onLoadFailed(errorDrawable: Drawable?) {\r\n                            super.onLoadFailed(errorDrawable)\r\n                            addNotificationToPlayer()\r\n                        }\r\n\r\n                        override fun onResourceReady(resource: Bitmap, transition:\r\n                        Transition<in Bitmap>?) {\r\n                            image = resource\r\n                            addNotificationToPlayer()\r\n                        }\r\n\r\n                        override fun onLoadCleared(placeholder: Drawable?) {\r\n                        }\r\n                    })\r\n\r\n        }\r\n\r\n\r\n        return START_NOT_STICKY\r\n    }\r\n\r\n    private fun addNotificationToPlayer() {\r\n        if (player != null) {\r\n\r\n            playerNotificationManager = createWithNotificationChannel(\r\n                    this,\r\n                    NOTIFICATION_CHANNEL_ID,\r\n                    R.string.playback_channel_name,\r\n                    0,\r\n                    NOTIFICATION_ID,\r\n                    object : MediaDescriptionAdapter {\r\n\r\n                        override fun createCurrentContentIntent(player: Player?): PendingIntent? {\r\n                            val intent = VideoPlayer.getInstance().mediaSessionIntent\r\n                            intent.putExtra(MVConstants.MEDIA_JSON, additionalJson)\r\n                            intent.putExtra(MVConstants.PLAYBACK_TRACK_ID, trackId)\r\n                            intent.putExtra(MVConstants.FROM_NOTIFICATION, true)\r\n                            return PendingIntent.getActivity(applicationContext,\r\n                                    2, intent, PendingIntent.FLAG_UPDATE_CURRENT)\r\n                        }\r\n\r\n                        override fun getCurrentContentText(player: Player?): String? {\r\n                            return \"\"\r\n                        }\r\n\r\n                        override fun getCurrentContentTitle(player: Player?): String {\r\n                            return trackTitle\r\n                        }\r\n\r\n                        override fun getCurrentLargeIcon(player: Player?, callback:\r\n                        BitmapCallback?): Bitmap? {\r\n                            return image\r\n\r\n                        }\r\n                    },\r\n                    object : NotificationListener {\r\n\r\n                        override fun onNotificationPosted(notificationId: Int,\r\n                                                          notification: Notification?,\r\n                                                          ongoing: Boolean) {\r\n                            super.onNotificationPosted(notificationId, notification, ongoing)\r\n                            startForeground(notificationId, notification)\r\n                        }\r\n\r\n                        override fun onNotificationCancelled(notificationId: Int,\r\n                                                             dismissedByUser: Boolean) {\r\n                            super.onNotificationCancelled(notificationId, dismissedByUser)\r\n                            stopSelf()\r\n                        }\r\n                    }\r\n            )\r\n            // omit skip previous and next actions\r\n            playerNotificationManager.setUseNavigationActions(false);\r\n            // omit fast forward action by setting the increment to zero\r\n            playerNotificationManager.setFastForwardIncrementMs(0);\r\n            // omit rewind action by setting the increment to zero\r\n            playerNotificationManager.setRewindIncrementMs(0);\r\n\r\n            playerNotificationManager.setSmallIcon(R.drawable.ico_notification_wings)\r\n\r\n            if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP) {\r\n                playerNotificationManager.setColor(ResourceUtils.getColor(R.color.mva_blue))\r\n            }\r\n\r\n            //assign the player to it\r\n            playerNotificationManager.setPlayer(player)\r\n        }\r\n    }\r\n\r\n    override fun onTaskRemoved(rootIntent: Intent) {\r\n        stopService()\r\n        super.onTaskRemoved(rootIntent)\r\n    }\r\n\r\n    /**\r\n     * Stop service and release the video player\r\n     * This is only executed if we remove the app from tasks or memory is low\r\n     */\r\n    private fun stopService() {\r\n        stopSelf()\r\n        VideoPlayer.getInstance().release()\r\n    }\r\n\r\n    override fun onTrimMemory(level: Int) {\r\n        stopService()\r\n        super.onTrimMemory(level)\r\n    }\r\n\r\n    override fun onPlayerStateChanged(playWhenReady: Boolean, playbackState: Int) {\r\n        super.onPlayerStateChanged(playWhenReady, playbackState)\r\n        when (playbackState) {\r\n            Player.STATE_BUFFERING -> {\r\n\r\n            }\r\n            Player.STATE_READY -> {\r\n                val videoPlaying = player?.playWhenReady ?: false\r\n                if (!videoPlaying) {\r\n                    **stopForeground(false)**\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    override fun onDestroy() {\r\n        if (::playerNotificationManager.isInitialized) {\r\n            playerNotificationManager.setPlayer(null)\r\n        }\r\n        //save the last played position for that track\r\n        if (player != null) {\r\n            PreferenceManager.putLong(\"$trackId\",\r\n                    player?.currentPosition ?: 0)\r\n            player?.removeListener(this)\r\n        }\r\n        super.onDestroy()\r\n    }\r\n\r\n\r\n}\r\n```\r\n\r\nMy minimum SDK is 16. I have also tried minimum SDK 21 but still does not works.\r\nMy Target SDK is 28.\r\nI have checked quite a few forums but could not find a solution.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/6651/comments",
    "author": "harshmittal29",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2019-11-14T10:39:06Z",
        "body": "I think you do not need your own event listener. You can remove your `onPlayerStateChanged` and just do:\r\n\r\n```\r\npublic void onNotificationPosted(int notificationId,\r\n   Notification notification,\r\n   ongoing: Boolean) {\r\n  if (!ongoing) {\r\n    stopForeground(false)\r\n  } else {\r\n    startForeground(notificationId, notification)\r\n  }\r\n}\r\n```"
      },
      {
        "user": "goldy1992",
        "created_at": "2019-11-23T17:13:48Z",
        "body": "@marcbaechinger I had that same issue and I can confirm four solution **fixes the issue**."
      },
      {
        "user": "harshmittal29",
        "created_at": "2019-11-24T15:02:15Z",
        "body": "@marcbaechinger This fixes the issue. Thanks a lot. "
      }
    ],
    "satisfaction_conditions": [
      "Solution must allow notification to become user-dismissable when media playback is paused",
      "Implementation must correctly handle notification's ongoing state based on playback status",
      "Approach should leverage PlayerNotificationManager's built-in notification state management",
      "Must maintain compatibility with API 16+"
    ]
  },
  {
    "number": 6448,
    "title": " Is it possible to download PDF files with CacheDataSourceFactory?",
    "created_at": "2019-09-19T19:15:57Z",
    "closed_at": "2019-09-24T08:19:46Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/6448",
    "body": "For example, I have an application that caches audios and videos for offline studies, and would like to use the \"same logic\" for PDF files. It's possible?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/6448/comments",
    "author": "matheusbrandao",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2019-09-23T11:12:02Z",
        "body": "The downloader for progressive files (like the one you'd use for an mp4 file) is not making any assumptions about the file contents. So, yes, downloading the PDF file into the ExoPlayer cache would work. \r\n\r\nThe question is - how do you plan to use it afterwards? The cache is build for playback and the only sensible way to read the contents of the file is to use a `CacheDataSource`. So unless you have a PDF reader/viewer that can use ExoPlayer's `DataSource` as an input, it's difficult to retrieve. You may be able to wrap the `CacheDataSource` with an `DataSourceInputStream` and I guess it may be possible to display the PDF using an `InputStream`. Note that we can't provide any more advice on customizations like that because it goes beyond media playback. "
      },
      {
        "user": "matheusbrandao",
        "created_at": "2019-09-23T18:29:16Z",
        "body": "Hey man. \r\n\r\nThat is exactly the point. I saw that it was possible to download, but did not know how to consume the content.\r\n\r\nBut thanks to your tip, I was able to do it with `DataSourceInputStream`. Thank you very much."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to retrieve cached PDF content for non-playback usage",
      "Integration with existing caching logic used for audio/video",
      "Compatibility with standard PDF viewing mechanisms",
      "Stream-based access to cached content"
    ]
  },
  {
    "number": 6428,
    "title": "Play a specific portion of a video but display the whole video?",
    "created_at": "2019-09-13T20:07:19Z",
    "closed_at": "2019-11-17T00:56:06Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/6428",
    "body": "## Searched documentation and issues\r\nI have looked at ClippingMediaSource.\r\n\r\n## Question\r\nI want to play a video from url. The whole video shows on the seek bar and player but it starts playing from a specific point and pauses at a specific point. The user can press play and continue watching the rest of the video. How can I achieve that?\r\n\r\n<!-- DO NOT DELETE\r\nvalidate_template=true\r\ntemplate_path=.github/ISSUE_TEMPLATE/question.md\r\n-->\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/6428/comments",
    "author": "PranjalDesai",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2019-09-16T09:12:35Z",
        "body": "> it starts playing from a specific point \r\n\r\nYou can call `player.seekTo` before `player.prepare` to ensure the video starts from the desired position.\r\n\r\n> and pauses at a specific point.\r\n\r\nYou can send a message that gets triggered at this point and pauses the player:\r\n```\r\nplayer.createMessage((type, payload) -> player.setPlayWhenReady(false))\r\n  .setHandler(new Handler()).setPositionMs(pausePosition).send();\r\n```\r\n> The user can press play and continue watching the rest of the video.\r\n\r\nThat just works with the method above because the video is paused in the normal way.\r\n\r\n\r\n"
      },
      {
        "user": "PranjalDesai",
        "created_at": "2019-09-16T15:35:28Z",
        "body": "That works for a single video but if you have multiple videos being passed as ConcatenatingMediaSource than how do you handle starting point for each video?"
      },
      {
        "user": "tonihei",
        "created_at": "2019-09-16T15:45:03Z",
        "body": "That's unfortunately not yet supported but tracked by #6373. \r\n\r\nIf you need such a feature urgently, you can make it (mostly) work by writing a `MediaSource` wrapper that returns a `Timeline` wrapper that sets your start position as `windowDefaultStartPositionUs`."
      },
      {
        "user": "PranjalDesai",
        "created_at": "2019-09-16T16:00:23Z",
        "body": "Awesome thanks!"
      }
    ],
    "satisfaction_conditions": [
      "Maintains full video timeline visibility while controlling playback boundaries",
      "Enables seamless continuation of playback after pause points"
    ]
  },
  {
    "number": 6057,
    "title": "Getting informed about user actions",
    "created_at": "2019-06-18T12:58:46Z",
    "closed_at": "2019-06-18T18:45:03Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/6057",
    "body": "### Searched documentation and issues\r\nOfficial ExoPlayer documentation and source code of `MediaControllerCompat`, `MediaSessionConnector`, `MediaSession` classes.\r\n\r\n### Question\r\nIs it possible to get notified about user actions? I'm using `ExoPlayer` and `MediaSessionConnector` for handling MediaSession, so I'm not able to register `MediaSession.Callback`, that would have solved my problem, because it can be registered only once and it is done inside of `MediaSessionConnector` class.\r\n\r\nI would like to be informed about user actions like \"PLAY\", \"PAUSE\", \"SKIP TO NEXT\", \"SKIP TO PREVIOUS\" etc. The only way to do it, I have found, is to register `MediaControllerCompat.Callback`, that has `onPlaybackStateChanged` method. The problem is that after testing it, I have found that only states that are dispatched to this method are `STATE_NONE`, `STATE_PAUSED`, `STATE_PLAYING` and `STATE_BUFFERING`. There are other states like `STATE_SKIPPING_TO_PREVIOUS`, `STATE_SKIPPING_TO_NEXT` I would like to be notified about, but it never happens. \r\n\r\n<!-- DO NOT DELETE\r\nvalidate_template=true\r\ntemplate_path=.github/ISSUE_TEMPLATE/question.md\r\n-->\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/6057/comments",
    "author": "Kamil-H",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2019-06-18T15:10:48Z",
        "body": "Do you need to be aware of skip to next/previous in the app which has access to the `SimpleExoPlayer` instance or does it need to be reported to external client via `MediaControllerCompat.Callback`? From your comment above I understand it's the app (because the `MediaSession.Callback` would help which is in the app).\r\n\r\nIf it's the app, you can \r\n\r\n1) add a listener by using `player.addListener(EventListener)`. When the player transitions from one item to the next, the `onPositionDiscontinuity(int reason)` is called with `reason==DISCONTINUITY_REASON_PERIOD_TRANSITION`. This will be called if the user does skip as well as when playback automatically transitions to the next period in the timeline. In the callback method you can use `player.getCurrentWindowIndex()` to check whats the new item.\r\n\r\n2) Another option is just provide your own ControlDispatcher with connector.setControlDispatcher() and intercept dispatchSeekTo() calls.\r\n\r\nIf you need to know about this in a `MediaControllerCompat.Callback`, you are right that the `STATE_SKIPPING_TO_PREVIOUS, STATE_SKIPPING_TO_NEXT` states are not published by the connector. \r\n\r\nI see two options:\r\n\r\n1) If you are using a `TimelineQueueNavigator` the `PlaybackStateCompat` has a method `getActiveQueueItemId()` which returns the current window index.\r\n\r\n2) If the active item changes `MediaControllerCompat.Callback.onMetadataChanged(MediaMetadataCompat metadata)` is called with a new metadata object when the player transitions to the next or previous item.\r\n\r\nLet me know if one of these options help."
      },
      {
        "user": "Kamil-H",
        "created_at": "2019-06-18T17:02:07Z",
        "body": "Thank you @marcbaechinger for quick replay. \r\nI need this data for statistics purpose. I would like to get to know how users use my app and eventually improve some part of content/app.\r\nTo be more specific, I'm using ExoPlayer in `MediaBrowserServiceCompat`, I have access to both `ExoPlayer` and `MediaControllerCompat.Callback`.\r\nCurrently I'm using something you also mentioned: `MediaControllerCompat.Callback.onMetadataChanged` to detect that media item has been changed and it works pretty well. Unfortunately I don't see an option to distinguish skipping by user and the fact that one media has been finished and another started playing and this is something crucial in my case."
      },
      {
        "user": "marcbaechinger",
        "created_at": "2019-06-18T18:17:17Z",
        "body": "I think in this case it's best to register an `EventListener` with `player.addListener(eventListener)`.\r\n\r\nThe player will call `onPositionDiscontinuity(int reason)` and pass a reason. If it's a seek by the user (skip is a seek) the reason is `Player.DISCONTINUITY_REASON_SEEK`. If playback transitioned automatically the reason is `Player.DISCONTINUITY_REASON_PERIOD_TRANSITION`.\r\n\r\nYou may also want to look into `AnalyticsListener` if you want to collect other events. You can add it by using `SimpleExoPlayer.addAnalyticsListener(AnalyticsListener)`."
      },
      {
        "user": "Kamil-H",
        "created_at": "2019-06-18T18:38:40Z",
        "body": "I was able to play with `onPositionDiscontinuity(int reason)` a little bit and it seem like it will solve my problem. \r\nThank you!  "
      },
      {
        "user": "marcbaechinger",
        "created_at": "2019-06-18T18:45:03Z",
        "body": "Great to hear. I'm closing this issue. Please re-open if needed."
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to distinguish user-initiated skips from automatic media transitions",
      "Reliable notification system for all user playback control actions",
      "Integration with ExoPlayer's native event system rather than MediaSession.Callback",
      "Event tracking without interfering with MediaSessionConnector's internal operations"
    ]
  },
  {
    "number": 6020,
    "title": "Player currentPosition is 0 on PlayerNotificationManager.onNotificationCancelled",
    "created_at": "2019-06-11T17:57:38Z",
    "closed_at": "2019-06-19T19:13:48Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/6020",
    "body": "### [REQUIRED] Issue description\r\n\r\nThe currentPosition is 0 on dismissing the player from the PlayerNotificationManager with method onNotificationCancelled. Also in the EventListener.onPlayerStateChanged the currentPosition is 0.\r\n\r\n### [REQUIRED] Reproduction steps\r\n\r\n1. Start the ExoPlayer with PlayerNotificationManager\r\n2. Release the player from the notification\r\n3. Check the currentPosition of the player on dismissing the notification and releasing the player.\r\n\r\n###  [REQUIRED] Link to test content\r\n\r\n-\r\n\r\n### [REQUIRED] A full bug report captured from the device\r\n\r\n-\r\n\r\n### Version of ExoPlayer being used\r\nExoPlayer version 2.10.1\r\n\r\n### Device(s) and version(s) of Android being used\r\nAndroid API 28\r\n\r\n<!-- DO NOT DELETE\r\nvalidate_template=true\r\ntemplate_path=.github/ISSUE_TEMPLATE/bug.md\r\n-->\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/6020/comments",
    "author": "AleksandarKovachev",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2019-06-12T20:27:20Z",
        "body": "The `PlayerNotificationManager` uses roughly `Player.add/removeEventListener` and setters methods of the player which is passed to `PlayerNotificationManager.setPlayer(player)`. These do not affect the playback position. Besides this no other methods are called, which potentially could affect the position of the player.\r\n\r\nI added the `PlayerNotificationManager` to `PlayerActivity` of the demo app. Then I paused at 0:20, dismissed the notification and then continued playback at 0:20 in the player activity. The playback position has not been reset to 0.\r\n\r\nCan you provide some code around what you do in `onNotificationCancelled` of your notification listener. I don't exactly understand what you mean with step 2 and 3?"
      },
      {
        "user": "AleksandarKovachev",
        "created_at": "2019-06-17T14:20:02Z",
        "body": "I am running the player in foreground service. In the foreground service, I have EventListener and in the EventListener.onPlayerStateChanged I am saving the currentPosition in shared preferences. When I am dismissing the PlayerNotification (clicking the stop button) while still playing, the method EventListener.onPlayerStateChanged is called with 0 currentPosition."
      },
      {
        "user": "marcbaechinger",
        "created_at": "2019-06-18T18:31:47Z",
        "body": "When the `PlayerNotificationManager` receives the `ACTION_STOP` action, it calls `controlDispatcher.dispatchStop(player, /* reset= */ true)`. This resets the player, which means the position is reset to 0. \r\n\r\nYou can intercept this call by using your own `ControlDispatcher`. Something like this:\r\n\r\n```\r\nplayerNotificationManager.setControlDispatcher(new DefaultControlDispatcher() {\r\n      @Override\r\n      public boolean dispatchStop(Player player, boolean reset) {\r\n        // store current position to shared preferences now.\r\n        return super.dispatchStop(player, reset);\r\n      }\r\n});\r\n```"
      },
      {
        "user": "AleksandarKovachev",
        "created_at": "2019-06-19T19:13:48Z",
        "body": "Perfect! This helped me a lot. Thank you!"
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to capture playback position before player reset",
      "Interception of notification dismissal/stop action",
      "Preservation of playback state during notification lifecycle",
      "Integration with ExoPlayer's notification management system"
    ]
  },
  {
    "number": 5871,
    "title": "Is there an eventListener for subtitles?",
    "created_at": "2019-05-10T12:30:37Z",
    "closed_at": "2019-05-12T20:38:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/5871",
    "body": "I figured how to load subtitle and merge with `MediaSource`.\r\n\r\nBut I'm wondering if there is an eventListner for loading subtitles.\r\nHere's how I load subtitle\r\n\r\n```\r\nSingleSampleMediaSource.Factory(DefaultHttpDataSourceFactory(\"ua\"))\r\n   .createMediaSource(Uri.parse( subtitleUri ), vttFormat, C.TIME_UNSET)\r\n```\r\n\r\nHow can I set the loadFailedListener....?\r\n\r\n\r\nThank you !",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/5871/comments",
    "author": "BROUDING",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2019-05-10T19:47:15Z",
        "body": "There is another `createMediaSource` method which offers two additional parameters which are a `Handler` and a `MediaSourceEventListener`. Is this what you are looking for?\r\n\r\n```\r\npublic SingleSampleMediaSource createMediaSource(\r\n        Uri uri,\r\n        Format format,\r\n        long durationUs,\r\n        @Nullable Handler eventHandler,\r\n        @Nullable MediaSourceEventListener eventListener) \r\n```"
      }
    ],
    "satisfaction_conditions": [
      "Demonstrates how to handle subtitle loading events",
      "Shows error handling for subtitle loading failures",
      "Explains MediaSource event listener integration",
      "Provides callback mechanism for asynchronous operations"
    ]
  },
  {
    "number": 5791,
    "title": "playlist with PagedList(AAC)",
    "created_at": "2019-04-23T08:07:28Z",
    "closed_at": "2019-04-30T10:45:01Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/5791",
    "body": "\r\n### [REQUIRED] Searched documentation and issues\r\nI found playlist feature can be implemented using ConcatenatingMediaSource class which be added MediaSource instance.\r\n\r\n\r\n### [REQUIRED] Question\r\nHi, I'm implementing playlist feature that has about 700 songs.\r\nI've implemented using ConcatenatingMediaSource instance.\r\nBut it require to instantiate HlsMediaSource instance about 700 times at once to add there .\r\n\r\nI use PageList class(AAC) to show playlist in view. \r\nIs there any way to use the pageList to exoplayer playlist feature.\r\n\r\nIs any advice in this scenario?\r\n\r\n<!-- DO NOT DELETE\r\nvalidate_template=true\r\ntemplate_path=.github/ISSUE_TEMPLATE/question.md\r\n-->\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/5791/comments",
    "author": "simpler23",
    "comments": [
      {
        "user": "AquilesCanta",
        "created_at": "2019-04-25T10:35:52Z",
        "body": "@tonihei can you provide advise here?"
      },
      {
        "user": "tonihei",
        "created_at": "2019-04-25T14:59:12Z",
        "body": "I think the easiest solution is to create all 700 MediaSources and set the `useLazyPreparation` parameter is the constructor to `true`. This causes the source to not prepare all HLS sources at once but only if they are actually needed. This way the index in the playlist can also stay the same as the index in your PagedList and you don't need any extra logic. "
      },
      {
        "user": "simpler23",
        "created_at": "2019-04-26T14:38:14Z",
        "body": "Thank you for sharing your tip!\r\nBut I worry about instantiating 700 objects at once that might not be used.\r\nIs it fine in memory perspective?"
      },
      {
        "user": "tonihei",
        "created_at": "2019-04-30T10:44:59Z",
        "body": "That shouldn't be an issue. I just tested creating 700 HlsMediaSource and they use up only 233 KB  of memory.\n\n---\n\nClosing, because the question has been answered."
      },
      {
        "user": "simpler23",
        "created_at": "2019-05-01T10:52:54Z",
        "body": "Thank you for the answers!!"
      }
    ],
    "satisfaction_conditions": [
      "Solution must handle memory efficiently when dealing with a large number of media sources",
      "Implementation must maintain index alignment between playlist and PagedList",
      "Approach should avoid upfront resource allocation for unused items"
    ]
  },
  {
    "number": 5727,
    "title": "Question: How to override the video track selection for multiple videos",
    "created_at": "2019-04-04T14:00:08Z",
    "closed_at": "2019-04-12T16:54:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/5727",
    "body": "Can you change the resolution of all the videos that are playing in the player without having to create a new instance of the player?\r\n\r\nExoplayer version 2.9.4\r\n\r\nTo make the exchange of quality I am using this method\r\n\r\n```\r\nprivate fun applySelection() {\r\n        val trackInfo = trackSelector.currentMappedTrackInfo ?: return\r\n        val trackGroups = trackInfo.getTrackGroups(videoRendererIndex)\r\n\r\n        val parametersBuilder = trackSelector.buildUponParameters()\r\n        parametersBuilder.setRendererDisabled(videoRendererIndex, false)\r\n\r\n        if (overridePlayer != null) {\r\n            parametersBuilder.setSelectionOverride(videoRendererIndex, trackGroups, overridePlayer)\r\n        } else {\r\n            parametersBuilder.clearSelectionOverrides(videoRendererIndex)\r\n        }\r\n\r\n        trackSelector.setParameters(parametersBuilder)\r\n}\r\n```",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/5727/comments",
    "author": "DionataFerraz",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2019-04-07T15:56:48Z",
        "body": "Selection overrides only apply to content that has the same set of tracks that you've set the override for. Or more precisely, a video track override will only apply to content where the `trackGroups` assigned to the video renderer are the same as those that you've set the override for. If you start playing content that has a different set of tracks, you'll need to set a new override for the new `trackGroups` (note: there is no requirement that you create a new instance of the player to do this).\r\n\r\nIf possible, try using constraint based track selection rather than specific track overrides when playing multiple videos. For example if you're trying to impose a maximum quality, use `parametersBuilder.setMaxVideoSize` or `parametersBuilder.setMaxVideoBitrate`. Constraints are a lot more flexible than specific overrides, and apply naturally over multiple videos. Setting minimum qualities via constraints is currently not possible; adding this functionality is tracked by #4511."
      },
      {
        "user": "DionataFerraz",
        "created_at": "2019-04-11T19:54:02Z",
        "body": "Solved with that\r\nOBS: it was not me that did\r\n```\r\nimport com.google.android.exoplayer2.source.TrackGroup\r\nimport com.google.android.exoplayer2.trackselection.AdaptiveTrackSelection\r\nimport com.google.android.exoplayer2.trackselection.TrackSelection\r\nimport com.google.android.exoplayer2.upstream.BandwidthMeter\r\nimport com.google.android.exoplayer2.util.Clock\r\n\r\ntypealias SelectedIndex = () -> Int?\r\n\r\nclass FixedAdaptiveTrackSelection(\r\n    group: TrackGroup,\r\n    tracks: IntArray,\r\n    bandwidth: BandwidthMeter,\r\n    minDurationForQualityIncreaseMs: Long,\r\n    maxDurationForQualityDecreaseMs: Long,\r\n    minDurationToRetainAfterDiscardMs: Long,\r\n    bandwidthFraction: Float,\r\n    bufferedFractionToLiveEdgeForQualityIncrease: Float,\r\n    minTimeBetweenBufferReevaluationMs: Long,\r\n    clock: Clock,\r\n    private var selectedIndexFunction: SelectedIndex?\r\n) : AdaptiveTrackSelection(\r\n    group,\r\n    tracks,\r\n    bandwidth,\r\n    minDurationForQualityIncreaseMs,\r\n    maxDurationForQualityDecreaseMs,\r\n    minDurationToRetainAfterDiscardMs,\r\n    bandwidthFraction,\r\n    bufferedFractionToLiveEdgeForQualityIncrease,\r\n    minTimeBetweenBufferReevaluationMs,\r\n    clock\r\n) {\r\n\r\n    class Factory : TrackSelection.Factory {\r\n\r\n        private var bandwidthMeter: BandwidthMeter? = null\r\n        private var minDurationForQualityIncreaseMs: Int? = null\r\n        private var maxDurationForQualityDecreaseMs: Int? = null\r\n        private var minDurationToRetainAfterDiscardMs: Int? = null\r\n        private var bandwidthFraction: Float? = null\r\n        private var bufferedFractionToLiveEdgeForQualityIncrease: Float? = null\r\n        private var minTimeBetweenBufferReevaluationMs: Long? = null\r\n        private var clock: Clock\r\n        private var selectedIndex: SelectedIndex? = null\r\n\r\n        constructor(selectedIndex: SelectedIndex?) : this(\r\n            AdaptiveTrackSelection.DEFAULT_MIN_DURATION_FOR_QUALITY_INCREASE_MS,\r\n            DEFAULT_MAX_DURATION_FOR_QUALITY_DECREASE_MS,\r\n            DEFAULT_MIN_DURATION_TO_RETAIN_AFTER_DISCARD_MS,\r\n            DEFAULT_BANDWIDTH_FRACTION,\r\n            DEFAULT_BUFFERED_FRACTION_TO_LIVE_EDGE_FOR_QUALITY_INCREASE,\r\n            DEFAULT_MIN_TIME_BETWEEN_BUFFER_REEVALUTATION_MS,\r\n            Clock.DEFAULT,\r\n            selectedIndex\r\n        )\r\n\r\n        constructor(\r\n            minDurationForQualityIncreaseMs: Int,\r\n            maxDurationForQualityDecreaseMs: Int,\r\n            minDurationToRetainAfterDiscardMs: Int,\r\n            bandwidthFraction: Float,\r\n            bufferedFractionToLiveEdgeForQualityIncrease: Float,\r\n            minTimeBetweenBufferReevaluationMs: Long,\r\n            clock: Clock,\r\n            selectedIndex: SelectedIndex?\r\n        ) {\r\n            this.minDurationForQualityIncreaseMs = minDurationForQualityIncreaseMs\r\n            this.maxDurationForQualityDecreaseMs = maxDurationForQualityDecreaseMs\r\n            this.minDurationToRetainAfterDiscardMs = minDurationToRetainAfterDiscardMs\r\n            this.bandwidthFraction = bandwidthFraction\r\n            this.bufferedFractionToLiveEdgeForQualityIncrease = bufferedFractionToLiveEdgeForQualityIncrease\r\n            this.minTimeBetweenBufferReevaluationMs = minTimeBetweenBufferReevaluationMs\r\n            this.clock = clock\r\n            this.selectedIndex = selectedIndex\r\n        }\r\n\r\n        override fun createTrackSelection(group: TrackGroup, bandwidth: BandwidthMeter, vararg tracks: Int): FixedAdaptiveTrackSelection {\r\n            var meter = bandwidth\r\n            if (bandwidthMeter != null) {\r\n                meter = bandwidthMeter as BandwidthMeter\r\n            }\r\n            return FixedAdaptiveTrackSelection(\r\n                group,\r\n                tracks,\r\n                meter,\r\n                minDurationForQualityIncreaseMs?.toLong() ?: 0,\r\n                maxDurationForQualityDecreaseMs?.toLong() ?: 0,\r\n                minDurationToRetainAfterDiscardMs?.toLong() ?: 0,\r\n                bandwidthFraction ?: 0F,\r\n                bufferedFractionToLiveEdgeForQualityIncrease ?: 0F,\r\n                minTimeBetweenBufferReevaluationMs ?: 0,\r\n                clock,\r\n                selectedIndex)\r\n        }\r\n\r\n    }\r\n\r\n    override fun getSelectedIndex(): Int {\r\n        return selectedIndexFunction?.invoke() ?: super.getSelectedIndex()\r\n    }\r\n\r\n}\r\n```\r\n\r\n\r\n```\r\nval trackSelector: DefaultTrackSelector by lazy {\r\n        DefaultTrackSelector(FixedAdaptiveTrackSelection.Factory(::getSelectedQualityIndex)).apply {\r\n            parameters = trackSelectorParameters\r\n        }\r\n }\r\n```\r\n"
      }
    ],
    "satisfaction_conditions": [
      "Solution must allow changing video resolution dynamically without creating a new player instance",
      "Must handle different track groups across multiple video sources",
      "Must provide a way to override default adaptive track selection behavior"
    ]
  },
  {
    "number": 5652,
    "title": "VTT caption file download",
    "created_at": "2019-03-19T13:14:25Z",
    "closed_at": "2019-03-20T13:06:33Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/5652",
    "body": "### [REQUIRED] Searched documentation and issues\r\nI been looking every where but not success finding appropriated solution\r\n\r\n### [REQUIRED] Question\r\nexoplayer r2.4.  In a hls stream with multiple vtt captions files why exoplayer loads the same file after seek back to the beginning of the stream. ie content start playback from 0 position and plays for 3 minutes and 3 .vtt files download for that period, then a user interaction set the content back to 0 and content resume and plays for the same 3 minutes and download the same files again. Is there a way to make exoplayer cache the already  downloaded vtt files?\r\n\r\n<!-- DO NOT DELETE\r\nvalidate_template=true\r\ntemplate_path=.github/ISSUE_TEMPLATE/question.md\r\n-->\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/5652/comments",
    "author": "andresdiez",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2019-03-20T12:50:39Z",
        "body": "That's possible using a `new CacheDataSourceFactory(new SimpleCache(fileDir, evictor), normalDataSource)` as the data source factory for your `MediaSource`. Please also have a look at similar questions on this issue tracker and other websites."
      },
      {
        "user": "andresdiez",
        "created_at": "2019-03-20T13:06:33Z",
        "body": "That work, thank you."
      }
    ],
    "satisfaction_conditions": [
      "Demonstrates a caching mechanism for VTT subtitle files in ExoPlayer",
      "Integrates with ExoPlayer's existing data source architecture",
      "Applies to multiple subtitle tracks in HLS streams"
    ]
  },
  {
    "number": 5627,
    "title": "Custom Load Error message: available or not?",
    "created_at": "2019-03-13T11:54:46Z",
    "closed_at": "2019-03-31T20:27:14Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/5627",
    "body": "### Searched documentation and issues\r\nI have been looking around the web, offical Android Dev. website, Medium, in this repository Issue category and in the Source code.\r\n\r\n### Question\r\nI am working with the ExoPlayer error handling. I found that when my Server response is an exception of type \"InvalidResponseCodeException\" I am not able to find the server message, just the default http status message (in the LoadErrorHandlingPolicy custom class as well as for the player listener onPlayerError() method). I am wondering if is there a way to get it or it is a feature not yet implemented.\r\n\r\n<!-- DO NOT DELETE\r\nvalidate_template=true\r\ntemplate_path=.github/ISSUE_TEMPLATE/question.md\r\n-->\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/5627/comments",
    "author": "JonathanImperato",
    "comments": [
      {
        "user": "AquilesCanta",
        "created_at": "2019-03-13T12:11:38Z",
        "body": "It should be available through InvalidResponseCodeException#responseMessage. Is that empty? If so, are you sure the server is providing a non-empty response body? Have you tried different HTTP DataSources?"
      },
      {
        "user": "JonathanImperato",
        "created_at": "2019-03-13T13:24:00Z",
        "body": "> It should be available through InvalidResponseCodeException#responseMessage. Is that empty? If so, are you sure the server is providing a non-empty response body? Have you tried different HTTP DataSources?\r\n\r\nInvalidResponseCodeException#responseMessage prints the default http status message such as 401 Unauthorized, not the server message (eg. For 401: You are not authorized)..."
      },
      {
        "user": "AquilesCanta",
        "created_at": "2019-03-13T13:34:05Z",
        "body": "Oh right, the responseMessage doesn't contain the response body. I can confirm this is not provided out of the box. I don't think reading the response body for an error is something we want to add to any default implementation.\r\n\r\nCan you explain the usecase for this?"
      },
      {
        "user": "JonathanImperato",
        "created_at": "2019-03-13T13:49:01Z",
        "body": "> Oh right, the responseMessage doesn't contain the response body. I can confirm this is not provided out of the box. I don't think reading the response body for an error is something we want to add to any default implementation.\r\n> \r\n> Can you explain the usecase for this?\r\n\r\nIt is usefull because we don't want to keep this messages inside the app, these are messages that may change over time and mostly they are translated.\r\nFor example we are handling error 429 \"Too many requests\", when ExoPlayer reaches this error it will show an AlertDialog with the wanted information.\r\nWe want to have this message customizable on the Server side.\r\nI hope it is a little bit more clear."
      },
      {
        "user": "AquilesCanta",
        "created_at": "2019-03-28T10:52:57Z",
        "body": "The easiest way I can think of implementing the provision of the error's response body is including it in the InvalidResponseCodeException. However, it's probably not ideal to block until we read the response body, before we throw the exception. So, we might also want to add a per-implementation flag that enables populating the response body for this case.\r\n\r\n@JonathanImperato, I see slim chances of us adding this any time soon. You might want to think of using your own DataSource implementation that does this for you. It shouldn't be hard, if you part from an existing implementation.\r\n\r\n@ojw28, can you think of a better way of providing the response body of a non-2xx response?"
      },
      {
        "user": "amozoss",
        "created_at": "2019-03-29T21:38:12Z",
        "body": "Not ideal, but if you can have the server return the error in a header, you can get the error message that way. I have a custom header called `X-Client-Error`, which I am able to access.\r\n``` \r\n @Override\r\n    public void onPlayerError(ExoPlaybackException error) {\r\n      String message = \"Unknown\";\r\n      switch (error.type) {\r\n        case ExoPlaybackException.TYPE_SOURCE:\r\n          message = \"TYPE_SOURCE: \" + error.getSourceException().getMessage();\r\n          if (error.getSourceException() instanceof HttpDataSource.InvalidResponseCodeException) {\r\n            HttpDataSource.InvalidResponseCodeException invalidResponseCodeException = (HttpDataSource.InvalidResponseCodeException) error.getSourceException();\r\n            List<String> strings = invalidResponseCodeException.headerFields.get(\"X-Client-Error\");\r\n            if (strings.size() > 0) {\r\n              message +=  \"\\n\" + strings.get(0);\r\n            }\r\n          }\r\n          break;\r\n...\r\n```"
      },
      {
        "user": "JonathanImperato",
        "created_at": "2019-03-30T07:24:03Z",
        "body": "> Not ideal, but if you can have the server return the error in a header, you can get the error message that way. I have a custom header called `X-Client-Error`, which I am able to access.\r\n> \r\n> ```\r\n>  @Override\r\n>     public void onPlayerError(ExoPlaybackException error) {\r\n>       String message = \"Unknown\";\r\n>       switch (error.type) {\r\n>         case ExoPlaybackException.TYPE_SOURCE:\r\n>           message = \"TYPE_SOURCE: \" + error.getSourceException().getMessage();\r\n>           if (error.getSourceException() instanceof HttpDataSource.InvalidResponseCodeException) {\r\n>             HttpDataSource.InvalidResponseCodeException invalidResponseCodeException = (HttpDataSource.InvalidResponseCodeException) error.getSourceException();\r\n>             List<String> strings = invalidResponseCodeException.headerFields.get(\"X-Client-Error\");\r\n>             if (strings.size() > 0) {\r\n>               message +=  \"\\n\" + strings.get(0);\r\n>             }\r\n>           }\r\n>           break;\r\n> ...\r\n> ```\r\n\r\nYes, it is what I am doing right now, but instead of a string I pass a serialized json."
      },
      {
        "user": "ojw28",
        "created_at": "2019-03-31T20:24:43Z",
        "body": "Pretty much all apps that I've seen will include the strings (and translations) as resources inside the app. I don't understand why it would be particularly important to enable these messages to be changed on the server side. Typically an error code has a well defined meaning, and the strings inside the app will reflect that. I understand that the exact wording may be tweaked from release to release, but I'd expect any string that was included in a previous release to still make sense. I also don't understand why translation is important here. Android already provides a resources mechanism that supports translations.\r\n\r\nI don't think it's important that we go out of our way to support this use case. Putting content into a response header as described above is one way of achieving what's being requested, for those who really want to do this."
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to retrieve server-provided error messages from HTTP response bodies",
      "Solution avoids hardcoding error messages in client app",
      "Non-blocking error message retrieval implementation",
      "Integration with ExoPlayer's existing error handling flow",
      "Support for dynamic message updates without app redeployment"
    ]
  },
  {
    "number": 5621,
    "title": "Prebuffer next MediaSource in dynamic ConcatenatingMediaSource",
    "created_at": "2019-03-12T13:13:17Z",
    "closed_at": "2019-03-14T08:33:21Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/5621",
    "body": "### [REQUIRED] Searched documentation and issues\r\n> You can call any of these methods before and after playback has started, no matter which item is currently playing. Access to these methods is thread-safe. And you can also rest assured that ExoPlayer pre-buffers the next playlist items to ensure gapless playback.\r\n\r\nI've found only this general description about prebuffering on Medium, want to get into more details.\r\n\r\n### [REQUIRED] Question\r\nI compose a playlist dynamically with ConcatenatingMediaSource and want to ensure that the next MediaSource is prebuffered after it's added with addMediaSource().\r\n\r\nFor example, there is 1 source in ConcatenatingMediaSource that is currently playing. I add a second one with addMediaSource().\r\n\r\nWhen a player will start to prebuffer it?\r\n\r\n- Immediately after adding? \r\n- Or should I call SimpleExoPlayer.prepare() after adding without reseting position/state?- \r\n- How about default caching behavior, if the currently playing MediaSource is not buffered to the end at the moment, will the added MediaSource will start buffering after adding?\r\n\r\n<!-- DO NOT DELETE\r\nvalidate_template=true\r\ntemplate_path=.github/ISSUE_TEMPLATE/question.md\r\n-->\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/5621/comments",
    "author": "nicolausYes",
    "comments": [
      {
        "user": "marcbaechinger",
        "created_at": "2019-03-12T18:49:33Z",
        "body": "The player will start buffering as soon as its needed. So when it gets towards the end of the first window (MediaSource), the player notices that there is a second item and starts filling the buffers for this item. \r\n\r\nTo answer your questions concretely:\r\n\r\nQ1) It does not necessarily start immediately after adding. Given the first item is eg. 5 minutes before the end and you add a second media source, the player will just wait until playback is close to the end and then start loading for the second item.\r\n\r\nQ2) You do need to call prepare() only once with the ConcatenatingMediaSource. After you have done this you can add and remove media sources as you wish. No need to call prepare again.\r\n\r\nQ3) In this case the player would buffer to the end of the first item first and then continuing to buffer for the second item as soon as it's indicated to do so.\r\n\r\n"
      },
      {
        "user": "nicolausYes",
        "created_at": "2019-03-12T19:57:34Z",
        "body": "@marcbaechinger so prebuffering of the next MediaSource roughly depends on a playback position of a currently playing MediaSource.\r\n\r\nIs there a way to force prebuffer of the next MediaSource? \r\nFor example, if the first MediaSource playing somewhere in the middle, I want to have the next MediaSource to be prebuffered if the user decides to play the Next track."
      },
      {
        "user": "marcbaechinger",
        "created_at": "2019-03-12T21:13:46Z",
        "body": "No, that's currently not possible. There is #3327 which is the enhancement tracking bug for this feature. AFAIK we haven't started with this though."
      },
      {
        "user": "nicolausYes",
        "created_at": "2019-03-14T08:33:21Z",
        "body": "#3327 is exactly what I'm talking about. Will follow updates there, thanks. Closed."
      }
    ],
    "satisfaction_conditions": [
      "Clarification of when ExoPlayer initiates prebuffering for dynamically added MediaSources in ConcatenatingMediaSource",
      "Explanation of prepare() method requirements when modifying playlist",
      "Description of default caching behavior priority between current and queued sources",
      "Acknowledgement of feature gap for forced prebuffering before playback proximity",
      "Documentation of prebuffering trigger mechanisms in dynamic playlists"
    ]
  },
  {
    "number": 5602,
    "title": "ConcateningMedia, RepeatOne and next / previous",
    "created_at": "2019-03-06T13:22:36Z",
    "closed_at": "2019-03-06T13:30:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/5602",
    "body": "I have a question regarding REPEAT_ONE mode, ConcateningMedia and using SimpleExoPlayer.next(), previous() and related methods.\r\n\r\nFrom my understanding, REPEAT_ONE should function by endlessly looping same MediaSource. From what I see in the source code of Timeline.getNextWindowIndex, it should return currentWindowIndex when repeat mode is REPEAT_ONE. But this isn't the case. Instead using simpleExoPlayer.next() moves to next window index and plays next MediaSource. \r\n\r\nIn short, I have a ConcateningMedia with MediaSourceA, MediaSourceB and MediaSourceC.\r\nWhen I set REPEAT_ONE and play MediaSourceA, I expect getPreviousWindowIndex() and getNextWindowIndex() to return same values as getCurrentWindowIndex() and that calling next() replays MediaSourceA. Instead, MediaSourceB is played.\r\n \r\nIs this expected behavior? \r\n\r\n<!-- DO NOT DELETE\r\nvalidate_template=true\r\ntemplate_path=.github/ISSUE_TEMPLATE/question.md\r\n-->\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/5602/comments",
    "author": "tomislavturcic",
    "comments": [
      {
        "user": "google-oss-bot",
        "created_at": "2019-03-06T13:22:37Z",
        "body": "This issue does not seem to follow the issue template. Make sure you provide all the required information."
      },
      {
        "user": "tonihei",
        "created_at": "2019-03-06T13:28:15Z",
        "body": "Yes, that is expected behaviour. \r\n\r\nThe idea is that you can have UI elements which let you skip to the next and previous item (using `player.next()` and `player.previous()` even though you have REPEAT_ONE enabled. The current item is still repeated endlessly without any interaction. The `getNextWindowIndex()` and `getPreviousWindowIndex()` methods return matching values to tell you which window index will be played when calling `next()` or `previous()`."
      },
      {
        "user": "tomislavturcic",
        "created_at": "2019-03-06T13:30:11Z",
        "body": "Ok, thanks for clarification!"
      },
      {
        "user": "tonihei",
        "created_at": "2019-03-06T13:30:57Z",
        "body": "If you'd like to know the next item the player will play automatically, you can use `player.getCurrentTimeline().getNextWindowIndex(windowIndex, repeatMode, shuffleMode)` to query any transition under different repeat and shuffle mode conditions."
      },
      {
        "user": "ojw28",
        "created_at": "2020-11-24T15:50:53Z",
        "body": "`Player` Javadoc will be improved to more explicitly explain this behavior in a future release. Removing the `documentation candidate` label as these changes have been made internally."
      }
    ],
    "satisfaction_conditions": [
      "Clarification of the intended behavior of REPEAT_ONE mode in relation to navigation methods like next() and previous()",
      "Explanation of how user-triggered navigation interacts with repeat modes",
      "Guidance on programmatically determining media transitions under different playback modes",
      "Documentation of the relationship between player controls and repeat mode configurations"
    ]
  },
  {
    "number": 5339,
    "title": "Playing mp4 video from assets",
    "created_at": "2019-01-04T15:06:33Z",
    "closed_at": "2019-01-04T16:10:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/5339",
    "body": "I'm trying to use a video that is inside the assets directory, but I always take an exception \r\n com.google.android.exoplayer2.upstream.HttpDataSource$HttpDataSourceException: Unable to connect to assets://vid.mp4\r\n```\r\nExtractorMediaSource.Factory(DefaultDataSourceFactory(context, BuildConfig.USER_AGENT_VALUE)).createMediaSource(Uri.parse(\"assets://vid.mp4\"))\r\n```",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/5339/comments",
    "author": "DionataFerraz",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2019-01-04T15:08:19Z",
        "body": "Does `asset://...` work?"
      },
      {
        "user": "marcbaechinger",
        "created_at": "2019-01-04T15:18:24Z",
        "body": "Or you need to prefix your path with android_asset. So for your example it would be:\r\n\r\nfile:///android_asset/vid.mp4"
      },
      {
        "user": "DionataFerraz",
        "created_at": "2019-01-04T15:33:06Z",
        "body": "I've tried, but throws an exception that the file was not found\r\n    com.google.android.exoplayer2.upstream.AssetDataSource$AssetDataSourceException: java.io.FileNotFoundException: \r\n\r\npackage assets is inside the main, should it be somewhere else?\r\n\r\nI put the package assets in the singular and also did not work, it throws the same exception above\r\n\r\nI tried putting it in the package raw inside the res and it does not work either\r\n\r\ni try \r\n```\r\nExtractorMediaSource.Factory(DefaultDataSourceFactory(context, BuildConfig.USER_AGENT_VALUE))\r\n.createMediaSource(Uri.parse(\"android.resource://com.dionata.player.dev/raw/video.mp4\"))\r\n```\r\n\n\n---\n\nif I try with the Android VideoView I can play the video using that path\r\n`android.resource://com.video.player.dev/raw/video`\r\n\r\nI'm using version 2.9.3"
      },
      {
        "user": "andrewlewis",
        "created_at": "2019-01-04T15:37:03Z",
        "body": "If it's stored as a resource rather than an asset then try `RawResourceDataSource.buildRawResourceUri(R.raw.video)`."
      },
      {
        "user": "DionataFerraz",
        "created_at": "2019-01-04T15:55:23Z",
        "body": "Thanks\r\nI did it here and it worked.\r\n```\r\nExtractorMediaSource.Factory(DefaultDataSourceFactory(context, BuildConfig.USER_AGENT_VALUE))\r\n                .createMediaSource(RawResourceDataSource.buildRawResourceUri(R.raw.videog))\r\n```\r\n\r\nThank you very much\r\n"
      }
    ],
    "satisfaction_conditions": [
      "Correct URI format specification for accessing app resources",
      "Clear distinction between asset and resource file handling",
      "Proper data source configuration for ExoPlayer"
    ]
  },
  {
    "number": 5282,
    "title": "How to create AudioProcessor to boost volume",
    "created_at": "2018-12-19T20:32:09Z",
    "closed_at": "2019-01-02T14:07:15Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/5282",
    "body": "I read issues #3657 where @andrewlewis  is saying that to increase volume above normal limits  one should implement custom AudioProcessor.\r\n\r\nI've made couple of test, but not sure how to implement it, key problem is that input PCM data (16 bit PCM) into my AudioProcessor are already normalized to 16 bit range (so values are already in range 32768 - 32767) , so there is no space to increase amplitude more.\r\n\r\nI tried to change output encoding to PCM 32 bits to have some space for increase, but then got unhanded configuration exception \r\n\r\n(And generally it looks like only PCM 16 bit is supported.\r\nCustom AudioProcessors seem to be used before standard processors - especially SilenceSkippingAudioProcessor, which requires PCM 16 bit as it's input -  so I guess if I'll change resolution to 24 or 32 bits it'll not be working.)\r\n\r\nCan you provide bit more detailed advice how to implement AudioProcessor to boost volume? Or is there any other trick I can use? Any ideas are welcomed.\r\nThanks",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/5282/comments",
    "author": "izderadicka",
    "comments": [
      {
        "user": "izderadicka",
        "created_at": "2019-01-02T10:23:57Z",
        "body": "I've made another attempt - now going to platform LoudnessEnhancer AudioEffect, which will be applied after exoplayer AudioProcessors.    I have simple code below plugged to player\r\n```kotlin\r\nprivate class VolumeBooster(enabled: Boolean): AudioListener {\r\n    var enabled: Boolean = false\r\n        set(value) {\r\n            field = value\r\n            this.booster?.apply {\r\n                enabled = value\r\n            }\r\n        }\r\n    private var booster: LoudnessEnhancer? = null\r\n    init {\r\n        this.enabled = enabled\r\n    }\r\n    override fun onAudioSessionId(audioSessionId: Int) {\r\n        Log.d(LOG_TAG, \"Audio session id is ${audioSessionId}, supported gain ${LoudnessEnhancer.PARAM_TARGET_GAIN_MB}\")\r\n        booster?.release()\r\n        booster = LoudnessEnhancer(audioSessionId)\r\n        booster?.apply {\r\n            this@VolumeBooster.enabled\r\n            setTargetGain(3000)\r\n        }\r\n\r\n    }\r\n\r\n}\r\n```\r\n\r\nand it's plugged to player like this:\r\n```kotlin\r\nvolumeBooster = VolumeBooster(boostEnabled)\r\nplayer.audioComponent?.addAudioListener(volumeBooster)\r\n```\r\n\r\nBut this also does not work - the result is that track in initially boosted for second or two (but not always) and  then volume returns to normal level.  Not sure why this is happening.\r\n\r\nSo I'd welcome any ideas, experiences in this area, as it's hard to find any reliable information. Thanks.\n\n---\n\nAny ideas anybody?  I'm stuck on what I described above. Thanks"
      },
      {
        "user": "andrewlewis",
        "created_at": "2019-01-02T11:04:51Z",
        "body": "Regarding using audio processing for this: #3657 is about amplifying quiet sources rather than increasing volume beyond \"normal limits\" so perhaps not relevant to what you're trying to do. I don't think the bit depth of the PCM audio is going to make a difference to the audio volume. If your audio is already at full volume I wonder if you can do a non-linear transformation that still boosts volume for quite sections, but this may cause distortion!\r\n\r\nFor the loudness enhancer approach: in the code snippet above does the new `LoudnessEnhancer` actually get stored in the field? I vaguely recall a problem when trying to use audio effects previously where the effect was getting garbage collected unless I kept a reference to it."
      },
      {
        "user": "izderadicka",
        "created_at": "2019-01-02T14:07:15Z",
        "body": "@andrewlewis - Thanks that might be it! I did not notice that I used local var instead of field. Will check.\n\n---\n\n@andrewlewis - this was it - thanks a million. What a stupid error, I indeed wantedit  to be field of my class, just put there val by mistake and was it. Poor `LoudnessEnhancer` got shredded. I updated the code above to correct one, if someone in future has similar question."
      }
    ],
    "satisfaction_conditions": [
      "Ensures audio effects (e.g., LoudnessEnhancer) are retained in memory to prevent premature garbage collection",
      "Compatibility with ExoPlayer's audio processing chain and supported configurations"
    ]
  },
  {
    "number": 5267,
    "title": "How can I switch the video that I just add to the concatenatingmediasource while the exoplay is runing?",
    "created_at": "2018-12-18T01:41:52Z",
    "closed_at": "2019-01-18T17:49:34Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/5267",
    "body": "How can I switch the video that I just add to the concatenatingmediasource while the exoplay is runing?\r\nCan make it whihout reprepare the player?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/5267/comments",
    "author": "qjh5606",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2018-12-18T09:20:36Z",
        "body": "If I understand your question correctly, you just need to seek to the new window after it has been added.\r\nYou can use the `Runnable` in `addMediaSource` to run something immediately after the source has been added:\r\n```\r\nconcatenatingMediaSource.addMediaSource(\r\n    newIndex, newMediaSource, () -> player.seekToDefaultPosition(newIndex));\r\n```"
      },
      {
        "user": "qjh5606",
        "created_at": "2018-12-20T01:05:44Z",
        "body": "> If I understand your question correctly, you just need to seek to the new window after it has been added.\r\n> You can use the `Runnable` in `addMediaSource` to run something immediately after the source has been added:\r\n> \r\n> ```\r\n> concatenatingMediaSource.addMediaSource(\r\n>     newIndex, newMediaSource, () -> player.seekToDefaultPosition(newIndex));\r\n> ```\r\n\r\nThank you very much. It seems solve my problem.\n\n---\n\n@tonihei \r\nwhen I call the\r\n`concatenatingMediaSource.addMediaSource(\r\n    newIndex, newMediaSource, () -> player.seekToDefaultPosition(newIndex));`\r\non the `onPositionDiscontinuity` \r\n\r\nThe screen will be black for a short time then it start to play the MediaSource that I just added.\r\nHow can I fix the  black problem?\r\n\r\nHere's what I do on  onPositionDiscontinuity:\r\n\r\n` \r\nplayer.addListener(new Player.EventListener() {\r\n      @Override\r\n      public void onPositionDiscontinuity(int reason) {\r\n        int latestWindowIndex = player.getCurrentWindowIndex();\r\n        if (latestWindowIndex != lastWindowIndex) {\r\n          // item selected in playlist has changed, handle here\r\n          lastWindowIndex = latestWindowIndex;\r\n\r\n          String addString=null;\r\n          addString = new String(\"/storage/emulated/0/Download/3D_Rio_shark.MP4\");\r\n          MediaSource addMediaSource = buildMediaSource(Uri.parse(addString));\r\n\r\n          int Size = mediaSource.getSize();\r\n          mediaSource.addMediaSource(lastWindowIndex, addMediaSource, new Runnable() {\r\n            @Override\r\n            public void run() {\r\n              player.seekToDefaultPosition(lastWindowIndex);\r\n            }\r\n          });\r\n        }\r\n      }\r\n    });\r\n`\r\n\r\n\r\n\r\n"
      },
      {
        "user": "tonihei",
        "created_at": "2018-12-21T13:19:08Z",
        "body": "The black screen is visible because you seek to another source and the content needs to buffer first before we can continue playback. What would you expect to be visible during that time?"
      },
      {
        "user": "qjh5606",
        "created_at": "2018-12-21T13:26:56Z",
        "body": "@tonihei \r\nIt would be very nice if the screen render the previous MediaSource's last frame which make it seamless/gapless visually."
      },
      {
        "user": "tonihei",
        "created_at": "2019-01-18T17:49:34Z",
        "body": "> previous MediaSource's last frame\r\n\r\nIf you seek after receiving a `onPositionDiscontinuity` event, you are already in a new media source and the frame that could potentially be displayed is the first frame in the media source which is not going to be played, but that doesn't seem to make much sense.\r\n\r\nIf your intention is to play this new item after the previous one (which played before receiving the `onPositionDiscontinuity` event), then you should probably insert the new source after this item and just let playback proceed automatically? \n\n---\n\nCan you try setting the `keep_content_on_player_reset` property of the `PlayerView` to true (or call `PlayerView.setKeepContentOnPlayerReset(true)`). That may help to keep the previous frame visible. \n\n---\n\nReopened to track improving documentation for this method. \n\n---\n\nClosing as docs have been improved."
      }
    ],
    "satisfaction_conditions": [
      "Seamless visual transition when switching media sources during playback",
      "Dynamic media source modification without full player reinitialization",
      "Proper handling of media source insertion timing",
      "Frame persistence during source transitions"
    ]
  },
  {
    "number": 5163,
    "title": "How to use use decode_mode, headers and secure_uri tags in Exoplayer?",
    "created_at": "2018-11-28T09:10:05Z",
    "closed_at": "2018-11-28T11:26:33Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/5163",
    "body": "Hi,\r\n\r\nUsing latest version 2.9.1\r\n\r\nNow I want to play a url which is playing in MxPlayer if we pass these tags else not playing. I want to use that tags in ExoPlayer too, If possible please let me know.\r\n\r\nlike this:-\r\n```java\r\nintent.putExtra(\"decode_mode\", (byte) 2);\r\nintent.putExtra(\"headers\", new String[]{\"User-Agent\", this.userAgent, \"Extra-Header\", \"911\"});\r\nintent.putExtra(\"secure_uri\", true);\r\n```\r\nThanks.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/5163/comments",
    "author": "jmimohsin",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2018-11-28T11:26:33Z",
        "body": "For selection of software vs hardware decoders see #3039. For most use cases it's preferable to leave this up to the platform.\r\n\r\n`DefaultHttpDataSourceFactory` allows for setting the user agent and custom HTTP headers (request properties) via its constructor and methods.\r\n\r\nThe current versions of ExoPlayer's provided UI components do not show the media URI."
      },
      {
        "user": "jmimohsin",
        "created_at": "2018-11-28T12:28:07Z",
        "body": "Thanks for help, Video is working but now no sound. I use this one too:-\r\n```kotlin\r\nval rf = DefaultRenderersFactory(this@SinglePlayerActivity, DefaultRenderersFactory.EXTENSION_RENDERER_MODE_PREFER)\r\nexoPlayer = ExoPlayerFactory.newSimpleInstance(this@SinglePlayerActivity, rf, trackSelector)\r\n```\r\n\r\nI am able to play video but sound is not coming now."
      },
      {
        "user": "andrewlewis",
        "created_at": "2018-11-28T13:05:05Z",
        "body": "Hard to say what's the cause without more information but you can probably remove `DefaultRenderersFactory.EXTENSION_RENDERER_MODE_PREFER` (unless you really do want to use extensions, in which case you'll need to build them by following the instructions in the READMEs)."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to configure decoder mode equivalent to MX Player's decode_mode parameter",
      "Method to set custom HTTP headers including User-Agent and additional headers",
      "Implementation that maintains audio playback functionality when configuring decoders/renderers",
      "Clear guidance on renderer configuration tradeoffs without relying on unspecified extensions"
    ]
  },
  {
    "number": 5159,
    "title": "Limit of ByteBuffer at queueInput (AudioProcessor)",
    "created_at": "2018-11-27T15:33:06Z",
    "closed_at": "2018-11-29T10:25:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/5159",
    "body": "Hello!\r\nI currently using ExoPlayer v2.7.3 and try to write custom AudioProcessor. For my processing method i should know exactly how much samples of audio i will get before queueInput send me this amount of data, but i can't understand the way it generates.\r\n(I using MPEG-DASH streaming)\r\n\r\nFor ex.: If i play some video with two audio channels queueInput will return me 8192 bytes of data (4096 PCM16 values, so 2048 on one channel), but if i play video with six channels it return me 12288 bytes (6144 PCM16 values, so 1024 on one channel).\r\n\r\nHow get this value for one channel before queueInput will give me data? or how set default value for one channel at 1024 or 2048 samples?\r\n\r\nBest Regards!",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/5159/comments",
    "author": "urbanovichwork",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2018-11-27T16:34:28Z",
        "body": "The input buffer's size is the size of the audio decoder output buffer written to the sink (if this is the first audio processor), or the size of output buffer from the preceding audio processor (otherwise). When using `MediaCodecAudioRenderer` I don't think there's a guarantee that the audio decoder output buffer will have a particular size.\r\n\r\nAudio processors can consume the input partially or fully without producing output. If you do that perhaps you can avoid making assumptions about the size of input buffers. Could you give a bit more detail about what you're trying to do?\n\n---\n\nTo give a concrete example: let's say you want to process batches of 2048 samples (for example). You can make an internal buffer that's big enough to store up to 2047 samples, and then when you receive more input you can process anything that's in your internal buffer followed by anything that was input up to a multiple of 2048 samples, then store anything that remains in the internal buffer. When `queueEndOfStream` is called you need some way to handle any data that remains in the internal buffer."
      },
      {
        "user": "urbanovichwork",
        "created_at": "2018-11-29T10:20:57Z",
        "body": "> To give a concrete example: let's say you want to process batches of 2048 samples (for example). You can make an internal buffer that's big enough to store up to 2047 samples, and then when you receive more input you can process anything that's in your internal buffer followed by anything that was input up to a multiple of 2048 samples, then store anything that remains in the internal buffer. When `queueEndOfStream` is called you need some way to handle any data that remains in the internal buffer.\r\n\r\nThanks for advice, did it in this way and everything is good.\r\n\r\nActualy, i have one more question. Maybe you can help me with playing audio from ExoPlayer at specific AudioSource of Unity3D? Is it possible and maybe it covered somewhere?"
      },
      {
        "user": "andrewlewis",
        "created_at": "2018-11-29T10:25:17Z",
        "body": "I don't think this is covered anywhere and I haven't tried it, but I think it's in theory possible to create a custom `AudioSink` implementation that outputs to a Unity audio source instead of writing to a platform `AudioTrack`. If you try this and manage to get it to work it would be cool if you could let us know here. Thanks!"
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to process audio in configurable batch sizes independent of input buffer variability",
      "Support for partial input consumption and residual data handling",
      "End-of-stream handling for remaining buffered data"
    ]
  },
  {
    "number": 5131,
    "title": "MediaSource identification",
    "created_at": "2018-11-21T22:02:21Z",
    "closed_at": "2018-11-21T22:13:31Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/5131",
    "body": "Is there a way of identifiying a MediaSource? Im trying to get the title of the current track as an example.\r\nSo I thought i could solve my problem by giving each queued MediaSource a specific id so that I can find the corrisponding track data (Title, Url , Image... ) internally with that id. \r\nConcatinatingMediaSource.getMediaSource(0) returns me the current media source (I assume that) but I cant find a way of setting the media source apart from the others.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/5131/comments",
    "author": "LowLevelSubmarine",
    "comments": [
      {
        "user": "LowLevelSubmarine",
        "created_at": "2018-11-21T22:13:31Z",
        "body": "For others: U can use the tag of the current window to identify a track ;)"
      },
      {
        "user": "ojw28",
        "created_at": "2018-11-22T01:08:15Z",
        "body": "Yes. the `Factory` classes for the various `MediaSource`s have `setTag(Object)` methods that allow you to set an arbitrary tag object (you could even put the metadata directly into the tag object, if it makes sense for your use case). You can then retrieve the tag associated with the currently playing source by calling `getCurrentTag` on the player."
      },
      {
        "user": "tonihei",
        "created_at": "2018-11-22T09:05:53Z",
        "body": "One further note: Please be aware that the tag is only available in the `Timeline` or from `getCurrentTag` if the media has been prepared. That means right after calling `player.prepare` or after adding a new source to the `ConcatenatingMediaSource`, this will still return null. That's not optimal and we should be probably fix this in the future."
      }
    ],
    "satisfaction_conditions": [
      "Provides a method to uniquely identify individual MediaSource instances",
      "Allows association of custom metadata with media sources",
      "Offers reliable retrieval of identifiers during playback",
      "Maintains compatibility with ConcatenatingMediaSource workflows"
    ]
  },
  {
    "number": 4971,
    "title": "Getting the resolution(1080p,430p etc) when a video is played in \"AUTO\" in quality",
    "created_at": "2018-10-17T08:46:23Z",
    "closed_at": "2018-10-17T11:36:20Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4971",
    "body": "Is there a way in which we can show the resolution when auto is selected in quality.I just want to show if auto is selected the resolution its selecting to play the video\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4971/comments",
    "author": "meenukrishnamurthy",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2018-10-17T08:51:45Z",
        "body": "Please add a `VideoListener` to `SimpleExoPlayer.addVideoListener`. The callback `onVideoSizeChanged` notifies you when the currently displayed size changes. \r\n\r\nIf you need the `Format` object of the selected quality, please add an `AnalyticsListener` and listen to `onDownStreamFormatChanged` which is similar but gives you the `Format` object and selection reason and other data."
      },
      {
        "user": "meenukrishnamurthy",
        "created_at": "2018-10-17T09:23:21Z",
        "body": "I am actually using an older fork.Have added exoplayer as library in my app.There is no analytics listener in it.I just want to know which track is being selected while playing Auto.My video format is HLS"
      },
      {
        "user": "tonihei",
        "created_at": "2018-10-17T09:30:25Z",
        "body": "You can use `addVideoDebugListener` on older versions with the same callback. \r\n\r\nNote that for HLS specifically, the `Format` reported in `onDownStreamFormatChanged` may include both video and audio if they are muxed together. In this case you'll only get the actual video size when listening to `onVideoSizeChanged`. Depends on what information you need."
      },
      {
        "user": "meenukrishnamurthy",
        "created_at": "2018-10-17T11:36:20Z",
        "body": "thanks i used onVideoSizeChanged.Its working"
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to detect selected video resolution during auto-quality playback",
      "Compatibility with older ExoPlayer versions lacking AnalyticsListener",
      "Handling of HLS stream format characteristics",
      "Real-time resolution tracking during playback"
    ]
  },
  {
    "number": 4913,
    "title": "Sound stop after a while when looping",
    "created_at": "2018-10-04T23:34:08Z",
    "closed_at": "2018-10-11T08:15:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4913",
    "body": "### Issue description\r\n\r\nUsing ExoPlayer 2.8.2 to play a local .m4a sound file in repeat mode, the sound stop after a while (typically a couple of hours). If playing several files simultaneously, each file stop at a different time. No error is reported in neither the player event listener nor the media source event listener.\r\n\r\nThe error occurs with both `player.setRepeatMode(Player.REPEAT_MODE_ALL);` or by using a LoopingMediaSource object.\r\n\r\nWhen the audio stop, the following lines appears in Logcat:\r\n    1536-1577/? I/AudioFlinger: BUFFER TIMEOUT: remove(4096) from active list on thread 0xf1203680\r\n    1430-1578/? W/audio_hw_generic: Not supplying enough data to HAL, expected position 942828484 , only wrote 934428960\r\n\r\ntoggling player.setPlayWhenReady(...) does not restore the playback.\r\n\r\nWe didn't notice this issue (and none of our users complain) with the previous version of ExoPlayer we were using: r2.4.1. Unfortunately it is not possible to roll back as an audio glitch was audible at the end of each loop.\r\n\r\n### Reproduction steps\r\n\r\nThe following code is running in a service:\r\n\r\n```\r\n...\r\ndataSourceFactory = new DefaultDataSourceFactory(context, Util.getUserAgent(context, \"XXXX\"), null);\r\nplayer = ExoPlayerFactory.newSimpleInstance(context, new DefaultTrackSelector());\r\nMediaSource audioSource = new ExtractorMediaSource.Factory(dataSourceFactory).createMediaSource(audioItem.getUri());\r\nplayer.setRepeatMode(Player.REPEAT_MODE_ALL);\r\nplayer.prepare(audioSource);\r\n...\r\nplayer.setPlayWhenReady(true);\r\n```\r\n\r\nWait until the sound stops\r\n\r\n### Link to test content\r\nSent by email\r\n\r\n### Version of ExoPlayer being used\r\n2.8.2\r\n\r\n### Device(s) and version(s) of Android being used\r\nPixel XL simulator with Android Oreo 8.1\r\nSome of our users complained about the same issue on different devices.\r\n\r\n### A full bug report captured from the device\r\nSent by email\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4913/comments",
    "author": "retameur",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2018-10-05T16:31:48Z",
        "body": "I couldn't see any obvious issues with the media or in the bug report.\r\n\r\nPlease could you try to reproduce this in the ExoPlayer demo app, but modified to set repeat mode, and on a physical device rather than using the emulator? If you can reproduce it please send the bug report. If not, that suggests there's something wrong with the service (perhaps a leak or not holding locks required to keep the device awake). Thanks.\n\n---\n\nI think the issue here is that there's a discrepancy between the duration declared in the MP4 container metadata and the actual duration of audio after applying the iTunSMPB trimming for gapless playback. I think the actual duration is 18955260 us (this is the declared duration 19017142 us, which is the duration of audio before trimming, minus the duration of 2112 + 617 audio frames at 44.1 kHz, which are trimmed). This discrepancy causes the renderer position to drift slowly away from the expected position based on the durations of earlier loops, until the player stops loading because it permanently thinks it has enough data buffered, at which point audio runs out.\r\n\r\nIf you have control over the media you may be able to fix the issue by rewriting the duration in the container to take into account trimmed frames, or possibly switching to using edit lists to signal gapless trimming.\r\n\r\nThe next steps here are to verify the hypothesis by hardcoding the calculated duration and verifying that playback doesn't get stuck, then possibly altering the extractor to update the duration to compensate for audio frames trimmed based on iTunSMPB metadata."
      },
      {
        "user": "retameur",
        "created_at": "2018-10-10T19:26:54Z",
        "body": "I have been able to reproduce the bug with ExoPlayer Demo 2.8.4 (report sent by email). The playback stops after the same number of loops (which varies with each specific sound file) as in our app. Its 241 for the frogs.m4a file I've sent by email.\r\n\r\nWe have control over the media, but it is not a solution for us, as the same media are also used for iOS and the Web. And most of the current users have already downloaded the files.\r\n\r\nI'm not sure it is related to the iTunSMPB metatag. I've re-encoded the file twice using fdkaac:\r\n    - once with the --gapless-mode option set to 0 (iTunSMPB)\r\n    - once with the option set to 1: ISO standard (edts and sgpd)\r\nThe playback of both files fails simultaneously.\r\n\r\nAs for the steps you are suggesting verifying the hypothesis, I have no idea how to do so.\n\n---\n\nI have also tested with ExoPlayer demo 2.9.0 and the bug seems to be fixed now (if it still occurs, it is after way more loops). So problem solved. \r\n\r\nThanks for your help."
      },
      {
        "user": "tonihei",
        "created_at": "2018-10-11T08:15:49Z",
        "body": "Yes, it was fixed by a change in 2.9.0 which prevents the problem you describe. Still, if you want perfect gapless playback of the looped file, you should try to ensure the duration exactly matches the content."
      }
    ],
    "satisfaction_conditions": [
      "Solution must resolve audio playback stopping during long-term looping without requiring media file modifications",
      "Addresses underlying timing discrepancy between container metadata and actual audio content",
      "Maintains gapless playback functionality across loop iterations",
      "Compatible with multiple gapless signaling methods (iTunSMPB and ISO standard)"
    ]
  },
  {
    "number": 4843,
    "title": "How to seperate default time bar",
    "created_at": "2018-09-20T06:25:44Z",
    "closed_at": "2018-09-20T07:41:27Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4843",
    "body": "hi there, i am looking for default time bar separated even though i make media source ConcatenatingMediaSource. For example, like play music list supposed current bar show only time of current music play instead of combine them all together in on line timeba.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4843/comments",
    "author": "hafiz013",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2018-09-20T07:41:27Z",
        "body": "The default behavior is to show each song separately (one at a time). If you call `playerView.setShowMultiWindowTimeBar(true)` then the time bar will show the concatenation of the songs as if they were one long track, but see also #4727 for limitations of this."
      },
      {
        "user": "hafiz013",
        "created_at": "2018-09-25T09:47:48Z",
        "body": "so in that case how to play next media source programmatically in stead of next button from controller."
      },
      {
        "user": "andrewlewis",
        "created_at": "2018-09-25T10:08:25Z",
        "body": "Is this the same as #4863 or a different question? If you pass the player a concatenation it should advance automatically from one item to the next."
      },
      {
        "user": "hafiz013",
        "created_at": "2018-09-26T02:29:12Z",
        "body": "different question.playerView.setShowMultiWindowTimeBar(false) make time bar separated media source even though already concatenation. thank for info."
      }
    ],
    "satisfaction_conditions": [
      "Display individual time bars for each media item in a ConcatenatingMediaSource",
      "Show only the current track's duration in the time bar during playback"
    ]
  },
  {
    "number": 4836,
    "title": "VP9 ext crash from libvpx 1.7.0",
    "created_at": "2018-09-18T10:53:04Z",
    "closed_at": "2018-09-23T15:17:10Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4836",
    "body": "It seems libvpx 1.7.0 has more neon code added. There was error when I run config. By adding -mfloat-abi=softfp -mfpu=neon to cflag, I have managed to get the so file compiled. However, after the first frame is decoded, the sample app always crashes with: \r\n\r\ncom.google.android.exoplayer2.demo A/libc: Fatal signal 11 (SIGSEGV), code 1, fault addr 0x10 in tid 18160 (Thread-1825)\r\n\r\nMy ExoPlayer version is 2.8.2. The working libvpx is 1.6.2, which is from Jan 2017.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4836/comments",
    "author": "blueslabs",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2018-09-21T16:32:42Z",
        "body": "I think the errors that occur during configuration might not actually be problematic. What do you see if you just ignore the errors during configuration? I tried building with libvpx 1.7.0, ignoring the errors and playing a video with the vp9 extension and it worked."
      },
      {
        "user": "blueslabs",
        "created_at": "2018-09-22T18:53:46Z",
        "body": "Thanks! Did a clean build, it works now. -mfloat-abi=softfp -mfpu=neon is actually only required for the current master, otherwise build can fail. 1.7.0 can build without this."
      }
    ],
    "satisfaction_conditions": [
      "Ensures libvpx 1.7.0 builds successfully without requiring manual compiler flag additions like -mfloat-abi=softfp -mfnu=neon",
      "Provides a stable build process that avoids fatal SIGSEGV crashes during VP9 decoding",
      "Addresses configuration errors during the build process without requiring workarounds",
      "Maintains compatibility with ExoPlayer 2.8.2"
    ]
  },
  {
    "number": 4802,
    "title": "Question: Analytics Listener Play Status + Detect Replay",
    "created_at": "2018-09-11T13:39:22Z",
    "closed_at": "2018-09-13T17:04:00Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4802",
    "body": "Using: Exoplayer 2.8.4\r\n\r\nI am trying to implement some tracking from our analytics team, and there are two tracking events that I'm having trouble finding a way to track through the Analytics Listener.\r\n\r\nFirstly, is it possible to detect replays if the video is set to loop when it completes? I tried to listen to:\r\n\r\n```\r\noverride fun onPlayerStateChanged(\r\n        eventTime: AnalyticsListener.EventTime?,\r\n        playWhenReady: Boolean,\r\n        playbackState: Int\r\n    )\r\n```\r\n\r\nbut it doesn't appear as though this event is fired with state ENDED (or anything for that matter) when the video replays.\r\n\r\nSecondly, we would like to track how far into a video a user has watched at certain intervals (e.g. 1s, 5s, 10s, 30s). Is it possible to receive callbacks at certain points in the media's playback? As far as I can see, there's no way to receive callbacks once every second or so. I was thinking that I could implement this via a timer that runs alongside the video, but the problem with that approach is that the second the video has to spend time buffering or the user has seeked, the timer will no longer be accurate to the actual video position.\r\n\r\nThanks",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4802/comments",
    "author": "ghost",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2018-09-11T13:50:27Z",
        "body": "For looping (\"replay\"), you should receive a `onPositionDiscontinuity` event with reason `DISCONTINUITY_REASON_PERIOD_TRANSITION`.\r\n\r\nFor the regular timer, you can either:\r\n- Call a Handler method in regular intervals (every x seconds in real time) and then check the current position with `player.getCurrentPosition()`.\r\n- Or send messages at pre-defined media positions. You can do that by calling `player.createMessage(messageHandler).setPosition(position).setHandler(appHandler).send()`. You may also want to add `setDeleteAfterDelivery(false)` to resend the message even if the user seeks back."
      },
      {
        "user": "ghost",
        "created_at": "2018-09-11T18:49:50Z",
        "body": "The replay check you mentioned does work, so thank you.\r\n\r\nI've done the below for play time tracking and it doesn't ever seem to fire back to the message target. In the below, `recordPlayTime` is never called.\r\n\r\n```\r\nprivate fun createMessageAtPosition(videoPlayer: SimpleExoPlayer, position: Int, handler: Handler) {\r\n        val positionInMilliseconds = position.toLong() * 1000\r\n        Log.v(TAG, \"createMessageAtPosition, Adding message at ${positionInMilliseconds}ms\")\r\n        videoPlayer.createMessage { _: Int, _: Any -> recordPlayTime(position) }\r\n            .setPosition(positionInMilliseconds)\r\n            .setDeleteAfterDelivery(false)\r\n            .setHandler(handler)\r\n            .send()\r\n    }\r\n\r\n    private fun recordPlayTime(position: Int) {\r\n        analyticsLogger.playTime(position)\r\n    }\r\n```\r\n"
      },
      {
        "user": "tonihei",
        "created_at": "2018-09-13T11:13:18Z",
        "body": "I just tried and added the following lines to our demo app:\r\n```\r\nplayer\r\n    .createMessage((type, payload) -> Log.d(\"POSITION\", \"message triggered at 5 seconds.\"))\r\n    .setPosition(5000)\r\n    .setDeleteAfterDelivery(false)\r\n    .setHandler(new Handler())\r\n    .send();\r\n```\r\nThis works fine and logs the message every time I play past the 5 second mark. Can you check what is different in your app? Especially whether the position is actually in milliseconds."
      },
      {
        "user": "ghost",
        "created_at": "2018-09-13T17:04:00Z",
        "body": "For some reason, this started working after I forced the handler to and message to be created on the main thread. Unsure of why exactly that worked, since technically the UI should only be created on the main thread. \r\n\r\nAlso worth noting: PlayerMessage.Target is missing nullity parameters and Kotlin incorrectly assumes these fields will be non-null, which caused a crash since payload is null\r\n\r\n```\r\npublic interface Target {\r\n    void handleMessage(int messageType, Object payload) throws ExoPlaybackException;\r\n  }\r\n```\r\n\r\nThank you for your help, closing."
      },
      {
        "user": "tonihei",
        "created_at": "2018-09-14T13:22:55Z",
        "body": "Thanks for noting the missing annotations! We'll add them to the PlayerMessage class."
      }
    ],
    "satisfaction_conditions": [
      "Track playback progress at specific intervals accounting for buffering and seeking",
      "Ensure message-based position tracking works across thread boundaries",
      "Handle nullable parameters in callback interfaces"
    ]
  },
  {
    "number": 4745,
    "title": "m3u8 subtitles are not supported",
    "created_at": "2018-08-29T12:39:55Z",
    "closed_at": "2018-08-29T14:10:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4745",
    "body": "Hi,\r\nI am facing a problem with m3u8 links for displaying subtitles, are m3u8 links are not supported with v2.2.0.\r\nTrying to construct the media source like:\r\n\r\n\r\n```\r\nFormat englishSubsFormat = Format.createTextSampleFormat(null, MimeTypes.APPLICATION_M3U8, null, Format.NO_VALUE, Format.NO_VALUE, \"eng\", null);\r\n            MediaSource englishSubSource = new SingleSampleMediaSource(Uri.parse(englishSubtitleLink), mediaDataSourceFactory, englishSubsFormat, C.TIME_UNSET);\r\n            MergingMediaSource mergedSource = new MergingMediaSource(videoSource, englishSubSource);\r\n````\r\n\r\nEventLogger shows below logs,\r\n\r\n> Renderer:None [\r\n08-27 15:35:51.903 27269-27269/com.myplex.vodafonestaging D/EventLogger: Group:0 [\r\n[ ] Track:0, id=null, mimeType=application/x-mpegURL, language=English, supported=NO\r\n]\r\n\r\n\r\nPlease let me know if anything wrong with Format creation.\r\nNote: englishSubtitleLink is \"m3u8\" link.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4745/comments",
    "author": "srikanthsunkari",
    "comments": [
      {
        "user": "AquilesCanta",
        "created_at": "2018-08-29T14:10:11Z",
        "body": "Try replacing your single sample media source with an HlsMediaSource. \r\n\r\nThe only way to reproduce m3u8 files is to use HlsMediaSource. SingleSampleMediaSource is only used for media which is made up by a single sample. For example, subtitle files (example: vtt, srt, etc). Note that m3u8 files themselves are not subtitles, but may contain a list of subtitles.\r\n\r\nDepending on the type of `videoSource`, it might make more sense including subtitles as part of the original media. For example, if videoSource is an HlsMediaSource, then try referring to your subtitles m3u8 from an EXT-X-MEDIA. Please provide more context below (media links, for example), if this does not answer your question."
      },
      {
        "user": "srikanthsunkari",
        "created_at": "2018-08-30T08:06:20Z",
        "body": "Thank you @AquilesCanta, I am able to show subtitles with HlsMediaSource now.\r\n      \r\nThe subtitle hls source is different from the video source, though the video source is also an hls source and each language subtitle has its own m3u8 link. \r\n\r\nThough being able to show subtitles, constructing HlsMediaSource for a specific subtitle will not allow me to specify the format id or language code except track group index, whereas with SingleSameMediaSource expects format and we can specify the language code in Format. \r\n\r\n It would be great if there is a way to identify the Format belonging to a specific language using HlsMediaSource. Please let me know if I am missing anything here or is there any other way.\r\n\r\n"
      },
      {
        "user": "AquilesCanta",
        "created_at": "2018-08-30T09:59:14Z",
        "body": "No, there is no straightforward way to do it. I insist that the right way is to include the subtitles as part of the original master playlist (which would allow you to provide a language as well). You could potentially pass a custom playlist parser that injects the subtitle rendition client side. So, basically you could wrap the default playlist parser, and once the master playlist is parsed, you add your subtitle link to the `subtitles` field. Hope this helps."
      },
      {
        "user": "srikanthsunkari",
        "created_at": "2018-08-30T13:18:44Z",
        "body": "Thank you @AquilesCanta, It is not possible to include subtitles as part of an original master playlist. Well, for now, I get it managed with the positions of added subtitles. I will sure do look into constructing custom playlist parser for customizing.\r\nThank you again for the help.\n\n---\n\nHi @AquilesCanta, I observed playback is not in sync with the subtitles. I see that subtitles are displayed earlier than the usual point. Is this an issue with the subtitle link or am I missing anything? \n\n---\n\nPlease let me know if any info is required from my end, or If it is required to raise a new Issue? If you feel that originally raised issue has closed."
      },
      {
        "user": "AquilesCanta",
        "created_at": "2018-08-30T13:40:01Z",
        "body": "> I observed playback is not in sync with the subtitles\r\n\r\nWhich approach are you using?\r\n\r\nI am going to assume the subtitles are webvtt. Then the files should start with\r\n\r\nWEBVTT\r\nX-TIMESTAMP-MAP=MPEGTS:XXXXXXX,LOCAL:00:00:00.000\r\n\r\nYou need to make sure is that the MPEGTS value equals the first PTS in the TS files. This is the way in which HLS ensures the subtitles are in sync. If this does not work for you, you can still go with the MergingMediaSource approach, combined with custom playlist tracker (in the HlsMediaSource of the subtitles playlist) that wraps the default one and injects the language to the getMasterPlaylist method. In this case you don't need a custom playlist parser, just a custom tracker."
      },
      {
        "user": "srikanthsunkari",
        "created_at": "2018-08-31T08:14:52Z",
        "body": "Yes, I am following the WEBVTT approach with MergingMediaSource and custom tracker.\r\nI don't see\r\n> WEBVTT\r\n>  X-TIMESTAMP-MAP=MPEGTS:XXXXXXX,LOCAL:00:00:00.000\r\n\r\n\r\nSample m3u8 file look like :\r\n\r\n> #EXTM3U\r\n> #EXT-X-VERSION:3\r\n> #EXT-X-TARGETDURATION:5859\r\n> #EXT-X-MEDIA-SEQUENCE:0\r\n> #EXT-X-PLAYLIST-TYPE:VOD\r\n> #EXTINF:5859\r\n> XYZ-cap_eng.vtt\r\n> #EXT-X-ENDLIST\r\n> \r\n\r\nVideo source and multiple m3u8 subtitles media source with MergingMediaSource\r\n\r\n```\r\n`               int mediaSourceArraySize = subtitles.values.size() + 1;\r\n                MediaSource[] mediaSourceArray = new MediaSource[mediaSourceArraySize];\r\n                int i = 0;\r\n                mediaSourceArray[i] = videoSource;\r\n                i++;\r\n                for (SubtitleItem subtitleItem :\r\n                        subtitles.values) {\r\n                    String mimeType = MimeTypes.APPLICATION_TTML;\r\n                    MediaSource subTitleSource;\r\n                    //builds HlsMediaSource similar to video source\r\n                    subTitleSource = buildMediaSource(Uri.parse(subtitleItem.link_sub),null);\r\n                    mediaSourceArray[i] = subTitleSource;\r\n                    i++;\r\n                }\r\n                MergingMediaSource mergedSource = new MergingMediaSource(mediaSourceArray);\r\n                player.prepare(mergedSource, true, false);\r\n            }\r\n`\r\n```\r\nBelow is first subtitle to be displayed:\r\n\r\n> \r\n> WEBVTT\r\n> \r\n> 00:00:31.398 --> 00:00:35.402\r\n> <i>I get to work before the sun comes up\r\n> </i>and I leave long after it's gone down.\r\n> \r\n\r\nWhereas it is displaying as soon as playback starts. \n\n---\n\nHi @AquilesCanta, waiting for your reply on subtitles duration issue, Please let me know if in case you want me to raise a new issue.\n\n---\n\nRaised new issue for playback sync with subtitles #4758 ."
      }
    ],
    "satisfaction_conditions": [
      "Support for separate subtitle m3u8 links with language identification",
      "Synchronization between video playback and subtitle timing",
      "Integration of external subtitle tracks without modifying the original master playlist",
      "Metadata preservation for subtitle formats"
    ]
  },
  {
    "number": 4692,
    "title": "Does onTracksChanged gets called when video track changes due to ABR ?",
    "created_at": "2018-08-20T13:03:25Z",
    "closed_at": "2018-08-21T14:19:02Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4692",
    "body": "onTracksChanged is not getting called when video changes due to ABR. I tried getting updated track using `getCurrentTrackSelections`, but it is not returning updated list.\r\n\r\n`player.getVideoFormat()` is giving right format selected, but has incorrect values about bitrate.\r\nexample -  getting bitrate as -1, track id is wrong.\r\n\r\nWhat is the best way to get notified and get all track related info when video track changes.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4692/comments",
    "author": "sravan1213",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2018-08-21T13:57:11Z",
        "body": "`onTracksChanged` only gets called when the available tracks change, not when the adaptive selection changes. You should use `getVideoFormat`. You can also register an `AnalyticsListener` that overrides `onDecoderInputFormatChanged` to be notified when a change occurs.\r\n\r\nYou should see the bitrate and track id set correctly for DASH and SmoothStreaming adaptive playbacks. HLS we made some recent improvements in how this information is propagated, so you may have to try the `dev-v2` branch and/or wait for the 2.9.x release. Please give that a try and let us know if you're still not seeing the data you expect."
      },
      {
        "user": "tonihei",
        "created_at": "2018-08-21T14:05:56Z",
        "body": "Just to add to this, you may prefer to use `onVideoSizeChanged` which gives the selected video format specifically. That makes a difference if using HLS and `onDecoderInputFormatChanged` has a muxed audio and video format."
      },
      {
        "user": "sravan1213",
        "created_at": "2018-08-21T14:19:02Z",
        "body": "@ojw28 @tonihei thanks for the help.\r\nIt is working as expected in `dev-v2` for both HLS and DASH streams."
      }
    ],
    "satisfaction_conditions": [
      "Provides a reliable method to detect video track changes caused by Adaptive Bitrate (ABR) switching",
      "Ensures accurate track metadata retrieval (bitrate, track ID) after ABR changes",
      "Works consistently across HLS and DASH streaming formats",
      "Offers real-time notification rather than polling-based solutions"
    ]
  },
  {
    "number": 4613,
    "title": "Order of execution of listeners",
    "created_at": "2018-08-02T23:43:17Z",
    "closed_at": "2018-08-16T20:57:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4613",
    "body": "Hi,\r\n\r\nI am using ExoPlayer 2.8.2 release and trying to implement a feature where I want to use the bandwidth measurement from the latest video segment download to influence the quality of the next segment. This is for Dash videos.\r\nI have extended trackSelection to `CustomTrackSelection` object. But, the problem on several occasions, by the time the `DefaultDashChunkSource` calls `updateSelectedTrack` function, the previous download end event hasn't been processed by my `listener` and I haven't had a chance to register the latest throughput sample. \r\nI guess what's happening is that the `onLoadCompleted` event is processed by `ChunkSampleStream` and it proceeds with the next download start _before_ my listener is invoked.\r\nIs there any way to get around this? Is there any way I can \"wait\" before downloading the next segment if my listener hasn't registered the download end event?\r\n\r\nThanks for your attention and help! I appreciate any pointers.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4613/comments",
    "author": "kanthicn1",
    "comments": [
      {
        "user": "erdemguven",
        "created_at": "2018-08-07T08:52:12Z",
        "body": "Why don't you use AdaptiveTrackSelection? It already selects tracks according to bandwidth measurement. "
      },
      {
        "user": "kanthicn1",
        "created_at": "2018-08-09T18:58:46Z",
        "body": "Fair enough @erdemguven . Sorry for not writing the complete problem. I don't want to use `AdaptiveTrackSelection` because I want to use my own track selection logic which doesn't quite agree with what `AdaptiveTrackSelection` is doing. Also, the `DefaultBandwidthMeter`, which is used by `AdaptiveTrackSelection`,  gives a  \"SlidingPercentile\" estimate of bandwidth while I want the last instantaneous value of the bandwidth measurement. \r\nOne approach that might actually work for my case is to use a different bandwidth meter instead of relying on throughput measurements from listeners.\r\n\r\n(a) implement `CustomBandwidthMeter` and pass that to the `buildDataSourceFactory` and `customTrackSelection`. -- this is so that my `CustomBandwidthMeter` can expose the last instantaneous measurement of bandwidth sample.\r\n(b) Query the `CustomBandwidthMeter` for the latest throughput sample from `CustomTrackSelection` and use it in my track selection logic.\r\n\r\nMy question is: in the above logic, is there a chance that I might not get the latest throughput sample due to race conditions in event processing? i.e., Is the `DataSourceFactory` guaranteed to update the bandwidth sample before `CustomTrackSelection` is called for picking the quality for the next segment to be loaded?"
      },
      {
        "user": "erdemguven",
        "created_at": "2018-08-16T20:49:57Z",
        "body": "@ojw28 could you look at this?"
      },
      {
        "user": "ojw28",
        "created_at": "2018-08-16T20:57:30Z",
        "body": "> My question is: in the above logic, is there a chance that I might not get the latest throughput sample due to race conditions in event processing? i.e., Is the DataSourceFactory guaranteed to update the bandwidth sample before CustomTrackSelection is called for picking the quality for the next segment to be loaded?\r\n\r\nThere is a guarantee, which is that the `TransferListener.onTransferEnd` call corresponding to a chunk will always be called before `TrackSelection.updateSelectedTrack` is called to pick the quality for the next chunk. Note that `DefaultBandwidthMeter` updates its bitrate estimate in `onTransferEnd`, and `AdaptiveTrackSelection` gets the bitrate estimate in `TrackSelection.updateSelectedTrack`. Hence it's guaranteed that the updated bitrate estimate is used.\r\n\r\nSo in short, as long as you follow the same model in your custom components (albeit changing the actual logic for estimating the bitrate and/or choosing the track), then you'll get the same guarantee, which I think is what you want."
      },
      {
        "user": "kanthicn1",
        "created_at": "2018-08-16T21:03:35Z",
        "body": "Perfect. Thanks @ojw28 and @erdemguven. "
      }
    ],
    "satisfaction_conditions": [
      "Guarantees bandwidth measurement updates occur before next track selection",
      "Provides synchronization mechanism for event processing order",
      "Supports custom track selection using latest instantaneous bandwidth values",
      "Maintains ExoPlayer's internal execution guarantees for custom components"
    ]
  },
  {
    "number": 4547,
    "title": "getWindowIndex() sometime is delay",
    "created_at": "2018-07-22T15:50:48Z",
    "closed_at": "2018-07-23T09:44:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4547",
    "body": "//Version\r\n2.7.3\r\n\r\n//Description\r\nI'm using ClippingMediaSource and DynamicConcatenatingMediaSource to play multiple video clips, and i need to know the current index of window when onVideoSizeChanged callback, but i found sometime the index is not correct because onPositionDiscontinuity->DISCONTINUITY_REASON_PERIOD_TRANSITION is later than  onVideoSizeChanged.\r\nso i getWindowIndex() is an un correct index.\r\n\r\nMy question is how to get exact window index when onVideoSizeChanged?\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4547/comments",
    "author": "RuijiePan",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2018-07-23T08:28:45Z",
        "body": "What you describe is basically working as intended. The reason is that these two event (onVideoSizeChanged and onPositionDiscontinuity) belong to different listeners and our listeners are not synchronized to each other for various reasons.\r\n\r\nHowever, we recently added the `AnalyticsListener` class which combines all listeners we have in one place and gives additional information for each event (including which window they belong to). This new listener has been added in 2.8.0. The easiest way to use it is with `SimpleExoPlayer.addAnalyticsListener`. "
      }
    ],
    "satisfaction_conditions": [
      "Synchronization between video size changes and window index tracking",
      "Event context preservation for media source transitions",
      "Listener integration that maintains window association"
    ]
  },
  {
    "number": 4526,
    "title": "How to reduce increasing latency for RTMP live stream",
    "created_at": "2018-07-17T15:16:21Z",
    "closed_at": "2018-07-27T08:44:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4526",
    "body": "I'm having issues with increasing latency over time when playing RTMP stream.\r\n\r\nThe problem occurs only when the stream needs to be buffered during playback. Every time this happens the latency increases. \r\n\r\nI'm aware this is not an issue with ExoPlayer itself, but maybe you could help me how to handle that? \r\n\r\nI know that LoadControl is responsible for buffer strategy but in overall I would like to get rid of this buffer. Not like totally but whenever we need to buffer we should skip all frames and start buffering the latest frames so that the latency will not increase.\r\n\r\nI could listen for `Player.STATE_BUFFERING` state and when this occurs call `player.seekToDefaultPosition()` but I'm not sure if this is the right approach.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4526/comments",
    "author": "AdamGrzybkowski",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2018-07-18T09:31:06Z",
        "body": "If the approach you mention works, then I'd probably suggest doing that. ExoPlayer doesn't skip forward to the live edge automatically."
      },
      {
        "user": "AdamGrzybkowski",
        "created_at": "2018-07-27T06:10:58Z",
        "body": "@ojw28 looks like this solution works fine, thanks :) You can close the issue"
      }
    ],
    "satisfaction_conditions": [
      "Solution must allow the player to automatically skip to the live edge when buffering occurs",
      "Approach must prevent cumulative latency increases after buffering events",
      "Implementation should not depend on ExoPlayer's default buffering behavior"
    ]
  },
  {
    "number": 4490,
    "title": "IllegalStateException: Assertions.checkState When using same instance of SimpleCache",
    "created_at": "2018-07-10T07:59:00Z",
    "closed_at": "2018-07-10T09:06:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4490",
    "body": "Hi,\r\nI am getting the exception\r\n```\r\njava.lang.IllegalStateException\r\nat com.google.android.exoplayer2.util.Assertions.checkState(Assertions.java:81)\r\nat com.google.android.exoplayer2.upstream.cache.SimpleCache.getContentMetadata(SimpleCache.java:348)\r\nat com.google.android.exoplayer2.upstream.cache.SimpleCache.getContentLength(SimpleCache.java:335)\r\nat com.google.android.exoplayer2.upstream.cache.CacheUtil.getCached(CacheUtil.java:88)\r\n```\r\n when I'm trying to use the singleton instance of SimpleCache.\r\n```\r\ncompanion object DownloadCache {\r\n        private var downloadCache: Cache? = null\r\n        private var downloadDirectory: File? = null\r\n\r\n        @Synchronized\r\n        internal fun getDownloadCache(context: Context): Cache {\r\n            if (downloadCache == null) {\r\n                val downloadContentDirectory = File(getDownloadDirectory(context), \"cache\")\r\n                downloadCache = SimpleCache(downloadContentDirectory, NoOpCacheEvictor())\r\n            }\r\n            return downloadCache!!\r\n        }\r\n\r\n        private fun getDownloadDirectory(context: Context): File {\r\n            if (downloadDirectory == null) {\r\n                downloadDirectory = File(LogTrackUtil().getDir(context))\r\n                if (downloadDirectory == null) {\r\n                    downloadDirectory = context.filesDir\r\n                }\r\n            }\r\n            return downloadDirectory!!\r\n        }\r\n    }\r\n```\r\n\r\nI am checking the cached data for a particular URL.\r\nThe below code works perfectly for the first time but following calls to this code throws the exception.\r\n```\r\ndownloadCache = VideoPlayerUtil.getDownloadCache(mContext!!) as SimpleCache\r\nval uri = Uri.parse(mExercise?.fileUrl)\r\nval counters = CacheUtil.CachingCounters()\r\nCacheUtil.getCached(DataSpec(uri), downloadCache, counters)\r\n```\r\n\r\nWhat am I doing wrong?? Please help.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4490/comments",
    "author": "joecizac",
    "comments": [
      {
        "user": "erdemguven",
        "created_at": "2018-07-10T09:06:39Z",
        "body": "Probably, you're releasing your singleton instance of SimpleCache (using SimpleCache.release() method) at some point and then try to reuse it. That's why it's throwing that exception.\r\n\r\nAs you use a singleton, I think you can just remove the call to release(). Otherwise you need to recreate another SimpleCache instance after release() call."
      }
    ],
    "satisfaction_conditions": [
      "Identify why the SimpleCache instance becomes invalid after initial use",
      "Explain proper lifecycle management for SimpleCache singleton",
      "Address potential premature release of cache resources",
      "Prevent IllegalStateException when reusing cache instance"
    ]
  },
  {
    "number": 4217,
    "title": "Question on achieving a low latency HLS live stream",
    "created_at": "2018-05-07T20:54:04Z",
    "closed_at": "2018-05-11T13:57:35Z",
    "labels": [
      "question",
      "need more info"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4217",
    "body": "I'm using Exoplayer to play HLS live streams with a 30 sec window and 2 second segments, and I'am trying to optimize for low latency.\r\n\r\nEverything works great using all the default settings for `LoadControl` and the default `HlsExtractorFactory`, with playback starting 3 segments before the end of the window as expected. \r\n\r\nThe issue i'm seeing is when I'm on a good connection, I often get into a very short buffering states (around a second) after playing the stream for a few seconds.\r\n\r\nThis happens even more frequently if I lower the resolution of my stream to the lowest possible, and stay on a fast internet connection.\r\n\r\nAfter debugging what's happening, it looks like the renderers are asking for the next segment, but the backend hasn't made that next segment available yet. Almost as if the renderer is ahead of the backend, and when asking for more, instead of just waiting and continuing playback (there's still buffered data to be played), it immediately sets the player state to `Player.STATE_BUFFERING`, until the new segment is available.\r\n\r\nIf I set the stream to start further back in the window, say 4-5 segments from the edge, the problem disappears completely, and my buffer sizes stay healthy, but I obviously loose in latency.\r\n\r\nI'm surprised by this behavior as it seems like a common case for live HLS live streams to try to be as close as possible to the edge of the window.\r\n\r\nI'm trying to understand why I'm getting this behavior, and wondering if I'm missing a configuration setting on the client, or if it's something that needs to be tweaked on the backend.\r\n\r\nThanks in advance!\r\n\r\n### Version of ExoPlayer being used\r\n2.7.3\r\n\r\n### Device(s) and version(s) of Android being used\r\nGoogle Pixel XL 2\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4217/comments",
    "author": "joaquim-verges",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2018-05-08T09:50:11Z",
        "body": "Can you provide us with a link to your test stream to ensure we can reproduce the issue? \r\n\r\nI tested another HLS live stream and manually set the start position to a few seconds to the end of the window. This also causes some buffering as soon as I reach the end of the  window. However, this is clearly caused by running out of media as the playlist update and prebuffering of the next segment doesn't happen fast enough. \r\n\r\nNote that our  `DefaultLoadControl` waits until it has 5 seconds of buffered media before continuing playback when in `STATE_BUFFERING`. This is the `bufferForPlaybackAfterRebufferMs` parameter.\r\nWhen I set this to zero, it continues playing immediately after getting new media. That allowed me to set the playback position to 1-2 seconds behind the live edge while still having a smooth playback with only the occasional small hick-up when loading didn't catch up fast enough. "
      },
      {
        "user": "joaquim-verges",
        "created_at": "2018-05-11T05:46:17Z",
        "body": "Thank you for the prompt reply @tonihei! That makes much more sense now, didn't think of reducing the `bufferForPlaybackAfterRebufferMs` value, it does help getting better latency on good connections.\r\n\r\nI'll play with the right value to balance between latency and good experience for slower connections.\r\n\r\nI'm also thinking of subclassing `DefaultLoadControl` to increase the `bufferForPlaybackAfterRebufferMs` value as I hit more buffer empties, to make the value more dynamic.\r\n\r\nSeems like something like this should work?\r\n\r\n```\r\n// bufferForPlaybackAfterRebufferUs == 1 sec initially\r\n\r\n@Override\r\npublic boolean shouldStartPlayback(long bufferedDurationUs, float playbackSpeed, boolean rebuffering) {\r\n\tboolean shouldStartPlayback = super.shouldStartPlayback(bufferedDurationUs, playbackSpeed, rebuffering);\r\n\tif (rebuffering) {\r\n\t\t// add new condition to start playback dependent on the rebuffer count \r\n\t\tshouldStartPlayback &= bufferedDurationUs >= bufferForPlaybackAfterRebufferUs * rebufferCount;\r\n                 // increment rebuffer count when we resume playback\r\n                if (shouldStartPlayback) {\r\n\t                rebufferCount++;\r\n                }\r\n\t}\r\n\treturn shouldStartPlayback;\r\n}\r\n```\r\n\r\nDoes this makes sense for a live stream rebuffer behavior to keep requiring more buffered data as we hit more hiccups? and is `DefaultLoadController.shouldStartPlayback` the right place to add this logic?\r\n\r\nThanks again for the precious help.\r\n\r\n\n\n---\n\nJust wanted to post an update for my buffering issue. I was lucky enough to meet @AquilesCanta from your team at Google I/O, and after inspecting a stream that reproduced the issue, he pointed out that I had an incorrect `#EXT-X-TARGETDURATION` of 5 seconds, while my segments are only 2 seconds.\r\n\r\nThis was causing exoplayer to only load new segments every 5 seconds, which I believe was the main cause of my rebuffering issue.\r\n\r\nTo verify this, I recompiled the HLS module with a hardcoded value of 2 seconds for `targetDurationUs` when building new `HlsMediaPlaylist` objects, and indeed the issue is now completely gone! I'm getting great latency and smooth playback :)\r\n\r\nWanted to post this in case it helps other people, and say a huge thanks to @AquilesCanta for helping me debug the issue.\r\n\r\nCongrats on a great library, and keep up the good work!"
      },
      {
        "user": "AquilesCanta",
        "created_at": "2018-05-11T13:38:38Z",
        "body": "Great news, Joaquim! Nice meeting you. Feel free to reach out if you run into any more issues."
      },
      {
        "user": "tonihei",
        "created_at": "2018-05-11T13:57:35Z",
        "body": "Closing the issue then, as it seems the question was solved."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of client-side buffering configuration parameters that affect latency-rebuffering balance",
      "Validation of server-side HLS playlist configuration accuracy",
      "Mechanism to dynamically adapt buffering requirements based on network conditions",
      "Guidance on maintaining live edge proximity without segment availability gaps"
    ]
  },
  {
    "number": 4155,
    "title": "DRM onDrmSessionManagerError JSON body response",
    "created_at": "2018-04-19T16:37:45Z",
    "closed_at": "2018-04-20T08:31:27Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4155",
    "body": "### Issue description\r\nI'm trying to get JSON body responce in `onDrmSessionManagerError` but there is no such info in `HttpDataSource.InvalidResponseCodeException` error. Could you please provide me info how can I get JSON body inside `DefaultDrmSessionManager.EventListener` `onDrmSessionManagerError` callback.\r\n \r\n### Version of ExoPlayer being used\r\ncom.google.android.exoplayer:exoplayer:2.6.1\r\n\r\nI'll appreciate a quick answer.\r\nThanks in advance.\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4155/comments",
    "author": "AlinaVoronkovaEpam",
    "comments": [
      {
        "user": "botaydotcom",
        "created_at": "2018-04-19T17:00:57Z",
        "body": "Hi @AlinaVoronkovaEpam,\r\nI'm not sure about your specific situation (are you using `DefaultHttpDataSource`, `CronetDataSource`, or `OkHttpDataSource` for the DRM callback?), but I don't think this is supported by default.\r\n\r\nOne thing you may try is to debug and step into the place where the `InvalidResponseCodeException` was thrown - probably from the `open(DataSpec)` method of one of these data source classes. Try to inspect the response at that point to see if you can get the expected JSON body response in that case.\r\n\r\nIf you can get your expected JSON body there, one option is to subclass/encapsulate whatever `HttpDataSource` you are using into a new `HttpDataSource` implementation, catch when the `InvalidResponseCodeException` was thrown, and try to read from the connection at that point. Then you can inject that custom `HttpDataSource` in the `HttpMediaDrmCallback` yourself."
      },
      {
        "user": "brol1dev",
        "created_at": "2018-04-20T01:59:04Z",
        "body": "@botaydotcom I'm working with @AlinaVoronkovaEpam on this one. I was able to read the JSON by subclassing `DefaultHttpDataSource`. but I see that `InvalidResponseCodeException` doesn't accept a body as part of its arguments, so what do you think is the right approach? I'm thinking we should subclass `InvalidResponseCodeException` (in reality its parent since `InvalidResponseCodeException` is final) to add an extra field that will contain the JSON and that way we can read it on our callback accordingly.\n\n---\n\nBTW I was able to finish the whole workflow. I ended up extending `HttpDataSourceException` and adding a new field which contains the JSON response body and we can read that right when the error happens.\r\n\r\nThanks for the help @botaydotcom \ud83d\udc4d \n\n---\n\nTo add more details if anyone else has the same problem. We extended `OoyalaDrmHttpDataSource` and on the `open(DataSpec dataSpec)` method when we identify there's an error, we just parse the `connection.getErrorStream()` object which contains the response body that for our case it's a JSON text."
      },
      {
        "user": "botaydotcom",
        "created_at": "2018-04-20T08:31:27Z",
        "body": "Cool, glad that you can resolve your problem!"
      },
      {
        "user": "AlinaVoronkovaEpam",
        "created_at": "2018-04-24T14:01:02Z",
        "body": "Thanks!"
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to access HTTP error response body during DRM errors",
      "Error propagation with response body details",
      "Custom HTTP data source integration",
      "Compatibility with ExoPlayer's DRM callback system"
    ]
  },
  {
    "number": 4107,
    "title": "Grabbing synchronized audio samples",
    "created_at": "2018-04-10T17:20:05Z",
    "closed_at": "2018-04-22T21:57:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4107",
    "body": "Is it possible to grab _synchronized_ audio samples from a running ExoPlayer instance, without having to modify the source code?\r\n\r\nCurrently I'm getting the decoded audio samples inside of `processOutputBuffer` in `MediaCodecAudioRenderer`, but these don't seem to be in sync with the video.  Also this has required me to essentially write my own renderer (and subsequently my own `AudioSink`, since `DefaultAudioSink` is a `final` class). I tried grabbing them from `handleBuffer` in `DefaultAudioSink` instead, but again it seems like the samples I get there (just before the `writeNonBlockingV21` call) are kind of decoupled from the sync logic.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4107/comments",
    "author": "kunaljathal",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2018-04-11T08:16:27Z",
        "body": "During normal playback we synchronize video to the audio playout position, so I think the request here is to get a stream of PCM audio data that's synchronized with playout position of the underlying `AudioTrack` (but please correct me if I've misunderstood).\r\n\r\nThe platform `AudioTrack` keeps a buffer of data internally, which introduces latency, so it's not sufficient to output data at the moment it's written to the track. Instead, I think you'll need to keep a buffer of audio that's been written to the track, then output data from your own buffer based on the current playout position.\r\n\r\nI'm afraid we don't have a built-in way to do this at the moment so some level of customization is necessary. There are lots of ways this could be done, but if you want to minimize the number of customized components I think it should be possible with only a custom `AudioProcessor` as follows.\r\n\r\n- Instantiate a `DefaultAudioSink`, passing in a custom `AudioProcessor`, and set up the player with a `MediaCodecAudioRenderer` outputting to this sink.\r\n- Each time the custom audio processor receives input, it should copy it to an output buffer, but also copy the bytes into an additional internal buffer. We are using it as a way to intercept the audio.\r\n- At the same time as populating its internal buffer, we can also check the current playout position via `AudioSink.getCurrentPositionUs`, as we have a reference to the sink. The position can be converted into a frame count, which in turns maps onto a byte offset in the internal buffer, which is the position up to which audio has been played out. You can handle this portion of the internal buffer however you want, then compact the buffer.\r\n- Note: all audio processor methods run on ExoPlayer's internal playback thread, so you may want to pass the data that's been output to an application thread."
      },
      {
        "user": "kunaljathal",
        "created_at": "2018-04-11T19:48:23Z",
        "body": "Okay, gotcha. A couple of preliminary clarifications:\r\n\r\n> Instantiate a `DefaultAudioSink`, passing in a custom `AudioProcessor`, and set up the player with a `MediaCodecAudioRenderer` outputting to this sink.\r\n\r\nI'm creating an instance of `SimpleExoPlayer` via `ExoPlayerFactory.newSimpleInstance`, so I'm assuming I can do what you're describing by simply overriding `DefaultRenderersFactory.buildAudioProcessors` (in the renderers factory that I pass to the constructor of `ExoPlayerFactory.newSimpleInstance`) with my custom `AudioProcessor`, right? Because this `AudioProcessor` then internally gets passed to the underlying `MediaCodecAudioRenderer`, which will then further pass it to it's `DefaultAudioSink`. Does this make sense?\r\n\r\n> At the same time as populating its internal buffer, we can also check the current playout position via `AudioSink.getCurrentPositionUs`, as we have a reference to the sink.\r\n\r\nI'm a bit confused here -- where's the reference? i.e. where in my custom `AudioProcessor` am I able to access the sink?"
      },
      {
        "user": "andrewlewis",
        "created_at": "2018-04-11T19:53:47Z",
        "body": "You need to instantiate the `DefaultAudioSink` yourself so that you can provide a reference to it to your custom audio processor. This means you need to instantiate the `MediaCodecAudioRenderer` yourself, passing in the sink. Overriding `buildAudioRenderers` from `DefaultRenderersFactory` is a good way to do that."
      },
      {
        "user": "kunaljathal",
        "created_at": "2018-04-14T00:46:58Z",
        "body": "Okay, gotcha. I think my final clarification is the following:\r\n\r\n>At the same time as populating its internal buffer, we can also check the current playout position via `AudioSink.getCurrentPositionUs`, as we have a reference to the sink. The position can be converted into a frame count, which in turns maps onto a byte offset in the internal buffer, which is the position up to which audio has been played out. You can handle this portion of the internal buffer however you want, then compact the buffer.\r\n\r\nDoes this imply that the buffer of data I'm getting in the `queueInput` call contains audio data, _a portion of which has already been played out_? Because, if I'm understanding correctly, what you're saying is that I can discard this portion, and collect the samples after it, which are representative of the samples that are about to be played out next (presumably soon after the `getOutputBuffer` call), and hence in sync with the video frames about to be played out next."
      },
      {
        "user": "andrewlewis",
        "created_at": "2018-04-16T11:02:10Z",
        "body": "The audio data just passed to `queueInput` has not been played out yet, as the `AudioTrack` is 'downstream' from the chain of audio processors. The audio data you've already buffered on previous invocations of `queueInput` may have been played out, though. The idea is to use `getCurrentPositionUs` to determine how many bytes of the input have been played out so far, which corresponds to a position in your internal buffer.\r\n\r\nAs the internal buffer can't grow indefinitely, when you determine that some of its audio has been played (based on the current position), you'll need to discard data up to there from your internal buffer, and update a stored offset for the start of the internal buffer. This offset should be reset on each call to `flush`.\r\n\r\nOne other caveat, which may not be relevant to your use case: speed/pitch/trim silence are applied after any custom `AudioProcessor`s at the moment, so the player position will reflect any offset/scaling applied for those."
      },
      {
        "user": "kunaljathal",
        "created_at": "2018-04-16T17:36:39Z",
        "body": "OK, I see. In the case of speed/pitch/trim etc applied _after_ the custom `AudioProcessor` -- is this factored into the position returned by `getCurrentPositionUs` ? To be clear, I'll be using ExoPlayer for streaming video most of the time i.e. the use case that's most relevant to me is interruptions in streaming -- in the case of network issues etc., if the video ends up momentarily lagging / pausing and resuming (i.e. buffering) for any reason, I would want to stop/re-play the audio at the correct positions, keeping it in sync with the video at all times. So if `getCurrentPositionUs` is going to incorporate all that, then that's enough for me."
      },
      {
        "user": "andrewlewis",
        "created_at": "2018-04-17T08:14:07Z",
        "body": "The position returned by `getCurrentPositionUs` will take into account playback parameters, buffering, pausing etc.. If you're not overriding the default playback speed it should work fine."
      },
      {
        "user": "kunaljathal",
        "created_at": "2018-06-11T13:30:39Z",
        "body": "Thanks, this worked. "
      }
    ],
    "satisfaction_conditions": [
      "Provides synchronized audio samples aligned with video playback timing",
      "Works with ExoPlayer's internal synchronization mechanisms",
      "Requires minimal customization of ExoPlayer components",
      "Handles AudioTrack buffer latency automatically",
      "Maintains synchronization during playback interruptions"
    ]
  },
  {
    "number": 4031,
    "title": "Custom listener to show playback controls",
    "created_at": "2018-03-24T11:22:17Z",
    "closed_at": "2018-05-04T09:11:33Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4031",
    "body": "Hi. I want to to show playback controls only when onTouch event is fired. How to prevent control buttons being showed up when on long pressing, dragging etc.?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4031/comments",
    "author": "elnurvl",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2018-03-26T10:48:12Z",
        "body": "Our `PlayerView` class checks for `MotionEvent.ACTION_DOWN` to show the playback controls. \r\n\r\nIf you like to have a custom behavior, you could extend `PlayerView` and override `onTouchEvent(MotionEvent ev)`. In there, you can call `showController()` or `hideController()` to achieve your intended effect."
      },
      {
        "user": "elnurvl",
        "created_at": "2018-03-26T12:00:02Z",
        "body": "I use ExoPlayerFactory to make a player object. I am not sure if it is the correct way to make a player object with new statement. Can't I set onTouchListener after player object being created?"
      },
      {
        "user": "tonihei",
        "created_at": "2018-03-26T12:22:23Z",
        "body": "Yes, ExoPlayerFactory is the correct way to create the player. I think that's irrelevant for your problem though. For my suggestion, you'd need to overwrite `PlayerView` which is the UI component you may have put somewhere in your layout."
      },
      {
        "user": "elnurvl",
        "created_at": "2018-03-26T14:37:13Z",
        "body": "Sorry, I confused `PlayerView` with `ExoPlayer` object. So in this case I should create my own widget with custom `onTouchEvent` method and use it in my layout instead of standard `PlayerView`, right?"
      },
      {
        "user": "tonihei",
        "created_at": "2018-03-26T14:39:54Z",
        "body": "Sounds right."
      },
      {
        "user": "elnurvl",
        "created_at": "2018-05-02T20:54:07Z",
        "body": "Thank you. It would be more convenient to do customization if a method like setOnTouchListener are added to PlayerView class in the next releases.\n\n---\n\n@tonihei , I am trying to implement your solution to customize the event which is responsiple for showing playback controls. Unfortunately it is not working. Because `controller` variable is private and I cannot access it in my own `PlayerView`. I cannot use `super` either, because it checks for `MotionEvent.ACTION_DOWN` implicitly as you said. What I need is to fire the event when a user single taps on the player. Isn't it possible to achieve it in ExoPlayer without changing the library files?"
      },
      {
        "user": "tonihei",
        "created_at": "2018-05-03T09:34:55Z",
        "body": "You can change the visibility of the controller with `showController()` and `hideController()` and you can listen to its visibility with `setControllerVisibilityListener`. That means you don't actually need access to the `controller` variable to achieve your custom `onTouchEvent` handling.\r\n\r\nTo confirm that it's actually working, I tried to implement what you are trying to do with the following code.  Using this custom view, the playback controls are only shown or hidden for short taps. Dragging and long presses are filtered out.\r\n\r\n```\r\npublic final class CustomPlayerView\r\n    extends PlayerView implements PlayerControlView.VisibilityListener {\r\n\r\n  private static final float DRAG_THRESHOLD = 10;\r\n  private static final long LONG_PRESS_THRESHOLD_MS = 500;\r\n\r\n  private boolean controllerVisible;\r\n  private long tapStartTimeMs;\r\n  private float tapPositionX;\r\n  private float tapPositionY;\r\n\r\n  public CustomPlayerView(Context context) {\r\n    this(context, null);\r\n  }\r\n\r\n  public CustomPlayerView(Context context, AttributeSet attrs) {\r\n    this(context, attrs, 0);\r\n  }\r\n\r\n  public CustomPlayerView(Context context, AttributeSet attrs, int defStyleAttr) {\r\n    super(context, attrs, defStyleAttr);\r\n    setControllerVisibilityListener(this);\r\n  }\r\n\r\n  @Override\r\n  public boolean onTouchEvent(MotionEvent ev) {\r\n    switch (ev.getActionMasked()) {\r\n      case MotionEvent.ACTION_DOWN:\r\n        tapStartTimeMs = SystemClock.elapsedRealtime();\r\n        tapPositionX = ev.getX();\r\n        tapPositionY = ev.getY();\r\n        break;\r\n      case MotionEvent.ACTION_MOVE:\r\n        if (tapStartTimeMs != 0\r\n            && (Math.abs(ev.getX() - tapPositionX) > DRAG_THRESHOLD\r\n                || Math.abs(ev.getY() - tapPositionY) > DRAG_THRESHOLD)) {\r\n          tapStartTimeMs = 0;\r\n        }\r\n        break;\r\n      case MotionEvent.ACTION_UP:\r\n        if (tapStartTimeMs != 0) {\r\n          if (SystemClock.elapsedRealtime() - tapStartTimeMs < LONG_PRESS_THRESHOLD_MS) {\r\n            if (!controllerVisible) {\r\n              showController();\r\n            } else if (getControllerHideOnTouch()) {\r\n              hideController();\r\n            }\r\n          }\r\n          tapStartTimeMs = 0;\r\n        }\r\n    }\r\n    return true;\r\n  }\r\n\r\n  @Override\r\n  public void onVisibilityChange(int visibility) {\r\n    controllerVisible = visibility == View.VISIBLE;\r\n  }\r\n}\r\n```"
      },
      {
        "user": "elnurvl",
        "created_at": "2018-05-03T16:44:57Z",
        "body": "Thank you! Exactly what I was looking for."
      }
    ],
    "satisfaction_conditions": [
      "Solution must allow playback controls to be shown only for single taps, not long presses or drag gestures",
      "Implementation must work without modifying ExoPlayer library internals",
      "Approach must leverage PlayerView's existing controller visibility APIs",
      "Solution must maintain compatibility with standard PlayerView usage patterns"
    ]
  },
  {
    "number": 4023,
    "title": "Playback buffer value",
    "created_at": "2018-03-22T23:21:12Z",
    "closed_at": "2018-03-23T17:12:36Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/4023",
    "body": "I am writing a DASH video player using ExoPlayer demo app as the base for my application. How can I get the actual playback buffer size in seconds, without messing with the actual MediaSource and other  code libraries (and short of maintaining my own variable tracking media downloaded, played, paused and all that mess)? \r\nBy actual playback buffer size, I mean the 'total duration duration of the video chunks that's already buffered' - 'total duration of the video chunks that's been watched'. \r\nFor example, if the player has downloaded 60s worth of data and the renderer has already played 50s of this video, I want to know that there's 10 more seconds to go before the player might hit a re-buffer. I am trying to eventually get to a feature that minimizes re-buffering events.\r\nI want to do this with minimal changes to the existing code and achieve this with event listeners, as much as possible. I know if I write my own trackSelector, this is easy to obtain. But, can I get it at the app layer?\r\nThanks for any pointers.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/4023/comments",
    "author": "kanthicn1",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2018-03-23T09:23:11Z",
        "body": "`player.getBufferedPosition() - player.getCurrentPosition()` should give you what you want for most situations. \r\n\r\nThe only exception is when the player pre-buffers the following items in a playlist. In this case the calculation would only give you the buffered duration in the current playlist item. But, we are planning to fix this soon. "
      },
      {
        "user": "kanthicn1",
        "created_at": "2018-03-23T16:44:52Z",
        "body": "Thank you! This works perfectly for me right now. However, I want to understand the caveat in this solution that you mentioned. If the player pre-buffers the other items in the playlist, are you saying this method won't give me the buffer values of all the tracks? But, this method will always give me the correct buffer value of the track that is currently being played. Correct?"
      },
      {
        "user": "tonihei",
        "created_at": "2018-03-23T16:48:30Z",
        "body": "Yes, that's correct. We are currently adding a new method the interface `Player.getTotalBufferedDuration()` which returns the total duration of buffered media across all playlist items."
      }
    ],
    "satisfaction_conditions": [
      "Provides a method to calculate remaining buffered duration using existing ExoPlayer APIs",
      "Handles playlist pre-buffering scenarios in buffer calculation",
      "Works at the application layer without modifying MediaSource implementations",
      "Supports real-time buffer monitoring through event listeners",
      "Provides accurate remaining buffer duration (buffered content - played content)"
    ]
  },
  {
    "number": 3993,
    "title": "Making my own ABR algorithm in HLS",
    "created_at": "2018-03-15T11:20:15Z",
    "closed_at": "2018-03-19T10:29:12Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3993",
    "body": "Hello,\r\n\r\nI am making my own ABR algorithm class in HLS extended from BaseTrackSelection and I am facing with a problem. I need targetDuration in my class but there is no way I can get the information from the application level. Plus, I am making my own LoadController, and it needs bitrate information. In this case, is there simple way that I can pass these information to my class in application level?(like PlayerActivity) \r\n\r\nThank you ",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3993/comments",
    "author": "tedKim5178",
    "comments": [
      {
        "user": "AquilesCanta",
        "created_at": "2018-03-15T11:31:54Z",
        "body": "`Player.EventListener#onTimelineChanged`  includes the manifest as one of the arguments. An `HlsManifest` includes a media playlist as one of its fields. Finally, HlsMediaPlaylist contains targetDurationUs. Hope this helps.\n\n---\n\nSorry, I missed the bitrate part. Could you clarify the usecase for the bitrate? You can use the media source event listener to get load events to retrieve certain information. The master playlist will also include useful information (also obtainable through onTimelineChanged)."
      },
      {
        "user": "tedKim5178",
        "created_at": "2018-03-18T06:16:48Z",
        "body": "Thanks for your reply. You solved my problem perfectly. Now I am using onTimelineChanged method to get targetDurationUs. Also, I found out onTrackSelected method in LoadControl. I can use this method to get bitrate. Thanks for your help!! Best Player ever!"
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to access targetDuration value from application-level components",
      "Method to retrieve bitrate information through application-level event listeners",
      "Integration with existing player event callbacks for data passing"
    ]
  },
  {
    "number": 3946,
    "title": "cannot resolve MediaSessionConnector",
    "created_at": "2018-03-06T17:44:51Z",
    "closed_at": "2018-03-06T17:47:07Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3946",
    "body": "I am using exoplayer v 2.6.1 but i am facing an issue that MediaSessionConnector is not working.\r\n\r\ngradle exoplayer import:\r\n    compile 'com.google.android.exoplayer:exoplayer:2.6.1'",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3946/comments",
    "author": "MohammadElKhatib",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2018-03-06T17:47:07Z",
        "body": "You need to also depend on `com.google.android.exoplayer:extension-mediasession:2.6.1`"
      },
      {
        "user": "MohammadElKhatib",
        "created_at": "2018-03-06T17:51:12Z",
        "body": "@ojw28 yes you are right this was not clear in installation.\r\nthank you"
      }
    ],
    "satisfaction_conditions": [
      "Identifies the missing dependency required for MediaSessionConnector functionality",
      "Clarifies that MediaSessionConnector is not part of ExoPlayer's core library",
      "Addresses incomplete documentation about ExoPlayer module structure"
    ]
  },
  {
    "number": 3943,
    "title": "How to notice me when next video playback and get current playback file's URI at the same time ?",
    "created_at": "2018-03-05T14:42:24Z",
    "closed_at": "2018-03-07T13:27:43Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3943",
    "body": "I try to find a listener that can notice me when the next or previous video playback.\r\n\r\nfor example: \r\n\r\nI have a List of uri by using *DynamicConcatenatingMediaSource* to ExoPlayer, when I click \"next\" button or auto play the next video, I hope to know this event and to know the current playback video's uri.\r\n\r\n I try to find some useful information from Demo App,but nothing.\r\nplease help me~\r\n\r\n#### Version of ExoPlayer being used\r\n2.6.1\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3943/comments",
    "author": "yibeiliu",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2018-03-05T14:49:03Z",
        "body": "You can retrieve the `MediaSource` at each index in the playlist by calling `DynamicConcatenatingMediaSource.getMediaSource(index)`. Unfortunately, our media sources don't have a `.getUri()` method. To work around this you can keep a `Map<MediaSource, Uri>` or similar in your app to lookup the `Uri` from the `MediaSource`. \r\n"
      },
      {
        "user": "yibeiliu",
        "created_at": "2018-03-07T13:27:43Z",
        "body": "Thank a lot! \r\n\r\nI've solved the problem as you said\uff01"
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to detect playback transition events (next/previous)",
      "Association between MediaSource objects and their original URIs",
      "Integration with DynamicConcatenatingMediaSource's structure"
    ]
  },
  {
    "number": 3930,
    "title": "Failed to resolve: com.google.android.exoplayer:exoplayer-core:r2.7.0 ",
    "created_at": "2018-03-03T10:00:54Z",
    "closed_at": "2018-03-04T11:32:04Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3930",
    "body": "Android studio 3.0\r\ngradle version 4.1\r\n\r\nUnable to resolve 2.7.0 dependencies?\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3930/comments",
    "author": "0x410c",
    "comments": [
      {
        "user": "FD-",
        "created_at": "2018-03-03T15:22:37Z",
        "body": "I'm not a project member, but according to the release notes, version names no longer contain the r.\r\n`com.google.android.exoplayer:exoplayer-core:2.7.0` should work fine."
      },
      {
        "user": "0x410c",
        "created_at": "2018-03-04T11:25:28Z",
        "body": "thanks brother. worked perfectly. i think they should change git readme."
      },
      {
        "user": "ojw28",
        "created_at": "2018-03-04T11:32:04Z",
        "body": "Which readme? It looks like we've already removed all the \"r\"s from the readme."
      }
    ],
    "satisfaction_conditions": [
      "Clarification of the correct version format for ExoPlayer dependencies",
      "Alignment with current project documentation standards"
    ]
  },
  {
    "number": 3894,
    "title": "Does ExoPlayer have the OnSeekCompleteListener?",
    "created_at": "2018-02-23T22:44:06Z",
    "closed_at": "2018-02-26T17:18:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3894",
    "body": "MediaPlayer class has the OnSeekCompleteListener.\r\n\r\nIf not, I can work around it by checking the current position got updated or not after seeking.\r\nFor the cleanliness of my code, I was looking for the OnSeekCompleteListener but could not find it.\r\n\r\nDoes ExoPlayer not have the listener or I am just not finding it?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3894/comments",
    "author": "jclova",
    "comments": [
      {
        "user": "ghost",
        "created_at": "2018-02-23T23:25:15Z",
        "body": "It's in Player.EventListener, there is a method called onSeekProcessed()."
      },
      {
        "user": "jclova",
        "created_at": "2018-02-26T17:18:39Z",
        "body": "Thank you so much. \r\nI was using the older version of ExoPlayer so I could not find it."
      }
    ],
    "satisfaction_conditions": [
      "Confirmation of whether ExoPlayer provides a mechanism to detect seek completion",
      "Identification of the correct API interface/method where seek completion handling occurs"
    ]
  },
  {
    "number": 3874,
    "title": "How to display ads of previous player",
    "created_at": "2018-02-21T11:40:09Z",
    "closed_at": "2018-02-21T13:10:15Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3874",
    "body": "Hi!\r\n\r\nMy app:\r\nI have an app that consists of a screen with a list of players with ads. (I am using RecyclerView).\r\nWhen the user scrolls the main screen and a video was playing, I display this video in a smaller player at the bottom of the screen (like youtube).\r\n\r\nTo display the smaller video, I create a new player and update it with content position of previous player.\r\n\r\nMy problem:\r\nWhen the user scrolls and an ads is playing, when updating the new player with content position of previous player, the ads starts to play from the beginning and not from the position that it had stopped in the other player. (I am reusing AdsLoader and )\r\n\r\nMy question:\r\nI would like to know if there is any way I can display ads from the position it stopped in previously player. \r\n\r\nCan someone help me, please?\r\n\r\nSome code:\r\n\r\n```\r\nMediaSource mediaSource = buildMediaSource(Uri.parse(url));\r\nString adTag = getAdsUrl();\r\n\r\n if (adTag != null) {\r\n    if (!reuseAds) {\r\n         releaseAdsLoader();\r\n         mAdsLoader = new ImaAdsLoader(context, Uri.parse(adTag));\r\n    }\r\n    mediaSource = new AdsMediaSource(mediaSource, new AdsMediaSourceFactory(), mAdsLoader, playerView.getOverlayFrameLayout(), null, null);\r\n}\r\n\r\nplayer.seekTo(position);\r\nplayer.setPlayWhenReady(true);\r\n\r\nplayer.prepare(mediaSource,false,false);\r\n```",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3874/comments",
    "author": "michelecorrea3",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2018-02-21T11:47:42Z",
        "body": "Are you definitely using exactly the same `ImaAdsLoader` instance when creating the `AdsMediaSource` that is played in the new player? It's also important that the old player is released before creating the new one. I think this should just work, as the situation is very similar to background/resuming a player while playing ads."
      },
      {
        "user": "michelecorrea3",
        "created_at": "2018-02-21T12:36:23Z",
        "body": "It was the same ImaAdsLoader, but I wasn't releasing the old player before creating the new one. I released and it worked! Thank you so much :)"
      },
      {
        "user": "andrewlewis",
        "created_at": "2018-02-21T13:10:15Z",
        "body": "Glad to hear it works!"
      }
    ],
    "satisfaction_conditions": [
      "Solution must preserve ad playback state when transitioning between players",
      "Answer must address proper lifecycle management of media players",
      "Approach should maintain continuity of ads loader instances",
      "Method must handle seamless transition of ad playback between UI components"
    ]
  },
  {
    "number": 3637,
    "title": "Continue buffering while in pause",
    "created_at": "2017-12-24T16:44:31Z",
    "closed_at": "2018-01-04T18:18:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3637",
    "body": "Hi!\r\n\r\nCurrently when player is paused it stops to receive new data in buffer.\r\nIs it possible to continue buffering while player is in pause state?\r\n\r\nIf there is no other options, guess, I could use Cache feature to save data in separate thread and then use cached data to play when it is buffered enough while in pause. If it is the case, could you please explain should I use Downloader to save data in one thread and then use another Cache with the link to the same DataSpec or can I use the same Cache instance in another thread for playback?\r\n\r\nThanks!",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3637/comments",
    "author": "aarondib",
    "comments": [
      {
        "user": "erdemguven",
        "created_at": "2017-12-27T19:39:29Z",
        "body": "For the second part of the question, it's an error to create two Cache instances which store cache files on the same folder. It's OK to access to a single instance of Cache from different threads but there are issues with writing and reading the same content on the cache. In your case as long as you stop the downloader before player resumes it should be fine.  "
      },
      {
        "user": "ojw28",
        "created_at": "2018-01-02T21:00:04Z",
        "body": "For the first part of the question: We don't stop buffering when the player is paused. We stop buffering when the criteria for how much media should be buffered is reached, which is independent of whether the player is paused or not. You can customize how much media is buffered by instantiating a `DefaultLoadControl` using one of the constructors that allows specifying minimum and maximum buffer durations, and then passing that instance into a `ExoPlayerFactory` when instantiating the player. You can also implement your own `LoadControl` from scratch if that's easier.\r\n\r\nNote that `LoadControl` controls buffering in RAM, so there's only so far you can go before you'll end up with your process crashing with an out of memory error. If you want to buffer to disk then you should use the cache feature instead."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to customize buffering behavior during paused state",
      "Clarification on thread-safe cache usage patterns",
      "Guidance on preventing memory issues during extended buffering",
      "Differentiation between buffer management and playback state"
    ]
  },
  {
    "number": 3563,
    "title": "[Question] How to get the startTime and endTime from TextRenderer.Output cues",
    "created_at": "2017-12-07T19:28:54Z",
    "closed_at": "2017-12-11T10:41:59Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3563",
    "body": "Hi there!\r\nI'm currently implementing the TextRenderer.Output to received the List of Cues for WebVtt captions, and then I'm displaying those captions in our custom caption view.\r\nThe problem is that WebvttCue class is package-private so we can't cast it, so that we can use the startTime and endTime.\r\nIs there a reason to keep that class as package-private? What alternative do I have?\r\n\r\nThanks!\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3563/comments",
    "author": "sergiomartinez4",
    "comments": [
      {
        "user": "botaydotcom",
        "created_at": "2017-12-08T10:35:39Z",
        "body": "Hi @sergiomartinez4 ,\r\nCould you explain your use-case clearer, and why do you need to get access to startTime and endTime in order to display these Cues in your custom view?\r\nBy design, the player will parse these time values from underlying stream, and perform calculations internally to find out when to display these subtitles with respect to other tracks (video/audio etc...). Then the TextRenderer will output the List<Cue> to be displayed at the right time, and the client application only needs to handle displaying these Cues immediately upon receiving them. Attempting to parse startTime and endTime, without understanding fully the timing model of the player, may lead to wrong presentation time.\r\n\r\nPlease elaborate more on your use case and the reasoning behind, and we can answer your question better. Thank you very much.\r\n\r\nWith that said, because of other changes, WebvttCue class has been made public in dev-v2 branch, and may be released as such in the future (I don't know when). However, unless it's really necessary, I don't think you should rely on that given the problem I described.\r\n\r\n"
      },
      {
        "user": "sergiomartinez4",
        "created_at": "2017-12-08T15:15:28Z",
        "body": "@botaydotcom thanks for the reply.\r\n\r\nThe real concern is not about when to display them, as we display them as soon as the onCues method is called, but it's about when to stop displaying the captions. A caption duration property in the Cue object will be enough for our purposes.\r\n\r\nWithout any sense of time, we can either just stop displaying one caption after the next one appears or we can set a default duration timeout (or a combination both). We could also adjust the duration depending on the length of the text and with this approach we can only hope to get a good approximation, but it wouldn't be the exact times as specified in the Webvtt document.\r\n\r\nHaving the public WebvttCue will make it easier with our current implementation, we only need to cast the Cue to WebvttCue and get the extra info, but If I'm missing something or there's an easier or better way to do it, I'm happy to try it out.\r\n\r\nBest!\r\n"
      },
      {
        "user": "botaydotcom",
        "created_at": "2017-12-08T15:31:03Z",
        "body": "Hi @sergiomartinez4 ,\r\nI think I understand your idea, but it is unfortunately it is not our intention behind `TextOutput` interface.\r\nThe idea with `TextOutput` is whenever the player sends a Cue list, the application should just take it and display as it is. If any of the cues are changed (some added, some removed etc...), the player will invoke that method again with a new Cue list reflecting the new state. So you don't need to time the display yourself or find out when to remove the displayed captions. The next time you receive a new list of cues, just remove everything and re-display the whole list accordingly (note that the list might be null if there's nothing to be displayed on the screen).\r\n\r\nI think an easy way to follow this is to check out `com.google.android.exoplayer2.ui.SubtitleView`, which follows this approach. Hope that help."
      },
      {
        "user": "sergiomartinez4",
        "created_at": "2017-12-08T20:11:43Z",
        "body": "@botaydotcom, removing the captions when getting empty cues did the trick. It makes sense now.\r\nThanks a lot for the help."
      },
      {
        "user": "botaydotcom",
        "created_at": "2017-12-11T10:41:58Z",
        "body": "Cool! Glad that it helps."
      }
    ],
    "satisfaction_conditions": [
      "Provides a method to determine when to stop displaying captions without direct access to WebvttCue timing data",
      "Works with the existing TextRenderer.Output interface without requiring class visibility changes",
      "Ensures synchronization between caption display and player's internal timing model"
    ]
  },
  {
    "number": 3509,
    "title": "EventListener.onTimelineChanged howto get current window",
    "created_at": "2017-11-28T01:14:50Z",
    "closed_at": "2017-11-28T08:23:42Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3509",
    "body": "I'm using ExoPlayer 2.6.0 and made a simple Activity which creates a ConcatenatingMediaSource of some ExtractorMediaSource with http URL to Videos. All playing in endless loop without any issues.\r\n\r\nNow i want to get the current window+position when the video changes. So i implement the DefaultEventListener and override the onTimelineChanged method.\r\n\r\nIf i ask my player within this method using player.getCurrentPeriodIndex() and player.getCurrentWindowIndex() i do not get the right values.\r\nAre those values updated after the onTimelineChanged Event is fired? I also tried the onTracksChanged event, but with the same results.\r\n\r\nIs there another way to get the current window directly after a new video was loaded? I looked in the EventLogger from the sample, but i could not find the right spot for my needed information.\r\n\r\nIf i put a Handler with a periodic postDelayed runnable to poll the getCurrentPeriodIndex and getCurrentWindowIndex i get the right results.\r\n\r\nI'd rather not do the polling since i want to syncronise some players via network.\r\n\r\nI'm using an Android TV box running 6.0.1 my App Compile SDK is 26, target 26, min 23. Build Tools Version 26.0.2\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3509/comments",
    "author": "derlucas",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2017-11-28T08:02:55Z",
        "body": "`onPositionDiscontinuity` is called when playback transitions from one item to the next. You can get the new window index by calling `getCurrentWindowIndex`. Does that provide the information you need?"
      },
      {
        "user": "derlucas",
        "created_at": "2017-11-28T08:23:42Z",
        "body": "Thank you very much. This is exactly what i need. Maybe yesterday it was too late and i sat too long on the problem so i did not see this onPositionDiscontinuity description :)"
      }
    ],
    "satisfaction_conditions": [
      "Identifies the correct event callback that triggers when playback transitions between media items",
      "Provides a way to access the updated window index without polling",
      "Ensures window index values are available immediately when the callback is invoked"
    ]
  },
  {
    "number": 3405,
    "title": "Multiple ClippingMediaSource not working for m3u8 files ",
    "created_at": "2017-10-30T05:28:00Z",
    "closed_at": "2017-10-31T13:04:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3405",
    "body": "# Issue \r\n**When I use two or more ClippingMediaSource not working for m3u8. But working same code for MP4**\r\n\r\n### Reproduction steps\r\n\r\n**Bug : When I use Multiple ClippingMediaSource for m3u8 files not working**\r\n\r\nBut working in following cases\r\n\r\n1. Only one ClippingMediaSource with m3u8 - working\r\n2. Multiple ClippingMediaSource with mp4 - working \r\n\r\n\r\n        MediaSource movieMediaSource =getMediaSourceFromUrl(context, mLiveURL);\r\n            final long oneMinute = 60000000L;\r\n            ClippingMediaSource videoSource1 = new ClippingMediaSource(movieMediaSource, 0, oneMinute/2);\r\n\r\n            ClippingMediaSource videoSource2 = new ClippingMediaSource(movieMediaSource, oneMinute/2, oneMinute);\r\n  \r\n            ConcatenatingMediaSource concatenatingMediaSource = new ConcatenatingMediaSource(videoSource1,videoSource2);\r\n\r\n\r\n       public static MediaSource getMediaSourceFromUrl(Context context, String url) {\r\n        mBandwidthMeter = new DefaultBandwidthMeter();\r\n       //Produces DataSource instances through which media data is loaded.\r\n        DefaultDataSourceFactory dataSourceFactory = new DefaultDataSourceFactory(context, \r\n        Util.getUserAgent(context, \"MOD\"), mBandwidthMeter);\r\n       //Produces Extractor instances for parsing the media data.\r\n        ExtractorsFactory extractorsFactory = new DefaultExtractorsFactory();\r\n        MediaSource videoSource = null;\r\n        if (url != null && !url.isEmpty()) {\r\n            Log.d(TAG, \"getMediaSourceFromUrl: 11\");\r\n            if (url.contains(\".m3u8\")) {\r\n          //FOR LIVESTREAM LINK:\r\n                Uri mp4VideoUri = Uri.parse(url);\r\n                videoSource = new HlsMediaSource(mp4VideoUri, dataSourceFactory, null, null);\r\n        \r\n            } else if (url.contains(\".mp4\")) {\r\n         //FOR SD CARD SOURCE:\r\n                Uri mp4VideoUri = Uri.parse(url);\r\n                videoSource = new ExtractorMediaSource(mp4VideoUri, dataSourceFactory, extractorsFactory, null, null);\r\n              }\r\n           }\r\n            return videoSource;\r\n        }\r\n\r\n\r\n### Version of ExoPlayer being used\r\n2.5.4\r\n\r\n### Device(s) and version(s) of Android being used\r\nAndroid 5.1 & Android 7.0\r\n\r\n### A full bug report captured from the device\r\n\r\nLenova A6000+  & Nexus 6\r\n\r\n\r\n### Error Log\r\n\r\n> Internal runtime error.\r\n                                                                    java.lang.IllegalStateException at com.google.android.exoplayer2.util.Assertions.checkState(Assertions.java:79) at com.ajax.mod.controller.player.MyHlsMediaSource.prepareSource(MyHlsMediaSource.java:97)  at com.google.android.exoplayer2.source.ClippingMediaSource.prepareSource(ClippingMediaSource.java:89) at com.google.android.exoplayer2.source.ConcatenatingMediaSource.prepareSource(ConcatenatingMediaSource.java:78) at com.google.android.exoplayer2.ExoPlayerImplInternal.prepareInternal(ExoPlayerImplInternal.java:425)  at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:328) at android.os.Handler.dispatchMessage(Handler.java:98)\r\nat android.os.Looper.loop(Looper.java:154)\r\nat android.os.HandlerThread.run(HandlerThread.java:61)",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3405/comments",
    "author": "rranjithkumar100",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2017-10-30T09:12:04Z",
        "body": "The problem is that you can't re-use MediaSources. That means you need to create a new movieMediaSource for each ClippingMediaSource. "
      },
      {
        "user": "rranjithkumar100",
        "created_at": "2017-10-31T13:04:58Z",
        "body": "Yes you are right.. @tonihei \r\n\r\nProblem solved. I close this issue \ud83d\udc4d "
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why reusing MediaSource instances causes failures with HLS streams",
      "Guidance on proper MediaSource instance management for concatenated HLS streams",
      "Clarification of HLS stream handling limitations in ExoPlayer's MediaSource composition"
    ]
  },
  {
    "number": 3296,
    "title": "Is exoplayer able to play video in reverse - question",
    "created_at": "2017-09-26T08:51:26Z",
    "closed_at": "2017-09-26T09:29:59Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3296",
    "body": "Hi, I am trying to make a feature in app, so user can play video in reverse order to seek to desired video position. So far, I have implemented the functionality to get player current position and decrease it by e.g. 10s. And it works fine but appearance is little bit choppy, so I am looking for feature to play video in reverse order(like we did in 90's with VHS).\r\nDose exoplayer support this or is there a way to achieve this?\r\n\r\nthanks\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3296/comments",
    "author": "lazarvgd",
    "comments": [
      {
        "user": "tonihei",
        "created_at": "2017-09-26T09:27:24Z",
        "body": "That's not something that can be done easily with a player, because video encodings make use of redundancies in the video frames and compress the data such that you need to decode the video in forward direction from a key frame to reconstruct the original frames. The choppy behaviour you see is the player constantly decoding everything from the last key frame to your requested position (which takes some time). The only way to do this is to re-encode your video in reverse order. "
      },
      {
        "user": "lazarvgd",
        "created_at": "2017-09-26T09:29:59Z",
        "body": "I thought that is much easier. Thank you, I will close this one."
      }
    ],
    "satisfaction_conditions": [
      "Clarification of ExoPlayer's native support for reverse video playback",
      "Explanation of technical limitations preventing smooth reverse playback",
      "Identification of fundamental requirements for reverse playback functionality"
    ]
  },
  {
    "number": 3177,
    "title": "skipping 10 sec forward of backward",
    "created_at": "2017-08-16T07:55:07Z",
    "closed_at": "2017-08-16T09:29:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3177",
    "body": "First of all I want to say sorry if this is duplicate question, I couldn't find the same or similar question.\r\n\r\nQuestion:\r\nIs there an option in exoplayer that allows skipping 10 seconds forward or backward? This feature is something like on YouTube when you press right or left arrow( J or L keys).\r\n\r\nThanks",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3177/comments",
    "author": "lazarvgd",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-08-16T08:00:55Z",
        "body": "`player.seekTo(player.getCurrentPosition() + 10000)` would seek forward 10 seconds (similar to seek backward)?"
      }
    ],
    "satisfaction_conditions": [
      "Demonstrates how to implement fixed-duration seeking in ExoPlayer",
      "Supports both forward and backward directions",
      "Uses ExoPlayer's native API capabilities",
      "Handles current position calculation accurately"
    ]
  },
  {
    "number": 3124,
    "title": "Question: Is there a same function in v2 for onDownstreamFormatChanged(v1)",
    "created_at": "2017-08-01T03:08:45Z",
    "closed_at": "2017-08-02T02:46:00Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3124",
    "body": "I am upgrading a video app from v1 to v2,  there is a third party logic added in the method onDownstreamFormatChanged as below \r\nfor example in the DemoPlayer in v1:\r\n```\r\n@Override\r\n\tpublic void onDownstreamFormatChanged(int sourceId, Format format, int trigger, long mediaTimeMs) {\r\n\t\tif (infoListener == null) {\r\n\t\t\treturn;\r\n\t\t}\r\n\t\tif (sourceId == TYPE_VIDEO) {\r\n\t\t\tvideoBitrate = format.bitrate;\r\n\t\t\tvideoFormat = format;\r\n\t\t\tinfoListener.onVideoFormatEnabled(format, trigger, mediaTimeMs);\r\n\t\t} else if (sourceId == TYPE_AUDIO) {\r\n\t\t\taudioBitrate = format.bitrate;\r\n\t\t\tinfoListener.onAudioFormatEnabled(format, trigger, mediaTimeMs);\r\n\t\t}\r\n\r\n\t\tif (videoBitrate > 0 && audioBitrate > 0) {\r\n\t\t\tAnalyticsManager.onBitrateChange(((audioBitrate + videoBitrate) / 1000));\r\n\t\t}\r\n\t}\r\n```\r\nas you can see there is a piece of code  AnalyticsManager.onBitrateChange(((audioBitrate + videoBitrate) / 1000));   is there function that i can add this code in the exoplayer v2?\r\n\r\nThanks in advance.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3124/comments",
    "author": "jiafei1986",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-08-01T11:28:16Z",
        "body": "There is still an `onDownstreamFormatChanged` in V2 (and it's used in `EventLogger` in the demo app)."
      },
      {
        "user": "jiafei1986",
        "created_at": "2017-08-02T02:46:00Z",
        "body": "@ojw28 thank you, just found out it ."
      }
    ],
    "satisfaction_conditions": [
      "Identification of an equivalent callback mechanism in ExoPlayer v2 for handling downstream format changes",
      "Support for tracking combined audio/video bitrate changes during playback",
      "Compatibility with the user's existing event listener pattern"
    ]
  },
  {
    "number": 3061,
    "title": "Question:How to set max bit rate in exoplayer v2",
    "created_at": "2017-07-13T15:52:23Z",
    "closed_at": "2017-07-14T02:24:03Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3061",
    "body": "I am now doing the video app of dash, there is a requirement to let the user choose video quality\r\nthere are 4 types (auto, high, medium,low),  the high, medium,low will be configed in the backend.\r\n\r\nI know there is a method in v1 DashRendererBuilder.setMaxBitrate(maxBitrate); but is there an easy way to set it in v2?\r\nThanks.",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3061/comments",
    "author": "jiafei1986",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-07-13T16:36:58Z",
        "body": "We centralized everything to do with track selection in V2. Assuming you have a `DefaultTrackSelector` somewhere, you can set the maximum bitrate with:\r\n\r\n```\r\ntrackSelector.setParameters(\r\n    trackSelector.getParameters().withMaxVideoBitrate(maxBitrate));\r\n```\r\n\r\nYou should do this before calling `player.prepare` if you want this to affect the initial track selection."
      },
      {
        "user": "jiafei1986",
        "created_at": "2017-07-29T01:13:10Z",
        "body": "@ojw28 Thanks for your answer. so you mean it will not affect when the user changes the quality during the playback? is it a way to change it during playback?\n\n---\n\n@ojw28  I tested this method,  it also affects during playback, thank you very much. Great work!!!\n\n---\n\n@ojw28 when user select auto, what value should i set to this method?  is it 0? "
      },
      {
        "user": "ojw28",
        "created_at": "2017-07-31T17:35:13Z",
        "body": "Use `Integer.MAX_VALUE` :)."
      },
      {
        "user": "erenbakac",
        "created_at": "2017-10-12T13:15:59Z",
        "body": "Hi,\r\n\r\nHowever i set withMaxVideoBitrate value before player.prepare, player still changes video profiles to higher than i set. For example i set 600.000.  when i checked current video bitrate after i while i get 3.000.000.   \r\n\r\nThe stream has 500.000,900.000,1.500.000,3.000.000 video formats\r\n\r\n\r\n        int maxBitrate=600000;\r\n        player.seekToDefaultPosition();\r\n        trackSelector.getParameters().withMaxVideoBitrate(maxBitrate);\r\n        player.prepare(mediaSource, !haveResumePosition, false);\r\n\r\n"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to configure maximum video bitrate using ExoPlayer v2's track selection system",
      "Support for dynamic quality changes during playback",
      "Clarification on resetting to 'auto' quality mode",
      "Proper parameter application to ensure configuration takes effect"
    ]
  },
  {
    "number": 3052,
    "title": "Question: How to change loopcount using LoopMediaSource on the fly",
    "created_at": "2017-07-12T13:17:54Z",
    "closed_at": "2017-07-13T17:26:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3052",
    "body": "I'm currently using LoopingDataSource, Can I change the loop count while video is playing? \r\nFor example:\r\nThe initial loop count is set to 3, while the player is playing at the 2nd loop, I want to stop **looping play the video** , not stop the video immediately. That means after the 2nd loop, the player shouldn't proceed to the 3nd loop.\r\n  ",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3052/comments",
    "author": "michalliu",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-07-13T16:46:05Z",
        "body": "What's the actual use case? If you want repeat mode functionality that can be toggled on and off during playback, this is resolved in the `dev-v2` branch where there's a new `ExoPlayer.setRepeatMode` method. This will be the recommended way to control looping, except for fairly niche use cases, and will remove the need for you to use `LoopingMediaSource` if that's what you're trying to achieve."
      },
      {
        "user": "michalliu",
        "created_at": "2017-07-13T17:26:39Z",
        "body": "Thanks, setRepeatMode is exactly what I need. Hope the new version releasing soon."
      }
    ],
    "satisfaction_conditions": [
      "Provides a way to dynamically modify looping behavior during active playback",
      "Allows completion of current loop iteration before applying changes",
      "Supports real-time control of playback repetition mode",
      "Avoids requiring media source recreation for loop adjustments"
    ]
  },
  {
    "number": 3042,
    "title": "Why don't DefaultBandwidthMeter's reported elapsedMs and EventLogger's reported loadDurationMs match? ",
    "created_at": "2017-07-10T12:37:28Z",
    "closed_at": "2017-07-10T12:45:10Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3042",
    "body": "Working in the demo application, I registered an event listener on the bandwidth meter, and then logged the provided elapsedMs values. I also logged the value of loadDurationMs provided to the event logger in onLoadCompleted.\r\n\r\nWhy don't these values match? The bandwidth listener's reported values seem to always be lower than those reported to the event logger, varying from about 50\u2013100ms lower.\r\n\r\nHere's my event listener:\r\n\r\n```\r\npublic class BandwidthListener implements BandwidthMeter.EventListener {\r\n    private static final String TAG = \"BandwidthListener\";\r\n\r\n    @Override\r\n    public void onBandwidthSample(int elapsedMs, long bytes, long bitrate) {\r\n        Log.d(TAG, \"elapsedMs: \" + elapsedMs);\r\n        Log.d(TAG, \"bytes: \" + bytes);\r\n        Log.d(TAG, \"Sampled bitrate (Mb) = \" + (double) bytes * 8 / (double) elapsedMs / 1000);\r\n        Log.d(TAG, \"Estimated bitrate (Mb) = \" + bitrate / 1E6);\r\n    }\r\n}\r\n```\r\n\r\nThis is the code I have included in the EventLogger class:\r\n\r\n```\r\n  @Override\r\n  public void onLoadCompleted(DataSpec dataSpec, int dataType, int trackType, Format trackFormat,\r\n                              int trackSelectionReason, Object trackSelectionData, long mediaStartTimeMs,\r\n                              long mediaEndTimeMs, long elapsedRealtimeMs, long loadDurationMs, long bytesLoaded) {\r\n    Log.d(TAG, \"Load duration: \" + Long.toString(loadDurationMs));\r\n  }\r\n```",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3042/comments",
    "author": "emdash-ie",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-07-10T12:38:26Z",
        "body": "What type of media are you playing?"
      },
      {
        "user": "emdash-ie",
        "created_at": "2017-07-10T12:39:36Z",
        "body": "I'm playing the Google Play video in the YouTube DASH category in the demo app."
      },
      {
        "user": "ojw28",
        "created_at": "2017-07-10T12:45:10Z",
        "body": "For DASH streams audio and video are demuxed into separate streams, whose segments are downloaded in parallel. So if time is going from left to right in the diagram below, you might end up with loads overlapping as follows:\r\n```\r\n<---a1---><---a2---><---a3--->\r\n<------v1-------><-----v2---->\r\n```\r\nThe bandwidth estimate is updated whenever any load ends, so you'll get an updated estimate at the end of a1, then another at the end of v1 and so on. The period of time covered by the event at the end of v1 covers only the period of time between the end of a1 and the end of v1. Conversely, the `onLoadCompleted` corresponding to the end of v1 will report the period of time from the start of v1 to the end of v1.\r\n\r\nSo in short, you just shouldn't expect them to be the same."
      },
      {
        "user": "emdash-ie",
        "created_at": "2017-07-10T12:49:14Z",
        "body": "I see, thanks for the explanation \u2013 I appreciate it.\r\n\r\nI also have a DASH stream that only contains video tracks, and for that stream the times still differ by 10\u201340 ms. What's happening there?"
      },
      {
        "user": "ojw28",
        "created_at": "2017-07-10T12:53:28Z",
        "body": "I think that's a result of the thread that the timing is done on in the two cases. To start a load, the playback thread posts a message to a background thread that then does the load. When the load completes, the background thread posts a message back to the playback thread to say that it's finished. The timing for the bandwidth events is done directly on the background thread, where-as the timing for the loading events is done on the playback thread. So the playback thread timings are most likely slightly larger, since they also include the time taken to pass the two messages between the threads."
      },
      {
        "user": "emdash-ie",
        "created_at": "2017-07-10T12:55:17Z",
        "body": "I understand \u2013 thanks for your help."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how concurrent media loading affects timing measurements",
      "Clarification of thread-related timing discrepancies",
      "Identification of system-level measurement boundaries",
      "Differentiation between bandwidth sampling scope and load completion scope"
    ]
  },
  {
    "number": 3006,
    "title": "Bitrate value is -1 for any HLS content",
    "created_at": "2017-06-30T13:27:15Z",
    "closed_at": "2017-07-13T16:17:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/3006",
    "body": "### Issue description\r\nWhen I try to reproduce an HLS content the method player.getVideoFormat().bitrate in DebugTextViewHelper returns always -1.\r\n\r\n### Reproduction steps\r\n - Open Exoplayer 2.4.2 demo app\r\n - Select any HLS content for example \"Apple 4x3 basic stream\"\r\n - Log _player.getVideoFormat().bitrate_ in _private String getVideoString()_ method in _DebugTextViewHelper_ class\r\n- bitrate is always -1\r\n\r\n### Link to test content\r\nAny HLS content, for example \"Apple 4x3 basic stream\" in Exoplayer demo app\r\n\r\n### Version of ExoPlayer being used\r\nExoplayer 2.4.2\r\n\r\n### Device(s) and version(s) of Android being used\r\nNexus 5, Android 6.0.1\r\n\r\n### A full bug report captured from the device\r\nno logs\r\n\r\n### Info\r\nI have checked in _HlsPlaylistParser_ class and the bitrate value is correct.\r\nI'm continuing to study this case and I will add more info soon.\r\n\r\nThanks\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/3006/comments",
    "author": "Gian84",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-07-03T10:39:13Z",
        "body": "The format you're seeing here is really only intended for internal use by the player (and for debugging purposes). It is correct to say that the bitrate is set to -1, but it's also correct to say this shouldn't really be a problem. Note that this format represents just the video component of the stream, after de-muxing and extraction from the container."
      },
      {
        "user": "Gian84",
        "created_at": "2017-07-13T16:17:30Z",
        "body": "So, it is not a bug.\r\nI had this doubt because other formats (DASH or SS) have this information in the same callback or in EventLogger.\r\n\r\nThank you for your answer."
      },
      {
        "user": "takn",
        "created_at": "2017-09-11T21:32:44Z",
        "body": "What should the proper way to access bitrate be?\r\n"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why HLS content returns bitrate=-1 in this context",
      "Clarification of proper method to access HLS bitrate information",
      "Differentiation between internal format data vs. actual stream metadata",
      "Guidance on accessing HLS-specific streaming metrics"
    ]
  },
  {
    "number": 2969,
    "title": "UnrecognizedInputFormatException when play dash live stream in v2 ",
    "created_at": "2017-06-19T13:11:15Z",
    "closed_at": "2017-06-19T14:59:23Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2969",
    "body": "There is a live stream(dash with widevine),  it worked fine in exoplayer v1, but after upgrade to v2, it shows below error   \r\n```                                              com.google.android.exoplayer2.source.UnrecognizedInputFormatException: None of the available extractors (MatroskaExtractor, FragmentedMp4Extractor, Mp4Extractor, Mp3Extractor, AdtsExtractor, Ac3Extractor, TsExtractor, FlvExtractor, OggExtractor, PsExtractor, WavExtractor) could read the stream.\r\n                                                                       at com.google.android.exoplayer2.source.ExtractorMediaPeriod$ExtractorHolder.selectExtractor(ExtractorMediaPeriod.java:722)\r\n                                                                       at com.google.android.exoplayer2.source.ExtractorMediaPeriod$ExtractingLoadable.load(ExtractorMediaPeriod.java:645)\r\n                                                                       at com.google.android.exoplayer2.upstream.Loader$LoadTask.run(Loader.java:295)\r\n                                                                       at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)\r\n                                                                       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)\r\n                                                                       at java.lang.Thread.run(Thread.java:761)\r\n06-19 22:23:13.812 2750-3372/com.test.player E/ExoPlayerImplInternal: Source error.\r\n                                                                             com.google.android.exoplayer2.source.UnrecognizedInputFormatException: None of the available extractors (MatroskaExtractor, FragmentedMp4Extractor, Mp4Extractor, Mp3Extractor, AdtsExtractor, Ac3Extractor, TsExtractor, FlvExtractor, OggExtractor, PsExtractor, WavExtractor) could read the stream.\r\n                                                                                 at com.google.android.exoplayer2.source.ExtractorMediaPeriod$ExtractorHolder.selectExtractor(ExtractorMediaPeriod.java:722)\r\n                                                                                 at com.google.android.exoplayer2.source.ExtractorMediaPeriod$ExtractingLoadable.load(ExtractorMediaPeriod.java:645)\r\n                                                                                 at com.google.android.exoplayer2.upstream.Loader$LoadTask.run(Loader.java:295)\r\n                                                                                 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1133)\r\n                                                                                 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:607)\r\n                                                                                 at java.lang.Thread.run(Thread.java:761)\r\n06-19 22:23:13.812 2750-2750/com.test.player E/playback\u00a0error\u00a0>>>: com.google.android.exoplayer2.ExoPlaybackException\r\n```\r\nShould I email you the MPD file?\r\nThanks.\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2969/comments",
    "author": "jiafei1986",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-06-19T13:46:21Z",
        "body": "You're trying to play a DASH stream using `ExtractorMediaSource`, where-as you should be using `DashMediaSource`."
      },
      {
        "user": "jiafei1986",
        "created_at": "2017-06-19T14:49:03Z",
        "body": "@ojw28 Thank you very very much, i just check the code, found the playback URL does not end with mpd, so the sample code will use ExtractorMediaSource,  now i force to use DashMediaSource, the problem fixed.  THANK YOU !!!!"
      }
    ],
    "satisfaction_conditions": [
      "Identification of the correct media source type required for DASH streams in ExoPlayer v2",
      "Explanation of ExoPlayer v2's stream type detection mechanism",
      "Clarification of API differences between ExoPlayer v1 and v2 regarding stream handling"
    ]
  },
  {
    "number": 2922,
    "title": "ConcatenatingMediaSource ,a single seekbar",
    "created_at": "2017-06-08T07:12:52Z",
    "closed_at": "2017-06-08T07:19:59Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2922",
    "body": "dear author:\r\n    we hava two or more  mp4 url,and we use ConcatenatingMediaSource, we want it play sequent\uff0cand it work as we want, except seekbar,  seekbar will reset when play next.\r\n     my question is \r\n     a url mp4 file duration is 200,b url mp4 file duration is 300 and seekbar would be 500, not 200 change to 300,my english is poor ,Do I make myself clear\u3002Look forward to your reply \r\n     ",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2922/comments",
    "author": "shoyu666",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2017-06-08T07:19:59Z",
        "body": "See #2122."
      },
      {
        "user": "shoyu666",
        "created_at": "2017-06-08T07:33:11Z",
        "body": "@andrewlewis \r\n    thanks \r\n   showMultiWindowTimeBar works fine"
      }
    ],
    "satisfaction_conditions": [
      "Seamless seekbar progression across concatenated media sources",
      "Continuous timeline representation for sequential playback"
    ]
  },
  {
    "number": 2899,
    "title": "Stop video from looping",
    "created_at": "2017-06-02T15:10:07Z",
    "closed_at": "2017-06-02T15:21:28Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2899",
    "body": "Is there any way to stop a video from looping (e.g. after a button press)? Seems that  `onPlayerStateChanged` is not fired for `LoopingMediaSource` when a video ends (or at any other state other than the beginning). I don't want to interrupt during the playback. \r\n\r\n### Version of ExoPlayer being used\r\nCurrently testing on `2.2.0`, not sure if it's any different later on.\r\n\r\n### Device(s) and version(s) of Android being used\r\nGalaxy S7, 7.0.0\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2899/comments",
    "author": "radko93",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-06-02T15:13:05Z",
        "body": "In the `dev-v2` branch there's an `ExoPlayer.setRepeatMode` method that allows looping behavior to be toggled on and off. It's intended that you should use this rather than `LoopingMediaSource` except for certain niche use cases.\r\n\r\nWill that let you do what you want?"
      },
      {
        "user": "radko93",
        "created_at": "2017-06-02T15:21:28Z",
        "body": "Yeah, I missed this while searching the repo. Waiting for the release then, thanks!"
      }
    ],
    "satisfaction_conditions": [
      "Solution must allow toggling video looping behavior without interrupting playback",
      "Mechanism must trigger standard player state change events when looping ends",
      "Approach should use supported ExoPlayer APIs rather than workarounds like LoopingMediaSource",
      "Solution must be compatible with ExoPlayer 2.x architecture"
    ]
  },
  {
    "number": 2823,
    "title": "A more convenient access to certain lifecycle event ",
    "created_at": "2017-05-14T13:10:45Z",
    "closed_at": "2017-05-15T14:30:46Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2823",
    "body": "Hello,\r\n\r\nThis is a request for a small adjustment.\r\n\r\nIn the `LoadControl` interface lies a certain number of very useful methods related to the exoplayer lifecycle:\r\n\r\nonPrepared()\r\nonReleased()\r\nonStopped()\r\n\r\nHowever at this point, we can only pass one instance of a `LoadControl` implementation into the `ExoPlayerFactory`, and by default this implementation is `DefaultLoadControl`, a class marked as final.\r\n\r\nRight now, the only way I can access these callbacks in my project is by implementing my own `LoadControl` logic (that is copy pasting the DefaultLoadControl class and tweaking it a bit).\r\n\r\nI think these kind of callbacks deserve their own separate interface so they can be accessed more conveniently.\r\n\r\nThanks",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2823/comments",
    "author": "q-litzler",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-05-15T01:19:59Z",
        "body": "These aren't intended for general purpose use outside of the player. They're intended for the `LoadControl` specifically. Note also that they're invoked directly on the player's internal playback thread, which is normally not what you'd want if you're trying to implement some external logic.\r\n\r\nIt's likely that whatever you're trying to do would be better off done in some other way, for example using an `ExoPlayer.EventListener`. What is it that you're trying to do, and why are the existing event listener callbacks not sufficient?"
      },
      {
        "user": "q-litzler",
        "created_at": "2017-05-15T09:58:09Z",
        "body": "What I need is to know precisely when the player is done preparing its `MediaSource`. I would love if there was a dedicated method in `ExoPlayer.EventListener` for that, but that is not the case right now.\r\nThat's why I have been using the `LoadControl` interface, I know it's not meant to be used for this, but it's the only solution I could come up with. I'm not asking for a modification of the `LoadControl` interface, it's fine as it is.\r\nBut a similiar `onPrepared` callback in `ExoPlayer.EventListener` would be greatly appreciated.\r\n\r\nConsider this simple scenario: I want to display a player only when the source is 100% ready to be played (It is part of the advertisement experience of the app I'm working on) and I want the assurance that this callback will not be called several times over the course of the MediaSource lifecycle (like it would be if I were using the `onLoadingChanged` or `onPlayerStateChanged` methods for example)"
      },
      {
        "user": "ojw28",
        "created_at": "2017-05-15T14:30:46Z",
        "body": "I don't think `LoadControl.onPrepared` is called when you think it is. It's called as soon as the playback thread receives the `MediaSource` but before it's actually done anything with it. There will typically be zero buffer at the point when it's fired. So it doesn't seem at all correct for the use case you describe.\r\n\r\nIf you want to do something when the player is ready to be played then you should use `ExoPlayer.EventListener.onPlayerStateChanged`. The first call with `playbackState == ExoPLayer.STATE_READY` is the point at which the player is ready."
      },
      {
        "user": "q-litzler",
        "created_at": "2017-05-15T15:54:44Z",
        "body": "Ok, good to know. Thank you."
      }
    ],
    "satisfaction_conditions": [
      "Provides a reliable way to detect when the player has fully prepared its MediaSource and is ready to play",
      "Avoids multiple redundant callbacks during MediaSource lifecycle",
      "Uses officially supported ExoPlayer APIs rather than internal implementation details",
      "Provides clear documentation about when readiness state transitions occur"
    ]
  },
  {
    "number": 2764,
    "title": "Adding request headers to ExtractorMediaSource ",
    "created_at": "2017-05-03T13:20:53Z",
    "closed_at": "2017-05-06T10:25:35Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2764",
    "body": "Hello,\r\n I need to add request headers for playing video with exoplayer. I could see it was available with ExtractorSampleSource and I could not add the same with ExtractorMediaSource. Also i dont see  ExtractorSampleSource part of r2.3.1.  Kindly help",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2764/comments",
    "author": "Arunkarthicknallasami",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-05-04T17:37:49Z",
        "body": "We will try and document customization points such as this a little better. You can do what you want as follows:\r\n\r\n```\r\nDefaultHttpDataSourceFactory dataSourceFactory = new DefaultHttpDataSourceFactory(userAgent);\r\ndataSourceFactory.getDefaultRequestProperties().set(\"headerName\", \"headerValue\");\r\nreturn new ExtractorMediaSource(uri, dataSourceFactory, ...);\r\n```"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to inject custom HTTP headers into media requests",
      "Demonstration of header configuration through ExoPlayer's data source components",
      "Compatibility with ExoPlayer 2.3.1 architecture",
      "Clear connection between request header setup and ExtractorMediaSource usage"
    ]
  },
  {
    "number": 2758,
    "title": "[Question] Closed Captions (CEA-608 & 708) support for B-Frames in H.264 ",
    "created_at": "2017-05-02T06:22:19Z",
    "closed_at": "2017-05-02T07:30:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2758",
    "body": "### Issue description\r\nI have a question about Closed Captions support. \r\nH.264 content that supports B Frames have frames decoding order different than presentation order.  It is expected that the CC (608 and 708) data present in them should be ordered on presentation timestamps. From the code in Exo2, it looks like this re-ordering is not supported. Any plans of adding this support? If I were to add the support, I guess a variant of InfoQueue and DataQueue, ie. OrderedInfoQueue & OrderedDataQueue in DefaultTrackOutput may be necessary that orders the samples on timestamps.  Or perhaps a OrderedTrackOutput. Your opinion?\r\n\r\n### Reproduction steps\r\nAny AVC content that supports B Frames and CC.\r\n\r\n### Link to test content\r\nCan't be shared as of now. Will check how it can be shared if necessary.\r\n\r\n### Version of ExoPlayer being used\r\n2.3.1\r\n\r\n### Device(s) and version(s) of Android being used\r\nAny. Not device specific.\r\n\r\n### A full bug report captured from the device\r\nNA\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2758/comments",
    "author": "peddisri",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-05-02T07:30:13Z",
        "body": "This is supported already (by the fact CeaDecoder uses a TreeSet). Trying to play some content of this form would presumably have allowed you to answer this question for yourself. If you're actually seeing captions being presented in the wrong order, please let us know."
      },
      {
        "user": "peddisri",
        "created_at": "2017-05-02T08:29:47Z",
        "body": "Thanks! My bad, I was looking at a higher level, not at CEADecoder level. This answers my question. "
      }
    ],
    "satisfaction_conditions": [
      "Confirmation that closed caption data is ordered according to presentation timestamps rather than decoding order",
      "Explanation of how existing components ensure correct temporal ordering of captions"
    ]
  },
  {
    "number": 2504,
    "title": "Media Metadata tags",
    "created_at": "2017-02-26T12:42:32Z",
    "closed_at": "2017-02-27T10:28:10Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2504",
    "body": "First thanks to this awesome library . \r\n\r\nSecond simply : **how can i get** loaded media(MP3/OGG/..) **meta data**(Artist , name,track no ,year and .. ) ? \r\nWhat about audio file artwork graphic ?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2504/comments",
    "author": "thesiamak",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-02-27T10:28:08Z",
        "body": "If you're using the ExoPlayer V2 demo app then you should see metadata output to logcat with the log tag \"EventLogger\". It should be pretty easy for you to find where that happens in the demo app code, and then go from there.\r\n\r\nWe currently parse metadata for MP3 and MP4. I don't think we parse metadata for OGG yet. Please file a separate feature request if you're able to confirm that this is the case, linking or attaching media that you know to contain metadata that's not being output to \"EventLogger\". Thanks!"
      },
      {
        "user": "thesiamak",
        "created_at": "2017-02-27T12:11:26Z",
        "body": "At this time i just need MP3 metadatas .\r\nI was be able to get metadata via the method that demo app uses to(EventLogger) but obviously developers need a simpler way to get this information.\r\n\r\nThanks a lot for your help \r\n"
      },
      {
        "user": "ojw28",
        "created_at": "2017-02-27T12:43:17Z",
        "body": "I'm not sure developers do need a simpler way. It's pretty simple already, once you remove the parts that you don't need:\r\n\r\n```\r\nMappedTrackInfo mappedTrackInfo = trackSelector.getCurrentMappedTrackInfo();\r\nif (mappedTrackInfo != null) {\r\n  for (int rendererIndex = 0; rendererIndex < mappedTrackInfo.length; rendererIndex++) {\r\n    TrackSelection trackSelection = trackSelections.get(rendererIndex);\r\n    if (trackSelection != null) {\r\n      for (int selectionIndex = 0; selectionIndex < trackSelection.length(); selectionIndex++) {\r\n        Metadata metadata = trackSelection.getFormat(selectionIndex).metadata;\r\n        if (metadata != null) {\r\n          // Metadata!\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nI'm not convinced that it's possible to make it simpler without introducing assumptions that might be true in your simple use case, but that may not be true in the general case (e.g. the assumption that there's only one set of metadata in the media, rather than potentially multiple pieces of metadata attached to different tracks, which may or may not be selected)."
      },
      {
        "user": "thesiamak",
        "created_at": "2017-02-27T13:07:51Z",
        "body": "Now it's more clear! I was using a wrong and complicated method(Passing an interface to Logger) . I appreciate that.\r\nCould you please let me know how to get MP3 artwork graphic too ? Since i couldn't find appropriate field for that in meta data(It's displaying an empty field in Logcat) i was looking for a way to get selected tracks artwork(cover) url . The goal is to load image in an ImageView."
      },
      {
        "user": "ojw28",
        "created_at": "2017-02-27T13:10:25Z",
        "body": "`SimpleExoPlayerView` pulls the artwork out of the `Metadata` object to display it, so take a look at what that class does (specifically, look at `SimpleExoPlayerView.setArtworkFromMetadata`)."
      }
    ],
    "satisfaction_conditions": [
      "Method to retrieve both text metadata (artist, track number, year) and artwork from MP3 files",
      "Simplified approach compared to EventLogger/demo app implementation",
      "Handling of artwork extraction from metadata",
      "Compatibility with ExoPlayer's metadata parsing capabilities",
      "Clear distinction between track-specific metadata retrieval"
    ]
  },
  {
    "number": 2489,
    "title": "How do add multiple subtitle tracks and list/select them",
    "created_at": "2017-02-22T12:35:47Z",
    "closed_at": "2017-02-24T14:59:34Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2489",
    "body": "How do you list/select subtitle tracks in 2.2.0?  I'm using the `SimpleExoPlayer`.  When I supply multiple tracks, the first one will load and be active, but I'm not sure what happens to the second now how I can access it, I can't seem to see how to change or list the available tracks for a track type.\r\n\r\nIn exo 1.x I'm used to `player.setSelectedTrack(TYPE, INDEX)`\r\n\r\nI'm trying to sideload 2 subtitle files like so:\r\n```\r\nFormat englishSubs = Format.createTextSampleFormat(null, MimeTypes.APPLICATION_SUBRIP, null, Format.NO_VALUE, Format.NO_VALUE, \"eng\", null);\r\nFormat thaiSubs = Format.createTextSampleFormat(null, MimeTypes.APPLICATION_SUBRIP, null, Format.NO_VALUE, Format.NO_VALUE, \"thai\", null);\r\nMediaSource englishSubsSource = new SingleSampleMediaSource(Uri.parse(ENGLISH), new DefaultHttpDataSourceFactory(\"userAgent\"), englishSubs, C.TIME_UNSET);\r\nMediaSource thaiSubsSource = new SingleSampleMediaSource(Uri.parse(THAI), new DefaultHttpDataSourceFactory(\"userAgent\"), thaiSubs, C.TIME_UNSET);\r\nMergingMediaSource mergedSource = new MergingMediaSource(videoSource, englishSubsSource, thaiSubsSource);\r\n```",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2489/comments",
    "author": "tmho",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-02-22T13:46:03Z",
        "body": "If you modify the demo app to build your source, do you see both options listed under the \"Text\" button? If so, I suggest you try answering your own question by taking a look at how the demo app is doing it."
      },
      {
        "user": "tmho",
        "created_at": "2017-02-24T05:59:41Z",
        "body": "Is this on the right track?  I am able to changed the selected track with the following:\r\n\r\nrendererIndex = index of the tracks you want to select from\r\nindexOfTrackSelected = index which you'd like to chose\r\n\r\n```\r\ntrackGroups = trackSelector.getCurrentMappedTrackInfo().getTrackGroups(rendererIndex);\r\noverride = new MappingTrackSelector.SelectionOverride(new FixedTrackSelection.Factory(), indexOfTrackSelected, 0);\r\ntrackSelector.setSelectionOverride(rendererIndex, trackGroups, override);\r\n```\r\n\r\nI'm still not clear what `0` value in the `MappingTrackSelector.SelectionOverride(new FixedTrackSelection.Factory(), indexOfTrackSelected, 0)` represents"
      },
      {
        "user": "ojw28",
        "created_at": "2017-02-24T14:59:25Z",
        "body": "Yes. Pretty much! Tracks are arranged into groups. The `trackGroups` variable is an array of `TrackGroup` instances. Each `TrackGroup` may contain multiple individual tracks, each with its own format. A `TrackGroup` contains multiple individual tracks when it's possible to adapt between different quality streams of the same content. So for an adaptive video playback you'll typically see a `TrackGroup` containing multiple individual video tracks whose formats have different resolutions or bitrates. You don't generally expect to adapt between different text tracks, so a text `TrackGroup` will typically contain only a single track.\r\n\r\nSo to add comments to your block of code:\r\n\r\n```\r\ntrackGroups = trackSelector.getCurrentMappedTrackInfo().getTrackGroups(rendererIndex);\r\n// Look in trackGroups to locate the track you want to enable. You should end up with the\r\n// index of the group and the index of the individual track within the group.\r\nint trackGroupIndex = .....;\r\nint trackIndexWithinGroup = .....; // Probably 0.\r\n// Create the selection override\r\noverride = new MappingTrackSelector.SelectionOverride(\r\n    new FixedTrackSelection.Factory(), trackGroupIndex, trackIndexWithinGroup);\r\ntrackSelector.setSelectionOverride(rendererIndex, trackGroups, override);\r\n```"
      },
      {
        "user": "tmho",
        "created_at": "2017-02-27T00:53:36Z",
        "body": "great! thanks for the info :+1: "
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to programmatically list available subtitle tracks in ExoPlayer 2.2.0",
      "Clear mechanism for selecting between multiple subtitle tracks at runtime",
      "Explanation of track group organization and index management for text tracks",
      "Differentiation between track group indices and track indices within groups"
    ]
  },
  {
    "number": 2471,
    "title": "Subtitle usage sample",
    "created_at": "2017-02-18T15:42:44Z",
    "closed_at": "2017-02-22T11:13:50Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2471",
    "body": "Can anyone provide a complete and functional example of how to load subtitles, and srt subtitles are supported?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2471/comments",
    "author": "eseffair",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2017-02-20T10:46:56Z",
        "body": "Does #2017 help?"
      },
      {
        "user": "eseffair",
        "created_at": "2017-02-20T12:41:30Z",
        "body": "Hi @andrewlewis, I'm doing exactly that way, but I always get this exception...\r\n\r\n```\r\njava.lang.NullPointerException: Attempt to invoke interface method 'com.google.android.exoplayer2.upstream.DataSource com.google.android.exoplayer2.upstream.DataSource$Factory.createDataSource()' on a null object reference\r\n                                                                                      at com.google.android.exoplayer2.source.SingleSampleMediaPeriod.continueLoading(SingleSampleMediaPeriod.java:119)\r\n                                                                                      at com.google.android.exoplayer2.source.CompositeSequenceableLoader.continueLoading(CompositeSequenceableLoader.java:55)\r\n                                                                                      at com.google.android.exoplayer2.source.MergingMediaPeriod.continueLoading(MergingMediaPeriod.java:133)\r\n                                                                                      at com.google.android.exoplayer2.ExoPlayerImplInternal.maybeContinueLoading(ExoPlayerImplInternal.java:1299)\r\n                                                                                      at com.google.android.exoplayer2.ExoPlayerImplInternal.handlePeriodPrepared(ExoPlayerImplInternal.java:1276)\r\n                                                                                      at com.google.android.exoplayer2.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:316)\r\n                                                                                      at android.os.Handler.dispatchMessage(Handler.java:98)\r\n                                                                                      at android.os.Looper.loop(Looper.java:135)\r\n                                                                                      at android.os.HandlerThread.run(HandlerThread.java:61)\r\n                                                                                      at com.google.android.exoplayer2.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\r\n```"
      },
      {
        "user": "andrewlewis",
        "created_at": "2017-02-22T10:14:37Z",
        "body": "It looks like the `DataSourceFactory` you're passing to `SingleSampleMediaSource` is null. Please share the code you're using to construct the `MediaSource`s."
      },
      {
        "user": "eseffair",
        "created_at": "2017-02-22T11:13:50Z",
        "body": "Hi @andrewlewis, thank you, I realized my mistake."
      }
    ],
    "satisfaction_conditions": [
      "Demonstration of proper initialization for subtitle-related dependencies (e.g., DataSourceFactory)",
      "Complete end-to-end example covering subtitle integration with all necessary components",
      "Explicit confirmation of SRT subtitle format support"
    ]
  },
  {
    "number": 2460,
    "title": "How to hide all control components?",
    "created_at": "2017-02-16T04:02:53Z",
    "closed_at": "2017-02-16T17:43:36Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2460",
    "body": "How to hide all controllers  (start button, pause, and so on) that they did not exist, and the screen will always full.\r\n\r\nI looked, there is simpleExoPlayerView.setUseController(true) method;\r\n\r\nBut it deactivate the player ...\r\n\r\n```\r\npublic void setUseController (boolean useController) {\r\n    this.useController = useController;\r\nif (useController) {\r\n      controller.setPlayer(player);\r\n    } else {\r\n      controller.hide();\r\n      controller.setPlayer(null);\r\n    }\r\n}\r\n```\r\nHow to hide or delete these components?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2460/comments",
    "author": "ghost",
    "comments": [
      {
        "user": "directable",
        "created_at": "2017-02-16T04:17:01Z",
        "body": "Have you tried just doing\r\nsimpleExoPlayerView.setUseController(false);\r\nsimpleExoPlayerView.hideController();\r\n\r\nsimpleExoPlayerView.setPlayer(playeryoucreated);\r\n"
      },
      {
        "user": "ghost",
        "created_at": "2017-02-16T04:20:53Z",
        "body": "this method is not - hideController()\r\nBut it works for me. Thank you!\r\n```\r\nsimpleExoPlayerView.setUseController(false);\r\nsimpleExoPlayerView.setPlayer(playeryoucreated);\r\n```\r\n"
      }
    ],
    "satisfaction_conditions": [
      "Hides all player controls permanently without breaking player functionality",
      "Uses officially supported methods to remove UI elements",
      "Avoids reliance on unavailable methods"
    ]
  },
  {
    "number": 2407,
    "title": "Font color of subtitle is not changing using CaptionStyleCompat",
    "created_at": "2017-02-01T10:46:36Z",
    "closed_at": "2017-02-01T12:19:48Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2407",
    "body": "My requirement is to change the font color of Closed caption sub title text. For fulfill requirement I am using\r\n```\r\ncaptionStyleCompat = new CaptionStyleCompat(Color.BLACK, Color.BLUE, Color.TRANSPARENT, CaptionStyleCompat.EDGE_TYPE_DROP_SHADOW, Color.GREEN, null);\r\n\r\nsimpleExoPlayerView.getSubtitleView().setStyle(captionStyleCompat);\r\n```\r\nAs per above method my subtitle font color should be black. but still it is default color that is white where as background color has been changed from black to blue.\r\nWhy font color is not changed to black from its default color? I am also changing different color of first and second parameter. All the time background has been changed but foreground has not been changed.\r\n\r\nAs per documentation there is no any method found to change the font color of subtitle text.\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2407/comments",
    "author": "shailesh2208",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-02-01T11:25:31Z",
        "body": "It depends a bit on the source media. If the media doesn't say anything about the caption style, then what you've done should work fine. If the media explicitly indicates a caption style, then anything it indicates takes priority by default. Given what you're seeing, I suspect the media has an explicit embedded caption style that specifies white text.\r\n\r\nYou can disable application of embedded caption styles and have ExoPlayer use only the style you provide by calling `simpleExoPlayerView.getSubtitleView().setApplyEmbeddedStyles(false)`. Please give that a try and let us know if it works. Thanks!"
      },
      {
        "user": "shailesh2208",
        "created_at": "2017-02-01T12:15:53Z",
        "body": "Hi ojw28,\r\nUsing `simpleExoPlayerView.getSubtitleView().setApplyEmbeddedStyles(false)` It is working now. Thank u so much for suggestion."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why custom caption styles might be overridden by media-defined styles",
      "Method to ensure custom caption styles take precedence over media-defined styles",
      "Clarification about priority levels between application settings and media-inherent styles"
    ]
  },
  {
    "number": 2357,
    "title": "set equalizer",
    "created_at": "2017-01-22T16:10:22Z",
    "closed_at": "2017-01-23T18:28:38Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2357",
    "body": "Hello! I got following code to play mp3 tracks. What should i do to get audioSessionId correct? When i try with getAudioSessionId() and give result to equalizer constructor it says following:\r\nRuntimeException: Cannot initialize effect engine for type: 0bed4300-ddd6-11db-8f34-0002a5d5c51b Error: -3.\r\n\r\nMy code:\r\n```\r\n private void createPlayer(){\r\n        TrackSelector trackSelector = new DefaultTrackSelector();\r\n        LoadControl loadControl = new DefaultLoadControl();\r\n        player = ExoPlayerFactory.newSimpleInstance(context, trackSelector, loadControl);\r\n        player.addListener(this);\r\n    }\r\n\r\npublic void playTrack(Track track) {\r\n        createPlayer();\r\n        this.track = track;\r\n        this.url = track.getPath();\r\n        Uri builtUri = Uri.parse(url);\r\n        DataSource.Factory dataSourceFactory = new DefaultDataSourceFactory(context, Util.getUserAgent(context, \"yourApplicationName\"));\r\n        ExtractorsFactory extractorsFactory = new DefaultExtractorsFactory();\r\n        MediaSource streamSource = new ExtractorMediaSource(builtUri, dataSourceFactory, extractorsFactory, null, null);\r\n        isNotificated = false;\r\n        type = Player_Fragment.Type.MEMORY;\r\n        setVolumeMax();\r\n        player.prepare(streamSource);\r\n        player.setPlayWhenReady(true);\r\n}\r\n```",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2357/comments",
    "author": "Merseyside",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-01-23T09:27:21Z",
        "body": "The sample code you've provided lacks the very piece you're asking for help on (i.e. any handling of audioSessionId), which makes it quite difficult for us to help."
      },
      {
        "user": "Merseyside",
        "created_at": "2017-01-23T13:45:07Z",
        "body": "```\r\n@Override\r\n    public void onPlayerStateChanged(boolean playWhenReady, int playbackState) {\r\n        if (playbackState == ExoPlayer.STATE_ENDED){\r\n            if (isLooping){\r\n                playTrack(track);\r\n            }\r\n            else if (!isNotificated) myInterface.endOfTrack();\r\n        }\r\n        else if (playbackState == ExoPlayer.STATE_READY){\r\n            EqualizerEngine equalizerEngine = new EqualizerEngine(context);\r\n            PrintString.printLog(\"Equalizer\", player.getAudioSessionId() + \"\");\r\n            equalizerEngine.setEqualizers(player.getAudioSessionId());\r\n        }\r\n    }\r\n```\r\nthis override method, where i try to get audioSessionId, but it always equals zero"
      },
      {
        "user": "ojw28",
        "created_at": "2017-01-23T14:24:02Z",
        "body": "That means it hasn't been set yet. You can use `player.setAudioDebugListener` to listen for the ID being set (the ID will be passed via `onAudioSessionId` when it is)."
      },
      {
        "user": "Merseyside",
        "created_at": "2017-01-23T18:20:00Z",
        "body": "okay, i will try it. Thanks very muck\n\n---\n\nIt works, thanks)"
      }
    ],
    "satisfaction_conditions": [
      "Ensure audio session ID is retrieved after it has been properly initialized by the player",
      "Handle asynchronous initialization of audio session resources",
      "Provide mechanism to capture valid audio session ID through player lifecycle events"
    ]
  },
  {
    "number": 2342,
    "title": "How to create MutliPeriod or MultiWindow Timeline from single media file?",
    "created_at": "2017-01-17T23:15:38Z",
    "closed_at": "2017-01-25T15:19:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2342",
    "body": "Is it possible to create MultiPeriod or MultiWindow Timeline from a single media file.\r\n\r\nFor example, if my media file is playing for 10 minutes then is it possible to create period/window for each 1 minute. It is like creating playlist from single media file consist of 10 playable windows.\r\n\r\nThanks, \r\n-Kuppa",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2342/comments",
    "author": "skuppa",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-01-18T10:28:56Z",
        "body": "I don't really see why you'd want to do this. If it's just to make the UI appear differently (i.e. as though the content consists of multiple pieces of media with << and >> skip buttons) then it seems more appropriate to customise the UI, not fake a structure for the media that's not really true."
      },
      {
        "user": "skuppa",
        "created_at": "2017-01-18T19:03:41Z",
        "body": "Thank you for responding my question.\r\n\r\nI am trying to index the big video with multiple chapters like DVD menu, and let user skip to next chapter or pick any chapter as per his needs."
      },
      {
        "user": "ojw28",
        "created_at": "2017-01-25T15:19:58Z",
        "body": "As above, I think you should implement this kind of thing in your own UI above the player. The timeline represents the structure of the media being played. Faking the structure of the media just because the default UI components use it isn't the right solution."
      },
      {
        "user": "skuppa",
        "created_at": "2017-02-08T19:33:27Z",
        "body": "Thanks for the suggestion.  Here is my use case, please advise me to the right direction..  I have video files that was shot in multiple angles and all video files have same timings.   I need to play video by switching the different angled's video file without any gaps.  My example as follows (I use second instead of microsecond):\r\n\r\n Assume, I have two video files.\r\nClip1_Angle1.mp4 (120 seconds)\r\nClip1_Angle2.mp4 (120 seconds)\r\n\r\nAnd I expect my player should be playing\r\nClip1_Angle1.mp4 (0-5s) -> Clip1_Angle2.mp4(6s-10s) -> Clip1_Angle1.mp4 (11-15s) -> Clip1_Angle2.mp4(16s-20s) ->...\r\n\r\nThanks,\r\n-Kuppa\r\n\r\n"
      },
      {
        "user": "andrewlewis",
        "created_at": "2017-02-10T13:53:48Z",
        "body": "@skuppa Can you use a ConcatenatingMediaSource joining several ClippingMediaSources, where each of those has the required start/end position and wraps an ExtractorMediaSource with the required URI? Note that for seamless video playback you'll need to ensure that the start time of every ClippingMediaSource is a keyframe (see #1988). It's fine to load the same URI more than once in different sources."
      },
      {
        "user": "skuppa",
        "created_at": "2017-02-10T21:34:54Z",
        "body": "Thank you Andrew.  This is really helps.  "
      }
    ],
    "satisfaction_conditions": [
      "Support chapter-based navigation like DVD menus for segmented content",
      "Enable seamless switching between media segments at arbitrary time boundaries",
      "Handle dynamic composition of media segments from same/different sources",
      "Maintain synchronization across media segments",
      "Support non-linear playback navigation"
    ]
  },
  {
    "number": 2286,
    "title": "SimpleExoPlayer.setVideoListener() causes rendering issues r2.1.1",
    "created_at": "2017-01-03T14:12:35Z",
    "closed_at": "2017-01-04T10:51:19Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2286",
    "body": "Setting SimpleExoPlayer.VideoListener() causes rendering issues (SimpleExoPlayerView does not show any frames). audio plays fine and even the VideoListener's are invoked properly. Am I missing something here?\r\nFollowing code illustrates the problem.\r\n\r\n```\r\n   private void playStream(final Uri mediaUrl) {\r\n        Log.d(LOGTAG, \"Now playing: \" + mediaUrl);\r\n        mUrl.setText(mediaUrl.toString());\r\n        // Measures bandwidth during playback. Can be null if not required.\r\n        DefaultBandwidthMeter bandwidthMeter = new DefaultBandwidthMeter();\r\n        // Produces DataSource instances through which media data is loaded.\r\n        DataSource.Factory dataSourceFactory = new DefaultDataSourceFactory(this, Util.getUserAgent(this, \"yourApplicationName\"), bandwidthMeter);\r\n        // Produces Extractor instances for parsing the media data.\r\n        ExtractorsFactory extractorsFactory = new DefaultExtractorsFactory();\r\n        // This is the MediaSource representing the media to be played.\r\n        MediaSource videoSource;\r\n        if(mediaUrl.getLastPathSegment().contains(\".m3u8\"))\r\n            videoSource = new HlsMediaSource(mediaUrl,dataSourceFactory, 10, null, null);\r\n        else\r\n            videoSource = new ExtractorMediaSource(mediaUrl,dataSourceFactory, extractorsFactory, null, null);\r\n        // Following listener breaks rendering\r\n        player.setVideoListener(new SimpleExoPlayer.VideoListener() {\r\n            @Override\r\n            public void onVideoSizeChanged(int width, int height, int unappliedRotationDegrees, float pixelWidthHeightRatio) {\r\n                Log.e(LOGTAG, \"onVideoSizeChanged: \" + width + \":\" +height);\r\n            }\r\n\r\n            @Override\r\n            public void onRenderedFirstFrame() {\r\n                Log.e(LOGTAG, \"onRenderedFirstFrame \");\r\n            }\r\n        });\r\n        // Prepare the player with the source.\r\n        player.prepare(videoSource);\r\n        player.setPlayWhenReady(true);\r\n    }\r\n```\r\nReplacing setVideoListener() with setVideoDebugListener() solves the issue.\r\nTested on Nexus 9 running 7.0",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2286/comments",
    "author": "pilzflorian",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2017-01-03T14:54:45Z",
        "body": "SimpleExoPlayerView registers itself as the video listener, so when you set it you're replacing SimpleExoPlayerView as the listener. Hence SimpleExoPlayerView doesn't receive the events that it needs.\r\n\r\nWhy do you need to register a video listener when also using SimpleExoPlayerView?"
      },
      {
        "user": "pilzflorian",
        "created_at": "2017-01-04T10:51:19Z",
        "body": "Thank you so much for clarification, I will create my own SurfaceView and Controller instances. \r\nI need the information for gathering QOS statistics.\r\nI'll close this, thanks again for the quick response!"
      },
      {
        "user": "ojw28",
        "created_at": "2017-01-04T10:55:10Z",
        "body": "You should use `setVideoDebugListener` to gather QOS statistics, and let the view use `setVideoListener`."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why setting a custom VideoListener breaks SimpleExoPlayerView functionality",
      "Identification of proper listener type for quality-of-service monitoring",
      "Clear separation between debug/statistics listeners and core rendering listeners",
      "Guidance on listener prioritization in ExoPlayer architecture"
    ]
  },
  {
    "number": 2173,
    "title": "[HLS switch variants] catch the first rendered frame of a new variant",
    "created_at": "2016-12-09T06:59:23Z",
    "closed_at": "2016-12-16T09:13:56Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2173",
    "body": "I'm currently playing with the ExoPlayer r2.0.4.\r\nI noticed that in the HLS implementation, it supports adaptive video track selection. The demo application can seamlessly switching between variants in the HLS master playlist.\r\nWhile, now I wish I could catch the first frame output by decoder from a new variant and synchronically do some operation when the very frame is rendered onto the screen.\r\nDoes ExoPlayer support this behavior? \r\nI already customized the trackSelection a little bit so that I can arbitrarily switch between self generated variants (all variants have the same format).\r\n\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2173/comments",
    "author": "optimus1130",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-12-11T23:13:24Z",
        "body": "Please can you clarify exactly what your use case is? What operation do you want to do, exactly, and how synchronous does it really need to be?"
      },
      {
        "user": "optimus1130",
        "created_at": "2016-12-14T02:36:18Z",
        "body": "Thank you. My language is limited, but l'll try my best to clarify my use case:\r\nIn my application, the codec output frames are rendered onto an OpenGL shape.  Also, here is a camera in the OpenGL world to \"see\" the object. What I want is to know from which variant the new frame comes so that I can adjust camera position according the frame source when a frame form a new source (or, using the variable name used in ExoPlayer, a new video variant) is rendered onto the OpenGL shape. \r\nWhat I already have is: \r\nI can seamlessly switch between variants. \r\nThe problem is:\r\nI still can't catch the first frame that comes from a new variant each time when the variant change happens. Since all video variants have a same format, the onOutputFormatChanged method in MediaCodecVideoRenderer.java is never called. \r\n "
      },
      {
        "user": "ojw28",
        "created_at": "2016-12-15T11:28:27Z",
        "body": "Is onInputFormatChanged called on MediaCodecVideoRenderer? The format on the input side of the decoder has quite a bit of extra data in it, so that's more likely.\r\n\r\nIf it is then the listener will see an invocation of onVideoInputFormatChanged, which might be good enough. If it's too early, you could do something like:\r\n1. Set a flag in onInputFormatChanged\r\n2. When an input buffer is queued, if the flag is set, clear it and record the timestamp of that buffer. This will be the timestamp of the first buffer after the format switch.\r\n3. When an output buffer is rendered, look at its timestamp. If it matches the timestamp recorded in the previous step then it's the first buffer after the format switch. Generate an event and do what you want in response to it."
      },
      {
        "user": "optimus1130",
        "created_at": "2016-12-16T03:04:33Z",
        "body": "Thank you so much!! I got it done yesterday using exactly the same strategy."
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to detect the first rendered frame after a variant switch",
      "Solution works with variants sharing identical format specifications",
      "Event triggering synchronous with actual frame rendering"
    ]
  },
  {
    "number": 2154,
    "title": "Retrieving current playback video and audio formats",
    "created_at": "2016-12-05T11:21:17Z",
    "closed_at": "2016-12-11T20:39:00Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2154",
    "body": "Hello, I want to retrieve data about currently active tracks(Format).\r\n\r\nWhen i am implementing TrackSelector.EventListener interface i have an \r\nonTrackSelectionsChanged() method which is triggered each time the track selection is changed.\r\nThere i am trying to get the formats by player.getVideoFormat and player.getAudioFormat().\r\nBut when i am trying to get the format it is null. At least the one i am changing. As i understand, this happens because the onVideoDisabled() of the VideoRendererEventListener happens first. Is it a bug or it is me, who doing something wrong?\r\nAnother question, is there any way to get the current TextFormat?",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2154/comments",
    "author": "AntonAFA",
    "comments": [
      {
        "user": "gvidda",
        "created_at": "2016-12-08T09:03:28Z",
        "body": "In Exo2 you can listen to AdaptiveMediaSourceEventListener.onDownStreamFormatChanged() event and check the trackType and save those trackFormat depending on the type. Then you always have the current Format for video/audio/text."
      },
      {
        "user": "AntonAFA",
        "created_at": "2016-12-11T10:16:08Z",
        "body": "thank you for your help."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to reliably retrieve current video/audio/text formats during track selection changes",
      "Solution must support text format retrieval",
      "Mechanism to track active formats across renderer state changes"
    ]
  },
  {
    "number": 2053,
    "title": "Playlist refresh UI",
    "created_at": "2016-11-09T20:16:37Z",
    "closed_at": "2016-11-09T23:10:35Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/2053",
    "body": "onPlayerStateChanged it's not called when a playlist change from one song to another\r\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/2053/comments",
    "author": "irenecs",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-11-09T20:29:05Z",
        "body": "Why would you expect it to change? One of the key selling points of playlist support in V2 is that we can perform transitions seamlessly, which means there wont be any changes to player state across the transition ;). You should probably be looking at `onPositionDiscontinuity` instead, which is invoked on seeks and also when transitioning from one song to the next.\n"
      },
      {
        "user": "irenecs",
        "created_at": "2016-11-09T20:35:18Z",
        "body": " i would like to refresh  my UI when the song on the playlist change \n"
      },
      {
        "user": "ojw28",
        "created_at": "2016-11-09T20:43:53Z",
        "body": "Yes. So use `onPositionDiscontinuity`. From there, you can use `ExoPlayer.getCurrentWindowIndex` to see the index of the track being played. If it's changed then you can refresh the UI accordingly.\n"
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to detect playlist track changes without relying on player state transitions",
      "Clear way to identify when playback moves to a new track in a playlist",
      "Integration with ExoPlayer's playlist position tracking system",
      "Event-driven approach for UI updates during seamless transitions"
    ]
  },
  {
    "number": 1918,
    "title": "[Question] Reuse BOTH SimpleExoPlayerView and SimpleExoPlayer after STATE_ENDED",
    "created_at": "2016-10-09T04:40:11Z",
    "closed_at": "2016-10-09T12:48:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1918",
    "body": "Assuming that I have played a local Video, using those 2 components. After the player reaches STATE_ENDED, it seems that it is not trivial to restart the playback again. What should I do if I want to \"click to one button\" to restart the playback from all over again.\n\nThanks and pardon me if I'm missing some thing.\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1918/comments",
    "author": "eneim",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-10-09T12:44:42Z",
        "body": "I think it is trivial; just seek back to 0 (by calling seekTo(0)) and that's it? Note that the ExoPlayer demo app allows you to seek back after the state has transitioned to ended (with the player controls).\n"
      }
    ],
    "satisfaction_conditions": [
      "Solution must enable restarting playback from beginning after STATE_ENDED",
      "Solution must work with existing SimpleExoPlayer/View instances",
      "Solution must handle player state transitions properly",
      "Solution must be triggerable via single user action"
    ]
  },
  {
    "number": 1892,
    "title": "Calculating size of SurfaceView",
    "created_at": "2016-10-04T16:15:29Z",
    "closed_at": "2016-10-04T18:55:37Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1892",
    "body": "Hello all, I am trying to add ExoPlayer 2.0.1 instead of MediaPlayer. With MediaPlayer in the onPrepared() method I use getVideoWidth() and getVideoHeight() to get width and height of video to calculate size of SurfaceView with correct aspect ratio. With ExoPlayer 2.0.1 library I am creating intance of SimpleExoPlayer:\n\n```\n            Handler mainHandler = new Handler();\n            BandwidthMeter bandwidthMeter = new DefaultBandwidthMeter();\n            TrackSelection.Factory videoTrackSelectionFactory =\n                    new AdaptiveVideoTrackSelection.Factory(bandwidthMeter);\n            TrackSelector trackSelector =\n                    new DefaultTrackSelector(mainHandler, videoTrackSelectionFactory);\n            LoadControl loadControl = new DefaultLoadControl();\n            exoPlayer = ExoPlayerFactory.newSimpleInstance(context, trackSelector, loadControl);\n            //simpleExoPlayerView.setPlayer(exoPlayer);\n            exoPlayer.setVideoSurfaceHolder(videoHolder);\n            exoPlayer.addListener(this);\n```\n\nI suppose I need to use this event to get width and height, but this event is not fired, why and what should I use? onPlayerStateChanged event is working.\n\n```\n    @Override\n    public void onVideoSizeChanged(int width, int height, int unappliedRotationDegrees,\n                                   float pixelWidthAspectRatio) {\n        appendLog(\"onVideoSizeChanged: \" +  String.valueOf(width) + \", \" + String.valueOf(height) + \", \" + String.valueOf(pixelWidthAspectRatio));\n    }\n```\n\nTried it on Android 6 on Sony Z3 Compact, LG Spirit.\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1892/comments",
    "author": "AntonAndev",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-10-04T18:50:20Z",
        "body": "Where in your code are you registering the listener? There should be a call to `SimpleExoPlayer.setVideoListener` somewhere?\n"
      },
      {
        "user": "AntonAndev",
        "created_at": "2016-10-04T18:55:32Z",
        "body": "oh yes, added it, now works, I was thinking addListener does it, thank you.\n"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to properly register a listener for video dimension changes in ExoPlayer",
      "Differentiation between player state listeners and video-specific listeners",
      "Mechanism to obtain video dimensions before/aspect ratio calculation"
    ]
  },
  {
    "number": 1469,
    "title": "[Question] Tracking Playback in HLS",
    "created_at": "2016-04-25T14:30:04Z",
    "closed_at": "2016-04-28T09:12:05Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1469",
    "body": "Hello, \n\nThanks for the great lib. I am streaming HLS (m3u8 files) for an audio app I'm building. I need to be able to track how much of the audio has been listened to. I'm having a difficult time trying to figure out where to hook into the player to gather this information. Is this possible? If so, what class/listener should I look at? Thanks!\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1469/comments",
    "author": "donnfelker",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-04-25T14:37:01Z",
        "body": "What's wrong with `ExoPlayer.getCurrentPosition` and `ExoPlayer.getDuration`?\n"
      },
      {
        "user": "donnfelker",
        "created_at": "2016-04-27T22:05:28Z",
        "body": "Seems to me it's a PEBCAK error in this case (me). \ud83d\ude04   Thanks for the quick tip @ojw28, not sure why I didn't see that before (facepalm). \n"
      }
    ],
    "satisfaction_conditions": [
      "Identifies methods to track real-time playback progress",
      "Specifies how to obtain both current position and total duration"
    ]
  },
  {
    "number": 1449,
    "title": "Rendering processed output buffer data as a waveform is always ahead of played audio",
    "created_at": "2016-04-16T21:54:12Z",
    "closed_at": "2016-04-17T15:47:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1449",
    "body": "I have extended the MediaCodecAudioTrackRenderer to get access to the output buffer to render the PCM data as a waveform.  The problem I am having is that the waveform seems to render faster than the audio being played. I assumed that once the output buffer was processed and discarded any rendering would be matched with the audio playback.  BTW: the player is using a uri datasource.  Code used is below:\n\n```\n@Override\nprotected boolean processOutputBuffer(long positionUs, long elapsedRealtimeUs, MediaCodec codec, ByteBuffer buffer, BufferInfo bufferInfo, int bufferIndex, boolean shouldSkip) throws ExoPlaybackException {\n    boolean processed = false;\n\n   //  Clone buffer \n    ByteBuffer bb = deepCopy(buffer);\n\n    processed = super.processOutputBuffer(positionUs,elapsedRealtimeUs,codec,buffer,bufferInfo, bufferIndex, shouldSkip);\n    if (processed & !shouldSkip)\n    {\n        // send data to be converted to shorts and then propogate a callback to render float data\n        transform(bb);\n        return true;\n    }\n    else\n    {\n        return false;\n    }\n}\n```\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1449/comments",
    "author": "m1c999",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-04-17T15:47:30Z",
        "body": "`MediaCodecAudioTrackRenderer.processOutputBuffer` feeds each output buffer into an `AudioTrack`, but note that an `AudioTrack` has its own audio buffer (at the platform level). So if that buffer is being kept full there will be a delay between an output buffer being processed and the corresponding audio actually being output from the device.\n\nTo do what you're wanting to do you would probably need to generate the data that you need for your visualization from each output buffer, then add that data to the back of a queue with the associated timestamp `bufferInfo.presentationTimeUs`. You could then pull items off the front of the queue and render them as `MediaCodecAudioTrackRenderer.getPositionUs()` reaches the associated timestamps.\n"
      }
    ],
    "satisfaction_conditions": [
      "Synchronize waveform rendering with actual audio playback timing",
      "Utilize audio presentation timestamps for visualization alignment"
    ]
  },
  {
    "number": 1413,
    "title": "HLS AES",
    "created_at": "2016-04-04T19:28:09Z",
    "closed_at": "2016-04-07T20:30:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1413",
    "body": "I have been searching but couldn\u00b4t found how to use ExoPlayer for playing a HSL encoded with Sample-AES or AES-128.\n\nCan anyone point me in which direction to search?\n\nThanks in advance,\n\nRodrigo\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1413/comments",
    "author": "igo88",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-04-04T22:14:45Z",
        "body": "We don't support SAMPLE-AES. AES-128 should \"just work\".\n"
      }
    ],
    "satisfaction_conditions": [
      "Clarifies ExoPlayer's support status for HLS streams encrypted with SAMPLE-AES vs. AES-128"
    ]
  },
  {
    "number": 1406,
    "title": "how to delay chunk download in exoplayer-DASH",
    "created_at": "2016-03-31T09:34:22Z",
    "closed_at": "2016-04-04T14:16:52Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1406",
    "body": "I am working on DASH streaming in ExoPlayer. \nI want to delay(time varies) the download of next chunk , because i have enough buffer to play for next few seconds.\nHow can i achieve this? \n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1406/comments",
    "author": "RamkumarVooda",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-03-31T09:47:11Z",
        "body": "Why don't you trust the player to buffer chunks in a sensible way? Or to put it another way, why do you actually want to do this? Having enough buffer to play the next few seconds isn't a good reason in itself, and artificially keeping the buffer small significantly increases the probability of re-buffers or playback failures.\n"
      },
      {
        "user": "RamkumarVooda",
        "created_at": "2016-03-31T12:37:39Z",
        "body": "I am implementing an adaptive streaming algorithm in FormatEvaluator Class. So according to the algorithm i need to delay the download for some time only if the buffer is exceeding certain threshold.\n"
      },
      {
        "user": "ojw28",
        "created_at": "2016-04-04T10:46:37Z",
        "body": "`LoadControl` (and `DefaultLoadControl`) implements this functionality currently, so you should start there.\n"
      },
      {
        "user": "RamkumarVooda",
        "created_at": "2016-04-04T14:16:52Z",
        "body": "yes got it.\nThank you\n"
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to conditionally delay chunk downloads based on buffer thresholds",
      "Integration with ExoPlayer's buffer management system",
      "Support for variable delay durations",
      "No degradation of adaptive streaming logic"
    ]
  },
  {
    "number": 1284,
    "title": "onPlayerError improvement",
    "created_at": "2016-02-19T04:15:00Z",
    "closed_at": "2016-02-19T15:24:02Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1284",
    "body": "Dear colleagues,\nI have an inquire about passing additional information with an error in ExoPlayer.\nI am talking about **StreamingDrmSessionManager.java** and it's method:\n`void onKeyResponse(Object response)`\nIn case of any error with License retrieving, our server returns important information with \"**Object response**\" and this causing exception in next line:\n`mediaDrm.provideKeyResponse(sessionId, (byte[]) response);`\nThat is OK. But, however, we loosing that information form client side.\nSo I am asking, whether it is possible to by-pass response with Exception, so it will be possible to get it in \"onPlayerError\" callback ?\n\nAs possible solution now, we inject custom listener into WidevineMediaDrmCallback.java and parse \n`byte[] executeKeyRequest(final UUID uuid, final MediaDrm.KeyRequest request)`\nresponse in order to intercept message.\n\nThanks a lot in advance.\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1284/comments",
    "author": "ChernyshovYuriy",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-02-19T12:02:46Z",
        "body": "You must be implementing `MediaDrmCallback`. You should have your implementation of `MediaDrmCallback.executeKeyRequest` check the response. If it's an error response this method should construct and throw an appropriate exception, which you can define yourself. Playback will then fail with this exception as the cause.\n\nTo provide more detail, the way I've seen this implemented elsewhere is for the license server to return a response whose body contains a status. For example:\n\n```\nStatus=X\n<data>\n```\n\nUpon obtaining the response, `MediaDrmCallback.executeKeyRequest` will parse the response and look at the status. If it's ok, it'll return `<data>`. If it's not ok, it'll construct and throw an appropriate exception. Note that the license server response is something you can design yourself, so you can put any information in there that you want to include in the exception.\n"
      },
      {
        "user": "ChernyshovYuriy",
        "created_at": "2016-02-19T14:33:20Z",
        "body": "Hi and thanks for the quick response.\n`MediaDrmCallback` is what I was talking about, in particular it's implementation in our project `class WidevineMediaDrmCallback implements MediaDrmCallback`.\nAccording to your suggestion I should intercept response and parse it. This is what I am doing, but I am not blocking farther execution and allow to return data from `byte[] executeKeyRequest(final UUID uuid, final MediaDrm.KeyRequest request)`.\nOk, thanks for the solution.\n\n\n---\n\nOh, I forget important thing!\nIn both methods of the `MediaDrmCallback`:\n`byte[] executeKeyRequest(final UUID uuid, final MediaDrm.KeyRequest request)`\n`byte[] executeProvisionRequest(final UUID uuid, final MediaDrm.ProvisionRequest request)`\nwe must return bytes array.\nThis is the point. In case of success - we have no issues, but in case of any error we have to pass these bytes farther. And this will cause finally `void onPlayerError(final ExoPlaybackException error)`.\nAnd, in case we processing `executeKeyRequest` and detect an error - then there is double error in the side of ExoPlayerImpl. One is `onPlayerError` and another is custom License Error listener.\n\nAnd intention of my initial question was to prevent it. To process an error in single place, in `onPlayerError` callback. Does it make sense for you now?\n"
      },
      {
        "user": "ojw28",
        "created_at": "2016-02-19T14:35:14Z",
        "body": "You don't have to return a byte array. You should be throwing an exception, meaning you don't need to (i.e. can't) return anything.\n"
      },
      {
        "user": "ChernyshovYuriy",
        "created_at": "2016-02-19T15:17:07Z",
        "body": "Ok, let me try tis approach.\n\n\n---\n\nThis approach works well, thanks a lot. I think question can be closed now :-)\n"
      },
      {
        "user": "ojw28",
        "created_at": "2016-02-19T15:24:02Z",
        "body": "Great!\n"
      }
    ],
    "satisfaction_conditions": [
      "Error information from server responses must be propagated to the onPlayerError callback",
      "Error handling must be consolidated to a single point (onPlayerError)",
      "Solution must preserve server error details without data loss"
    ]
  },
  {
    "number": 1248,
    "title": "Multiple ExoPlayer instances using one SurfaceHolder",
    "created_at": "2016-02-10T01:33:26Z",
    "closed_at": "2016-02-10T17:49:48Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1248",
    "body": "Is it possible to create more than one instance of `ExoPlayer` and use the same `SurfaceHolder`? I have the use case where I need one player for streaming content, and another for streaming client side ads. Only one player is supposed to play/show at a time, and they are directly on top of each other. Is there any way I can do this with just a single SurfaceHolder? I'm pretty sure it's only the `MediaCodec` api complaining with this error:\n\n`E/MediaCodec: native_window_api_connect returned an error: Invalid argument (-22)`\n`E/MediaCodec: configure failed with err 0xffffffea, resetting...`\n\nFollowed by an ExoPlayer exception:\n\n```\nE/ExoPlayerImplInternal: Internal track renderer error.\n    com.google.android.exoplayer.ExoPlaybackException: com.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException: Decoder init failed: OMX.qcom.video.decoder.avc, MediaFormat(null, video/avc, -1, -1, 704, 396, -1, 1.0, -1, -1, null, -1, false, 1280, 720)\n    at com.google.android.exoplayer.MediaCodecTrackRenderer.notifyAndThrowDecoderInitError(MediaCodecTrackRenderer.java:388)\n    at com.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:374)\n    at com.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:729)\n    at com.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:334)\n    at com.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:496)\n    at com.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:479)\n    at com.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:129)\n    at com.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:431)\n    at com.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:213)\n    at android.os.Handler.dispatchMessage(Handler.java:98)\n    at android.os.Looper.loop(Looper.java:135)\n    at android.os.HandlerThread.run(HandlerThread.java:61)\n    at com.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\n    Caused by: com.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException: Decoder init failed: OMX.qcom.video.decoder.avc, MediaFormat(null, video/avc, -1, -1, 704, 396, -1, 1.0, -1, -1, null, -1, false, 1280, 720)\n    at com.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:374)\u00a0\n    at com.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:729)\u00a0\n    at com.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:334)\u00a0\n    at com.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:496)\u00a0\n    at com.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:479)\u00a0\n    at com.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:129)\u00a0\n    at com.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:431)\u00a0\n    at com.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:213)\u00a0\n    at android.os.Handler.dispatchMessage(Handler.java:98)\u00a0\n    at android.os.Looper.loop(Looper.java:135)\u00a0\n    at android.os.HandlerThread.run(HandlerThread.java:61)\u00a0\n    at com.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\u00a0\n    Caused by: android.media.MediaCodec$CodecException: Error 0xffffffea\n    at android.media.MediaCodec.native_configure(Native Method)\n    at android.media.MediaCodec.configure(MediaCodec.java:580)\n    at com.google.android.exoplayer.MediaCodecVideoTrackRenderer.configureCodec(MediaCodecVideoTrackRenderer.java:328)\n    at com.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:363)\n    at com.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:729)\u00a0\n    at com.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:334)\u00a0\n    at com.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:496)\u00a0\n    at com.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:479)\u00a0\n    at com.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:129)\u00a0\n    at com.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:431)\u00a0\n    at com.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:213)\u00a0\n    at android.os.Handler.dispatchMessage(Handler.java:98)\u00a0\n    at android.os.Looper.loop(Looper.java:135)\u00a0\n    at android.os.HandlerThread.run(HandlerThread.java:61)\u00a0\n    at com.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\n```\n\nHowever, when I use two separate `SurfaceHolder`'s, it doesn't complain. Has anyone had any similar issues? Or am I possibly doing something wrong?\n\nThanks.\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1248/comments",
    "author": "Viddi",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-02-10T10:34:11Z",
        "body": "ExoPlayer doesn't know anything about `SurfaceHolder`; it only knows about `Surface` directly.\n\nI haven't tried, but it should be possible to have multiple ExoPlayer instances render to the same `Surface`, provided only one of them is doing so at any point in time. When you want to switch player from A to B, you'll need to clear the surface from A using `ExoPlayer.blockingSendMessage` and attach it to B using `ExoPlayer.sendMessage`. Note that the first call needs to be blocking so that you can be sure A really doesn't have access to the surface before you give it to B.\n"
      },
      {
        "user": "Viddi",
        "created_at": "2016-02-10T17:49:48Z",
        "body": "You're right, this was happening because when I switched players, I was using `sendMessage` instead of `blockingSendMessage`, so the surface was still in use when it was trying to make the switch.\n\nThanks!\n"
      }
    ],
    "satisfaction_conditions": [
      "Ensures only one ExoPlayer instance actively uses the shared Surface at any given time",
      "Provides a mechanism to safely transfer Surface ownership between players",
      "Explains synchronization requirements for Surface resource management",
      "Maintains seamless switching between multiple media sources"
    ]
  },
  {
    "number": 1208,
    "title": "Is there a state in EXO player like player is fast forwarding or rewinding?",
    "created_at": "2016-01-28T20:01:02Z",
    "closed_at": "2016-01-29T15:19:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1208",
    "body": "Hello,\n\nI want to know is there a specific state when we FF or Reverse the playback. I know that when we FF or Reverse the play back, it comes into the MediaCodecaudioTrackrenderer's \"SeekTo(position)\" function to adjust he play back. \n\nWhat I am doing is, calling player.SeekTo function to adjust it's position to couple of milliseconds but I am not doing FF, so I just want to differentiate when will it actually FF through which function?\n\nThanks\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1208/comments",
    "author": "joshimaulik",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-01-29T15:19:13Z",
        "body": "ExoPlayer doesn't have an API for fast-forward and rewind and so there isn't a corresponding state either. I'm not sure I understand your comment `when we FF or Reverse the playback`, since as above ExoPlayer doesn't have fast-forward and rewind APIs.\n"
      },
      {
        "user": "joshimaulik",
        "created_at": "2016-01-29T17:06:26Z",
        "body": "What I want to know is, when we fast forward on exo player, it goes multiple times into seekTo() function of mediacodecaudiotrackrenderer class. So is there any way to find out what was the last position of fast forward ? \n"
      },
      {
        "user": "ojw28",
        "created_at": "2016-02-01T17:47:20Z",
        "body": "There is no such thing as fast forward in ExoPlayer. As far as the player is concerned, it's just receiving lots of individual seek calls. You should probably implement your own playback controls that do have a concept of when the user is fast forwarding (i.e. user's finger is still dragging the control), and then use that.\n"
      },
      {
        "user": "joshimaulik",
        "created_at": "2016-02-01T19:42:11Z",
        "body": "okay, thank you!!\n"
      }
    ],
    "satisfaction_conditions": [
      "A method to distinguish between standard seek operations and user-initiated fast-forward/rewind actions",
      "Mechanism to track rapid position changes characteristic of fast-forward behavior",
      "Explanation of how to implement custom playback state tracking for FF/RW detection"
    ]
  },
  {
    "number": 1186,
    "title": "HLS - Handling low buffer and seek with no network connection",
    "created_at": "2016-01-25T22:22:33Z",
    "closed_at": "2016-01-26T00:21:03Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1186",
    "body": "I'm using ExoPlayer for audio only, HLS streams. As such, we can buffer quite a bit of audio which we want to continue playing even if the network drops or the device is put into airplane mode. In general that works fine, but there are a couple of no-network scenarios I'm trying to handle:\n1. Play through buffer \n2. Attempt to seek\n\nMy approach so far has been to register listeners with DefaultLoadControl and HlsSampleSource and to move my player into something similar to a buffering state when a load error is encountered. This solves the specific use cases I mentioned, but it doesn't give me very granular understanding of why loading failed. \n\nI realize that to some extent these are business / presentation layer concerns, but I'm wondering if there are recommended ways to address them in the context of ExoPlayer? For example, are there any ways to pause and resume loading? Is there a way to get a 'low buffer' warning before the loader kicks in? \n\nAny insights are greatly appreciated.\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1186/comments",
    "author": "jedhoffmann",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-01-25T22:56:29Z",
        "body": "I'm a little confused. Are you basically saying that you don't want playback to fail, ever, even if there's no network? Specifically, you'd rather the player enter an indefinite buffering state until network is restored?\n"
      },
      {
        "user": "jedhoffmann",
        "created_at": "2016-01-25T23:15:26Z",
        "body": "That is essentially how I have it coded right now, but it's clearly not ideal. Focusing just on the scenario of playing out the buffer with no network: is there a way you would recommend monitoring the buffers so that we can stop playback if they drop below a critical level and we don't have a network to load more?\n"
      },
      {
        "user": "ojw28",
        "created_at": "2016-01-25T23:26:07Z",
        "body": "You could probably stop the player from failing by passing a large value as minLoadableRetryCount to the HlsChunkSource constructor. You don't need to do anything special to have the player enter a buffering state when the buffer runs out; it'll do this automatically. So I think passing a large minLoadableRetryCount is all you'd need to do to achieve what you want.\n"
      },
      {
        "user": "jedhoffmann",
        "created_at": "2016-01-26T00:20:59Z",
        "body": "Thanks for the suggestion. It looks like that is doing the right thing for me. \n"
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to prevent playback failure during network loss",
      "Buffer monitoring capability",
      "Controlled retry behavior for loading attempts",
      "Integration with ExoPlayer's native buffering state"
    ]
  },
  {
    "number": 1172,
    "title": "DASH video track quality is set to max by default",
    "created_at": "2016-01-21T10:30:03Z",
    "closed_at": "2016-01-21T14:03:21Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1172",
    "body": "hello.\n\nI am developing a player app using the demo app as reference and bumped into this issue. When launching player activity, selected video track is 1080p, not auto. and video tracks are listed in the following order:\n1080p\nauto\n720p\n480p\nWhat can be the cause? Any fix for this?\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1172/comments",
    "author": "j-garin",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-01-21T10:49:21Z",
        "body": "The only thing I can think of that would cause this is if your DASH manifest has the 1080p representation in its own adaptation set at the top, and then a second adaptation set containing 720p/480p. Is that correct, and is there a reason why all three aren't in the same adaptation set?\n"
      },
      {
        "user": "j-garin",
        "created_at": "2016-01-21T11:13:06Z",
        "body": "Indeed there are 2 adaptation sets in the mpd file, because there are 2 codecs. What is the good way to handle this and have 'auto' at track[0]?\n"
      },
      {
        "user": "ojw28",
        "created_at": "2016-01-21T11:16:26Z",
        "body": "What are the two codecs, out of interest? Is the 1080p representation H265, or something like that?\n"
      },
      {
        "user": "j-garin",
        "created_at": "2016-01-21T11:26:10Z",
        "body": "one is H.285 (for 1080p) and the other is H.264\n1080p hevc\n1080p h264\n  720p h264\n  480p h264\n"
      },
      {
        "user": "ojw28",
        "created_at": "2016-01-21T11:31:22Z",
        "body": "It's typically not possible to seamlessly adapt between different codecs. The auto track generated in this case is 720p and 480p only, and so it's pretty ambiguous whether the player should default to the H265 stream or to the two H264 streams (unless you have something in your manifest that indicates this somehow).\n\nI think from the delivery point of view, it would be more normal to have H265 streams in 1080p, 720p and 480p, and then H264 streams in 720p and 480p. You'd then get an auto H265 track that can switch between the three H265 representations and would be enabled by default on devices with H265 decoders, and a separate auto H264 track, which would be the default on devices without an H265 decoder.\n"
      },
      {
        "user": "j-garin",
        "created_at": "2016-01-21T13:04:57Z",
        "body": "that worked. thank you.\nalso i am experiencing difficulties with audio track selection. playback fails to incompatible track selection. is there a way to select audio track that is supported by the device automatically?\n"
      },
      {
        "user": "ojw28",
        "created_at": "2016-01-21T13:50:18Z",
        "body": "ExoPlayer should already select a compatible audio track. What tracks do you have in your manifest, and on what device, and what selection are you seeing?\n"
      },
      {
        "user": "j-garin",
        "created_at": "2016-01-21T14:03:21Z",
        "body": "It was the issue in mpd file. Sorry to have bothered you and thank you for your help.\n"
      },
      {
        "user": "jeprojects",
        "created_at": "2016-01-21T14:11:37Z",
        "body": "@ojw28 This is a great help. One question though, with the multiple resolutions (1080p, 720p, 480p) will mpeg dash (and exoplayer) change between them all seamlessly without buffering? \n\nOr does this only happen when you have multiple bitrates for the same resolution (example: 1080p 10mbit, 5mbit, 4mbit)\n"
      },
      {
        "user": "ojw28",
        "created_at": "2016-01-21T14:16:04Z",
        "body": "Yes, it's possible to switch resolution. On Jellybean and some KitKat devices there might be a slight (~50ms) freeze in the video across the resolution switch, but nothing worse than that. On newer devices it should be completely seamless. There's definitely no buffering involved.\n"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how DASH manifest adaptation set grouping affects default track selection",
      "Guidance on structuring multiple codec representations for automatic device compatibility",
      "Clarification on seamless resolution switching requirements",
      "Automatic selection of device-compatible tracks without playback errors"
    ]
  },
  {
    "number": 1168,
    "title": "Set Aspect Ratio of Frame",
    "created_at": "2016-01-20T06:52:21Z",
    "closed_at": "2016-01-20T11:16:36Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1168",
    "body": "I am having an issue. i am streaming a video from my server where the URL is at passedWorkoutObject.workoutMediaURL. The video plays fine, but I need to scale the frame to the right aspect ratio. onVideoSizeChanged is not called with this code below. How do I get the aspect ratio of the frame so I can scale my frame?\n\n```\n       player = ExoPlayer.Factory.newInstance(2);\n\n\n        Allocator allocator = new DefaultAllocator(BUFFER_SEGMENT_SIZE);\n        DataSource dataSource = new DefaultUriDataSource(this, null, versionName);\n\n        MediaPresentationDescriptionParser parser = new MediaPresentationDescriptionParser();\n        UriDataSource manifestDataSource = new DefaultUriDataSource(this, versionName);\n        ManifestFetcher<MediaPresentationDescription> manifestFetcher = new ManifestFetcher<>(passedWorkoutObject.workoutMediaURL, manifestDataSource, parser);\n        final DefaultBandwidthMeter bandwidthMeter = new DefaultBandwidthMeter();\n\n        ExtractorSampleSource sampleSource = new ExtractorSampleSource(\n        Uri.parse(passedWorkoutObject.workoutMediaURL), dataSource, allocator, BUFFER_SEGMENT_COUNT * BUFFER_SEGMENT_SIZE);\n\n\n        MediaCodecVideoTrackRenderer videoRenderer = new MediaCodecVideoTrackRenderer(\n                this, sampleSource, MediaCodec.VIDEO_SCALING_MODE_SCALE_TO_FIT, 100, null, new MediaCodecVideoTrackRenderer.EventListener() {\n            @Override\n            public void onDroppedFrames(int count, long elapsed) {\n\n            }\n\n            @Override\n            public void onVideoSizeChanged(int width, int height, int unappliedRotationDegrees, float pixelWidthHeightRatio) {\n                videoFrame.setAspectRatio(\n                        height == 0 ? 1 : (width * pixelWidthHeightRatio) / height);\n            }\n\n            @Override\n            public void onDrawnToSurface(Surface surface) {\n\n            }\n\n            @Override\n            public void onDecoderInitializationError(MediaCodecTrackRenderer.DecoderInitializationException e) {\n\n            }\n\n            @Override\n            public void onCryptoError(MediaCodec.CryptoException e) {\n\n            }\n\n            @Override\n            public void onDecoderInitialized(String decoderName, long elapsedRealtimeMs, long initializationDurationMs) {\n\n            }\n        }, 100);\n\n\n        MediaCodecAudioTrackRenderer audioRenderer = new MediaCodecAudioTrackRenderer(sampleSource);\n        player.prepare(videoRenderer, audioRenderer);\n\n        player.sendMessage(videoRenderer, MediaCodecVideoTrackRenderer.MSG_SET_SURFACE, surface);\n\n\n        player.setPlayWhenReady(true);\n        control = new PlayerControl(player);\n```\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1168/comments",
    "author": "sweatapp",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2016-01-20T08:19:52Z",
        "body": "If you want your listener to be invoked then you need to pass a something other than null as the value of `eventHandler` in the `MediaCodecVideoTrackRenderer` constructor.\n"
      },
      {
        "user": "sweatapp",
        "created_at": "2016-01-20T09:30:30Z",
        "body": "worked like a charm, thanks\nThe documentation should really be better on all of this. \n"
      },
      {
        "user": "ojw28",
        "created_at": "2016-01-20T11:16:36Z",
        "body": "Whilst I agree in general that we need more detailed documentation, the Javadoc seems pretty clear in this specific case:\n\n```\neventHandler - A handler to use when delivering events to eventListener. May be null if delivery of events is not required.\neventListener - A listener of events. May be null if delivery of events is not required.\n```\n\nChoosing to pass null implies that you're not interested in having your listener receive events.\n"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to properly configure event handling parameters in MediaCodecVideoTrackRenderer constructor",
      "Clarification on the relationship between eventHandler parameter and listener callback execution",
      "Guidance on proper setup of video dimension change listeners in ExoPlayer",
      "Documentation of critical constructor parameters affecting callback delivery"
    ]
  },
  {
    "number": 1046,
    "title": "Decoder init failed DTS",
    "created_at": "2015-12-11T05:04:02Z",
    "closed_at": "2015-12-16T19:19:50Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1046",
    "body": "Hi,\n\nI am getting the following error:\n\n``` js\ncom.google.android.exoplayer.ExoPlaybackException: com.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException: Decoder init failed: [-49999], MediaFormat(1, audio/vnd.dts, -1, 16, -1, -1, -1, -1.0, 2, 48000, und, 0, false, -1, -1)\n```\n\nAm I correct in thinking that this is trying to access the hardware decoder on the device but failing (Nexus 6p) because hardware decode support doesn't exist?\n\nIf so, does exoplayer include software decoding support? Or do we need to fall back to our own?\n\nThanks for your help.\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1046/comments",
    "author": "jeprojects",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2015-12-11T12:27:27Z",
        "body": "Yes. That log line would be output when trying to create a decoder for audio/vnd.dts on a device with no decoder that supports it. Like most phones, Nexus 6P does not have a built-in DTS decoder. If possible, it is best to switch to a more widely supported format like AAC.\n\nNote that cf27b83 added a check that there is a decoder for the source MIME type, before the track is enabled. So, on an up to date version of ExoPlayer, you shouldn't see this error if the source MIME type is accurate, and the stream should play with no audio (unless other playable audio formats are present). Is this a DASH stream with an incorrect codecs attribute?\n"
      },
      {
        "user": "jeprojects",
        "created_at": "2015-12-11T15:53:37Z",
        "body": "Thanks @andrewlewis for your help.\n\nThis is the part in the mpd file\n\n``` js\n  <Representation id=\"5\" mimeType=\"audio/mp4\" codecs=\"mp4a.a9\" audioSamplingRate=\"48000\" startWithSAP=\"1\" bandwidth=\"1512297\">\n    <AudioChannelConfiguration schemeIdUri=\"urn:mpeg:dash:23003:3:audio_channel_configuration:2011\" value=\"2\"/>\n    <BaseURL>audio0_dashinit.mp4</BaseURL>\n    <SegmentBase indexRangeExact=\"true\" indexRange=\"893-1296\">\n      <Initialization range=\"0-892\"/>\n    </SegmentBase>\n   </Representation>\n```\n\nThis was automatically generated using mp4box.\n"
      },
      {
        "user": "andrewlewis",
        "created_at": "2015-12-11T16:09:36Z",
        "body": "You could try changing codecs=\"mp4a.a9\" to codecs=\"dtsc\" to make the codecs attribute consistent with the actual media format. That should hopefully give video-only playback, as no decoders will be found for the audio stream.\n"
      },
      {
        "user": "jeprojects",
        "created_at": "2015-12-13T07:44:09Z",
        "body": "Thanks again.\n\nThat did the trick.\n\nI am curious though, the one it selected was AAC, when there is AC3 available next in line.\n\n``` js\n  <AdaptationSet segmentAlignment=\"true\" group=\"2\" lang=\"und\" subsegmentAlignment=\"true\" subsegmentStartsWithSAP=\"1\">\n   <Representation id=\"6\" mimeType=\"audio/mp4\" codecs=\"ac-3\" audioSamplingRate=\"48000\" startWithSAP=\"1\" bandwidth=\"449268\">\n    <AudioChannelConfiguration schemeIdUri=\"urn:mpeg:dash:23003:3:audio_channel_configuration:2011\" value=\"2\"/>\n    <BaseURL>audio1_dashinit.mp4</BaseURL>\n    <SegmentBase indexRangeExact=\"true\" indexRange=\"869-1260\">\n      <Initialization range=\"0-868\"/>\n    </SegmentBase>\n   </Representation>\n  </AdaptationSet>\n  <AdaptationSet segmentAlignment=\"true\" group=\"2\" lang=\"und\" subsegmentAlignment=\"true\" subsegmentStartsWithSAP=\"1\">\n   <Representation id=\"7\" mimeType=\"audio/mp4\" codecs=\"mp4a.40.2\" audioSamplingRate=\"48000\" startWithSAP=\"1\" bandwidth=\"309860\">\n    <AudioChannelConfiguration schemeIdUri=\"urn:mpeg:dash:23003:3:audio_channel_configuration:2011\" value=\"2\"/>\n    <BaseURL>audio2_dashinit.mp4</BaseURL>\n    <SegmentBase indexRangeExact=\"true\" indexRange=\"900-1303\">\n      <Initialization range=\"0-899\"/>\n    </SegmentBase>\n   </Representation>\n  </AdaptationSet>\n```\n\nIs there something wrong with my configuration? Why would it skip ac3?\n"
      },
      {
        "user": "andrewlewis",
        "created_at": "2015-12-13T09:12:18Z",
        "body": "It could skip AC-3 for the same reason it skips DTS: MediaCodecAudioTrackRenderer only handles the track if the device has a decoder for the track's format, or if there is an HDMI connection that advertises support for playing the format via encoded audio passthrough (on Android L and above).\n"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why ExoPlayer skips certain audio formats like AC-3 despite their presence in the manifest",
      "Clarification of ExoPlayer's codec support requirements (hardware vs software decoding)",
      "Guidance on proper manifest configuration for codec compatibility",
      "Understanding of ExoPlayer's decoder availability checks and error prevention mechanisms",
      "Explanation of audio track selection criteria including passthrough support"
    ]
  },
  {
    "number": 1009,
    "title": "Howto read from codec output buffers",
    "created_at": "2015-11-30T19:56:27Z",
    "closed_at": "2015-12-03T18:43:10Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/1009",
    "body": "I am attempting to play the HLS sample filie BipPop.  I have added code to MediaCodecVideoTrackRenderer. \n\nThe following code can be called in processOutputBuffer or in renderOutputBufferV21 but gets the same buffer freed error regardless (and the video successfully plays despite the buffer supposedly being freed).\n\n```\nprivate Boolean customHack(MediaCodec codec, int bufferIndex) {\nByteBuffer buffer = codec.getOutputBuffer(bufferIndex);\nbyte[] data =  new byte[buffer.remaining()];\n    try {\n      buffer.get(data);\n    }catch(Exception e){\n      Log.e(\"Custom\", \"Error trying to get the buffer\",e);\n      return false;\n    }\n}\n```\n\nMy objective is post-decode modification of the buffer.  I can do this using the regular Android player with non HLS content, but in ExoPlayer, I get the BufferFreed problem.\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/1009/comments",
    "author": "jadedResearcher",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2015-12-03T17:06:41Z",
        "body": "There are quite strict rules about calls to `getOutputBuffer`. Specifically, in the `MediaCodec` Javadoc, it says: \n\n_After calling this method, any ByteBuffer or Image object previously returned for the same output index MUST no longer be used._.\n\nIt's likely that your call to `getOutputBuffer` is causing an output buffer that ExoPlayer code already has a reference to to become invalid.\n\nIf you're modifying `processOutputBuffer` then you should read from the `buffer` argument that gets passed to it, rather than making any calls to `getOutputBuffer` yourself. Note also that you shouldn't rely on the position and limit of the buffer being set correctly. Use the `bufferInfo` argument to find out the offset and size of the data in the buffer. You can set the buffer position and limit using this information yourself, like:\n\n```\nbuffer.position(bufferInfo.offset);\nbuffer.limit(bufferInfo.offset + bufferInfo.size);\n```\n"
      },
      {
        "user": "jadedResearcher",
        "created_at": "2015-12-03T18:36:19Z",
        "body": "Thank you for response. I changed my code to use the buffer that is passed into the processOutputBuffer method directly, and it works unless I need to get the width and the height, which I use the bufferIndex to do as well.\n\nint h = codec.getOutputImage(bufferIndex).getHeight();\n\nIs there an alternate way to get the width and the height without running into this error?\n"
      },
      {
        "user": "ojw28",
        "created_at": "2015-12-03T18:39:35Z",
        "body": "MediaCodecVideoTrackRenderer already has `currentWidth` and `currentHeight` variables.\n"
      },
      {
        "user": "jadedResearcher",
        "created_at": "2015-12-03T18:42:27Z",
        "body": "I do in fact see that now, thank you so much, you have answered my question in full.\n"
      },
      {
        "user": "ojw28",
        "created_at": "2015-12-03T18:43:10Z",
        "body": "No worries; Glad you got it working!\n"
      },
      {
        "user": "nikhilkilivayil",
        "created_at": "2017-06-28T09:12:08Z",
        "body": "Can you post sample full source code? @ojw28 "
      }
    ],
    "satisfaction_conditions": [
      "Solution must allow accessing output buffer data without invalidating ExoPlayer's internal buffer references",
      "Must provide a method to obtain video dimensions without using buffer index-based MediaCodec calls",
      "Solution must enable post-decode buffer modification in ExoPlayer's HLS pipeline"
    ]
  },
  {
    "number": 967,
    "title": "Switching between encrypted streams",
    "created_at": "2015-11-18T12:49:19Z",
    "closed_at": "2015-11-26T12:15:28Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/967",
    "body": "Hello,\nI have encountered a problem while switching between encrypted HLS streams after upgrading to ExoPlayer 1.5.2 from 1.4.1, I am switching between streams as advised in question #931\nSwitching between non-encrypted streams is fine, also between encrypted and non-encrypted. But when switching between encrypted streams i get this exception\n\n``` java\n11-18 13:32:27.926 13748-13847/? E/LoadTask: Unexpected exception loading stream\n11-18 13:32:27.926 13748-13847/? E/LoadTask: java.lang.IllegalArgumentException\n11-18 13:32:27.926 13748-13847/? E/LoadTask:     at com.google.android.exoplayer.util.Assertions.checkArgument(Assertions.java:39)\n11-18 13:32:27.926 13748-13847/? E/LoadTask:     at com.google.android.exoplayer.util.ParsableByteArray.setPosition(ParsableByteArray.java:133)\n11-18 13:32:27.926 13748-13847/? E/LoadTask:     at com.google.android.exoplayer.util.ParsableByteArray.skipBytes(ParsableByteArray.java:145)\n11-18 13:32:27.926 13748-13847/? E/LoadTask:     at com.google.android.exoplayer.extractor.ts.TsExtractor.read(TsExtractor.java:141)\n11-18 13:32:27.926 13748-13847/? E/LoadTask:     at com.google.android.exoplayer.hls.HlsExtractorWrapper.read(HlsExtractorWrapper.java:240)\n11-18 13:32:27.926 13748-13847/? E/LoadTask:     at com.google.android.exoplayer.hls.TsChunk.load(TsChunk.java:108)\n11-18 13:32:27.926 13748-13847/? E/LoadTask:     at com.google.android.exoplayer.upstream.Loader$LoadTask.run(Loader.java:209)\n11-18 13:32:27.926 13748-13847/? E/LoadTask:     at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:390)\n11-18 13:32:27.926 13748-13847/? E/LoadTask:     at java.util.concurrent.FutureTask.run(FutureTask.java:234)\n11-18 13:32:27.926 13748-13847/? E/LoadTask:     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1080)\n11-18 13:32:27.926 13748-13847/? E/LoadTask:     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:573)\n11-18 13:32:27.926 13748-13847/? E/LoadTask:     at java.lang.Thread.run(Thread.java:841)\n```\n\nI have tried to track down the issue and found out that TS Extractor is trying to skip adaptation field longer than the size of tsPacket Buffer:\n\n``` java\n11-18 13:32:27.625 13748-13773/? E/null\u00a0check: position: 5, bytes: 7, limit: 188\n11-18 13:32:27.625 13748-13773/? E/null\u00a0check: position: 6, bytes: 1, limit: 9\n11-18 13:32:27.625 13748-13773/? E/null\u00a0check: position: 9, bytes: 0, limit: 9\n11-18 13:32:27.625 13748-13748/? E/Status: preparing\n11-18 13:32:27.896 13748-13847/? E/null\u00a0check: position: 5, bytes: 10, limit: 188\n11-18 13:32:27.926 13748-13847/? E/null\u00a0check: position: 5, bytes: 185, limit: 188\n```\n\nwhere preparing is status of player after switching and bytes is the number if bytes extractor is trying to skip. This never happened while i was using version 1.4.1. Encryption is standard AES so it should be replicable with any encrypted HLS streams.\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/967/comments",
    "author": "SnowcatSVK",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2015-11-18T17:21:43Z",
        "body": "You're probably not fully rebuilding the renderers when you switch. You shouldn't re-use any objects that you used to build one set of renderers when building the next set, particularly things like DataSource instances. Is it possible that you are re-using them? If so, try not doing so.\n"
      },
      {
        "user": "SnowcatSVK",
        "created_at": "2015-11-19T08:05:25Z",
        "body": "Well, i am using DemoPlayer and HLSRendererBuilder from demo directory in project, these are the methods i am using for switching:\n\n``` java\nprivate HlsRendererBuilder createRenderer() {\n        String userAgent = Util.getUserAgent(this, \"ExoplayerTest\");\n        return new HlsRendererBuilder(this, userAgent, contentUri.toString());\n    }\n\n    private void preparePlayer() {\n        if (player == null) {\n            player = new DemoPlayer(createRenderer());\n            player.addListener(this);\n            player.setCaptionListener(this);\n            player.setMetadataListener(this);\n            playerNeedsPrepare = true;\n\n        }\n        if (playerNeedsPrepare) {\n            player.prepare();\n            playerNeedsPrepare = false;\n        }\n        player.setSurface(surfaceView.getHolder().getSurface());\n        player.setPlayWhenReady(true);\n    }\n\n    private void releasePlayer() {\n        if (player != null) {\n            //playerPosition = player.getCurrentPosition();\n            player.release();\n            player = null;\n\n        }\n    }\n```\n\nand this is the way i am using those methods: \n\n``` javascript\n    releasePlayer();\n    preparePlayer();\n```\n\nonly thing i am reusing is surfaceView, unless there is something in DemoPlayer and HLSRendererBuilder that i have missed, but that shouldn't be the case since it never happened with nonencrypted streams\n"
      },
      {
        "user": "ojw28",
        "created_at": "2015-11-19T16:53:35Z",
        "body": "If that's the case then the two playbacks should be completely independent to one another. It's pretty much equivalent to backing out of playback in the demo activity and selecting another sample. In which case I don't understand how one playback could affect the next (at a theoretical level)?\n\nCan you modify the demo app in some way to reproduce the issue? And if so, can you upload it to GitHub so that we can reproduce ourselves?\n"
      },
      {
        "user": "SnowcatSVK",
        "created_at": "2015-11-20T10:25:01Z",
        "body": "I have my whole project in private repository on GitHub, i can privately send you link to that repository so you can test it yourself\n"
      },
      {
        "user": "ojw28",
        "created_at": "2015-11-26T12:15:28Z",
        "body": "The issue is related to the way that you've made `HlsChunkSource.encryptionKeyUri`static in your branch. The breaks the assumption that the second playback is independent of the first, because state is being left lying around from the first playback in the static variable. If I null it out where the player is released, then the second playback works fine.\n\nSo the conclude - It looks like an issue with your local modifications. As a general style point, it's worth exploring solutions that don't require statics except in the specific case of singletons (which definitely isn't the case for this particular variable). I also noticed some interesting code in User.java where initSingletons re-initializes singletons potentially multiple times, which looks wrong to me.\n"
      },
      {
        "user": "SnowcatSVK",
        "created_at": "2015-11-27T08:44:44Z",
        "body": "Thank you very much for help, I must have left it there from the time when I was trying different solutions and forgot about it, shame I couldn't find it myself, as for User.java, this is a recycled class from an older project written by different developer, I have recycled it as it was working well with our API and I needed to get going fast with testing, this project was just for testing purposes, so I am completely rewriting it since all of the issues are resolved now.\n"
      }
    ],
    "satisfaction_conditions": [
      "Ensure encryption state is fully reset between encrypted stream switches",
      "Guarantee complete independence between playback sessions",
      "Avoid static variables for non-singleton components",
      "Maintain proper resource lifecycle management"
    ]
  },
  {
    "number": 930,
    "title": "Explayer and wakelock",
    "created_at": "2015-11-05T17:29:38Z",
    "closed_at": "2015-11-08T21:03:29Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/930",
    "body": "hi, \nI hava a question I use exoplayer for online audio streaming and i see by testing and this without aquiring wakelock and wifilock that the player   keeps playing for more than 20 min without touching the phone . does this mean that i dont need wakelock and wifilock when i use exoplayer\n\nps: tested on LG G2 (4.4.2) \n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/930/comments",
    "author": "diabloo",
    "comments": [
      {
        "user": "andrewlewis",
        "created_at": "2015-11-08T19:20:13Z",
        "body": "ExoPlayer does not acquire a WakeLock or WifiLock directly, but MediaCodecAudioTrackRenderer uses an AudioTrack which should keep the device awake while audio is playing (and for a few seconds after audio playback stops). If audio playback was continuous that might explain why the device stayed awake with the screen off.\n\nHowever, the device can sleep if audio playback is interrupted and it is not being kept awake by a WakeLock. This could happen if the player runs out of data and needs to rebuffer from the network, for example. So streaming apps that play audio when the screen is off should acquire a WakeLock and WifiLock during playback. It is important to release the locks if/when playback is finished so that the device can sleep.\n"
      },
      {
        "user": "diabloo",
        "created_at": "2015-11-08T21:03:09Z",
        "body": "Thank your for this clear answer \n"
      }
    ],
    "satisfaction_conditions": [
      "Clarifies when ExoPlayer requires explicit wakelock/wifilock management for uninterrupted playback",
      "Explains the relationship between audio playback continuity and system resource management",
      "Provides guidance for handling edge cases like network interruptions during screen-off playback"
    ]
  },
  {
    "number": 702,
    "title": "How to pause and resume player correctly",
    "created_at": "2015-08-10T07:35:11Z",
    "closed_at": "2015-08-11T09:11:31Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/702",
    "body": "I use demoplayer in my project but i am confused that how to pause and resume player correctly.In the Exoplayer Demo i found two way to pause/resume:\n\n> 1. player.setPlayWhenReady(playwhenready);\n> 2. player.selectTrack(DemoPlayer.TYPE_VIDEO, -1);\n>       player.selectTrack(DemoPlayer.TYPE_AUDIO, -1);\n>    1. use mediacontroller\n\nBut unfortunately,i found some issue:\n## The way setPlayWhenReady:\n1. when onPause i setPlayWhenReady(false),and  setPlayWhenReady(true) when onResume.It takes a long time until video comes out(?sorr for my poor english,hope you can understand me) and the surfaceview is black but the audio is fine.\n## The way selectTrack:\n\nwhen i want the video stop ,i selectTrack(DemoPlayer.TYPE_VIDEO, -1),it appearances stopped  but not actually . \n\nDid i do somthing wrong or miss something important?\n\nWaiting for your help,thank you in advance!\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/702/comments",
    "author": "AlanCheen",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2015-08-10T20:28:58Z",
        "body": "Is this for when your activity is paused because it's gone into the background? You should be fully releasing the player in that case, recording the position the playback got to, and then instantiating a fresh player and restoring the position when the activity comes back later.\n\nThe alternative requires holding onto a bunch of stuff, including a lot of memory, which isn't being a good citizen when your application isn't in the foreground.\n"
      },
      {
        "user": "AlanCheen",
        "created_at": "2015-08-11T03:34:54Z",
        "body": "Thanks for your reply.\nI use exoplayer in my fragment.\nI had tried what you say , but it takes about 10 seconds even worse when bad network. \nI think it is not a good citizen too because user can't see anything except a black frame.\n\nHere are some codes in my application:\n\n``` java\n\n@Override\n    public void onResume() {\n        super.onResume();\n        if (!bInPauseManually) {\n            resumeVideoAndAudio();\n        }\n        // The player will be prepared on receiving audio capabilities.\n        audioCapabilitiesReceiver.register();\n    }\n\nprivate void resumeVideoAndAudio() {\n        bClosableWhenPause = true;\n        if (player != null) {\n//            player.setPlayWhenReady(true);\n            player.seekTo(playerPosition);\n            player.selectTrack(DemoPlayer.TYPE_VIDEO, 0);\n            player.selectTrack(DemoPlayer.TYPE_AUDIO, 0);\n        }\n    }\n```\n\n``` java\n\n@Override\n    public void onPause() {\n        super.onPause();\n        pauseVideoAndAudio(false);\n        audioCapabilitiesReceiver.unregister();\n    }\n\nprivate void pauseVideoAndAudio(boolean closableWhenPause) {\n        bClosableWhenPause = closableWhenPause;\n        if (player != null) {\n//            player.setPlayWhenReady(false);\n            player.selectTrack(DemoPlayer.TYPE_VIDEO, -1);\n            player.selectTrack(DemoPlayer.TYPE_AUDIO, -1);\n            playerPosition = player.getCurrentPosition();\n        }\n    }\n```\n\nI have no idea how to do it better , would give me some advices?\nThank you in advance!\n"
      },
      {
        "user": "ojw28",
        "created_at": "2015-08-11T09:11:31Z",
        "body": "Being a good citizen means not consuming resources when your application isn't in the foreground. It doesn't mean optimizing your own app's experience at the cost of overall platform health. So it is the right thing to do to be releasing the player. As a point of reference, the YouTube application appears to do this correctly.\n"
      },
      {
        "user": "AlanCheen",
        "created_at": "2015-08-12T05:20:06Z",
        "body": "Thank you for your reply!\nNow i konw how to deal with it~\nEveryone like YouTube ,lol~~~\nThanks!\n"
      }
    ],
    "satisfaction_conditions": [
      "Proper resource management during app backgrounding",
      "Guaranteed playback stoppage when paused"
    ]
  },
  {
    "number": 467,
    "title": "Unable to connect to local mp4 file by ExtractorSampleSource",
    "created_at": "2015-05-18T21:34:34Z",
    "closed_at": "2015-05-19T13:34:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/467",
    "body": "Hello!\n\nI am updating the ExoPlayer to 1.3.1 and I am experiencing the issue with  the playback of the local MP4 files:\ncom.google.android.exoplayer.ExoPlaybackException: com.google.android.exoplayer.upstream.HttpDataSource$HttpDataSourceException: Unable to connect to /storage/emulated/0/Android/data/com.getvictorious.staging.eatyourkimchi/files/DCIM/Video/Video-20150518_142803.mp4\n\nI am passing the uri to the ExtractorSampleSource: \nExtractorSampleSource sampleSource = new ExtractorSampleSource(uri, dataSource, extractor, 2,\n                BUFFER_SIZE);\n\nPlease advise what could cause this exception.\n\nThank you in advance!\nEdward\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/467/comments",
    "author": "edwardfoux",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2015-05-19T13:34:30Z",
        "body": "What are you passing as the dataSource when you make your ExtractorSampleSource? You're either not passing the right thing, or you're not formatting your local URI correctly. Covering both points:\n- Use DefaultUriDataSource, which will work for both local and network URIs\n- Your URI should be formatted to start with file:///\n\n\n---\n\nNote: DefaultUriDataSource no longer requires file:// (on the dev branch). If you omit a scheme completely, we'll assume file://.\n"
      },
      {
        "user": "edwardfoux",
        "created_at": "2015-05-19T17:22:58Z",
        "body": "Thank you very much!\n"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of proper URI formatting requirements for local files in ExoPlayer",
      "Identification of correct DataSource implementation for local file access",
      "Clarification of ExoPlayer's URI scheme expectations for different resource types",
      "Guidance on handling both local and network resources in ExoPlayer configuration"
    ]
  },
  {
    "number": 257,
    "title": "[Discussion] Potential race between HlsSampleSource and TsChunk?",
    "created_at": "2015-01-22T05:49:40Z",
    "closed_at": "2015-01-23T03:22:27Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/google/ExoPlayer/issues/257",
    "body": "This is not an issue, just some discussion about potential TsExtractor's race between HlsSampleSource and TsChunk.\n\nWhen I read the code related to how HlsSampleSource read the chunk data, it's noticed that reading-data from DataSource and getting-sample from Extractor are in two threads:\n- Reading data is in `TsChunk.load()`, which runs in a backgroud thread:\n\n``` java\n      while (bytesRead != -1 && !loadCanceled) {\n        bytesRead = extractor.read(dataSource);\n        if (bytesRead != -1) {\n          loadPosition += bytesRead;\n        }\n      }\n```\n- Getting sample is in `HlsSampleSource.readData()`, which runs in ExoPlayer's event loop. And other functions access the extractor, e.g. \n\n``` java\n    extractor.getSample(track, sampleHolder)\n    extractor.discardUntil(i, timeUs);\n```\n\nI don't see any protection of the two threads accessing extractor;\nAlthough there is `ConcurrentLinkedQueue` to protect the `SampleQueue.internalQueue` in TsExtractor, other members are not protected.\n\nThe question is, can we make sure there is no race accessing TsExtractor?\n",
    "comments_url": "https://api.github.com/repos/google/ExoPlayer/issues/257/comments",
    "author": "mine260309",
    "comments": [
      {
        "user": "ojw28",
        "created_at": "2015-01-23T02:49:57Z",
        "body": "Can you be specific about which members you're concerned about? The members that are accessed from both threads are marked as volatile, SamplePool is protected with synchronization, and as you say the sample queues use ConcurrentLinkedQueue. I can't see anything not covered by these measures.\n\nThanks!\n"
      },
      {
        "user": "mine260309",
        "created_at": "2015-01-23T03:22:25Z",
        "body": "Thanks for your comment!\nIt did not notice SamplePool is protected with synchronization.\n\nThe reason I asked the question is because I was planning to add a member in SampleQueue and realized that it should be protected by mutex or synchronization.\nNow it's clear and I'll close the question.\n"
      }
    ],
    "satisfaction_conditions": [
      "Identify all shared members/variables in TsExtractor accessed by both threads",
      "Explain synchronization mechanisms protecting non-queue components of TsExtractor",
      "Clarify thread safety guarantees for TsExtractor's internal state"
    ]
  }
]