[
  {
    "number": 3806,
    "title": "[Question]: Analyzer on es",
    "created_at": "2024-12-02T09:55:04Z",
    "closed_at": "2024-12-05T09:13:52Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/3806",
    "body": "### Describe your problem\n\nI would like to know why es uses whitespace analyzer when analysing documents, instead of analyzer such as ik, which can parse Chinese.",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/3806/comments",
    "author": "guijuzhejiang",
    "comments": [
      {
        "user": "KevinHuSh",
        "created_at": "2024-12-03T01:15:46Z",
        "body": "We tokenize Chinese outside of ES. And also, we can assign term weight to terms while querying."
      },
      {
        "user": "guijuzhejiang",
        "created_at": "2024-12-03T01:28:54Z",
        "body": "@KevinHuSh Yes, I see in term_weight.py what are doing with split words outside of es and attaching weights to them. Not saying this is bad, just wondering why don't just use the existing Chinese analyzer in es, after all, it's simpler. Is it because split words outside es can arbitrarily modify the split word dictionary (huqie.txt)"
      },
      {
        "user": "KevinHuSh",
        "created_at": "2024-12-04T03:07:30Z",
        "body": "The tokenization procedure of indexing and querying with term weight should be consistant.\r\nSo, both outside or both inside.\r\nOtherwise, what you mention about huqie is another reason that we can manipulate tokenizer freely."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why external tokenization is preferred over Elasticsearch's built-in Chinese analyzer",
      "Clarification about maintaining consistency between indexing and query processing",
      "Description of advantages in custom dictionary/tokenizer control",
      "Comparison of flexibility vs simplicity tradeoffs"
    ]
  },
  {
    "number": 3387,
    "title": "[Question]: how elastic search got used? and in the rag folder, how naive.py, qa.py different ? ",
    "created_at": "2024-11-13T09:28:03Z",
    "closed_at": "2024-11-14T03:54:01Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/3387",
    "body": "### Describe your problem\n\nas title\r\n1:how elastic search got used?\r\n2:how naive.py, qa.py different ?\r\n",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/3387/comments",
    "author": "bzr1",
    "comments": [
      {
        "user": "KevinHuSh",
        "created_at": "2024-11-14T03:50:05Z",
        "body": "Elasticsearch is used for full text search.\r\n`naive.py` and `qa.py` are two different chunk methods.\r\n - `naive.py` basicly apply token number as a chunking condition.\r\n - `qa.py`  is for Q&A fromated raw data, and only Q indexed.\r\n"
      },
      {
        "user": "bzr1",
        "created_at": "2024-11-14T03:51:58Z",
        "body": "> Elasticsearch is used for full text search. `naive.py` and `qa.py` are two different chunk methods.\r\n> \r\n> * `naive.py` basicly apply token number as a chunking condition.\r\n> * `qa.py`  is for Q&A fromated raw data, and only Q indexed.\r\n\r\nthank you so much"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of Elasticsearch's role/purpose in the project context",
      "Clear differentiation between chunking strategies/methodologies",
      "Description of data type specialization for each method",
      "Explanation of indexing scope differences"
    ]
  },
  {
    "number": 3148,
    "title": "[Question]: How to obtain detailed backend logs\uff1f",
    "created_at": "2024-11-01T07:52:23Z",
    "closed_at": "2024-11-04T02:27:23Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/3148",
    "body": "### Describe your problem\n\n# I have started ragflow from the source code\r\n- `docker logs -f ragflow-server` cannot meet the logging requirements. I need to obtain logs of front-end operations on the webpage, including logs from conversations and more details on file parsing. I hope to distinguish between the details of the conversation and the file. I use `Olama` as an API service provider\r\n- I used xinference as rerank provider. I saw the effect of rerank in the `test retrieval` of the knowledge base. Does this part also have background logs?\r\n- I hope that in the question, there is a more detailed check method for the situation that the documents cannot be retrieved, such as viewing the slice of the hits\r\n- Is there a more detailed document for viewing logs?",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/3148/comments",
    "author": "SiDaiJie",
    "comments": [
      {
        "user": "yuzhichang",
        "created_at": "2024-11-02T03:43:55Z",
        "body": "There are multiple log files under `docker/ragflow-logs`, each for a dedicated internal package.\r\nWe'll merge all into one log file in future, maybe v0.15.\r\n"
      },
      {
        "user": "KevinHuSh",
        "created_at": "2024-11-04T01:32:04Z",
        "body": "All the logs are in ragflow/logs."
      }
    ],
    "satisfaction_conditions": [
      "Clear identification of log locations for different components (frontend operations, conversations, file parsing)",
      "Method to differentiate between conversation logs and file processing logs"
    ]
  },
  {
    "number": 2612,
    "title": "[Question]:  When I chat with Agent, error: LookupError('Model(deepseek-chat) not authorized')",
    "created_at": "2024-09-26T12:29:40Z",
    "closed_at": "2024-09-26T13:32:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/2612",
    "body": "### Describe your problem\n\nfactory: 'Tongyi-Qianwen' \u8bbe\u7f6e\u901a\u4e49\u5343\u95ee\uff0c\u4f46\u662fagent\u95ee\u7b54\u7684\u65f6\u5019\u62a5\u9519\u8bf4LookupError('Model(deepseek-chat) not authorized')",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/2612/comments",
    "author": "LillyChen",
    "comments": [
      {
        "user": "JinHai-CN",
        "created_at": "2024-09-26T13:06:24Z",
        "body": "From the error message, it seems 'deepseek-chat' is used in your agent. You may change the LLM of your agent to 'Qianwen'.\r\n"
      },
      {
        "user": "LillyChen",
        "created_at": "2024-09-26T13:14:32Z",
        "body": "I found the problem. Thank you!"
      }
    ],
    "satisfaction_conditions": [
      "Ensure the agent's configured LLM matches the authorized model specified in the factory settings",
      "Identify why the agent references an unexpected model name"
    ]
  },
  {
    "number": 2304,
    "title": "[Question]: How to make the Python file in the API effective after modifying it. thank you",
    "created_at": "2024-09-09T00:41:21Z",
    "closed_at": "2024-09-10T04:31:37Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/2304",
    "body": "### Describe your problem\n\nHow to make the Python file in the API effective after modifying it. thank you",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/2304/comments",
    "author": "szfly888",
    "comments": [
      {
        "user": "KevinHuSh",
        "created_at": "2024-09-09T01:55:54Z",
        "body": "Modify it in docker container and kill the ragflow_server.py which will restart itself later.\r\nOne way or another, you need to restart ragflow server."
      }
    ],
    "satisfaction_conditions": [
      "Ensures the modified Python file is reloaded/restarted in the server environment",
      "Works within the context of the existing deployment architecture (likely Docker-based)",
      "Does not require full system/container restarts as a primary method"
    ]
  },
  {
    "number": 2027,
    "title": "[Question]: the max token of  raptor",
    "created_at": "2024-08-21T01:42:36Z",
    "closed_at": "2024-08-22T02:07:24Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/2027",
    "body": "### Describe your problem\n\nwhat is the relation of the max token of raptor and the token of chunk? if the max token of raptor should be multiple of the token of chunk?",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/2027/comments",
    "author": "HaoGuo98",
    "comments": [
      {
        "user": "HaoGuo98",
        "created_at": "2024-08-21T02:11:28Z",
        "body": "and what's suitable chunk size? 1024?\r\n"
      },
      {
        "user": "KevinHuSh",
        "created_at": "2024-08-22T02:05:28Z",
        "body": "Max token of RAPTOR means the summary of a cluster should be in that maxium length.\r\n1024 of chunk size is a reasonable choice."
      }
    ],
    "satisfaction_conditions": [
      "Clarify the relationship between RAPTOR's max token parameter and chunk token size",
      "Explain the functional purpose of RAPTOR's max token parameter"
    ]
  },
  {
    "number": 1563,
    "title": "[Question]: Why is the token count fixed at 128 when using the Ollama embedding model, instead of being based on the text content?",
    "created_at": "2024-07-17T05:53:35Z",
    "closed_at": "2024-07-18T03:54:09Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/1563",
    "body": "### Describe your problem\n\nWhy is the token count fixed at 128 when using the Ollama embedding model, instead of being based on the text content?",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/1563/comments",
    "author": "hwzhuhao",
    "comments": [
      {
        "user": "KevinHuSh",
        "created_at": "2024-07-18T03:46:11Z",
        "body": "It's just a mockup data since ollama doesn't return the count."
      },
      {
        "user": "hwzhuhao",
        "created_at": "2024-07-18T03:54:07Z",
        "body": "thanks\uff0ci try it and get the same result."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why token count appears fixed rather than dynamic",
      "Clarification about Ollama's API limitations regarding token metadata",
      "Confirmation that this is expected behavior rather than an error"
    ]
  },
  {
    "number": 1189,
    "title": "dependency conflict[Question]: ",
    "created_at": "2024-06-17T09:37:59Z",
    "closed_at": "2024-09-28T10:01:54Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/1189",
    "body": "### Describe your problem\n\nWhen I run the `pip install -r requirements.txt` command I get an error\uff1a\r\n```bash\r\nERROR: Cannot install -r requirements.txt (line 139), -r requirements.txt (line 77) and pytz==2024.1 because these package versions have conflicting dependencies.\r\n\r\nThe conflict is caused by:\r\n    The user requested pytz==2024.1\r\n    pandas 2.2.1 depends on pytz>=2020.1\r\n    volcengine 1.0.141 depends on pytz==2020.5\r\n\r\nTo fix this you could try to:\r\n1. loosen the range of package versions you've specified\r\n2. remove package versions to allow pip attempt to solve the dependency conflict\r\n``` ",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/1189/comments",
    "author": "Old-Lane",
    "comments": [
      {
        "user": "aopstudio",
        "created_at": "2024-06-17T10:05:17Z",
        "body": "You can delete `pytz==2024.1` in requirements.txt. It will be automatically installed by other dependencies."
      },
      {
        "user": "KevinHuSh",
        "created_at": "2024-06-18T01:06:24Z",
        "body": "We have refined the requirements.txt. What about the latest one?"
      },
      {
        "user": "Old-Lane",
        "created_at": "2024-06-18T01:55:21Z",
        "body": "> You can delete `pytz==2024.1` in requirements.txt. It will be automatically installed by other dependencies.\r\n\r\nThanks, no errors have been reported since then\n\n---\n\n> We have refined the requirements.txt. What about the latest one?\r\n\r\nThis doesn't work, it's still the same error."
      },
      {
        "user": "KevinHuSh",
        "created_at": "2024-06-19T00:51:17Z",
        "body": "pytz==2024.1 deleted."
      },
      {
        "user": "TeslaZY",
        "created_at": "2024-06-24T04:21:31Z",
        "body": "\u6700\u65b0\u7684main\u5206\u652f\uff0c\u5b89\u88c5\u4f9d\u8d56\u62a5\u9519\u3002\r\nINFO: pip is looking at multiple versions of volcengine to determine which version is compatible with other requirements. This could take a while.\r\nERROR: Cannot install -r requirements.txt (line 138), -r requirements.txt (line 52) and pycryptodome==3.20.0 because these package versions have conflicting dependencies.\r\n\r\nThe conflict is caused by:\r\n    The user requested pycryptodome==3.20.0\r\n    minio 7.2.4 depends on pycryptodome\r\n    volcengine 1.0.141 depends on pycryptodome==3.9.9\r\n\u9700\u8981\u4fee\u6539volcengine\u7684\u4f9d\u8d56\u7248\u672c\u8fd8\u662f\u4fee\u6539pycryptodome\u7684\u7248\u672c\u3002\r\n\r\n\r\n\r\n\r\n> We have refined the requirements.txt. What about the latest one?\r\n\r\n"
      },
      {
        "user": "yuzhichang",
        "created_at": "2024-09-28T10:01:54Z",
        "body": "We've replaced pip with poetry."
      }
    ],
    "satisfaction_conditions": [
      "Resolve dependency version conflicts between explicitly specified packages and their dependencies",
      "Ensure dependency management approach handles multiple conflicting requirements automatically",
      "Provide a maintainable dependency resolution strategy",
      "Avoid manual version pinning that creates incompatibilities"
    ]
  },
  {
    "number": 1012,
    "title": "[Question]: How to improve the parallelism of file parsing?",
    "created_at": "2024-05-31T08:12:12Z",
    "closed_at": "2024-06-03T02:13:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/1012",
    "body": "### Describe your problem\n\nI found that when I am processing multiple files at the same time, the parsing block is serial. \r\nAfter checking the server.py file, I found that the number of workers is only 1, and the parameters are not exposed in the configuration file.\r\n Is there any other way to improve the efficiency of parsing documents besides improving workers",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/1012/comments",
    "author": "liweiyang2023",
    "comments": [
      {
        "user": "CamusGao",
        "created_at": "2024-06-02T09:08:36Z",
        "body": "just see entrypoint.sh in docker folder and there is a variable WS. You could pass this variable to docker by using -e or writing into docker-compose.yml if you're using docker."
      },
      {
        "user": "liweiyang2023",
        "created_at": "2024-06-03T02:13:39Z",
        "body": "> just see entrypoint.sh in docker folder and there is a variable WS. You could pass this variable to docker by using -e or writing into docker-compose.yml if you're using docker.\u53ea\u9700\u5728 docker \u6587\u4ef6\u5939\u4e2d\u770b\u5230 entrypoint.sh\uff0c\u5c31\u4f1a\u6709\u4e00\u4e2a\u53d8\u91cf WS\u3002\u5982\u679c\u4f7f\u7528\u7684\u662f docker\uff0c\u5219\u53ef\u4ee5\u4f7f\u7528 -e \u6216\u5199\u5165 docker-compose.yml \u5c06\u6b64\u53d8\u91cf\u4f20\u9012\u7ed9 docker\u3002\r\n\r\nThank you for your answer! I have successfully improved the parsing using your method"
      }
    ],
    "satisfaction_conditions": [
      "Provides a method to configure worker count externally without modifying server.py",
      "Enables parallel processing of document parsing"
    ]
  },
  {
    "number": 448,
    "title": "[Question]: How to start RagFlow manually ?",
    "created_at": "2024-04-19T05:25:13Z",
    "closed_at": "2024-04-19T08:10:50Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/448",
    "body": "### Describe your problem\n\nHow to prevent RagFlow from auto startng, and instead start it manually when needed? My system is Ubuntu.",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/448/comments",
    "author": "Kryto614",
    "comments": [
      {
        "user": "Alphayellowcat",
        "created_at": "2024-04-19T07:09:58Z",
        "body": "@Kryto614 \r\nTo set up your Docker project so that containers only start when manually triggered rather than automatically on Docker start, you need to adjust the service settings in your `docker-compose.yml` file. Typically, containers start automatically if they are configured to do so, especially when the `restart` policy is set to `always`.\r\n\r\nHere's what you can do:\r\n\r\n1. **Modify the Restart Policy**: Locate the `restart` policy in your `docker-compose.yml` for the service you want to control. Change it from `always` to `no`:\r\n\r\n```\r\n    services:\r\n      ragflow:\r\n        restart: no\r\n\r\n```\r\n    This change ensures that the service won't automatically start when Docker starts.\r\n\r\n2. **Starting Containers Manually**: After making the above change, you will need to manually start your containers whenever you need them by using the Docker Compose command:\r\n\r\n    ```bash\r\n    docker compose up\r\n    ```"
      },
      {
        "user": "Kryto614",
        "created_at": "2024-04-19T08:09:51Z",
        "body": "> @Kryto614 To set up your Docker project so that containers only start when manually triggered rather than automatically on Docker start, you need to adjust the service settings in your `docker-compose.yml` file. Typically, containers start automatically if they are configured to do so, especially when the `restart` policy is set to `always`.\r\n> \r\n> Here's what you can do:\r\n> \r\n> 1. **Modify the Restart Policy**: Locate the `restart` policy in your `docker-compose.yml` for the service you want to control. Change it from `always` to `no`:\r\n> \r\n> ```\r\n>     services:\r\n>       ragflow:\r\n>         restart: no\r\n> ```\r\n> \r\n> ```\r\n> This change ensures that the service won't automatically start when Docker starts.\r\n> ```\r\n> \r\n> 2. **Starting Containers Manually**: After making the above change, you will need to manually start your containers whenever you need them by using the Docker Compose command:\r\n>    ```shell\r\n>    docker compose up\r\n>    ```\r\n\r\nThank you, that works for me perfectly !"
      }
    ],
    "satisfaction_conditions": [
      "Disables automatic startup of RagFlow service on system/Docker startup",
      "Provides a clear method to manually start the service when needed",
      "Does not require complex system-level service management"
    ]
  },
  {
    "number": 351,
    "title": "Setting OpenAI Models",
    "created_at": "2024-04-14T22:06:20Z",
    "closed_at": "2024-08-07T11:26:58Z",
    "labels": [
      "question",
      "Feature"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/351",
    "body": "### Describe your problem\n\nI am trying to use GPT-4-Turbo instead of GPT-4, when I make the change in the configuration files it is not be passed through when I rebuild the docker images, and start the service.  How can I change the name of the model for OpenAI to use GPT-4-Turbo?",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/351/comments",
    "author": "rhudock",
    "comments": [
      {
        "user": "KevinHuSh",
        "created_at": "2024-04-15T01:00:14Z",
        "body": "Fullfilled. git pull the latest souce code, and docker pull the latest image."
      },
      {
        "user": "rhudock",
        "created_at": "2024-04-15T02:22:58Z",
        "body": "Thank you.  The model should be gpt-4-turbo."
      }
    ],
    "satisfaction_conditions": [
      "Ensures configuration changes for the OpenAI model name are properly applied during Docker rebuilds",
      "Maintains synchronization between source code and Docker images when updating model settings",
      "Validates the OpenAI API accepts the specified model name format"
    ]
  },
  {
    "number": 310,
    "title": "Where is the \"Query Analyze\" part of the code?",
    "created_at": "2024-04-11T02:03:06Z",
    "closed_at": "2024-04-11T03:41:19Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/310",
    "body": "### Describe your problem\n\nI would like to read how this part is implements,thanks",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/310/comments",
    "author": "jiangsiYang",
    "comments": [
      {
        "user": "KevinHuSh",
        "created_at": "2024-04-11T02:23:35Z",
        "body": "In rag/nlp/query.py or search.py, all about query rewriting and ranking."
      }
    ],
    "satisfaction_conditions": [
      "Identifies the specific code location(s) handling query analysis functionality",
      "Links the implementation to query processing features like rewriting and ranking"
    ]
  }
]