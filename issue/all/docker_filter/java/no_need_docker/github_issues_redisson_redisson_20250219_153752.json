[
  {
    "number": 6443,
    "title": "Order Guarantees with the Async API",
    "created_at": "2025-02-18T17:09:07Z",
    "closed_at": "2025-02-19T09:56:35Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/6443",
    "body": "Hey,\nI\u2019m wondering if the following example guarantees execution order:\n```\nRBucket<String> bucket = redisson.getBucket(\"key\");\n\nbucket.setAsync(\"value\"); // Fire SET without waiting\nRFuture<String> future = bucket.getAsync(); \n\nfuture.thenAccept(System.out::println); \n```\nDoes SET always execute before GET, even though SET wasn\u2019t explicitly awaited?\n\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/6443/comments",
    "author": "barshaul",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2025-02-19T08:58:52Z",
        "body": "Hi,\n\nNo, due to the asynchronous nature of the connections handling. \n\nTo achieve that you can create a Redisson instance with `\u0441onnectionPoolSize = 1`."
      },
      {
        "user": "barshaul",
        "created_at": "2025-02-19T09:56:35Z",
        "body": "Ack, that answers my question. Thanks! "
      },
      {
        "user": "mrniko",
        "created_at": "2025-02-19T10:50:04Z",
        "body": "@barshaul \n\nTo achieve that you can create a Redisson instance with `\u0441onnectionPoolSize = 1`"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how asynchronous command execution order is managed in the library",
      "Identification of mechanisms to enforce command sequencing in async workflows",
      "Clarification of relationship between connection handling and command execution order",
      "Differentiation between fire-and-forget async patterns vs ordered execution requirements"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:48:39"
    }
  },
  {
    "number": 6315,
    "title": "Redisson is shutdown",
    "created_at": "2024-12-04T02:54:58Z",
    "closed_at": "2024-12-04T09:40:48Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/6315",
    "body": "### Redisson Version\r\n3.13.2\r\n\r\n### What is the Actual behavior?\r\nan error is reported by refreshing the local cache through Redis when the k8s pod is destroyed\r\n\r\n### Redisson configuration\r\n\r\n\r\n    @Bean\r\n    public StringRedisTemplate stringRedisTemplateMenu() {\r\n        StringRedisTemplate template = new StringRedisTemplate();\r\n        template.setConnectionFactory(redissonMenuConnectionFactory());\r\n        return template;\r\n    }\r\n    @Bean\r\n    public RedisConnectionFactory redissonMenuConnectionFactory() {\r\n        return new RedissonConnectionFactory(redissonMenu());\r\n    }\r\n    @Bean(destroyMethod = \"shutdown\")\r\n    public RedissonClient redissonMenu() {\r\n        if (StringUtils.isBlank(redissonMenuProperties.getSingleServerConfig().getPassword())) {\r\n            redissonMenuProperties.getSingleServerConfig().setPassword(null);\r\n        }\r\n        Config config = null;\r\n        try {\r\n            config = Config.fromJSON(JSON.toJSONString(redissonMenuProperties));\r\n        } catch (Exception e) {\r\n            log.error(\"spring.redisson-menu \u914d\u7f6e\u5f02\u5e38:{}\", e.getMessage(), e);\r\n            throw new BaseBizException(BaseErrorEnum.UNKNOW_SYSTEM_ERROR, \"spring.redisson-menu \u914d\u7f6e\u8bfb\u53d6\u5f02\u5e38\");\r\n        }\r\n        config.setCodec(new org.redisson.client.codec.StringCodec());\r\n        return Redisson.create(config);\r\n    }\r\n\r\n### Additional information\r\n`nested exception is org.redisson.RedissonShutdownException: Redisson is shutdown org.springframework.dao.InvalidDataAccessApiUsageException: Redisson is shutdown; nested exception is org.redisson.RedissonShutdownException: Redisson is shutdown\\n\\tat org.redisson.spring.data.connection.RedissonExceptionConverter.convert(RedissonExceptionConverter.java:48)\\n\\tat org.redisson.spring.data.connection.RedissonExceptionConverter.convert(RedissonExceptionConverter.java:35)\\n\\tat org.springframework.data.redis.PassThroughExceptionTranslationStrategy.translate(PassThroughExceptionTranslationStrategy.java:44)\\n\\tat org.redisson.spring.data.connection.RedissonConnection.transform(RedissonConnection.java:217)\\n\\tat org.redisson.spring.data.connection.RedissonConnection.syncFuture(RedissonConnection.java:212)\\n\\tat org.redisson.spring.data.connection.RedissonConnection.sync(RedissonConnection.java:378)\\n\\tat org.redisson.spring.data.connection.RedissonConnection.read(RedissonConnection.java:759)\\n\\tat org.redisson.spring.data.connection.RedissonConnection.get(RedissonConnection.java:493)\\n\\tat org.springframework.data.redis.connection.DefaultStringRedisConnection.get(DefaultStringRedisConnection.java:404)\\n\\tat org.springframework.data.redis.core.DefaultValueOperations$1.inRedis(DefaultValueOperations.java:57)\\n\\tat org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:60)\\n\\tat org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:228)\\n\\tat org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:188)\\n\\tat org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:96)\\n\\tat org.springframework.data.redis.core.DefaultValueOperations.get(DefaultValueOperations.java:53)\\n ...`\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/6315/comments",
    "author": "LHH7049",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2024-12-04T06:30:24Z",
        "body": "This is an expected behavior since pod is shutdown."
      },
      {
        "user": "LHH7049",
        "created_at": "2024-12-04T09:40:48Z",
        "body": "> This is an expected behavior since pod is shutdown.\r\n\r\nfine, thanks"
      }
    ],
    "satisfaction_conditions": [
      "Confirmation that the error is expected behavior during Kubernetes pod termination",
      "Clarification that the exception doesn't indicate a misconfiguration"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:49:00"
    }
  },
  {
    "number": 5830,
    "title": "Issue with Kryo5Codec in combination with org.springframework.cache.support.NullValue",
    "created_at": "2024-04-30T10:11:54Z",
    "closed_at": "2024-12-23T11:00:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/5830",
    "body": "Hi,\r\n\r\nI'm currently having an issue with the Spring Cache implementation in combination with Redisson. \r\nThe JCacheCache class provided by Redisson extends `org.springframework.cache.support.AbstractValueAdaptingCache`. In the method `protected Object fromStoreValue(@Nullable Object storeValue)` of the class AbstractValueAdaptingCache, there is an if condition, that check if the storeValue is equal to NullValue.INSTANCE using ==. \r\n\r\n```\r\nprotected Object fromStoreValue(@Nullable Object storeValue) {\r\n\tif (this.allowNullValues && storeValue == NullValue.INSTANCE) {\r\n\t\treturn null;\r\n\t}\r\n\treturn storeValue;\r\n}\r\n```\r\n\r\nThis condition evaluated to false in my case, because the instance of storeValue was not the same instance as NullValue.INSTANCE. Reason is the deserialisation, that was done by Kryo. It seems, that Kryo changes the constructor to \"public\" using reflections and creates a new instance by calling the constructor. It does not call the \"readResolve()\" method of NullValue class, which would return NullValue.INSTANCE.\r\nIs this a known issue? The only solution I came up with is extending the Kryo5Codec and adding a custom Serializer for NullValue.class. Is there another way to fix this issue?\r\n\r\nBest regards",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/5830/comments",
    "author": "MrKanister2000",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2024-04-30T12:12:56Z",
        "body": "> The JCacheCache class provided by Redisson\r\n\r\nSorry, Redisson doesn't implement such class"
      },
      {
        "user": "MrKanister2000",
        "created_at": "2024-04-30T13:07:27Z",
        "body": "> Sorry, Redisson doesn't implement such class\r\n\r\nYep sry, my bad. I got confused with the class names. JCacheCache is part of the Spring package. \r\nNevertheless, the `org.redisson.jcache.JCache` class returns a new instance of NullValue from the cache, because of the Kryo deserialization issue I described. Any hint how to fix this?\r\n"
      },
      {
        "user": "mrniko",
        "created_at": "2024-04-30T13:18:30Z",
        "body": "Can you add the code below into org.redisson.codec.Kryo5Codec#createKryo method and say if it works?\r\n\r\n```java\r\nif (com.esotericsoftware.kryo.util.Util.isClassAvailable(\"org.springframework.cache.support.NullValue\")) {\r\n   kryo.addDefaultSerializer(Class.forName(\"org.springframework.cache.support.NullValue\"), new JavaSerializer());\r\n}\r\n```"
      },
      {
        "user": "MrKanister2000",
        "created_at": "2024-04-30T14:06:05Z",
        "body": "Yes, it works, thanks. Do you see any trade-offs (like performance) when using the JavaSerializer?\r\n\r\nMy first solution was extending the Kryo5Codec class:\r\n\r\n```\r\npublic class MyKryo5Codec extends Kryo5Codec {\r\n\r\n    @Override\r\n    protected Kryo createKryo(ClassLoader classLoader) {\r\n        Kryo kryo = super.createKryo(classLoader);\r\n\r\n        kryo.addDefaultSerializer(NullValue.class, new NullValueSerializer(kryo, NullValue.class));\r\n\r\n        return kryo;\r\n    }\r\n}\r\n```\r\n\r\nand creating a custom NullValueSerializer:\r\n\r\n```\r\npublic class NullValueSerializer extends FieldSerializer<NullValue> {\r\n\r\n    public NullValueSerializer(Kryo kryo, Class type) {\r\n        super(kryo, type);\r\n    }\r\n\r\n    @Override\r\n    public NullValue read(Kryo kryo, Input input, Class type) {\r\n        return (NullValue) NullValue.INSTANCE;\r\n    }\r\n}\r\n```\r\n\r\nBut your solution has a way smaller footprint than mine."
      },
      {
        "user": "mrniko",
        "created_at": "2024-05-01T05:08:01Z",
        "body": "Thanks for testing. In your example Spring become a required dependency because of explicit NullValue class definition which I would like to avoid. It would be great if you rewrite it without explicit NullValue definition."
      }
    ],
    "satisfaction_conditions": [
      "Ensures NullValue deserialization returns the singleton instance",
      "Avoids making Spring a required dependency",
      "Maintains serialization/deserialization performance",
      "Requires minimal code changes",
      "Works with Kryo's reflection-based instantiation"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:49:27"
    }
  },
  {
    "number": 4890,
    "title": "Switching from Redis 4 to 6, will Redisson have compatibility issues?",
    "created_at": "2023-02-22T13:23:12Z",
    "closed_at": "2023-02-23T07:23:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4890",
    "body": "Hi team, \r\n\r\nWe are going to upgrade Redis 4 to Redis 6. I would like to ask team if there will be compatibility issues between Redission and Redis 6 after upgrading 4 to 6. Or do you know of any known Redission incompatibilities due to Redis 6 upgrades?\r\nAccording to redission documentation, Redission supports Redis 4 and 6. Does this mean that we don't need to modify any client code? \r\n\r\nMany thanks for your support!",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4890/comments",
    "author": "yunbozhang-msft",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2023-02-23T07:23:49Z",
        "body": "Hi,\r\n\r\nRedisson is fully compatible with 3.x up to 7.0.x version. No code modification is needed."
      },
      {
        "user": "yunbozhang-msft",
        "created_at": "2023-02-28T05:22:03Z",
        "body": "Thank you!"
      }
    ],
    "satisfaction_conditions": [
      "Confirmation of Redisson compatibility with Redis 6",
      "Clarification about required client code modifications",
      "Identification of any known incompatibilities between Redisson and Redis 6"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:49:46"
    }
  },
  {
    "number": 4768,
    "title": "Classfile version 61 (Java17) change intended?",
    "created_at": "2022-12-29T15:48:50Z",
    "closed_at": "2023-01-06T07:28:19Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4768",
    "body": "Is it an intended or accidental change to publish redisson compiled with java17 target and thus break everyone not yet lucky enough to be on 17?\r\nIf so, wouldn't a change like this be good to be documented as incompatible in the release notes?\r\n\r\nAlso i was expecting such a drastic thing to be a major, rather than a minor change (in terms of SemVer).",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4768/comments",
    "author": "uweschaefer",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2022-12-30T05:34:28Z",
        "body": "Can you point on that class? All classes of 3.19.0 version compiled with java 8 target. Checked it with javap\r\n\r\n```\r\npublic class org.redisson.Redisson implements org.redisson.api.RedissonClient\r\n  minor version: 0\r\n  major version: 52\r\n```\r\n"
      },
      {
        "user": "uweschaefer",
        "created_at": "2023-01-09T17:54:44Z",
        "body": "my bad. I rechecked all classes from 3.18,19.0 and 19.1... Don't know what i saw... :blush: "
      }
    ],
    "satisfaction_conditions": [
      "Confirmation of the Java version target used for compilation",
      "Verification methodology for classfile versions"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:49:53"
    }
  },
  {
    "number": 4674,
    "title": "Expire RRateLimiter",
    "created_at": "2022-11-15T08:22:44Z",
    "closed_at": "2022-11-17T07:52:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4674",
    "body": "I want to delete RRateLimiter hash from redis, post rate interval is over. e.g. I set rate interval of 10 sec then hash must be removed post 10 sec.\r\nIs there any built in api for this functinality exists? ",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4674/comments",
    "author": "pat246",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2022-11-17T07:52:56Z",
        "body": "You need to use `expire()` method"
      },
      {
        "user": "pat246",
        "created_at": "2022-11-17T12:41:16Z",
        "body": "Thanks.\r\nActually we are using redisson 3.12.x version, hence I was unable to call `expire()` method. However as workaround I've tried to expire using `RMap`  with expiry value of \"rate interval\" as below\r\n\r\n\r\n`RRateLimiter limiter = redisson.getRateLimiter(name);`\r\n`RMap<Object, Object> keyMap = redisson.getMap(name);`\r\n`keyMap.expire(10, TimeUnit.SECONDS); // 10 sec is rate interval of limitter`"
      }
    ],
    "satisfaction_conditions": [
      "Compatibility with Redisson 3.12.x version",
      "Mechanism to automatically remove Redis hash after rate interval duration",
      "Utilization of existing Redisson APIs for data expiration",
      "No dependency on newer API versions/methods"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:49:58"
    }
  },
  {
    "number": 4670,
    "title": "How to set cache properties for Hibernate scond level cache?",
    "created_at": "2022-11-13T08:38:42Z",
    "closed_at": "2022-12-12T06:04:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4670",
    "body": "I'm working on a Java spring project where I have multiple entities to be cached using `@Cache` annotation, ex:\r\n`@Cache(usage = CacheConcurrencyStrategy.READ_WRITE ,region = \"cache1\")`\r\n\r\nI have set ` spring.jpa.properties.hibernate.cache.region.factory_class` to be RedissonRegionFactory\r\n\r\nAs I'm using Redis cache as Hibernate second Level cache, I want a way to customize the properties of each cache region in a Java class, by properties I mean the TTL and maxEntriesLocalHeap.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4670/comments",
    "author": "AseelAbushhadeh",
    "comments": [
      {
        "user": "OdaybatLFC",
        "created_at": "2022-11-15T08:48:17Z",
        "body": "Hello @AseelAbushhadeh , what I have done in my project is configure each cached entity with my own configuration class. I am also open to hear if there is another way of achieving this."
      },
      {
        "user": "mrniko",
        "created_at": "2022-11-17T07:51:33Z",
        "body": "@OdaybatLFC \r\n\r\nWhy can't you use spring.jpa.properties.hibernate.cache... settings?\r\n\r\n```java\r\nspring.jpa.properties.hibernate.cache.redisson.entity.expiration.time_to_live=\r\nspring.jpa.properties.hibernate.cache.redisson.entity.expiration.max_idle_time=\r\nspring.jpa.properties.hibernate.cache.redisson.collection.expiration.time_to_live=\r\nspring.jpa.properties.hibernate.cache.redisson.collection.expiration.max_idle_time=\r\n```"
      },
      {
        "user": "AseelAbushhadeh",
        "created_at": "2022-11-17T10:37:03Z",
        "body": "thanks for the suggestion, I can use it but this will apply to all caches, I want to customize the properties for each entity cache individually.\r\n\r\n> @OdaybatLFC\r\n> \r\n> Why can't you use spring.jpa.properties.hibernate.cache... settings?\r\n> \r\n> ```java\r\n> spring.jpa.properties.hibernate.cache.redisson.entity.expiration.time_to_live=\r\n> spring.jpa.properties.hibernate.cache.redisson.entity.expiration.max_idle_time=\r\n> spring.jpa.properties.hibernate.cache.redisson.collection.expiration.time_to_live=\r\n> spring.jpa.properties.hibernate.cache.redisson.collection.expiration.max_idle_time=\r\n> ```\r\n\r\n"
      },
      {
        "user": "mrniko",
        "created_at": "2022-11-17T11:24:26Z",
        "body": "You can specify region name as well.\r\n```\r\nspring.jpa.properties.hibernate.cache.redisson.my_object.eviction.max_entries=\r\nspring.jpa.properties.hibernate.cache.redisson.my_object.expiration.time_to_live=\r\nspring.jpa.properties.hibernate.cache.redisson.my_object.expiration.max_idle_time=\r\n\r\nspring.jpa.properties.hibernate.cache.redisson.my_collection.expiration.time_to_live=\r\nspring.jpa.properties.hibernate.cache.redisson.my_collection.expiration.max_idle_time=\r\n```"
      },
      {
        "user": "AseelAbushhadeh",
        "created_at": "2022-11-17T12:16:45Z",
        "body": "> You can specify region name as well.\r\n> \r\n> ```\r\n> spring.jpa.properties.hibernate.cache.redisson.my_object.eviction.max_entries=\r\n> spring.jpa.properties.hibernate.cache.redisson.my_object.expiration.time_to_live=\r\n> spring.jpa.properties.hibernate.cache.redisson.my_object.expiration.max_idle_time=\r\n> \r\n> spring.jpa.properties.hibernate.cache.redisson.my_collection.expiration.time_to_live=\r\n> spring.jpa.properties.hibernate.cache.redisson.my_collection.expiration.max_idle_time=\r\n> ```\r\n\r\nThanks it works!! \r\nHoping I can find a way to do that in a java class."
      }
    ],
    "satisfaction_conditions": [
      "Allows per-region configuration of cache properties (TTL, max entries) for Hibernate second-level cache",
      "Supports programmatic configuration in Java code rather than only property files"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:50:06"
    }
  },
  {
    "number": 4284,
    "title": "What difference from `readAllEntrySet` and `getAll` in `RMap`",
    "created_at": "2022-05-10T12:57:00Z",
    "closed_at": "2022-05-10T13:15:01Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4284",
    "body": "Hi~ Community:\r\n    When I want to use `hmget` command in redis, I found `rMap.getAll(\"\")`, it returns all fields, so what difference from `readAllEntrySet` and `getAll` in `RMap`?\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4284/comments",
    "author": "xdshent",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2022-05-10T13:01:52Z",
        "body": "`getAll` methods allows to load map by specified keys. Whereas `readAllEntrySet` loads all map entries."
      },
      {
        "user": "xdshent",
        "created_at": "2022-05-10T13:14:57Z",
        "body": "> `getAll` methods allows to load map by specified keys. Whereas `readAllEntrySet` loads all map entries.\r\n\r\nthx! @mrniko "
      }
    ],
    "satisfaction_conditions": [
      "Clarify the scope of data retrieval for each method",
      "Differentiate between key-based retrieval and full entry retrieval"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:50:15"
    }
  },
  {
    "number": 4065,
    "title": "How to use 'zAdd'?",
    "created_at": "2022-01-10T09:22:53Z",
    "closed_at": "2022-01-11T07:26:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4065",
    "body": "How to use 'RedisZSetCommands.zAdd(byte[] key, double score, byte[] value)'?\r\nnot implemented\uff1f",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4065/comments",
    "author": "Jabwin",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2022-01-10T10:55:47Z",
        "body": "It's implemented in all versions. Starting from Spring Data Redis 2.5.0 it's routed to `zAdd(byte[] key, double score, byte[] value, ZAddArgs args)` method. Which is also implemented."
      }
    ],
    "satisfaction_conditions": [
      "Clarification of method availability across Spring Data Redis versions",
      "Explanation of method routing behavior",
      "Version-specific considerations for Spring Data Redis"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:50:31"
    }
  },
  {
    "number": 3989,
    "title": " ERR Error running script (call to f_0fd7cdd6c1224471b29d6f7fc503462f3b252f12): @user_script:1: user_script:1: bad argument #2 to 'unpack' (data string too short",
    "created_at": "2021-11-26T18:24:24Z",
    "closed_at": "2021-11-30T06:09:02Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3989",
    "body": "I am unable to understand this error. Please help.\r\n` Execution exception[[RedisException: ERR Error running script (call to f_0fd7cdd6c1224471b29d6f7fc503462f3b252f12): @user_script:1: user_script:1: bad argument #2 to 'unpack' (data string too short) . channel: [id: 0xd4089e92, L:/10.212.134.41:60921 - R:core-dev-redis.6cbkbd.0001.aps1.cache.amazonaws.com/192.168.2.46:6379] command: (EVAL), params: [local result = {}; local idleKeys = {}; local res; if (#ARGV == 4) then  res = redis.call('hscan', K..., 3, ALLUS_XXX, redisson__timeout__set:{ALLUS_XXX}, redisson__idle__set:{ALLUS_XXX}, 1637948919729, 0, 10]]]\\\r\n`\r\n\r\nI am trying to read using `getMapCache(ALLUS_XXX)`\r\n\r\nalso, in redis cli if I do `hgetall ALLUS_XXX`.  This is the output\r\n\r\n```\r\n 1) \"3\"\r\n 2) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"3\\\",\\\"ax\\\":\\\"21\\\",\\\"bp\\\":331.27,\\\"ap\\\":331.3,\\\"bs\\\":2,\\\"as\\\":1,\\\"t\\\":\\\"1637948895747\\\",\\\"q\\\":\\\"42893371\\\",\\\"z\\\":3}\"\r\n 3) \"2\"\r\n 4) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"2\\\",\\\"ax\\\":\\\"19\\\",\\\"bp\\\":330.03,\\\"ap\\\":330.13,\\\"bs\\\":2,\\\"as\\\":3,\\\"t\\\":\\\"1637949585689\\\",\\\"q\\\":\\\"46053648\\\",\\\"z\\\":3}\"\r\n 5) \"12\"\r\n 6) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"12\\\",\\\"ax\\\":\\\"11\\\",\\\"bp\\\":329.91,\\\"ap\\\":330.25,\\\"bs\\\":1,\\\"as\\\":12,\\\"t\\\":\\\"1637949676507\\\",\\\"q\\\":\\\"46258127\\\",\\\"z\\\":3}\"\r\n 7) \"9\"\r\n 8) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"9\\\",\\\"ax\\\":\\\"15\\\",\\\"bp\\\":330.43,\\\"ap\\\":330.44,\\\"bs\\\":3,\\\"as\\\":3,\\\"t\\\":\\\"1637949113455\\\",\\\"q\\\":\\\"43838492\\\",\\\"z\\\":3}\"\r\n 9) \"15\"\r\n10) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"15\\\",\\\"ax\\\":\\\"12\\\",\\\"bp\\\":330.34,\\\"ap\\\":330.37,\\\"bs\\\":2,\\\"as\\\":4,\\\"t\\\":\\\"1637949549028\\\",\\\"q\\\":\\\"45809932\\\",\\\"z\\\":3}\"\r\n11) \"10\"\r\n12) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"10\\\",\\\"ax\\\":\\\"12\\\",\\\"bp\\\":330.26,\\\"ap\\\":330.37,\\\"bs\\\":1,\\\"as\\\":2,\\\"t\\\":\\\"1637949585833\\\",\\\"q\\\":\\\"46055016\\\",\\\"z\\\":3}\"\r\n13) \"18\"\r\n14) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"18\\\",\\\"ax\\\":\\\"11\\\",\\\"bp\\\":330.15,\\\"ap\\\":330.25,\\\"bs\\\":2,\\\"as\\\":12,\\\"t\\\":\\\"1637949683953\\\",\\\"q\\\":\\\"46258667\\\",\\\"z\\\":3}\"\r\n15) \"1\"\r\n16) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"1\\\",\\\"ax\\\":\\\"17\\\",\\\"bp\\\":330.21,\\\"ap\\\":330.31,\\\"bs\\\":4,\\\"as\\\":1,\\\"t\\\":\\\"1637949583379\\\",\\\"q\\\":\\\"46033150\\\",\\\"z\\\":3}\"\r\n17) \"11\"\r\n18) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"11\\\",\\\"ax\\\":\\\"12\\\",\\\"bp\\\":329.91,\\\"ap\\\":330.2,\\\"bs\\\":4,\\\"as\\\":1,\\\"t\\\":\\\"1637949688637\\\",\\\"q\\\":\\\"46259504\\\",\\\"z\\\":3}\"\r\n19) \"7\"\r\n20) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"7\\\",\\\"ax\\\":\\\"11\\\",\\\"bp\\\":330.15,\\\"ap\\\":330.25,\\\"bs\\\":2,\\\"as\\\":12,\\\"t\\\":\\\"1637949684316\\\",\\\"q\\\":\\\"46258719\\\",\\\"z\\\":3}\"\r\n21) \"20\"\r\n22) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"20\\\",\\\"ax\\\":\\\"12\\\",\\\"bp\\\":330.11,\\\"ap\\\":330.26,\\\"bs\\\":1,\\\"as\\\":1,\\\"t\\\":\\\"1637949586232\\\",\\\"q\\\":\\\"46058248\\\",\\\"z\\\":3}\"\r\n23) \"19\"\r\n24) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"19\\\",\\\"ax\\\":\\\"11\\\",\\\"bp\\\":329.91,\\\"ap\\\":330.25,\\\"bs\\\":2,\\\"as\\\":12,\\\"t\\\":\\\"1637949676537\\\",\\\"q\\\":\\\"46258138\\\",\\\"z\\\":3}\"\r\n25) \"8\"\r\n26) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"8\\\",\\\"ax\\\":\\\"11\\\",\\\"bp\\\":330.06,\\\"ap\\\":330.25,\\\"bs\\\":1,\\\"as\\\":12,\\\"t\\\":\\\"1637949685035\\\",\\\"q\\\":\\\"46258880\\\",\\\"z\\\":3}\"\r\n27) \"17\"\r\n28) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"17\\\",\\\"ax\\\":\\\"17\\\",\\\"bp\\\":329.37,\\\"ap\\\":330.16,\\\"bs\\\":2,\\\"as\\\":2,\\\"t\\\":\\\"1637949606270\\\",\\\"q\\\":\\\"46241118\\\",\\\"z\\\":3}\"\r\n29) \"21\"\r\n30) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"21\\\",\\\"ax\\\":\\\"12\\\",\\\"bp\\\":330.9,\\\"ap\\\":331.09,\\\"bs\\\":1,\\\"as\\\":1,\\\"t\\\":\\\"1637949581667\\\",\\\"q\\\":\\\"46012327\\\",\\\"z\\\":3}\"\r\n```\r\n\r\n\r\nThis is easlily reproducible,\r\n1. ` HMSET ALLUS_XXX 1 \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"1\\\",\\\"ax\\\":\\\"20\\\",\\\"bp\\\":157.2,\\\"ap\\\":157.21,\\\"bs\\\":5,\\\"as\\\":1,\\\"t\\\":\\\"1637949207844\\\",\\\"q\\\":\\\"60303179\\\",\\\"z\\\":3}\"`\r\n2. Now try to access this using redisson `getMapCache(\"ALLUS_XXX\").readAllEntrySet()`",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3989/comments",
    "author": "ashwinreal",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-11-27T05:38:02Z",
        "body": "use the same codec for data store and reading"
      },
      {
        "user": "ashwinreal",
        "created_at": "2021-11-27T08:21:47Z",
        "body": "> use the same codec for data store and reading\r\n\r\nWhat is the codec when we add keys using redis-cli  and want to read using redisson  @mrniko ?  I tried a few at random did not work"
      },
      {
        "user": "SplotyCode",
        "created_at": "2021-11-27T09:15:05Z",
        "body": "Have you tried StringCodec?"
      },
      {
        "user": "ashwinreal",
        "created_at": "2021-11-28T16:16:26Z",
        "body": " @mrniko  @SplotyCode i have tried both\r\n` redisService.client.getMapCache(key, StringCodec.INSTANCE ).readAllEntrySet()\r\n      redisService.client.getMapCache(key, ByteArrayCodec.INSTANCE ).readAllEntrySet()\r\n`\n\n---\n\nI feel this should not be hard to do , there should be a codec already defined for this ... all I am trying to do is `HMSET test_key 1 \"123\"\r\n` \r\nand then read this using redission. Somehow I am not getting any of the codecs to work for this use case . \r\nDo I need to define a custom codec for this ? Pls suggest @mrniko @SplotyCode \n\n---\n\n@mrniko @SplotyCode I am really stuck here . Any suggestions pls ?"
      },
      {
        "user": "mrniko",
        "created_at": "2021-11-29T05:48:07Z",
        "body": "you can insert/update RMapCache entries only through its API or try RMap object"
      },
      {
        "user": "ashwinreal",
        "created_at": "2021-11-30T18:27:34Z",
        "body": "yes, this works \r\n`client.getMap(key, StringCodec.INSTANCE).readAllEntrySet`\r\nThanks @mrniko "
      },
      {
        "user": "chanhengseang3",
        "created_at": "2024-06-25T06:29:38Z",
        "body": "I got this error after added StringCodec.INSTANCE\r\n`redissonClient.getBoundedBlockingQueue(\"key\", StringCodec.INSTANCE)`\r\n```\r\ncom.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 65\r\n\tat com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:159)\r\n\tat com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:758)\r\n\tat com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:869)\r\n\tat org.redisson.codec.Kryo5Codec$4.decode(Kryo5Codec.java:144)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:433)\r\n\tat org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:490)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:442)\r\n\tat org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:216)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:144)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:120)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:529)\r\n\tat io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\n```"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of codec compatibility between Redis CLI operations and Redisson's data structures",
      "Clarification on proper Redisson API selection for HMSET-based data structures",
      "Guidance on maintaining consistent serialization/deserialization approaches",
      "Identification of root cause for 'data string too short' error in unpack operation"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:51:14"
    }
  },
  {
    "number": 3925,
    "title": "Redisson client injects weird characters at the beginning of strings",
    "created_at": "2021-10-29T12:01:41Z",
    "closed_at": "2021-10-29T12:28:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3925",
    "body": "I'm using Redisson client to publish String messages on a topic, but for some reasons, the published messages always contain some weird characters at the beginning:\r\n\r\neg: when I publish the string \"{\"event\":\"notification\"}\" at the redis level I end up with this: \"\\x04>\\x18{\"event\":\"notification\"}\"\r\n\r\n1) \"pmessage\"\r\n2) \"*\"\r\n3) \"active_project_users:1\"\r\n4) \"\\x04>\\x18{\\\"event\\\":\\\"notification\\\"}\"\r\n\r\nAny idea how I can make those weird chars go away?\r\n\r\nMy java code looks like this:\r\n\r\n private void publish(String channel, String message) {       \r\n        RTopic topic = redissonClient.getTopic(channel);\r\n        topic.publish(\"{\\\"event\\\":\\\"notification\\\"}\");\r\n    }\r\nI'm using redis:3.2 & radisson-spring-boot-starter 3.16.1\r\n\r\nThanks",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3925/comments",
    "author": "ghevge",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-10-29T12:28:17Z",
        "body": "default codec is MarshallingCodec. You need to define StringCodec if you want data stored as plain text."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why Redisson adds extra characters to published strings",
      "Identification of the serialization/deserialization mechanism responsible for the formatting",
      "Configuration guidance for storing data as plain text without serialization artifacts",
      "Solution that maintains message publishing functionality while removing encoding"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:51:25"
    }
  },
  {
    "number": 3777,
    "title": "Topic listener removal",
    "created_at": "2021-08-14T20:32:10Z",
    "closed_at": "2021-08-15T05:17:18Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3777",
    "body": "Is it necessary to explicitly remove a Topic listener before shutdown, or does shutdown remove it anyway?\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3777/comments",
    "author": "asarkar",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-08-15T04:53:12Z",
        "body": "No, it's not necessary."
      },
      {
        "user": "asarkar",
        "created_at": "2021-08-15T05:17:18Z",
        "body": "@mrniko Rephrasing as \u201cshutdown removes all local listeners, no need to do it explicitly\u201d, closing this ticket. Thank you."
      },
      {
        "user": "mrniko",
        "created_at": "2021-08-15T06:00:25Z",
        "body": "it doesn't remove listeners, just shutdown network connection to Redis."
      },
      {
        "user": "asarkar",
        "created_at": "2021-08-15T20:49:11Z",
        "body": "I\u2019m confused, isn\u2019t that the same thing? Unless the server keeps a count of the listeners.\n\n---\n\nFor the record, I've verified that the count is local to the JVM."
      }
    ],
    "satisfaction_conditions": [
      "Clarifies whether shutdown automatically removes Topic listeners or leaves them active",
      "Explains the relationship between network connection shutdown and listener resource management",
      "Addresses potential resource management implications of listener retention",
      "Differentiates between local JVM state and server-side state management"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:51:52"
    }
  },
  {
    "number": 3754,
    "title": "Is there any guideline for upgrading the middle value of a version",
    "created_at": "2021-08-02T05:14:11Z",
    "closed_at": "2021-08-05T07:43:14Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3754",
    "body": "Will it be an incompatible version when I upgrade from 3.11.x to 3.15.x?\r\nIs there any reason or guideline for the version value?",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3754/comments",
    "author": "ieiayaobb",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-08-02T08:28:20Z",
        "body": "There is no such guideline. No API breaking changes were made since 3.11.0 version."
      },
      {
        "user": "ieiayaobb",
        "created_at": "2021-08-05T07:43:14Z",
        "body": "I see, thanks.\r\nClose this PR"
      }
    ],
    "satisfaction_conditions": [
      "Clarification about backward compatibility between 3.11.x and 3.15.x versions",
      "Explanation of versioning scheme rationale"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:52:00"
    }
  },
  {
    "number": 3737,
    "title": "data consistency",
    "created_at": "2021-07-22T02:24:09Z",
    "closed_at": "2021-07-27T04:56:25Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3737",
    "body": "\u5206\u5e03\u5f0f\u9501\uff0c\u4ee5redlock\u4e3a\u4f8b\r\n\u5ba2\u6237\u7aef\u4e24\u53f0\uff1a\u5ba2\u6237\u7aefa\uff0c\u5ba2\u6237\u7aefb\r\n\u5ba2\u6237\u7aef\u6267\u884c\u79d2\u6740\u64cd\u4f5c\uff0c\u76f4\u63a5\u64cd\u4f5credis\uff0c\r\n1\u3001\u9996\u5148\u5ba2\u6237\u7aefa\uff0c\u5ba2\u6237\u7aefb\u540c\u65f6\u62a2\u9501\uff0c\r\n2\u3001\u6700\u7ec8\u5ba2\u6237\u7aefa\u83b7\u53d6\u9501\uff0c\u7136\u540e\u6267\u884c\u4e1a\u52a1\u5904\u7406\uff08\u4e0d\u9700\u8981\u7f51\u7edc\uff09\r\n3\u3001\u8fd9\u65f6\u5ba2\u6237\u7aefa \u7f51\u7edc\u901a\u4fe1\u6545\u969c\uff0c\u81f4\u4f7f\u5ba2\u6237\u7aefb\u83b7\u53d6\u5230\u9501\u4e86\uff0c\u5ba2\u6237\u7aefb\u6b63\u5e38\u64cd\u4f5c\uff0c\u4fee\u6539\u72b6\u6001\u6570\u636e\uff08redis \u6570\u636e\uff09\r\n4\u3001\u4e4b\u540e\u63a5\u7740\u5ba2\u6237\u7aefa\u7f51\u7edc\u6b63\u5e38\u4e86\uff0c\u4e5f\u76f4\u63a5\u4fee\u6539\u72b6\u6001\u6570\u636e\uff0c\uff08\u4fee\u6b63\u72b6\u6001\u5728lock \u4e4b\u540e\uff0c\u4f46\u662f\u663e\u7136\u6b64\u65f6\u5ba2\u6237\u7aefa\u5904\u4e8e\u65e0\u9501\u72b6\u6001\uff09\r\n\r\n\u8fd9\u6837\u6570\u636e\u4e00\u81f4\u6027\u4e0d\u5c31\u6ca1\u6709\u4fdd\u8bc1\u4e86\u5417\uff1f\r\n\r\n1\u3001a.lock\r\n2\u3001\u4e1a\u52a1\u903b\u8f91\r\n3\u3001\u4fee\u6b63\u72b6\u6001\r\n4\u3001a.unlock\r\n\r\n\u8d70\u7684\u7b2c\u4e8c\u6b65\uff0c\u7b2c\u4e09\u6b65\u5ba2\u6237\u7aef\u5904\u4e8e\u65e0\u9501\u72b6\u6001\u7684\uff0c\r\n\u4e00\u79cd\u60f3\u6cd51\u3001\u540e\u53f0watchdog \u7ebf\u7a0b\uff0c\u68c0\u6d4b\u5230\u8d85\u65f6\u540e\u963b\u585e\u4e1a\u52a1\u7ebf\u7a0b \uff08\u4f46\u662f\u597d\u50cf\u6ca1\u627e\u5230\u963b\u585e\u975e\u5f53\u524d\u7ebf\u7a0b\u7684api)\r\n\u53e6\u4e00\u79cd\u60f3\u6cd52\u3001\u5728unlock \u65f6\uff0c\u5047\u5982redis \u5f53\u524d\u6301\u9501\u7ebf\u7a0b\u975e\u81ea\u5df1\u65f6\uff0c\u629b\u5f02\u5e38\uff08\u8c8c\u4f3c\u662f\u8fd9\u4e48\u5904\u7406\u7684\uff0c\u4e0d\u8fc7\uff0c\u8fd9\u6837\u5904\u7406\u7684\u8bdd\uff0c\u90a3\u4e0d\u662f\u6b63\u786e\u64cd\u4f5c\r\n\u5e94\u5f53\u6355\u83b7unlock \u4e0b\u7684\u5f02\u5e38\uff0c\u7136\u540e\u5bf9\u4fee\u6539\u72b6\u6001\u7684\u64cd\u4f5c\u505a\u8865\u507f\u4e86\uff0c\u4e5f\u597d\u50cf\u4e0d\u592a\u5bf9\uff09\u3002",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3737/comments",
    "author": "TangXianJun1",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-07-23T05:59:16Z",
        "body": "you need to define big enough `leaseTimeout` value during lock acquisition. So Redis state can survive absence of client during this period of time."
      },
      {
        "user": "TangXianJun1",
        "created_at": "2021-07-30T03:20:10Z",
        "body": "define big enough leaseTimeout can solves most situations\uff0coptimistic locking can be used in extreme cases.\r\nhave studeied ,This is what happens with distributed locks today\r\nfinally thanks for your comments."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to prevent concurrent modifications when a client loses lock ownership mid-operation",
      "Mechanism to ensure lock validity spans the entire critical section duration",
      "Strategy for handling lock ownership verification during state modification",
      "Compensation pattern for failed lock retention scenarios"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:52:07"
    }
  },
  {
    "number": 3684,
    "title": "Connecting to AWS Elasticache cluster using cluster endpoint",
    "created_at": "2021-06-25T15:02:17Z",
    "closed_at": "2021-06-25T18:05:31Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3684",
    "body": "Hello,\r\nAWS EC exposes 2 ways of connecting to multi-node cluster.\r\nIt gives us a cluster-endpoint AND it also gives us endpoints for each node.\r\nNow, in redisson I see that there's a cluster connection config which requires each of the node endpoint address alongwith replicase i think.\r\nAnd then there's singleServerConfig.\r\n\r\nI was wondering what's the best way to handle this? If I use single server config with cluster endpoint, will it be okay?\r\n\r\nOr I always need to use cluster connection config with all node endpoints registered.",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3684/comments",
    "author": "mayurgoenka",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-06-25T15:17:29Z",
        "body": "you can use endpoint with AWS EC"
      },
      {
        "user": "mayurgoenka",
        "created_at": "2021-06-25T18:05:31Z",
        "body": "thanks @mrniko for confirmation."
      }
    ],
    "satisfaction_conditions": [
      "Confirmation that using the cluster endpoint with single-server configuration is valid for AWS ElastiCache"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:52:14"
    }
  },
  {
    "number": 3654,
    "title": "Is order of Operations in a RBatch guaranteed?",
    "created_at": "2021-06-11T06:09:58Z",
    "closed_at": "2021-06-14T07:58:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3654",
    "body": "Sorry if this is obvious, but i did not find any documentstion about this:\r\n\r\nIf i am using **RBatch** and create let's say a Bucket from it, and call setAsync on the bucket 100 times before executing the batch, is the order of the operations in the batch guaranteed to be the order in which\r\n```\r\nsetAsync(Object)\r\n```\r\nhas been called?\r\n\r\nIn other words, is there any way i could end up with anything but the last value i set to the bucket after the RBatch is executed? For instance if the Marshalling of the 99th value took some time?\r\n\r\nBucket is just an example here, i am also using RMaps the same way.",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3654/comments",
    "author": "uweschaefer",
    "comments": [
      {
        "user": "uweschaefer",
        "created_at": "2021-06-27T18:51:10Z",
        "body": "Thanks for answering, @mrniko \r\n\r\nis there an example somewhere? i fail to understand how RLock helps me in this case.\r\nOr did you refer to RedissonFairLock ?\r\n\r\nthx\r\n\r\nPS: One important thing i realized i failed to mention:\r\n\r\nall setAsync(Object) calls **come from the same Thread**.\r\njust like `stringList.stream().forEach(myStringBucket::setAsync);`"
      },
      {
        "user": "mrniko",
        "created_at": "2021-06-29T07:46:43Z",
        "body": "In batch list of operations is always ordered. But RBatch object isn't thread-safe."
      },
      {
        "user": "uweschaefer",
        "created_at": "2021-06-29T09:15:21Z",
        "body": "Thanks, this is very good news."
      }
    ],
    "satisfaction_conditions": [
      "Clarification of operation execution order guarantees in RBatch",
      "Explanation of thread-safety implications for RBatch usage"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:52:23"
    }
  },
  {
    "number": 3626,
    "title": "Will RLOS indexed based querying work in cluster enabled Redis?",
    "created_at": "2021-05-28T05:46:43Z",
    "closed_at": "2021-05-28T05:49:18Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3626",
    "body": "When we use cluster enabled Redis like AWS EC, it's possible that objects gets stored on different shards. Will the indexed based querying still work here?",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3626/comments",
    "author": "mayurgoenka",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-05-28T05:49:13Z",
        "body": "Sharded index supported only in PRO version."
      },
      {
        "user": "mayurgoenka",
        "created_at": "2021-05-28T05:51:10Z",
        "body": "I really appreciate the quick turnaround. You are doing a great job @mrniko. Thanks a lot!"
      },
      {
        "user": "mrniko",
        "created_at": "2021-05-28T06:02:53Z",
        "body": "@mayurgoenka \r\n\r\nThank you!"
      },
      {
        "user": "mayurgoenka",
        "created_at": "2021-06-02T13:15:33Z",
        "body": "Hi @mrniko , \r\nI see that the index is created in the following fashion:\r\n`\"redisson_live_object_index:{com.org.application.MyLiveObject}:index_field:<some_hash>\"`\r\n\r\nI see that we are using hash tag : `{com.org.application.MyLiveObject}` for storing all indices belonging to same class inside same keyslot.\r\n\r\nIn my use case, m trying to store billions of objects of the same class MyLiveObject and there are multiple indices as well. It's obvious that this won't fit in the same keyslot and will need sharding.\r\n\r\nYour comment, \"Sharded index supported only in PRO version.\", does this mean that the index itself will also get sharded across nodes and above use case will still work in PRO version? Same hashtag `{com.org.application.MyLiveObject}` won't be used in PRO version for indices?\r\n\r\nSorry for the repeated query, but just want to make sure before I finalise my design.\r\n\r\nHope my query is clear."
      },
      {
        "user": "mrniko",
        "created_at": "2021-06-02T13:30:41Z",
        "body": "Hi @mayurgoenka, \r\n\r\n> does this mean that the index itself will also get sharded across nodes and above use case will still work in PRO version\r\n\r\nIn this case name will be different to distribute evenly across all Redis master nodes.\r\n\r\n> Same hashtag {com.org.application.MyLiveObject} won't be used in PRO version for indices?\r\n\r\nThis name still will be present in key, but without braces.\r\n"
      },
      {
        "user": "mayurgoenka",
        "created_at": "2021-06-02T13:42:13Z",
        "body": "Thank you @mrniko , this means that I can safely use RLOS for huge data in redis clustered mode.\r\n\r\n\r\nAnother query is, are there any plans for supporting batch operations and transactions with RLOS objects? "
      },
      {
        "user": "mrniko",
        "created_at": "2021-06-02T14:03:16Z",
        "body": "What kind of batch / transaction operations over RLOS do you need? Could you describe some use cases?"
      },
      {
        "user": "mayurgoenka",
        "created_at": "2021-06-02T14:45:49Z",
        "body": "Suppose I want to merge 1000s of Live objects into redis cache, like a batch update OR batch insert. I see that we do have rlos.persist(list) but I not sure if its using pipelining inside or not? Also, rlos.merge(list) is what I was primarily looking for. \r\nThese operations are mainly required for warming up the cache in my use case.\r\n\r\n\r\nTransactions could be required when I want to update 2 different Live objects together or not do them at all. Live objects here can be of same class or different classes.\r\nI need this in my use case because there's a parent-child type of relationship in my application, where if I delete the parent object, child object also needs to get deleted."
      },
      {
        "user": "mrniko",
        "created_at": "2021-06-08T10:27:07Z",
        "body": "`org.redisson.api.RLiveObjectService#persist(T...)` method stores object in a batch. `merge()` method for multiple object isn't implemented yet.\r\n\r\nAs for transactions, I can recommend you to use RLock object."
      },
      {
        "user": "mayurgoenka",
        "created_at": "2021-06-09T05:58:26Z",
        "body": "yes, thank you for the response @mrniko , appreciate it."
      }
    ],
    "satisfaction_conditions": [
      "Clarification of how index sharding works in clustered Redis with RLOS",
      "Confirmation of horizontal scalability for large datasets",
      "Support for atomic operations across distributed objects",
      "Efficient bulk data operations capability",
      "Clear differentiation between PRO and non-PRO features"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:52:29"
    }
  },
  {
    "number": 3569,
    "title": "Simple key value read and write example",
    "created_at": "2021-04-23T06:54:37Z",
    "closed_at": "2021-04-27T05:59:20Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3569",
    "body": "Hi Team,\r\n            Can you share a sample on how to read/write a simple key value  using RedissonReactiveClient\r\n\r\nkey: String\r\nvalue:  java object\r\n\r\nReactive way of writing and reading will be great help.",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3569/comments",
    "author": "ShanmugamC",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-04-23T12:45:46Z",
        "body": "Use `RedissonReactiveClient.getBucket()` method."
      },
      {
        "user": "ShanmugamC",
        "created_at": "2021-04-23T15:44:50Z",
        "body": "@mrniko Thanks a lot for your quick help !"
      }
    ],
    "satisfaction_conditions": [
      "Demonstrates reactive read/write operations for key-value pairs using RedissonReactiveClient",
      "Shows handling of String keys and Java object values",
      "Uses standard Redisson reactive interfaces/methods"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:52:36"
    }
  },
  {
    "number": 3546,
    "title": "Object not added in RSet",
    "created_at": "2021-04-12T08:04:23Z",
    "closed_at": "2021-04-13T05:43:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3546",
    "body": "In the below code, we are facing intermittent issues where` System.out.println(\"Your Ids: \"+ids1)` is not printed when we add something and RedissionSet reference doesn't contain anything even after adding objects to it.\r\n```\r\nfinal Set<String> homeIds = platformCache.getSet(Home.fetchProductCacheKey(productId));\r\n\r\nList<String> getIds = callToDb.getProductId(productId);\r\n\r\nfor(String ids : getIds) {\r\nhomeIds.add(ids);\r\n}\r\n\r\nfor(String ids1: homeIds) { // This for loop is not run since homeids were empty sometimes.\r\nSystem.out.println(\"Your Ids: \"+ids1);\r\n}\r\n\r\n```\r\n\r\nAre we doing anything wrong? Any help will be appreciated.",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3546/comments",
    "author": "vipul1231",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-04-12T08:53:19Z",
        "body": "Try ReadMode.MASTER setting"
      },
      {
        "user": "vipul1231",
        "created_at": "2021-04-12T10:10:54Z",
        "body": "I believe this setting will move reading data to master node ?. This will increase traffic to my master node. Please correct me if I am wrong."
      },
      {
        "user": "mrniko",
        "created_at": "2021-04-12T12:43:20Z",
        "body": "This issue happens due to replication lag between slave/master nodes."
      },
      {
        "user": "vipul1231",
        "created_at": "2021-04-13T05:43:13Z",
        "body": "Ok thanks. Closing this issue."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why added elements might not be immediately visible in a distributed set",
      "Guidance on ensuring data consistency in Redis-based distributed collections",
      "Approaches to handle asynchronous replication in distributed caching systems",
      "Configuration strategies for read/write consistency in Redisson"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:53:01"
    }
  },
  {
    "number": 3544,
    "title": "Why ExpirationEntry use LinkedHashMap to save threadId",
    "created_at": "2021-04-09T09:28:20Z",
    "closed_at": "2021-04-13T02:50:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3544",
    "body": "Reddison watchDog strategy use timerTask to increase key expiration time while set the lock success\r\n\r\n    private void renewExpiration() {\r\n        ExpirationEntry ee = EXPIRATION_RENEWAL_MAP.get(getEntryName());\r\n        if (ee == null) {\r\n            return;\r\n        }\r\n        \r\n        Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() {\r\n            @Override\r\n            public void run(Timeout timeout) throws Exception {\r\n                ExpirationEntry ent = EXPIRATION_RENEWAL_MAP.get(getEntryName());\r\n                if (ent == null) {\r\n                    return;\r\n                }\r\n                Long threadId = ent.getFirstThreadId();\r\n                if (threadId == null) {\r\n                    return;\r\n                }\r\n                \r\n                RFuture<Boolean> future = renewExpirationAsync(threadId);\r\n                ......\r\n       }\r\n   }\r\n\r\n  First use **entryName** to get ExpirationEntry object. For the same entryName, other threads can't get the key because locked(ps: same thread can get and counter++)\uff0cso why use LinkedHashMap to save thread if there only have one thread?\r\n\r\n`public static class ExpirationEntry {\r\n\r\n        private final Map<Long, Integer> threadIds = new LinkedHashMap<>();\r\n        private volatile Timeout timeout;\r\n\r\n        public ExpirationEntry() {\r\n            super();\r\n        }\r\n\r\n        public synchronized void addThreadId(long threadId) {\r\n            Integer counter = threadIds.get(threadId);\r\n            if (counter == null) {\r\n                counter = 1;\r\n            } else {\r\n                counter++;\r\n            }\r\n            threadIds.put(threadId, counter);\r\n        }\r\n}`",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3544/comments",
    "author": "yukerui",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-04-12T13:14:20Z",
        "body": "in case of readwrite lock there are might be multiple read locks."
      },
      {
        "user": "yukerui",
        "created_at": "2021-04-13T02:50:36Z",
        "body": "> in case of readwrite lock there are might be multiple read locks.\r\n\r\nUnderstood, thank you for your reply"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of concurrency scenarios where multiple threads might interact with the same lock entry",
      "Clarification of how lock reentrancy or multiple lock types affect thread tracking",
      "Identification of use cases requiring thread ID counting beyond simple single-threaded locking"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:53:11"
    }
  },
  {
    "number": 3493,
    "title": "Transaction in Redis Live Object Service",
    "created_at": "2021-03-16T21:14:11Z",
    "closed_at": "2021-03-18T06:56:07Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3493",
    "body": "Hi,\r\n\r\nIs it possible to perform transaction on Redis Live Object?\r\nI want write a new instance of MyClass - only if new instance is newer than previous one. \r\nI need method similar to 'merge' in RMap. \r\n\r\n    @REntity\r\n    public class MyClass {\r\n\r\n        @RId\r\n        private String key;\r\n\r\n        @RIndex\r\n        public Date createDate;\r\n\r\n        @RIndex\r\n        public String externalValue;\r\n     }\r\n\r\nSo I need to compare dates of old and new objects and then save new object only if it newer. It has be executed in one transaction. In other thread someone can update fields in this object.",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3493/comments",
    "author": "bbartekb",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-03-17T08:46:35Z",
        "body": "Wrap this function with RLock object with name based on object id."
      },
      {
        "user": "bbartekb",
        "created_at": "2021-03-17T21:33:02Z",
        "body": "Thank you for your response!\r\n\r\nIt works for me with tryLock()\r\n\r\n    public void updateLiveObjectEntry(MyClass myObject) {\r\n        RLiveObjectService rLiveObjectService = getRedissonConnection().getClient().getLiveObjectService();\r\n        RLock lock = getRedissonConnection().getClient().getLock(myObject.getKey());\r\n\r\n        try {\r\n            lock.tryLock(10, TimeUnit.SECONDS);\r\n            if (myObject.getCreateDate().after(rLiveObjectService.get(MyClass.class, myObject.getKey()).getCreateDate())) {\r\n                rLiveObjectService.merge(myObject);\r\n            }\r\n        } catch (InterruptedException e) {\r\n        } finally {\r\n            lock.unlock();\r\n        }\r\n    }\r\n    \r\nIs my solution correct? \r\nI think this lock is not connected with my LiveObject, so myObject entry is not locked. It will be work if in all usage I use method updateLiveObjectEntry().\r\n    "
      },
      {
        "user": "mrniko",
        "created_at": "2021-03-18T05:31:12Z",
        "body": "you can use follow lock name: `String lockName = MyClass.class.getName() + \":\" + myObject.getKey()`. If you have any doubts about the key uniqueness with different Object classes."
      }
    ],
    "satisfaction_conditions": [
      "Atomic check-and-update operation",
      "Concurrency control mechanism",
      "Lock scope tied to object identity",
      "Version validation based on temporal ordering",
      "Cross-process synchronization"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:53:18"
    }
  },
  {
    "number": 3398,
    "title": "org.redisson.api.RAtomicLong#expireAt(long)  Cause the value to be deleted  ",
    "created_at": "2021-02-03T07:55:21Z",
    "closed_at": "2021-02-03T07:59:08Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3398",
    "body": "Redisson:3.15.0\r\nredis:4.0.9\r\n\r\norg.redisson.api.RAtomicLong#expireAt(long)\r\nCannot find the key of aKey after execution\r\n\r\nWhy is this ?\r\n\r\njava code\r\n```\r\n        Config config = new Config();\r\n        config.useSingleServer()\r\n                .setAddress(\"redis://127.0.0.1:6379\")\r\n                .setDatabase(0);\r\n        RedissonClient redissonClient = Redisson.create(config);\r\n\r\n        String aKey = \"aKey\";\r\n        RAtomicLong aAtomic = redissonClient.getAtomicLong(aKey);\r\n        long aValue0 = aAtomic.get();\r\n        LOG.info(\"aKey-value0[{}]\", aValue0);\r\n\r\n        aAtomic.incrementAndGet();\r\n        long aValue1 = aAtomic.get();\r\n        LOG.info(\"aKey-value1[{}]\", aValue1);\r\n        aAtomic.expireAt(1000 * 60 * 60);\r\n\r\n        long aValue2 = aAtomic.get();\r\n        LOG.info(\"aKey-value2[{}]\", aValue2);\r\n\r\n        LOG.info(\"---------------------------------------------------------\");\r\n\r\n        String bKey = \"bKey\";\r\n        RAtomicLong bAtomic = redissonClient.getAtomicLong(bKey);\r\n        long bValue0 = bAtomic.get();\r\n        LOG.info(\"bKey-value0[{}]\", bValue0);\r\n\r\n        bAtomic.incrementAndGet();\r\n        bAtomic.expire(10, TimeUnit.HOURS);\r\n\r\n        long bValue1 = bAtomic.get();\r\n        LOG.info(\"bKey-value1[{}]\", bValue1);\r\n\r\n        LOG.info(\"---------------------------------------------------------\");\r\n\r\n        String cKey = \"cKey\";\r\n        RAtomicLong cAtomic = redissonClient.getAtomicLong(cKey);\r\n        long cValue0 = cAtomic.get();\r\n        LOG.info(\"cKey-value0[{}]\", cValue0);\r\n\r\n        cAtomic.incrementAndGet();\r\n\r\n        long cValue1 = cAtomic.get();\r\n        LOG.info(\"cKey-value1[{}]\", cValue1);\r\n\r\n        redissonClient.shutdown();\r\n```\r\nlog...\r\n```\r\n15:45:35.913 [main] INFO org.redisson.Version - Redisson 3.15.0\r\n15:45:36.804 [redisson-netty-2-17] INFO org.redisson.connection.pool.MasterPubSubConnectionPool - 1 connections initialized for /127.0.0.1:6379\r\n15:45:36.817 [redisson-netty-2-17] INFO org.redisson.connection.pool.MasterConnectionPool - 24 connections initialized for /127.0.0.1:6379\r\n15:45:36.877 [main] INFO RedissonClient - aKey-value0[0]\r\n15:45:36.880 [main] INFO RedissonClient - aKey-value1[1]\r\n15:45:36.881 [main] INFO RedissonClient - aKey-value2[0]\r\n15:45:36.881 [main] INFO RedissonClient - ---------------------------------------------------------\r\n15:45:36.882 [main] INFO RedissonClient - bKey-value0[0]\r\n15:45:36.886 [main] INFO RedissonClient - bKey-value1[1]\r\n15:45:36.887 [main] INFO RedissonClient - ---------------------------------------------------------\r\n15:45:36.887 [main] INFO RedissonClient - cKey-value0[0]\r\n15:45:36.889 [main] INFO RedissonClient - cKey-value1[1]\r\n```\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3398/comments",
    "author": "NoSugarIce",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-02-03T07:59:08Z",
        "body": "Because `expireAt()` method accepts date in milliseconds."
      },
      {
        "user": "NoSugarIce",
        "created_at": "2021-02-03T08:10:28Z",
        "body": "> Because `expireAt()` method accepts date in milliseconds.\r\n\r\n@mrniko Thanks, I realized the problem when I saw the code comments a few minutes after issuing the question ."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why expireAt() causes immediate key deletion in this context",
      "Clarification of parameter requirements for RAtomicLong.expireAt()",
      "Differentiation between expireAt() and expire() method behaviors",
      "Explanation of how Redisson handles expiration timestamps in the past"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:53:32"
    }
  },
  {
    "number": 3390,
    "title": "RBatch response order with cluster env ?",
    "created_at": "2021-01-28T16:31:38Z",
    "closed_at": "2021-02-05T06:19:16Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3390",
    "body": "> In cluster environment batch executed in map\\reduce way. It aggregates commands for each node and sends them simultaneously, then result got from each node added to common result list.\r\n\r\n```\r\n\r\n    /**\r\n     * Executes all operations accumulated during async methods invocations.\r\n     * <p>\r\n     * If cluster configuration used then operations are grouped by slot ids\r\n     * and may be executed on different servers. Thus command execution order could be changed\r\n     *\r\n     * @return List with result object for each command\r\n     * @throws RedisException in case of any error\r\n     *\r\n     */\r\n    BatchResult<?> execute() throws RedisException;\r\n```\r\n\r\nRead above tips, I was not sure about responses order for origin commands.\r\nCould you help me make sure about this?\r\n\r\n1.When commands send group by slots, but I want know responses order is right with original commands?\r\n\r\n\r\nthx~ ",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3390/comments",
    "author": "waylink",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-01-29T07:03:15Z",
        "body": "You'll always get correct response, but in cluster environment result in BatchResult can have different order."
      },
      {
        "user": "waylink",
        "created_at": "2021-01-29T07:12:57Z",
        "body": "> You'll always get correct response, but in cluster environment result in BatchResult can have different order.\r\n\r\n~~in cluster env result in batchResult have different order.~~\r\n\r\nHow to understand ?  in cluster env"
      },
      {
        "user": "mrniko",
        "created_at": "2021-01-31T09:37:01Z",
        "body": "result has different order since single request spliced into different requests and executed concurrently on different Redis nodes. If keys of such commands don't belong to the same master node."
      },
      {
        "user": "waylink",
        "created_at": "2021-01-31T10:13:27Z",
        "body": "> result has different order since single request spliced into different requests and executed concurrently on different Redis nodes. If keys of such commands don't belong to the same master node.\r\n\r\nall right.\r\n\r\nInvoker always get correct response in cluster env.\r\n\r\nOnly warning : BatchResult[] has different order for execute in cluster env."
      },
      {
        "user": "mrniko",
        "created_at": "2021-02-05T06:19:14Z",
        "body": "It's better to attach handler to each command executed in RBatch rather than use result list:\r\n\r\n```java\r\n\t\tRBatch batch = client.createBatch(batchOptions);\r\n\t\tfor (int i = 0; i < 10; i++) {\r\n\t\t\tString key = \"\" + i;\r\n                        RFuture<Object> t = batch.getBucket(key).getAsync();\r\n                        t.whenComplete((res, ex) -> {\r\n                \r\n                       });\r\n\t\t}\r\n\t\tbatch.execute();\r\n```"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how command grouping by slot affects response order in cluster environments",
      "Clear statement about response order guarantees when commands target multiple nodes",
      "Guidance on maintaining command-response correlation without relying on list order",
      "Identification of scenarios where order preservation is possible/impossible"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:53:37"
    }
  },
  {
    "number": 3187,
    "title": "Behavior of locks vs conditions like network partition",
    "created_at": "2020-11-04T14:00:54Z",
    "closed_at": "2020-11-05T11:44:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3187",
    "body": "Hello everyone,\r\n\r\nCouldn't find my answer in docs or by looking briefly at the implementation, so posting the question here.\r\n\r\nLet's assume a system, where X instances of the same application are working concurrently on processing some data. In general, the instances can work concurrently, but some specific data items must not be processed at the same time by more than one instance, as this would produce race condition.\r\n\r\nTo synchronize application instances and avoid race conditions, we've set up a Redis instance, and we use Redisson's locking mechanism to achieve exclusive execution. In general, the workflow for an instance looks like this:\r\n(take a lock A) -> (process data) -> (release lock A)\r\n\r\nThen, obviously, the other instances, that want to process the conflicting data item, need to wait for lock A to be released. Processing an item can take anywhere between several seconds and several days. so a lock might be held for a long time (and we use this auto-renewal feature for locks to have the lock prolonged as needed behind the scenes by Redisson).\r\n\r\nMy question is - what happens if an instance, that is currently holding the lock, loses connectivity to Redis (and therefore the lock times out and is then taken by another instance), and then after some time it regains the connectivity? Will it finish processing the data without holding the lock, and then fail on releasing the lock? Or maybe something else would happen?\r\n\r\nI'd really appreciate your feedback on this.\r\n\r\nBest Regards,\r\nPawe\u0142",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3187/comments",
    "author": "pnaw94",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-11-04T15:44:25Z",
        "body": "> Will it finish processing the data without holding the lock, and then fail on releasing the lock?\r\n\r\nIt will finish without holding lock if connectionWatchdogTimeout occured by that moment."
      },
      {
        "user": "pnaw94",
        "created_at": "2020-11-05T11:44:58Z",
        "body": "@mrniko thanks for the answer! I think that's all I need at that point."
      }
    ],
    "satisfaction_conditions": [
      "Clarifies the behavior of Redisson locks when an instance loses and regains Redis connectivity",
      "Explains how lock expiration/auto-renewal interacts with prolonged disconnections"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:53:58"
    }
  },
  {
    "number": 3108,
    "title": "RMap's values(pattern) doesn't seem to work on a simple test",
    "created_at": "2020-10-07T13:18:25Z",
    "closed_at": "2020-11-11T08:12:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3108",
    "body": "The following simple test doesn't seem to work:\r\n```@Test\r\n    public void test() {\r\n\r\n        String mapName = UUID.randomUUID().toString();\r\n        RMap<String, String> map = redissonClient.getMap(mapName, JsonJacksonCodec.INSTANCE);\r\n\r\n        try {\r\n            map.put(\"prefix_1_1_\", \"1\");\r\n            map.put(\"prefix_1_2_\", \"2\");\r\n            map.put(\"prefix_2_3_\", \"3\");\r\n            map.put(\"prefix_2_4_\", \"4\");\r\n\r\n            Collection<String> entries = map.values(\"prefix*\");\r\n\r\n            assertThat(entries).hasSize(4);\r\n        } finally {\r\n            redissonClient.getMap(mapName).delete();\r\n        }\r\n    }\r\n```\r\nVersion of redisson is 3.13.4\r\nI'm pretty sure I'm missing something here so didn't post it as a bug",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3108/comments",
    "author": "peterlitvak",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-10-07T14:33:27Z",
        "body": "You need to use StringCodec for map keys."
      },
      {
        "user": "peterlitvak",
        "created_at": "2020-10-07T14:42:31Z",
        "body": "Does it mean I need to create my own codec with JsonJacksoCodec for the values (since I need values to be JSON encoded objects) and StringCodec for the keys?"
      },
      {
        "user": "mrniko",
        "created_at": "2020-10-07T14:43:39Z",
        "body": "You can use CompositeCodec to use StringCodec for keys and JsonJacksonCodec for values"
      },
      {
        "user": "peterlitvak",
        "created_at": "2020-10-07T14:44:19Z",
        "body": "Thank you!"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of codec requirements for pattern matching in RMap keys",
      "Support for different serialization formats between keys and values",
      "Compatibility with Redisson's pattern matching functionality",
      "Clear guidance on codec composition"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:54:28"
    }
  },
  {
    "number": 2897,
    "title": "Strange characters on value when read data in other language",
    "created_at": "2020-07-06T18:45:50Z",
    "closed_at": "2020-07-07T11:43:46Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2897",
    "body": "Hey there!\r\n\r\nI was wondering if it's possible to perform a simple operation like we do on Redis StackExchange (c#) client:\r\n\r\n```\r\nIDatabase db = redis.GetDatabase();\r\nstring value = \"abcdefg\";\r\nvar expires = 1000;\r\ndb.StringSet(\"mykey\", value, expires);\r\n...\r\nstring value = db.StringGet(\"mykey\");\r\nConsole.WriteLine(value); // writes: \"abcdefg\r\n```\r\n\r\nRight now I'm using a Map but I would like to make it simple as this example on C#. \r\n\r\n```\r\n    override fun put(collection: String, key: String, value: String, expiresInSeconds: Long) {\r\n        logger.info(\"Storing key $key into collection $collection\")\r\n        val cacheMap = getMapCache(collection)\r\n\r\n        cacheMap.put(key, value, 3600, TimeUnit.SECONDS)\r\n    }\r\n\r\n    private fun getMapCache(collection: String) = redissonClient.getMapCache<String, String>(\"any\", StringCodec())\r\n```\r\n\r\nWhen I try to retrieve values fro other clients like C# or Python, I got some strange characters on value like `????????\ufffd\u0003??????myvalue`.\r\n\r\nIs there any option to clear/remove those characters on Redisson and store it as plain string?\r\n\r\nIs there any option to store it simple as we do in C#?",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2897/comments",
    "author": "daviddelucca",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-07-07T04:37:33Z",
        "body": "Here is how you can do the same with Redisson:\r\n\r\n```java\r\nRBucket b = redisson.getBucket(\"mykey\", StringCodec.INSTANCE);\r\nb.set(\"value\", 1, TimeUnit.SECONDS);\r\n\r\nb.get(); // = \"value\"\r\n```\r\n\r\n> When I try to retrieve values fro other clients like C# or Python, I got some strange characters on value like ????????\ufffd\ufffd??????myvalue.\r\n\r\nBecause default Redisson codec is `MarshallingCodec`"
      },
      {
        "user": "daviddelucca",
        "created_at": "2020-07-07T09:12:38Z",
        "body": "Is possible to remove those characters or create a custom codec?\r\n\r\n"
      },
      {
        "user": "mrniko",
        "created_at": "2020-07-07T11:20:56Z",
        "body": "You can use StringCodec instead"
      },
      {
        "user": "daviddelucca",
        "created_at": "2020-07-07T11:43:54Z",
        "body": "Thank you very much!"
      }
    ],
    "satisfaction_conditions": [
      "Ensure string values are stored/retrieved without serialization artifacts across clients",
      "Support simple string storage equivalent to Redis' native string operations",
      "Use a codec that performs plain UTF-8 string encoding",
      "Avoid data structure-specific serialization overhead"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:54:41"
    }
  },
  {
    "number": 2844,
    "title": "Is it possible to access to the data maintained or written by Redisson in Nodejs? And would it be a bad practice?",
    "created_at": "2020-06-17T04:51:15Z",
    "closed_at": "2020-06-29T06:23:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2844",
    "body": "Hi, I have using Redisson for not a long time, and I realize that I need my old project to access to Redis and retrieve data that is maintained by the current Java code which use Redisson. \r\nBut Redisson is not just a redis client but a In-Memory Data Grid, therefore it's quite different and not compatible friendly for nodejs program for it only has pure redis client tools to use. \r\nSo the idea I have is:\r\n1. Write a Java Redisson program as a proxy and serve data for nodejs program. \r\n2. Figure out how Redisson save data, for sorted set, and Bucket, and write a package for nodejs to decode data from Redis. \r\n3. Give up Redisson and use pure redis client, like Redis. \r\n\r\nIs there any other solutions? Or is there any nodejs middleware for Redisson? Would that be difficult to write one for Redisson(I haven't read much source code of Redisson yet)? \r\nThanks. ",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2844/comments",
    "author": "XLCYun",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-06-17T04:54:52Z",
        "body": "> But Redisson is not just a redis client but a In-Memory Data Grid, therefore it's quite different and not compatible friendly for nodejs program for it only has pure redis client tools to use.\r\n\r\nIt's still remains redis client and compatible with others as long as they store the data in the same format."
      },
      {
        "user": "XLCYun",
        "created_at": "2020-06-17T05:43:41Z",
        "body": "> > But Redisson is not just a redis client but a In-Memory Data Grid, therefore it's quite different and not compatible friendly for nodejs program for it only has pure redis client tools to use.\r\n> \r\n> It's still remains redis client and compatible with others as long as they store the data in the same format.\r\n\r\nHi, thanks for you reply. I see that Redisson use `Marshalling` Codec as default codec, and it store `true` as `\"\\x04P\"` and `false` as `\"\\x04Q\"`, and String `\"A\"` as `\"\\x04>\\x01A\"`.\r\nI think these prefixes are added by `MarshallingCodec`, so are you saying I should write a nodejs program to decode these value if it's possible, or I should write a Codec on my own? \r\nAm I going to the right direction and which one should be preferred by your opinion? Thanks. "
      },
      {
        "user": "mrniko",
        "created_at": "2020-06-17T07:17:20Z",
        "body": "You can use json codec, for example."
      },
      {
        "user": "XLCYun",
        "created_at": "2020-06-29T06:23:55Z",
        "body": "Locks maintained by Redisson might be bit tricky to cooperate with in Node.js. Use `JsonJacksonCodec` or other codec is easy for sharing data between different program written in different language. Issue closed, thanks for the help @mrniko . "
      }
    ],
    "satisfaction_conditions": [
      "Enable data interoperability between Redisson (Java) and Node.js programs",
      "Provide a maintainable approach for cross-language data serialization/deserialization",
      "Avoid requiring complete migration away from Redisson"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:54:49"
    }
  },
  {
    "number": 2842,
    "title": "How to retrieve DelayedQueue by name using getDelayedQueue",
    "created_at": "2020-06-17T02:39:53Z",
    "closed_at": "2020-06-17T14:42:38Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2842",
    "body": "Want to understand how to retrieve delayed queue (RDelayedQueue) by name using getDelayedQueue method on org.redisson.api.RedissonClient. \r\n\r\nDoes it require to call redissonClient.getDelayedQueue(destinationQueue) every time before queuing a message as below or retrieve queue once and use it for every message queuing ?\r\n\r\nRDelayedQueue..offer(message, delayInMillisFromCurrent, TimeUnit.MILLISECONDS);",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2842/comments",
    "author": "anilkonduru",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-06-17T04:52:10Z",
        "body": "No, you can store RDelayedQueue instance and use it."
      },
      {
        "user": "anilkonduru",
        "created_at": "2020-06-17T14:42:38Z",
        "body": "@mrniko Thanks, that helps."
      }
    ],
    "satisfaction_conditions": [
      "Clarifies whether RDelayedQueue instances can be reused after initial retrieval",
      "Addresses performance implications of multiple getDelayedQueue() calls"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:54:56"
    }
  },
  {
    "number": 2782,
    "title": "How to configure scheduling times? ",
    "created_at": "2020-05-19T03:56:55Z",
    "closed_at": "2020-05-19T05:29:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2782",
    "body": "When using the periodic scheduling method\uff08e.g. RScheduledExecutorService.scheduleAtFixedRate\uff09, I want to stop scheduling after a specified number of times. What should I do?\r\nThanks!",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2782/comments",
    "author": "hgqapp",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-05-19T05:29:49Z",
        "body": "You can implement this logic right in the task.\r\n\r\n```java\r\nclass RunnableTask implements Runnable {\r\n\r\n    @RInject\r\n    private RedissonClient redissonClient;\r\n\r\n    @RInject\r\n    private String taskId;\r\n\r\n    public void run() {\r\n         if (redissonClient.getAtomicLong(\"\").incrementAndGet() == 10) {\r\n              redissonClient.getExecutorService(\"\").cancelTask(taskId);\r\n         }\r\n    }\r\n}\r\n```"
      },
      {
        "user": "hgqapp",
        "created_at": "2020-05-19T06:04:34Z",
        "body": "@mrniko Thanks, your answer is very useful to me."
      }
    ],
    "satisfaction_conditions": [
      "Mechanism to track and limit the number of task executions",
      "Automatic cancellation of the scheduled task when limit is reached",
      "Integration with the scheduling framework's task management",
      "No external manual intervention required"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:55:01"
    }
  },
  {
    "number": 2538,
    "title": "\u6570\u636e\u7c7b\u578b\u95ee\u9898",
    "created_at": "2020-01-13T07:40:33Z",
    "closed_at": "2020-01-13T08:12:31Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2538",
    "body": "\u6211\u7528spring\u4e2d\u7684@cacheable\u65f6\uff0c\u4ece\u6570\u636e\u5e93\u4e2d\u53d6\u51fa\u6765\u51c6\u5907\u5e8f\u5217\u5316\u5b58\u5230redis\u4e2d\u7684\u6570\u636e\u662fByte\u7c7b\u578b\uff0c\u4f46\u662f\u518d\u4eceredis\u4e2d\u67e5\u51fa\u6765\u8fd4\u56de\u7684\u5374\u662fInteger\uff0c\u8fd9\u4e2a\u662f\u9700\u8981\u4fee\u6539redisson\u7684\u6570\u636e\u5e8f\u5217\u5316\u65b9\u5f0f\u5417\uff1f\u6211\u8bd5\u4e86\u4e00\u4e0b\u5305\u88c5\u7c7bShort\u3001Byte\u90fd\u4f1a\u53d8\u6210Integer\uff0cCharacter\u4f1a\u53d8\u6210String\uff0cFloat\u4f1a\u53d8\u6210Double\u3002",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2538/comments",
    "author": "MarionSong",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-01-13T08:06:07Z",
        "body": "Which codec do you use?"
      },
      {
        "user": "MarionSong",
        "created_at": "2020-01-13T08:10:45Z",
        "body": "JsonJacksonCodec"
      },
      {
        "user": "mrniko",
        "created_at": "2020-01-13T08:12:31Z",
        "body": "Switch to FST, KryoCodec or SerializationCodec"
      },
      {
        "user": "MarionSong",
        "created_at": "2020-01-13T09:01:23Z",
        "body": "thank you \uff0cI switch to SerializationCodec"
      }
    ],
    "satisfaction_conditions": [
      "Ensures Redis serialization/deserialization preserves original data types",
      "Addresses type safety in cache storage/retrieval workflow"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:55:26"
    }
  },
  {
    "number": 2524,
    "title": "Deserialization the object from redis to RList throws InvocationTargetException",
    "created_at": "2020-01-07T09:19:40Z",
    "closed_at": "2020-01-07T09:21:26Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2524",
    "body": "Deserialization the object from redis to RList throws InvocationTargetException\r\n\r\nredisson:3.12.0\r\nfst:2.56\r\n1.8.0_152\r\n\r\nstacktrace:\r\n\r\n`\r\nCaused by: java.lang.reflect.InvocationTargetException: null\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n\tat org.redisson.command.RedisExecutor.getCodec(RedisExecutor.java:681)\r\n\t... 109 common frames omitted\r\nCaused by: java.lang.NoSuchMethodError: org.nustaq.serialization.FSTConfiguration.getJsonFieldNames()Lorg/nustaq/serialization/coders/FSTJsonFieldNames;\r\n\tat org.redisson.codec.FstCodec.copy(FstCodec.java:201)\r\n\tat org.redisson.codec.FstCodec.<init>(FstCodec.java:190)\r\n\t... 114 common frames omitted\r\n`\r\n\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2524/comments",
    "author": "fengzhenxing",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-01-07T09:21:26Z",
        "body": "`java.lang.NoSuchMethodError: org.nustaq.serialization.FSTConfiguration.getJsonFieldNames`\r\n\r\nmake sure you have latest version of fst codec in classpath"
      },
      {
        "user": "fengzhenxing",
        "created_at": "2020-01-07T09:26:47Z",
        "body": "@mrniko yes. The lastest fst codec version is 2.57.Thanks"
      },
      {
        "user": "mrniko",
        "created_at": "2020-01-07T09:28:20Z",
        "body": "Unable to reproduce it."
      },
      {
        "user": "fengzhenxing",
        "created_at": "2020-01-07T09:29:40Z",
        "body": "@mrniko I add the lastest fst codec version,then throws NPE.\r\n\r\nstacktrace:\r\n\r\n`\r\njava.io.IOException: java.lang.NullPointerException\r\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:247)\r\n\tat org.redisson.codec.FstCodec$1.decode(FstCodec.java:250)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:368)\r\n\tat org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:493)\r\n\tat io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:271)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:355)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.NullPointerException: null\r\n\tat org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:357)\r\n\tat org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331)\r\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:311)\r\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:245)\r\n\t... 24 common frames omitted\r\n`"
      },
      {
        "user": "mrniko",
        "created_at": "2020-01-07T09:30:35Z",
        "body": "is there code example to reproduce it?"
      },
      {
        "user": "fengzhenxing",
        "created_at": "2020-01-07T09:35:01Z",
        "body": "Here is some example code:\r\n\r\n`\r\nRList<ExampleObject> serviceUserList = redisson.getList(key);\r\n`\r\nif I add  new properties in ExampleObject,then throws NPE. The properties of exampleObject stored in redis is not equals"
      },
      {
        "user": "mrniko",
        "created_at": "2020-01-07T09:36:56Z",
        "body": "> if I add new properties in ExampleObject,then throws NPE. The properties of exampleObject stored in redis is not equals\r\n\r\nConsider to use JacksonCodec for this purpose."
      },
      {
        "user": "fengzhenxing",
        "created_at": "2020-01-07T09:38:19Z",
        "body": "yes,I replace the type of codec so it works.\r\n\r\n"
      }
    ],
    "satisfaction_conditions": [
      "Solution must address serialization/deserialization compatibility issues when modifying object schemas",
      "Must provide a way to handle version mismatches between serialized data and current class definitions",
      "Should support schema evolution without requiring complete data migration",
      "Must work with Redisson's data structure implementations (like RList)",
      "Should explain codec selection criteria for evolving data schemas"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:55:54"
    }
  },
  {
    "number": 1860,
    "title": "Why does RMapCache is designed to use Hash instead of simple key-value structure?",
    "created_at": "2019-01-16T02:58:44Z",
    "closed_at": "2019-01-17T11:58:34Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/1860",
    "body": "\r\nI am curious why RMapCache is designed to use Hash instead of simple key-value structure? Simple key-value can use TTL while Hash cannot. What benefit does RMapCache get when using Hash compared with using key-value?\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/1860/comments",
    "author": "a2232189",
    "comments": [
      {
        "user": "jackygurui",
        "created_at": "2019-01-16T22:32:35Z",
        "body": "`Simple key-value can use TTL while Hash cannot.` I think you have just answered your own question here. \r\n\r\nThere are use cases where string structure would be more suitable than hash and vice versa, RMapCache is here to bridge the gap between them. "
      },
      {
        "user": "a2232189",
        "created_at": "2019-01-17T02:44:40Z",
        "body": "Some want to save the data in redis with TTL and some want to save the data in redis forever, so you choose to use a never-out-ouf-date strcture `HASH` to save all data, and run a schedule task to delete those data that are set with TTL. Am my understand right?\r\n\r\nIf my conclusion above is right, I think that you choose to use `hash` instead of simple key-value is because the maintainability. Since it's easier to maintain the code if the data structure is only `hash`, compared with the thought that when user choose to save data with TTL, Redisson use `simple key-value` and when ser choose to save data forever (without TTL), Redisson use `Hash`.\n\n---\n\n> I think that you choose to use `hash` instead of simple key-value is because the maintainability. Since it's easier to maintain the code if the data structure is only `hash`, compared with the thought that when user choose to save data with TTL, Redisson use `simple key-value` and when ser choose to save data forever (without TTL), Redisson use `Hash`.\r\n\r\nAm my conclusion right here?"
      },
      {
        "user": "jackygurui",
        "created_at": "2019-01-17T11:27:21Z",
        "body": "Redisson doesn't choose data types between string and hash on user's behalf. If the user wants to use string, he/she can use RBucket, if he/she wants to use hash, then there is RMap for the job. Other map objects Redisson offers are complementary to provide extra functionalities that vanila hash doesn't do. \r\n\r\nUsers decide which data type they need, Redisson provides every possibilities for them. I hope I have answered your question."
      },
      {
        "user": "a2232189",
        "created_at": "2019-01-17T11:58:34Z",
        "body": "Didn't know `RBucket`  before. thanks."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of the design rationale for choosing Hash over simple key-value in RMapCache",
      "Comparison of use cases for different Redis data structures (Hash vs String)",
      "Description of how Redisson's design philosophy addresses multiple data structure needs"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:56:00"
    }
  },
  {
    "number": 1706,
    "title": "What is the best practice for setting local caches ttl against Redis caches?",
    "created_at": "2018-10-30T07:35:33Z",
    "closed_at": "2018-10-31T12:15:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/1706",
    "body": "Is it correct if Redis cache ttl is the same as timeToLiveInMillis for local cache?\r\n\r\nMY_CACHE: \r\n ttl: 300000\r\n maxIdleTime: 300000\r\n maxSize: 1000\r\n \r\n localCacheOptions:\r\n    evictionPolicy: \"LRU\"\r\n    reconnectionStrategy: \"CLEAR\"\r\n    syncStrategy: \"INVALIDATE\"\r\n    writeMode: \"WRITE_THROUGH\"\r\n    cacheSize: 1000\r\n    timeToLiveInMillis: 300000\r\n    maxIdleInMillis: 300000",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/1706/comments",
    "author": "bkoroliuk-amplify",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2018-10-30T08:12:59Z",
        "body": "Do you use RMapCache and RLocalCachedMapCache under the same name?"
      },
      {
        "user": "bkoroliuk-amplify",
        "created_at": "2018-10-30T08:54:09Z",
        "body": "> Do you use RMapCache and RLocalCachedMapCache under the same name?\r\n\r\nyes"
      },
      {
        "user": "mrniko",
        "created_at": "2018-10-30T08:55:39Z",
        "body": "That's a bad idea, since compatibility between these objects is not guaranteed."
      },
      {
        "user": "bkoroliuk-amplify",
        "created_at": "2018-10-30T08:58:34Z",
        "body": "What about this setup? (max ttl for local caches)\r\n```\r\nMY_CACHE:\r\nttl: 300000\r\nmaxIdleTime: 300000\r\nmaxSize: 1000\r\n\r\nlocalCacheOptions:\r\nevictionPolicy: \"LRU\"\r\nreconnectionStrategy: \"CLEAR\"\r\nsyncStrategy: \"INVALIDATE\"\r\nwriteMode: \"WRITE_THROUGH\"\r\ncacheSize: 1000\r\ntimeToLiveInMillis: 0\r\nmaxIdleInMillis: 0\r\n```\r\n"
      },
      {
        "user": "mrniko",
        "created_at": "2018-10-30T09:04:48Z",
        "body": "That config looks correct. What is your concerns about it?"
      },
      {
        "user": "bkoroliuk-amplify",
        "created_at": "2018-10-31T12:15:57Z",
        "body": "@mrniko No concerns, thank you"
      },
      {
        "user": "mrniko",
        "created_at": "2018-10-31T12:16:26Z",
        "body": "@bkoroliuk-amplify \r\n\r\nYou're welcome!"
      }
    ],
    "satisfaction_conditions": [
      "Ensures compatibility between Redis cache and local cache configurations",
      "Provides clear guidance on TTL relationship between distributed and local caches",
      "Addresses potential conflicts in cache eviction strategies",
      "Validates configuration against connection failure handling best practices"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:56:08"
    }
  },
  {
    "number": 1687,
    "title": "Default values for local cache in RedissonSpringLocalCachedCacheManager",
    "created_at": "2018-10-23T14:46:37Z",
    "closed_at": "2018-10-24T17:45:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/1687",
    "body": "What are default values for the mentioned below properties?\r\nAre these values from LocalCachedMapOptions::defaults()?\r\nI see that local caches work, but only ttl, idle and maxSize are defined.\r\n```\r\n localCacheOptions:\r\n    evictionPolicy: \"LRU\"\r\n    reconnectionStrategy: \"CLEAR\"\r\n    syncStrategy: \"UPDATE\"\r\n    writeMode: \"WRITE_THROUGH\"\r\n    cacheSize: 1000\r\n    timeToLiveInMillis: 300000\r\n    maxIdleInMillis: 300000\r\n```",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/1687/comments",
    "author": "bkoroliuk-amplify",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2018-10-24T14:39:26Z",
        "body": "> What are default values for the mentioned below properties?\r\n\r\nevictionPolicy = NONE,\r\nreconnectionStrategy = NONE,\r\nsyncStrategy = INVALIDATE\r\nwriteMode = WRITE_THROUGH\r\ncacheSize = 0\r\ntimeToLiveInMillis = 0\r\nmaxIdleInMillis = 0\r\n\r\n> Are these values from LocalCachedMapOptions::defaults()?\r\n\r\nNo, seems config instance had been changed further in code."
      }
    ],
    "satisfaction_conditions": [
      "List default values for all properties mentioned in LocalCachedMapOptions configuration",
      "Clarify the relationship between LocalCachedMapOptions::defaults() and actual configuration values",
      "Identify discrepancies between documented defaults and actual observed behavior",
      "Explain configuration precedence in RedissonSpringLocalCachedCacheManager"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-04 23:56:14"
    }
  }
]