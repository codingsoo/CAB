[
  {
    "number": 10416,
    "title": "Always getting .nan reward while training with PPO or DQN",
    "created_at": "2020-08-29T04:38:03Z",
    "closed_at": "2020-08-30T02:54:07Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/ray-project/ray/issues/10416",
    "body": "<!--Please include [tune], [rllib], [autoscaler] etc. in the issue title if relevant-->\r\n\r\n### Can anyone please give me hints why I am always getting the following while training with PPO or DQN?\r\nepisode_len_mean: .nan\r\nepisode_reward_max: .nan\r\nepisode_reward_mean: .nan\r\nepisode_reward_min: .nan\r\nepisodes_this_iter: 0\r\nepisodes_total: 0\r\n\r\nRay Version: 0.8.7\r\nOS: macOS\r\n",
    "comments_url": "https://api.github.com/repos/ray-project/ray/issues/10416/comments",
    "author": "ashutosh1906",
    "comments": [
      {
        "user": "ericl",
        "created_at": "2020-08-29T07:15:57Z",
        "body": "`episodes_total: 0`. This is the reason. Until an episode has finished, we can't calculate any rewards. Does your env eventually return done=True at some point?"
      },
      {
        "user": "ashutosh1906",
        "created_at": "2020-08-30T02:54:07Z",
        "body": "Thank you. After putting \"done = True\" at some points, episodes_total becomes non-zero and does not return any .nan."
      }
    ],
    "satisfaction_conditions": [
      "Identifies why episodes_total remains at 0 during training",
      "Addresses environment termination conditions (done=True)",
      "Explains how to ensure environment episodes complete properly",
      "Provides methods to verify episode completion during training"
    ],
    "_classification": {
      "category": "Requires build environment but hard to be dockerized",
      "timestamp": "2025-04-04 23:53:56"
    }
  },
  {
    "number": 7467,
    "title": "[tune][rllib] _InactiveRpcError Deadline Exceeded",
    "created_at": "2020-03-05T16:32:58Z",
    "closed_at": "2020-04-22T17:22:40Z",
    "labels": [
      "question",
      "tune"
    ],
    "url": "https://github.com/ray-project/ray/issues/7467",
    "body": "<!--Please include [tune], [rllib], [autoscaler] etc. in the issue title if relevant-->\r\n\r\n### What is your question?\r\nI have VirtualBox running on Centos 7 and I am having trouble initializing Ray. After I run ray.init(), I get an _InactiveRpcError due to a Deadline Exceeded exception. What info should I provide in order to troubleshoot this error?\r\n\r\n\r\n*Ray version and other system information (Python version, TensorFlow version, OS):*\r\nray 0.8.2\r\nredis 3.4.1\r\nPython 3.6\r\nCentos 7 on VirtualBox",
    "comments_url": "https://api.github.com/repos/ray-project/ray/issues/7467/comments",
    "author": "Leonolovich",
    "comments": [
      {
        "user": "Leonolovich",
        "created_at": "2020-03-05T20:46:30Z",
        "body": "Running ray.init(local_mode=True) allows me to continue without errors to my tune.run() step, but I havent been able to resolve the Inactive Rcp Error. This is not ideal as I can only get one worker to perform training when using local_mode=True."
      },
      {
        "user": "richardliaw",
        "created_at": "2020-04-22T02:36:49Z",
        "body": "Can you please try again on the latest Ray version?"
      },
      {
        "user": "Leonolovich",
        "created_at": "2020-04-22T17:22:39Z",
        "body": "That appears to have made the issue go away. For documentation, I was having the issue on version 0.8.2 or Ray and I no longer have the issue on version 0.8.4.\r\n\r\nThanks"
      }
    ],
    "satisfaction_conditions": [
      "The solution must resolve the _InactiveRpcError/Deadline Exceeded exception during Ray initialization",
      "The solution must enable running Ray in a multi-worker configuration without requiring local_mode=True",
      "The solution must address version-specific compatibility issues in Ray"
    ],
    "_classification": {
      "category": "Requires build environment but hard to be dockerized",
      "timestamp": "2025-04-04 23:55:32"
    }
  }
]