[
  {
    "number": 14171,
    "title": "[Question]: Big problem on saving and retrieve KnowledgeGraphIndex (Neo4j)",
    "created_at": "2024-06-15T13:49:02Z",
    "closed_at": "2024-06-16T14:16:31Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/run-llama/llama_index/issues/14171",
    "body": "### Question Validation\n\n- [X] I have searched both the documentation and discord for an answer.\n\n### Question\n\nI have a big problem, i can't save or retrieve the graph in memory do perform queries on it, so everytime the graph gets recalculated. This is the code that after 2 days Im arrived at, also asking help to chatgpt and reading  docs, but it doesn't work.\r\n\r\nIf anyone know how to do it please help me.\r\n\r\nThank you!\r\n\r\n```\r\nimport os\r\nimport openai\r\nfrom llama_index.llms.azure_openai import AzureOpenAI\r\nfrom llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex\r\nfrom dotenv import load_dotenv\r\nfrom llama_index.core import Settings\r\nfrom llama_index.graph_stores.neo4j import Neo4jGraphStore\r\nfrom llama_index.embeddings.ollama import OllamaEmbedding\r\nfrom llama_index.core import StorageContext\r\nfrom llama_index.core.indices.loading import load_graph_from_storage\r\nfrom llama_index.core.indices.composability.graph import ComposableGraph\r\n\r\nload_dotenv()\r\nprint(os.getenv('AZURE_OPENAI_LLM_DEPLOYMENT_NAME'))\r\nprint(os.getenv('AZURE_OPENAI_API_ENDPOINT'))\r\nprint(os.getenv('AZURE_OPENAI_API_KEY'))\r\nprint(os.getenv('AZURE_OPENAI_API_VERSION'))\r\n\r\nllm = AzureOpenAI(\r\n    engine=os.getenv('AZURE_OPENAI_LLM_DEPLOYMENT_NAME'),\r\n    model=\"gpt-4o\",\r\n    temperature=0.0,\r\n    azure_endpoint=os.getenv('AZURE_OPENAI_API_ENDPOINT'),\r\n    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\r\n    api_version=os.getenv('AZURE_OPENAI_API_VERSION'),\r\n)\r\n\r\nembed_model = OllamaEmbedding(model_name=\"mxbai-embed-large:335m\", embed_batch_size=512)\r\n\r\nSettings.llm = llm\r\nSettings.embed_model = embed_model\r\nSettings.chunk_size = 512\r\n\r\nusername = \"neo4j\"\r\ndatabase = \"neo4j\"\r\npassword = \"xxx\"\r\nurl = \"bolt://localhost:7687\"\r\nprint(username, password, url, database)\r\n\r\ngraph_store = Neo4jGraphStore(\r\n    username=username,\r\n    password=password,\r\n    url=url,\r\n    database=database,\r\n)\r\n\r\n# Directory for the serialized graph\r\nstorage_dir = './storage'\r\nos.makedirs(storage_dir, exist_ok=True)\r\n\r\n# Define a consistent root ID\r\nroot_id = 'knowledge_graph_index'\r\n\r\n# Check if storage context files exist\r\ndocstore_path = os.path.join(storage_dir, 'docstore.json')\r\nindex_store_path = os.path.join(storage_dir, 'index_store.json')\r\ngraph_store_path = os.path.join(storage_dir, 'graph_store.json')\r\n\r\n# Attempt to load the graph\r\ntry:\r\n    if os.path.exists(docstore_path) and os.path.exists(index_store_path) and os.path.exists(graph_store_path):\r\n        storage_context = StorageContext.from_defaults(graph_store=graph_store, persist_dir=storage_dir)\r\n        knowledge_graph_index = load_graph_from_storage(storage_context, root_id=root_id)\r\n        print(\"Loaded graph from storage.\")\r\n        print(f\"Root ID: {root_id}\")\r\n    else:\r\n        raise FileNotFoundError(\"Required storage files not found, creating new graph.\")\r\nexcept Exception as e:\r\n    print(f\"Failed to load graph from storage: {e}\")\r\n    # Graph doesn't exist, so create it from documents\r\n    documents = SimpleDirectoryReader(\"./content/Documents\").load_data()\r\n    storage_context = StorageContext.from_defaults(graph_store=graph_store)\r\n\r\n    # NOTE: can take a while!\r\n    knowledge_graph_index = KnowledgeGraphIndex.from_documents(\r\n        documents,\r\n        storage_context=storage_context,\r\n        max_triplets_per_chunk=3,\r\n        show_progress=True,\r\n        include_embeddings=True,\r\n    )\r\n    # Set the root ID and save the newly created graph\r\n    knowledge_graph_index.set_index_id(root_id)\r\n    \r\n    storage_context.persist(persist_dir=storage_dir)\r\n    print(f\"Persisted graph in directory: {storage_dir}\")\r\n\r\n# Verify that the graph is correctly loaded\r\ntry:\r\n    if knowledge_graph_index is None:\r\n        raise ValueError(\"Failed to create or load KnowledgeGraphIndex.\")\r\n    print(\"Successfully created or loaded KnowledgeGraphIndex.\")\r\n    \r\n    # Check the contents of all_indices\r\n    print(f\"Contents of all_indices: {knowledge_graph_index.all_indices}\")\r\n    # Check the root_id\r\n    print(f\"Root ID set in graph: {knowledge_graph_index._root_id}\")\r\n\r\n    # Verify the root_id is in all_indices\r\n    if knowledge_graph_index.root_id not in knowledge_graph_index.all_indices:\r\n        raise KeyError(f\"The specified root_id '{knowledge_graph_index.index_id()}' was not found in the graph indices.\")\r\n    print(\"The root ID was found in the graph indices.\")\r\nexcept Exception as e:\r\n    print(f\"Error verifying the KnowledgeGraphIndex: {e}\")\r\n\r\n# Now, whether loaded or created, you can use `knowledge_graph_index` as before\r\ntry:\r\n    query_engine = knowledge_graph_index.as_query_engine(\r\n        include_text=True,\r\n        response_mode=\"tree_summarize\",\r\n        embedding_mode=\"hybrid\",\r\n        similarity_top_k=5,\r\n    )\r\n    response = query_engine.query(\"Quali sono le chiese disegnate da Raffaello?\")\r\n    print(response)\r\nexcept KeyError as e:\r\n    print(f\"KeyError: {e} - The specified root_id '{root_id}' was not found in the graph indices.\")\r\nexcept Exception as e:\r\n    print(f\"An error occurred while creating the query engine: {e}\")\r\n    \r\n    \r\n    \r\n\r\n```",
    "comments_url": "https://api.github.com/repos/run-llama/llama_index/issues/14171/comments",
    "author": "robertobalestri",
    "comments": [
      {
        "user": "logan-markewich",
        "created_at": "2024-06-15T13:53:34Z",
        "body": "Is there any error? Does this line every print?\r\n\r\n`print(f\"Failed to load graph from storage: {e}\")` ?"
      },
      {
        "user": "robertobalestri",
        "created_at": "2024-06-15T14:19:11Z",
        "body": "This is my output... but it desn't print your string. \r\n\r\nneo4j xxx bolt://localhost:7687 neo4j\r\nFailed to load graph from storage: Required storage files not found, creating new graph.\r\nParsing nodes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 124.90it/s]\r\nGenerating embeddings: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:16<00:00,  5.36s/it] \r\nGenerating embeddings: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:06<00:00,  2.22s/it] \r\nGenerating embeddings: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:06<00:00,  2.20s/it] \r\nGenerating embeddings: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:06<00:00,  2.21s/it] \r\nGenerating embeddings: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:06<00:00,  2.22s/it] \r\nGenerating embeddings: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:06<00:00,  2.23s/it] \r\nProcessing nodes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [01:02<00:00, 10.37s/it] \r\nPersisted graph in directory: ./storage\r\nSuccessfully created or loaded KnowledgeGraphIndex.\r\nError verifying the KnowledgeGraphIndex: 'KnowledgeGraphIndex' object has no attribute 'all_indices'\r\nUna delle chiese disegnate da Raffaello \u00e8 S. Eligio degli Orefici.\r\n\r\n\r\n\r\n\n\n---\n\nOk, after days tryng i fount out that the load_graph doesn't work, but load index does.\r\n\r\n\r\n```\r\nimport os\r\nfrom llama_index.llms.azure_openai import AzureOpenAI\r\nfrom llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex, Settings, StorageContext\r\nfrom llama_index.graph_stores.neo4j import Neo4jGraphStore\r\nfrom llama_index.embeddings.ollama import OllamaEmbedding\r\nfrom llama_index.core.indices.loading import load_index_from_storage\r\nfrom dotenv import load_dotenv\r\n\r\n# Load environment variables from .env file\r\nload_dotenv()\r\n\r\n# Configure Azure OpenAI\r\nllm = AzureOpenAI(\r\n    engine=os.getenv('AZURE_OPENAI_LLM_DEPLOYMENT_NAME'),\r\n    model=\"gpt-4o\",\r\n    temperature=0.0,\r\n    azure_endpoint=os.getenv('AZURE_OPENAI_API_ENDPOINT'),\r\n    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\r\n    api_version=os.getenv('AZURE_OPENAI_API_VERSION'),\r\n)\r\n\r\n# Configure the embedding model\r\nembed_model = OllamaEmbedding(model_name=\"mxbai-embed-large:335m\", embed_batch_size=512)\r\n\r\n# Set configuration parameters\r\nSettings.llm = llm\r\nSettings.embed_model = embed_model\r\nSettings.chunk_size = 512\r\n\r\n# Configure the Neo4j database connection\r\nusername = \"neo4j\"\r\ndatabase = \"neo4j\"\r\npassword = \"password\"\r\nurl = \"bolt://localhost:7687\"\r\n\r\ngraph_store = Neo4jGraphStore(\r\n    username=username,\r\n    password=password,\r\n    url=url,\r\n    database=database,\r\n)\r\n\r\n# Directory for storage\r\nstorage_dir = './storage'\r\nos.makedirs(storage_dir, exist_ok=True)\r\n\r\n# Consistent root ID\r\nroot_id = 'knowledge_graph_index'\r\n\r\n# Load or create the knowledge graph\r\ntry:\r\n    storage_context = StorageContext.from_defaults(graph_store=graph_store, persist_dir=storage_dir)\r\n    knowledge_graph_index = load_index_from_storage(storage_context, index_id=root_id)\r\n    print(\"Graph loaded from storage.\")\r\nexcept Exception as e:\r\n    print(f\"Failed to load graph from storage: {e}\")\r\n    # Create the graph from documents if it doesn't exist\r\n    documents = SimpleDirectoryReader(\"./content/Documents\").load_data()\r\n    storage_context = StorageContext.from_defaults(graph_store=graph_store)\r\n    knowledge_graph_index = KnowledgeGraphIndex.from_documents(\r\n        documents,\r\n        storage_context=storage_context,\r\n        max_triplets_per_chunk=3,\r\n        show_progress=True,\r\n        include_embeddings=True,\r\n    )\r\n    knowledge_graph_index.set_index_id(root_id)\r\n    storage_context.persist(persist_dir=storage_dir)\r\n    print(f\"Graph created and stored in: {storage_dir}\")\r\n\r\n# Verify the graph is loaded correctly\r\ntry:\r\n    if knowledge_graph_index is None:\r\n        raise ValueError(\"Failed to create or load KnowledgeGraphIndex.\")\r\n    print(\"KnowledgeGraphIndex created or loaded successfully.\")\r\n    root_id_set = knowledge_graph_index.index_id\r\n    if root_id_set != root_id:\r\n        raise KeyError(f\"The specified root ID '{root_id}' does not match the loaded root ID '{root_id_set}'.\")\r\n    print(\"The root ID matches and is correct.\")\r\nexcept Exception as e:\r\n    print(f\"Error verifying the KnowledgeGraphIndex: {e}\")\r\n\r\n# Use `knowledge_graph_index` for queries\r\ntry:\r\n    query_engine = knowledge_graph_index.as_query_engine(\r\n        include_text=True,\r\n        response_mode=\"tree_summarize\",\r\n        embedding_mode=\"hybrid\",\r\n        similarity_top_k=5,\r\n    )\r\n    response = query_engine.query(\"Quali chiese ha disegnato Raffaello?\")\r\n    print(response)\r\nexcept KeyError as e:\r\n    print(f\"KeyError: {e} - The specified root_id '{root_id}' was not found in the graph indices.\")\r\nexcept Exception as e:\r\n    print(f\"An error occurred while creating the query engine: {e}\")\r\n\r\n```"
      },
      {
        "user": "logan-markewich",
        "created_at": "2024-06-16T14:16:31Z",
        "body": "@robertobalestri ah good catch `load_graph` is an old method for something completely unrelated actually.\r\n\r\nLoad index is the one to use, I didn't notice that in your code "
      }
    ],
    "satisfaction_conditions": [
      "Clear explanation of proper persistence/loading workflow for KnowledgeGraphIndex with Neo4j",
      "Correct method for loading a persisted graph index from Neo4j storage",
      "Proper handling of index IDs and root node identification",
      "Validation of complete storage context persistence",
      "Error-free verification of loaded index structure"
    ],
    "_classification": {
      "category": "Can be dockerized without any issue",
      "timestamp": "2025-04-05 00:29:53"
    }
  }
]