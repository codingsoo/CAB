{
  "number": 4492,
  "title": "Model m2m-100 in fairseq-interactive mode",
  "created_at": "2022-06-15T11:27:53Z",
  "closed_at": "2022-06-16T08:56:56Z",
  "labels": [
    "question",
    "needs triage"
  ],
  "url": "https://github.com/facebookresearch/fairseq/issues/4492",
  "body": "I have a nice implementation of `fairseq-generate` on the pretrained m2m-100 model for EN-RU language pair. At the binarization stage with `fairseq-preprocess`, I noticed that `--srcdict` and `--tgtdict` options contain **the same** file, `model_dict.128k.txt` - exactly as it is recommended on the m2m-100 web page. That file is subsequently used in `--fixed-dictionary` option in `fairseq-generate`.\r\nThe main lack of this workflow is that I need to preprocess a **reference** translation file, which is a priori absent when my goal is simple translation without necessity to measure the quality of the translation. Thereby it's reasonable to assume that, if my EN-RU translation successfully completes with `fairseq-generate`, there is an opportunity to do the same with `fairseq-interactive`.\r\n\r\nInitially, when I tried `fairseq-interactive`, I got the error that files `dict.en.txt` and `dict.ru.txt` are not found. Really these dictionaries are not distributed with pretrained m2m-100 models. Then, if I copy the only available model dictionary `model_dict.128k.txt` twice, and rename one of those copies to `dict.en.txt`, the other - to `dict.ru.txt`, then there is no more error, but the output text turns out to be translated into a **random** language (EL, PT, etc. or even EN), as if my option `--target-lang ru` was ignored. The same occurs if I use `dict.en.txt` and `dict.ru.txt` files from my binarized data folder - they are the same as `model_dict.128k.txt`.\r\n\r\nThe full `fairseq-interactive` translation command which I use:\r\n\r\n`fairseq-interactive --input=testdata/ex.txt --path 1.2B_last_checkpoint.pt . --source-lang en --target-lang ru --tokenizer moses --bpe sentencepiece --sentencepiece-model spm.128k.model > testdata/ex.txt.out`\r\n\r\nAny ideas and suggestions to use m2m-100 in fairseq-interactive correctly?",
  "comments_url": "https://api.github.com/repos/facebookresearch/fairseq/issues/4492/comments",
  "author": "molokanov50",
  "comments": [
    {
      "user": "gmryu",
      "created_at": "2022-06-16T01:11:44Z",
      "body": "To be honest, I have not tested m2m-100 myself.\r\nFrom a side perspecitive, I guess you should give the following arguments:\r\n```\r\n--task translation_multi_simple_epoch \\\r\n--lang-pairs language_pairs.txt \\\r\n--decoder-langtok --encoder-langtok src \r\n```\r\nor what is the command you used to generate? just switch that generate to interactive, add tokenizer,bpe.\r\n\r\n\r\nAnyway, for this case I believe TranslationTask (default task if not specified) read the model_dict.128k.txt, moses tokenized and spm your data correctly.\r\nThe reason you got random language is m2m-100 model requires a special token in sentences to identify which language pair is used. A normal translation task do not need to."
    },
    {
      "user": "molokanov50",
      "created_at": "2022-06-16T08:56:56Z",
      "body": "The addition of `--decoder-langtok --encoder-langtok src` solved my question, now the target translation language is taken from `--target-lang` option. Thx a lot."
    }
  ],
  "satisfaction_conditions": [
    "Ensures the model respects the specified target language during translation",
    "Works with fairseq-interactive without requiring reference translations",
    "Maintains compatibility with the model's shared dictionary setup"
  ],
  "_classification": {
    "category": "Can be dockerized without any issue",
    "timestamp": "2025-03-21 18:15:00"
  },
  "git_commit_info": {
    "sha": "85f097141d83d6aac378838b6c0c8f2a0f77154f",
    "date": "2020-10-13T19:32:58Z",
    "message": "Remove FileContentsAction for --langs\n\nSummary:\n# Facebook:\n\nRevert changes made in D24059296 (https://github.com/pytorch/fairseq/commit/0557ed8b0df90fe671bcb745f384ef7fd0386ab3) since it breaks normal --langs usage. To specify languages in a file, use --lang-dict instead\n\nAlso update integration test params so it can catch this\n\nReviewed By: tangyuq\n\nDifferential Revision: D24224622\n\nfbshipit-source-id: 292eeb86e02528128ced09f8165045be9c847c19",
    "author": "Wei Ho"
  },
  "repository_info": {
    "structure": {
      "name": "/",
      "path": "",
      "type": "directory",
      "contents": [
        {
          "name": ".github",
          "path": ".github",
          "type": "directory",
          "contents": [
            {
              "name": "ISSUE_TEMPLATE.md",
              "path": ".github/ISSUE_TEMPLATE.md",
              "type": "file",
              "size": 250
            },
            {
              "name": "ISSUE_TEMPLATE",
              "path": ".github/ISSUE_TEMPLATE",
              "type": "directory",
              "contents": [
                {
                  "name": "bug_report.md",
                  "path": ".github/ISSUE_TEMPLATE/bug_report.md",
                  "type": "file",
                  "size": 1068
                },
                {
                  "name": "documentation.md",
                  "path": ".github/ISSUE_TEMPLATE/documentation.md",
                  "type": "file",
                  "size": 268
                },
                {
                  "name": "feature_request.md",
                  "path": ".github/ISSUE_TEMPLATE/feature_request.md",
                  "type": "file",
                  "size": 762
                },
                {
                  "name": "how-to-question.md",
                  "path": ".github/ISSUE_TEMPLATE/how-to-question.md",
                  "type": "file",
                  "size": 763
                }
              ]
            },
            {
              "name": "PULL_REQUEST_TEMPLATE.md",
              "path": ".github/PULL_REQUEST_TEMPLATE.md",
              "type": "file",
              "size": 609
            },
            {
              "name": "workflows",
              "path": ".github/workflows",
              "type": "directory",
              "contents": [
                {
                  "name": "build.yml",
                  "path": ".github/workflows/build.yml",
                  "type": "file",
                  "size": 1331
                }
              ]
            }
          ]
        },
        {
          "name": ".gitignore",
          "path": ".gitignore",
          "type": "file",
          "size": 1642
        },
        {
          "name": ".gitmodules",
          "path": ".gitmodules",
          "type": "file",
          "size": 342
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "path": "CODE_OF_CONDUCT.md",
          "type": "file",
          "size": 3350
        },
        {
          "name": "CONTRIBUTING.md",
          "path": "CONTRIBUTING.md",
          "type": "file",
          "size": 1144
        },
        {
          "name": "LICENSE",
          "path": "LICENSE",
          "type": "file",
          "size": 1086
        },
        {
          "name": "README.md",
          "path": "README.md",
          "type": "file",
          "size": 12422
        },
        {
          "name": "config",
          "path": "config",
          "type": "directory",
          "contents": [
            {
              "name": "config.yaml",
              "path": "config/config.yaml",
              "type": "file",
              "size": 172
            },
            {
              "name": "config_eval_lm.yaml",
              "path": "config/config_eval_lm.yaml",
              "type": "file",
              "size": 171
            },
            {
              "name": "criterion",
              "path": "config/criterion",
              "type": "directory",
              "contents": [
                {
                  "name": "adaptive_loss.yaml",
                  "path": "config/criterion/adaptive_loss.yaml",
                  "type": "file",
                  "size": 125
                },
                {
                  "name": "cross_entropy.yaml",
                  "path": "config/criterion/cross_entropy.yaml",
                  "type": "file",
                  "size": 125
                }
              ]
            },
            {
              "name": "lr_scheduler",
              "path": "config/lr_scheduler",
              "type": "directory",
              "contents": [
                {
                  "name": "cosine.yaml",
                  "path": "config/lr_scheduler/cosine.yaml",
                  "type": "file",
                  "size": 117
                },
                {
                  "name": "inverse_sqrt.yaml",
                  "path": "config/lr_scheduler/inverse_sqrt.yaml",
                  "type": "file",
                  "size": 59
                }
              ]
            },
            {
              "name": "model",
              "path": "config/model",
              "type": "directory",
              "contents": [
                {
                  "name": "transformer_lm.yaml",
                  "path": "config/model/transformer_lm.yaml",
                  "type": "file",
                  "size": 990
                },
                {
                  "name": "transformer_lm_baevski_gbw.yaml",
                  "path": "config/model/transformer_lm_baevski_gbw.yaml",
                  "type": "file",
                  "size": 991
                },
                {
                  "name": "transformer_lm_baevski_wiki103.yaml",
                  "path": "config/model/transformer_lm_baevski_wiki103.yaml",
                  "type": "file",
                  "size": 1010
                },
                {
                  "name": "transformer_lm_big.yaml",
                  "path": "config/model/transformer_lm_big.yaml",
                  "type": "file",
                  "size": 995
                },
                {
                  "name": "transformer_lm_gbw.yaml",
                  "path": "config/model/transformer_lm_gbw.yaml",
                  "type": "file",
                  "size": 991
                },
                {
                  "name": "transformer_lm_gpt.yaml",
                  "path": "config/model/transformer_lm_gpt.yaml",
                  "type": "file",
                  "size": 992
                },
                {
                  "name": "transformer_lm_gpt2_big.yaml",
                  "path": "config/model/transformer_lm_gpt2_big.yaml",
                  "type": "file",
                  "size": 995
                },
                {
                  "name": "transformer_lm_gpt2_medium.yaml",
                  "path": "config/model/transformer_lm_gpt2_medium.yaml",
                  "type": "file",
                  "size": 995
                },
                {
                  "name": "transformer_lm_gpt2_small.yaml",
                  "path": "config/model/transformer_lm_gpt2_small.yaml",
                  "type": "file",
                  "size": 995
                },
                {
                  "name": "transformer_lm_wiki103.yaml",
                  "path": "config/model/transformer_lm_wiki103.yaml",
                  "type": "file",
                  "size": 1010
                }
              ]
            },
            {
              "name": "optimizer",
              "path": "config/optimizer",
              "type": "directory",
              "contents": [
                {
                  "name": "adam.yaml",
                  "path": "config/optimizer/adam.yaml",
                  "type": "file",
                  "size": 99
                },
                {
                  "name": "nag.yaml",
                  "path": "config/optimizer/nag.yaml",
                  "type": "file",
                  "size": 52
                }
              ]
            },
            {
              "name": "params",
              "path": "config/params",
              "type": "directory",
              "contents": [
                {
                  "name": "eval_lm_params.yaml",
                  "path": "config/params/eval_lm_params.yaml",
                  "type": "file",
                  "size": 2452
                },
                {
                  "name": "training_params.yaml",
                  "path": "config/params/training_params.yaml",
                  "type": "file",
                  "size": 2264
                }
              ]
            },
            {
              "name": "task",
              "path": "config/task",
              "type": "directory",
              "contents": [
                {
                  "name": "language_modeling.yaml",
                  "path": "config/task/language_modeling.yaml",
                  "type": "file",
                  "size": 213
                }
              ]
            }
          ]
        },
        {
          "name": "docs",
          "path": "docs",
          "type": "directory",
          "contents": [
            {
              "name": "Makefile",
              "path": "docs/Makefile",
              "type": "file",
              "size": 607
            },
            {
              "name": "_static",
              "path": "docs/_static",
              "type": "directory",
              "contents": [
                {
                  "name": "theme_overrides.css",
                  "path": "docs/_static/theme_overrides.css",
                  "type": "file",
                  "size": 192
                }
              ]
            },
            {
              "name": "command_line_tools.rst",
              "path": "docs/command_line_tools.rst",
              "type": "file",
              "size": 1893
            },
            {
              "name": "conf.py",
              "path": "docs/conf.py",
              "type": "file",
              "size": 4235
            },
            {
              "name": "criterions.rst",
              "path": "docs/criterions.rst",
              "type": "file",
              "size": 758
            },
            {
              "name": "data.rst",
              "path": "docs/data.rst",
              "type": "file",
              "size": 1202
            },
            {
              "name": "docutils.conf",
              "path": "docs/docutils.conf",
              "type": "file",
              "size": 25
            },
            {
              "name": "fairseq.gif",
              "path": "docs/fairseq.gif",
              "type": "file",
              "size": 2664833
            },
            {
              "name": "fairseq_logo.png",
              "path": "docs/fairseq_logo.png",
              "type": "file",
              "size": 73036
            },
            {
              "name": "getting_started.rst",
              "path": "docs/getting_started.rst",
              "type": "file",
              "size": 8290
            },
            {
              "name": "hydra_integration.md",
              "path": "docs/hydra_integration.md",
              "type": "file",
              "size": 4978
            },
            {
              "name": "index.rst",
              "path": "docs/index.rst",
              "type": "file",
              "size": 1002
            },
            {
              "name": "lr_scheduler.rst",
              "path": "docs/lr_scheduler.rst",
              "type": "file",
              "size": 1055
            },
            {
              "name": "make.bat",
              "path": "docs/make.bat",
              "type": "file",
              "size": 805
            },
            {
              "name": "models.rst",
              "path": "docs/models.rst",
              "type": "file",
              "size": 2830
            },
            {
              "name": "modules.rst",
              "path": "docs/modules.rst",
              "type": "file",
              "size": 241
            },
            {
              "name": "optim.rst",
              "path": "docs/optim.rst",
              "type": "file",
              "size": 846
            },
            {
              "name": "overview.rst",
              "path": "docs/overview.rst",
              "type": "file",
              "size": 2708
            },
            {
              "name": "requirements.txt",
              "path": "docs/requirements.txt",
              "type": "file",
              "size": 27
            },
            {
              "name": "tasks.rst",
              "path": "docs/tasks.rst",
              "type": "file",
              "size": 1391
            },
            {
              "name": "tutorial_classifying_names.rst",
              "path": "docs/tutorial_classifying_names.rst",
              "type": "file",
              "size": 16984
            },
            {
              "name": "tutorial_simple_lstm.rst",
              "path": "docs/tutorial_simple_lstm.rst",
              "type": "file",
              "size": 21220
            }
          ]
        },
        {
          "name": "examples",
          "path": "examples",
          "type": "directory",
          "contents": [
            {
              "name": ".gitignore",
              "path": "examples/.gitignore",
              "type": "file",
              "size": 16
            },
            {
              "name": "__init__.py",
              "path": "examples/__init__.py",
              "type": "file",
              "size": 238
            },
            {
              "name": "backtranslation",
              "path": "examples/backtranslation",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/backtranslation/README.md",
                  "type": "file",
                  "size": 10775
                },
                {
                  "name": "deduplicate_lines.py",
                  "path": "examples/backtranslation/deduplicate_lines.py",
                  "type": "file",
                  "size": 1221
                },
                {
                  "name": "extract_bt_data.py",
                  "path": "examples/backtranslation/extract_bt_data.py",
                  "type": "file",
                  "size": 2363
                },
                {
                  "name": "prepare-de-monolingual.sh",
                  "path": "examples/backtranslation/prepare-de-monolingual.sh",
                  "type": "file",
                  "size": 3240
                },
                {
                  "name": "prepare-wmt18en2de.sh",
                  "path": "examples/backtranslation/prepare-wmt18en2de.sh",
                  "type": "file",
                  "size": 3699
                },
                {
                  "name": "sacrebleu.sh",
                  "path": "examples/backtranslation/sacrebleu.sh",
                  "type": "file",
                  "size": 961
                },
                {
                  "name": "tokenized_bleu.sh",
                  "path": "examples/backtranslation/tokenized_bleu.sh",
                  "type": "file",
                  "size": 1137
                }
              ]
            },
            {
              "name": "bart",
              "path": "examples/bart",
              "type": "directory",
              "contents": [
                {
                  "name": "README.glue.md",
                  "path": "examples/bart/README.glue.md",
                  "type": "file",
                  "size": 4060
                },
                {
                  "name": "README.md",
                  "path": "examples/bart/README.md",
                  "type": "file",
                  "size": 7973
                },
                {
                  "name": "README.summarization.md",
                  "path": "examples/bart/README.summarization.md",
                  "type": "file",
                  "size": 4355
                }
              ]
            },
            {
              "name": "byte_level_bpe",
              "path": "examples/byte_level_bpe",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/byte_level_bpe/README.md",
                  "type": "file",
                  "size": 3416
                },
                {
                  "name": "get_bitext.py",
                  "path": "examples/byte_level_bpe/get_bitext.py",
                  "type": "file",
                  "size": 7743
                },
                {
                  "name": "get_data.sh",
                  "path": "examples/byte_level_bpe/get_data.sh",
                  "type": "file",
                  "size": 1890
                },
                {
                  "name": "gru_transformer.py",
                  "path": "examples/byte_level_bpe/gru_transformer.py",
                  "type": "file",
                  "size": 5028
                }
              ]
            },
            {
              "name": "camembert",
              "path": "examples/camembert",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/camembert/README.md",
                  "type": "file",
                  "size": 3977
                }
              ]
            },
            {
              "name": "constrained_decoding",
              "path": "examples/constrained_decoding",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/constrained_decoding/README.md",
                  "type": "file",
                  "size": 5540
                },
                {
                  "name": "normalize.py",
                  "path": "examples/constrained_decoding/normalize.py",
                  "type": "file",
                  "size": 697
                },
                {
                  "name": "tok.py",
                  "path": "examples/constrained_decoding/tok.py",
                  "type": "file",
                  "size": 841
                }
              ]
            },
            {
              "name": "conv_seq2seq",
              "path": "examples/conv_seq2seq",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/conv_seq2seq/README.md",
                  "type": "file",
                  "size": 1926
                }
              ]
            },
            {
              "name": "cross_lingual_language_model",
              "path": "examples/cross_lingual_language_model",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/cross_lingual_language_model/README.md",
                  "type": "file",
                  "size": 3043
                }
              ]
            },
            {
              "name": "joint_alignment_translation",
              "path": "examples/joint_alignment_translation",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/joint_alignment_translation/README.md",
                  "type": "file",
                  "size": 3130
                },
                {
                  "name": "prepare-wmt18en2de_no_norm_no_escape_no_agressive.sh",
                  "path": "examples/joint_alignment_translation/prepare-wmt18en2de_no_norm_no_escape_no_agressive.sh",
                  "type": "file",
                  "size": 3339
                }
              ]
            },
            {
              "name": "language_model",
              "path": "examples/language_model",
              "type": "directory",
              "contents": [
                {
                  "name": "README.adaptive_inputs.md",
                  "path": "examples/language_model/README.adaptive_inputs.md",
                  "type": "file",
                  "size": 1992
                },
                {
                  "name": "README.conv.md",
                  "path": "examples/language_model/README.conv.md",
                  "type": "file",
                  "size": 1262
                },
                {
                  "name": "README.md",
                  "path": "examples/language_model/README.md",
                  "type": "file",
                  "size": 5469
                },
                {
                  "name": "prepare-wikitext-103.sh",
                  "path": "examples/language_model/prepare-wikitext-103.sh",
                  "type": "file",
                  "size": 827
                }
              ]
            },
            {
              "name": "layerdrop",
              "path": "examples/layerdrop",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/layerdrop/README.md",
                  "type": "file",
                  "size": 8438
                }
              ]
            },
            {
              "name": "linformer",
              "path": "examples/linformer",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/linformer/README.md",
                  "type": "file",
                  "size": 768
                },
                {
                  "name": "src",
                  "path": "examples/linformer/src",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "examples/linformer/src/__init__.py",
                      "type": "file",
                      "size": 224
                    },
                    {
                      "name": "models",
                      "path": "examples/linformer/src/models",
                      "type": "directory",
                      "contents": [
                        {
                          "name": "__init__.py",
                          "path": "examples/linformer/src/models/__init__.py",
                          "type": "file",
                          "size": 0
                        },
                        {
                          "name": "linformer_roberta.py",
                          "path": "examples/linformer/src/models/linformer_roberta.py",
                          "type": "file",
                          "size": 5308
                        }
                      ]
                    },
                    {
                      "name": "modules",
                      "path": "examples/linformer/src/modules",
                      "type": "directory",
                      "contents": [
                        {
                          "name": "__init__.py",
                          "path": "examples/linformer/src/modules/__init__.py",
                          "type": "file",
                          "size": 0
                        },
                        {
                          "name": "linformer_sentence_encoder.py",
                          "path": "examples/linformer/src/modules/linformer_sentence_encoder.py",
                          "type": "file",
                          "size": 6276
                        },
                        {
                          "name": "linformer_sentence_encoder_layer.py",
                          "path": "examples/linformer/src/modules/linformer_sentence_encoder_layer.py",
                          "type": "file",
                          "size": 2648
                        },
                        {
                          "name": "multihead_linear_attention.py",
                          "path": "examples/linformer/src/modules/multihead_linear_attention.py",
                          "type": "file",
                          "size": 18684
                        }
                      ]
                    }
                  ]
                }
              ]
            },
            {
              "name": "mbart",
              "path": "examples/mbart",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/mbart/README.md",
                  "type": "file",
                  "size": 4790
                }
              ]
            },
            {
              "name": "megatron_11b",
              "path": "examples/megatron_11b",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/megatron_11b/README.md",
                  "type": "file",
                  "size": 5247
                },
                {
                  "name": "detok.py",
                  "path": "examples/megatron_11b/detok.py",
                  "type": "file",
                  "size": 737
                }
              ]
            },
            {
              "name": "multilingual",
              "path": "examples/multilingual",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/multilingual/README.md",
                  "type": "file",
                  "size": 6199
                },
                {
                  "name": "finetune_multilingual_model.sh",
                  "path": "examples/multilingual/finetune_multilingual_model.sh",
                  "type": "file",
                  "size": 1270
                },
                {
                  "name": "multilingual_fairseq_gen.sh",
                  "path": "examples/multilingual/multilingual_fairseq_gen.sh",
                  "type": "file",
                  "size": 594
                },
                {
                  "name": "train_multilingual_model.sh",
                  "path": "examples/multilingual/train_multilingual_model.sh",
                  "type": "file",
                  "size": 1117
                }
              ]
            },
            {
              "name": "noisychannel",
              "path": "examples/noisychannel",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/noisychannel/README.md",
                  "type": "file",
                  "size": 3666
                },
                {
                  "name": "__init__.py",
                  "path": "examples/noisychannel/__init__.py",
                  "type": "file",
                  "size": 216
                },
                {
                  "name": "rerank.py",
                  "path": "examples/noisychannel/rerank.py",
                  "type": "file",
                  "size": 12842
                },
                {
                  "name": "rerank_generate.py",
                  "path": "examples/noisychannel/rerank_generate.py",
                  "type": "file",
                  "size": 13194
                },
                {
                  "name": "rerank_options.py",
                  "path": "examples/noisychannel/rerank_options.py",
                  "type": "file",
                  "size": 7452
                },
                {
                  "name": "rerank_score_bw.py",
                  "path": "examples/noisychannel/rerank_score_bw.py",
                  "type": "file",
                  "size": 4369
                },
                {
                  "name": "rerank_score_lm.py",
                  "path": "examples/noisychannel/rerank_score_lm.py",
                  "type": "file",
                  "size": 2117
                },
                {
                  "name": "rerank_tune.py",
                  "path": "examples/noisychannel/rerank_tune.py",
                  "type": "file",
                  "size": 3034
                },
                {
                  "name": "rerank_utils.py",
                  "path": "examples/noisychannel/rerank_utils.py",
                  "type": "file",
                  "size": 27676
                }
              ]
            },
            {
              "name": "nonautoregressive_translation",
              "path": "examples/nonautoregressive_translation",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/nonautoregressive_translation/README.md",
                  "type": "file",
                  "size": 7440
                },
                {
                  "name": "scripts.md",
                  "path": "examples/nonautoregressive_translation/scripts.md",
                  "type": "file",
                  "size": 5991
                }
              ]
            },
            {
              "name": "paraphraser",
              "path": "examples/paraphraser",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/paraphraser/README.md",
                  "type": "file",
                  "size": 2761
                },
                {
                  "name": "paraphrase.py",
                  "path": "examples/paraphraser/paraphrase.py",
                  "type": "file",
                  "size": 2422
                }
              ]
            },
            {
              "name": "pay_less_attention_paper",
              "path": "examples/pay_less_attention_paper",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/pay_less_attention_paper/README.md",
                  "type": "file",
                  "size": 11060
                }
              ]
            },
            {
              "name": "pointer_generator",
              "path": "examples/pointer_generator",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/pointer_generator/README.md",
                  "type": "file",
                  "size": 3919
                },
                {
                  "name": "README.xsum.md",
                  "path": "examples/pointer_generator/README.xsum.md",
                  "type": "file",
                  "size": 6620
                },
                {
                  "name": "postprocess.py",
                  "path": "examples/pointer_generator/postprocess.py",
                  "type": "file",
                  "size": 3262
                },
                {
                  "name": "preprocess.py",
                  "path": "examples/pointer_generator/preprocess.py",
                  "type": "file",
                  "size": 3333
                },
                {
                  "name": "src",
                  "path": "examples/pointer_generator/src",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "examples/pointer_generator/src/__init__.py",
                      "type": "file",
                      "size": 215
                    },
                    {
                      "name": "transformer_pg.py",
                      "path": "examples/pointer_generator/src/transformer_pg.py",
                      "type": "file",
                      "size": 21404
                    }
                  ]
                }
              ]
            },
            {
              "name": "quant_noise",
              "path": "examples/quant_noise",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/quant_noise/README.md",
                  "type": "file",
                  "size": 15496
                },
                {
                  "name": "transformer_quantization_config.yaml",
                  "path": "examples/quant_noise/transformer_quantization_config.yaml",
                  "type": "file",
                  "size": 1049
                }
              ]
            },
            {
              "name": "roberta",
              "path": "examples/roberta",
              "type": "directory",
              "contents": [
                {
                  "name": "README.custom_classification.md",
                  "path": "examples/roberta/README.custom_classification.md",
                  "type": "file",
                  "size": 5382
                },
                {
                  "name": "README.glue.md",
                  "path": "examples/roberta/README.glue.md",
                  "type": "file",
                  "size": 4244
                },
                {
                  "name": "README.md",
                  "path": "examples/roberta/README.md",
                  "type": "file",
                  "size": 13015
                },
                {
                  "name": "README.pretraining.md",
                  "path": "examples/roberta/README.pretraining.md",
                  "type": "file",
                  "size": 4287
                },
                {
                  "name": "README.race.md",
                  "path": "examples/roberta/README.race.md",
                  "type": "file",
                  "size": 2755
                },
                {
                  "name": "commonsense_qa",
                  "path": "examples/roberta/commonsense_qa",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "README.md",
                      "path": "examples/roberta/commonsense_qa/README.md",
                      "type": "file",
                      "size": 4049
                    },
                    {
                      "name": "__init__.py",
                      "path": "examples/roberta/commonsense_qa/__init__.py",
                      "type": "file",
                      "size": 220
                    },
                    {
                      "name": "commonsense_qa_task.py",
                      "path": "examples/roberta/commonsense_qa/commonsense_qa_task.py",
                      "type": "file",
                      "size": 5933
                    },
                    {
                      "name": "download_cqa_data.sh",
                      "path": "examples/roberta/commonsense_qa/download_cqa_data.sh",
                      "type": "file",
                      "size": 594
                    }
                  ]
                },
                {
                  "name": "multiprocessing_bpe_encoder.py",
                  "path": "examples/roberta/multiprocessing_bpe_encoder.py",
                  "type": "file",
                  "size": 3756
                },
                {
                  "name": "preprocess_GLUE_tasks.sh",
                  "path": "examples/roberta/preprocess_GLUE_tasks.sh",
                  "type": "file",
                  "size": 5738
                },
                {
                  "name": "preprocess_RACE.py",
                  "path": "examples/roberta/preprocess_RACE.py",
                  "type": "file",
                  "size": 3395
                },
                {
                  "name": "preprocess_RACE.sh",
                  "path": "examples/roberta/preprocess_RACE.sh",
                  "type": "file",
                  "size": 2070
                },
                {
                  "name": "wsc",
                  "path": "examples/roberta/wsc",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "README.md",
                      "path": "examples/roberta/wsc/README.md",
                      "type": "file",
                      "size": 5643
                    },
                    {
                      "name": "__init__.py",
                      "path": "examples/roberta/wsc/__init__.py",
                      "type": "file",
                      "size": 245
                    },
                    {
                      "name": "wsc_criterion.py",
                      "path": "examples/roberta/wsc/wsc_criterion.py",
                      "type": "file",
                      "size": 6034
                    },
                    {
                      "name": "wsc_task.py",
                      "path": "examples/roberta/wsc/wsc_task.py",
                      "type": "file",
                      "size": 13160
                    },
                    {
                      "name": "wsc_utils.py",
                      "path": "examples/roberta/wsc/wsc_utils.py",
                      "type": "file",
                      "size": 8329
                    }
                  ]
                }
              ]
            },
            {
              "name": "scaling_nmt",
              "path": "examples/scaling_nmt",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/scaling_nmt/README.md",
                  "type": "file",
                  "size": 5225
                }
              ]
            },
            {
              "name": "simultaneous_translation",
              "path": "examples/simultaneous_translation",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/simultaneous_translation/README.md",
                  "type": "file",
                  "size": 3071
                },
                {
                  "name": "__init__.py",
                  "path": "examples/simultaneous_translation/__init__.py",
                  "type": "file",
                  "size": 225
                },
                {
                  "name": "criterions",
                  "path": "examples/simultaneous_translation/criterions",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "examples/simultaneous_translation/criterions/__init__.py",
                      "type": "file",
                      "size": 485
                    },
                    {
                      "name": "label_smoothed_cross_entropy_latency_augmented.py",
                      "path": "examples/simultaneous_translation/criterions/label_smoothed_cross_entropy_latency_augmented.py",
                      "type": "file",
                      "size": 3080
                    }
                  ]
                },
                {
                  "name": "docs",
                  "path": "examples/simultaneous_translation/docs",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "baseline.md",
                      "path": "examples/simultaneous_translation/docs/baseline.md",
                      "type": "file",
                      "size": 4855
                    },
                    {
                      "name": "evaluation.md",
                      "path": "examples/simultaneous_translation/docs/evaluation.md",
                      "type": "file",
                      "size": 4155
                    }
                  ]
                },
                {
                  "name": "eval",
                  "path": "examples/simultaneous_translation/eval",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "examples/simultaneous_translation/eval/__init__.py",
                      "type": "file",
                      "size": 177
                    },
                    {
                      "name": "agents",
                      "path": "examples/simultaneous_translation/eval/agents",
                      "type": "directory",
                      "contents": [
                        {
                          "name": "__init__.py",
                          "path": "examples/simultaneous_translation/eval/agents/__init__.py",
                          "type": "file",
                          "size": 568
                        },
                        {
                          "name": "agent.py",
                          "path": "examples/simultaneous_translation/eval/agents/agent.py",
                          "type": "file",
                          "size": 2007
                        },
                        {
                          "name": "simul_trans_agent.py",
                          "path": "examples/simultaneous_translation/eval/agents/simul_trans_agent.py",
                          "type": "file",
                          "size": 5890
                        },
                        {
                          "name": "simul_trans_text_agent.py",
                          "path": "examples/simultaneous_translation/eval/agents/simul_trans_text_agent.py",
                          "type": "file",
                          "size": 2614
                        },
                        {
                          "name": "word_splitter.py",
                          "path": "examples/simultaneous_translation/eval/agents/word_splitter.py",
                          "type": "file",
                          "size": 2331
                        }
                      ]
                    },
                    {
                      "name": "client.py",
                      "path": "examples/simultaneous_translation/eval/client.py",
                      "type": "file",
                      "size": 3056
                    },
                    {
                      "name": "eval_latency.py",
                      "path": "examples/simultaneous_translation/eval/eval_latency.py",
                      "type": "file",
                      "size": 2432
                    },
                    {
                      "name": "evaluate.py",
                      "path": "examples/simultaneous_translation/eval/evaluate.py",
                      "type": "file",
                      "size": 2494
                    },
                    {
                      "name": "scorers",
                      "path": "examples/simultaneous_translation/eval/scorers",
                      "type": "directory",
                      "contents": [
                        {
                          "name": "__init__.py",
                          "path": "examples/simultaneous_translation/eval/scorers/__init__.py",
                          "type": "file",
                          "size": 553
                        },
                        {
                          "name": "scorer.py",
                          "path": "examples/simultaneous_translation/eval/scorers/scorer.py",
                          "type": "file",
                          "size": 6141
                        },
                        {
                          "name": "text_scorer.py",
                          "path": "examples/simultaneous_translation/eval/scorers/text_scorer.py",
                          "type": "file",
                          "size": 1302
                        }
                      ]
                    },
                    {
                      "name": "server.py",
                      "path": "examples/simultaneous_translation/eval/server.py",
                      "type": "file",
                      "size": 2458
                    }
                  ]
                },
                {
                  "name": "models",
                  "path": "examples/simultaneous_translation/models",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "examples/simultaneous_translation/models/__init__.py",
                      "type": "file",
                      "size": 450
                    },
                    {
                      "name": "transformer_monotonic_attention.py",
                      "path": "examples/simultaneous_translation/models/transformer_monotonic_attention.py",
                      "type": "file",
                      "size": 11249
                    }
                  ]
                },
                {
                  "name": "modules",
                  "path": "examples/simultaneous_translation/modules",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "examples/simultaneous_translation/modules/__init__.py",
                      "type": "file",
                      "size": 632
                    },
                    {
                      "name": "monotonic_multihead_attention.py",
                      "path": "examples/simultaneous_translation/modules/monotonic_multihead_attention.py",
                      "type": "file",
                      "size": 21361
                    },
                    {
                      "name": "monotonic_transformer_layer.py",
                      "path": "examples/simultaneous_translation/modules/monotonic_transformer_layer.py",
                      "type": "file",
                      "size": 1919
                    }
                  ]
                },
                {
                  "name": "utils",
                  "path": "examples/simultaneous_translation/utils",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "examples/simultaneous_translation/utils/__init__.py",
                      "type": "file",
                      "size": 511
                    },
                    {
                      "name": "functions.py",
                      "path": "examples/simultaneous_translation/utils/functions.py",
                      "type": "file",
                      "size": 3912
                    },
                    {
                      "name": "latency.py",
                      "path": "examples/simultaneous_translation/utils/latency.py",
                      "type": "file",
                      "size": 14598
                    }
                  ]
                }
              ]
            },
            {
              "name": "speech_recognition",
              "path": "examples/speech_recognition",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/speech_recognition/README.md",
                  "type": "file",
                  "size": 6333
                },
                {
                  "name": "__init__.py",
                  "path": "examples/speech_recognition/__init__.py",
                  "type": "file",
                  "size": 48
                },
                {
                  "name": "criterions",
                  "path": "examples/speech_recognition/criterions",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "ASG_loss.py",
                      "path": "examples/speech_recognition/criterions/ASG_loss.py",
                      "type": "file",
                      "size": 5857
                    },
                    {
                      "name": "__init__.py",
                      "path": "examples/speech_recognition/criterions/__init__.py",
                      "type": "file",
                      "size": 470
                    },
                    {
                      "name": "cross_entropy_acc.py",
                      "path": "examples/speech_recognition/criterions/cross_entropy_acc.py",
                      "type": "file",
                      "size": 5372
                    }
                  ]
                },
                {
                  "name": "data",
                  "path": "examples/speech_recognition/data",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "examples/speech_recognition/data/__init__.py",
                      "type": "file",
                      "size": 247
                    },
                    {
                      "name": "asr_dataset.py",
                      "path": "examples/speech_recognition/data/asr_dataset.py",
                      "type": "file",
                      "size": 3870
                    },
                    {
                      "name": "collaters.py",
                      "path": "examples/speech_recognition/data/collaters.py",
                      "type": "file",
                      "size": 4812
                    },
                    {
                      "name": "data_utils.py",
                      "path": "examples/speech_recognition/data/data_utils.py",
                      "type": "file",
                      "size": 3429
                    },
                    {
                      "name": "replabels.py",
                      "path": "examples/speech_recognition/data/replabels.py",
                      "type": "file",
                      "size": 1970
                    }
                  ]
                },
                {
                  "name": "datasets",
                  "path": "examples/speech_recognition/datasets",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "asr_prep_json.py",
                      "path": "examples/speech_recognition/datasets/asr_prep_json.py",
                      "type": "file",
                      "size": 3670
                    },
                    {
                      "name": "prepare-librispeech.sh",
                      "path": "examples/speech_recognition/datasets/prepare-librispeech.sh",
                      "type": "file",
                      "size": 3822
                    }
                  ]
                },
                {
                  "name": "infer.py",
                  "path": "examples/speech_recognition/infer.py",
                  "type": "file",
                  "size": 14007
                },
                {
                  "name": "models",
                  "path": "examples/speech_recognition/models",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "examples/speech_recognition/models/__init__.py",
                      "type": "file",
                      "size": 266
                    },
                    {
                      "name": "vggtransformer.py",
                      "path": "examples/speech_recognition/models/vggtransformer.py",
                      "type": "file",
                      "size": 37043
                    },
                    {
                      "name": "w2l_conv_glu_enc.py",
                      "path": "examples/speech_recognition/models/w2l_conv_glu_enc.py",
                      "type": "file",
                      "size": 6079
                    }
                  ]
                },
                {
                  "name": "tasks",
                  "path": "examples/speech_recognition/tasks",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "examples/speech_recognition/tasks/__init__.py",
                      "type": "file",
                      "size": 263
                    },
                    {
                      "name": "speech_recognition.py",
                      "path": "examples/speech_recognition/tasks/speech_recognition.py",
                      "type": "file",
                      "size": 5311
                    }
                  ]
                },
                {
                  "name": "utils",
                  "path": "examples/speech_recognition/utils",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "wer_utils.py",
                      "path": "examples/speech_recognition/utils/wer_utils.py",
                      "type": "file",
                      "size": 11842
                    }
                  ]
                },
                {
                  "name": "w2l_decoder.py",
                  "path": "examples/speech_recognition/w2l_decoder.py",
                  "type": "file",
                  "size": 14872
                }
              ]
            },
            {
              "name": "stories",
              "path": "examples/stories",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/stories/README.md",
                  "type": "file",
                  "size": 4145
                }
              ]
            },
            {
              "name": "translation",
              "path": "examples/translation",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/translation/README.md",
                  "type": "file",
                  "size": 14814
                },
                {
                  "name": "prepare-iwslt14.sh",
                  "path": "examples/translation/prepare-iwslt14.sh",
                  "type": "file",
                  "size": 2978
                },
                {
                  "name": "prepare-iwslt17-multilingual.sh",
                  "path": "examples/translation/prepare-iwslt17-multilingual.sh",
                  "type": "file",
                  "size": 4386
                },
                {
                  "name": "prepare-wmt14en2de.sh",
                  "path": "examples/translation/prepare-wmt14en2de.sh",
                  "type": "file",
                  "size": 3962
                },
                {
                  "name": "prepare-wmt14en2fr.sh",
                  "path": "examples/translation/prepare-wmt14en2fr.sh",
                  "type": "file",
                  "size": 3724
                }
              ]
            },
            {
              "name": "translation_moe",
              "path": "examples/translation_moe",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/translation_moe/README.md",
                  "type": "file",
                  "size": 3500
                },
                {
                  "name": "score.py",
                  "path": "examples/translation_moe/score.py",
                  "type": "file",
                  "size": 6101
                },
                {
                  "name": "src",
                  "path": "examples/translation_moe/src",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "examples/translation_moe/src/__init__.py",
                      "type": "file",
                      "size": 216
                    },
                    {
                      "name": "logsumexp_moe.py",
                      "path": "examples/translation_moe/src/logsumexp_moe.py",
                      "type": "file",
                      "size": 835
                    },
                    {
                      "name": "mean_pool_gating_network.py",
                      "path": "examples/translation_moe/src/mean_pool_gating_network.py",
                      "type": "file",
                      "size": 2007
                    },
                    {
                      "name": "translation_moe.py",
                      "path": "examples/translation_moe/src/translation_moe.py",
                      "type": "file",
                      "size": 9143
                    }
                  ]
                }
              ]
            },
            {
              "name": "unsupervised_quality_estimation",
              "path": "examples/unsupervised_quality_estimation",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/unsupervised_quality_estimation/README.md",
                  "type": "file",
                  "size": 5003
                },
                {
                  "name": "aggregate_scores.py",
                  "path": "examples/unsupervised_quality_estimation/aggregate_scores.py",
                  "type": "file",
                  "size": 1135
                },
                {
                  "name": "meteor.py",
                  "path": "examples/unsupervised_quality_estimation/meteor.py",
                  "type": "file",
                  "size": 3318
                },
                {
                  "name": "repeat_lines.py",
                  "path": "examples/unsupervised_quality_estimation/repeat_lines.py",
                  "type": "file",
                  "size": 828
                }
              ]
            },
            {
              "name": "wav2vec",
              "path": "examples/wav2vec",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/wav2vec/README.md",
                  "type": "file",
                  "size": 15771
                },
                {
                  "name": "libri_labels.py",
                  "path": "examples/wav2vec/libri_labels.py",
                  "type": "file",
                  "size": 1836
                },
                {
                  "name": "vq-wav2vec_featurize.py",
                  "path": "examples/wav2vec/vq-wav2vec_featurize.py",
                  "type": "file",
                  "size": 7714
                },
                {
                  "name": "wav2vec_featurize.py",
                  "path": "examples/wav2vec/wav2vec_featurize.py",
                  "type": "file",
                  "size": 7110
                },
                {
                  "name": "wav2vec_manifest.py",
                  "path": "examples/wav2vec/wav2vec_manifest.py",
                  "type": "file",
                  "size": 2176
                }
              ]
            },
            {
              "name": "wmt19",
              "path": "examples/wmt19",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/wmt19/README.md",
                  "type": "file",
                  "size": 3936
                }
              ]
            },
            {
              "name": "xlmr",
              "path": "examples/xlmr",
              "type": "directory",
              "contents": [
                {
                  "name": "README.md",
                  "path": "examples/xlmr/README.md",
                  "type": "file",
                  "size": 5419
                }
              ]
            }
          ]
        },
        {
          "name": "fairseq",
          "path": "fairseq",
          "type": "directory",
          "contents": [
            {
              "name": "__init__.py",
              "path": "fairseq/__init__.py",
              "type": "file",
              "size": 887
            },
            {
              "name": "benchmark",
              "path": "fairseq/benchmark",
              "type": "directory",
              "contents": [
                {
                  "name": "__init__.py",
                  "path": "fairseq/benchmark/__init__.py",
                  "type": "file",
                  "size": 309
                },
                {
                  "name": "dummy_lm.py",
                  "path": "fairseq/benchmark/dummy_lm.py",
                  "type": "file",
                  "size": 3538
                },
                {
                  "name": "dummy_masked_lm.py",
                  "path": "fairseq/benchmark/dummy_masked_lm.py",
                  "type": "file",
                  "size": 3816
                },
                {
                  "name": "dummy_model.py",
                  "path": "fairseq/benchmark/dummy_model.py",
                  "type": "file",
                  "size": 2971
                },
                {
                  "name": "dummy_mt.py",
                  "path": "fairseq/benchmark/dummy_mt.py",
                  "type": "file",
                  "size": 3682
                }
              ]
            },
            {
              "name": "binarizer.py",
              "path": "fairseq/binarizer.py",
              "type": "file",
              "size": 3354
            },
            {
              "name": "checkpoint_utils.py",
              "path": "fairseq/checkpoint_utils.py",
              "type": "file",
              "size": 21012
            },
            {
              "name": "clib",
              "path": "fairseq/clib",
              "type": "directory",
              "contents": [
                {
                  "name": "libbleu",
                  "path": "fairseq/clib/libbleu",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "libbleu.cpp",
                      "path": "fairseq/clib/libbleu/libbleu.cpp",
                      "type": "file",
                      "size": 2923
                    },
                    {
                      "name": "module.cpp",
                      "path": "fairseq/clib/libbleu/module.cpp",
                      "type": "file",
                      "size": 791
                    }
                  ]
                },
                {
                  "name": "libnat",
                  "path": "fairseq/clib/libnat",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "edit_dist.cpp",
                      "path": "fairseq/clib/libnat/edit_dist.cpp",
                      "type": "file",
                      "size": 5958
                    }
                  ]
                },
                {
                  "name": "libnat_cuda",
                  "path": "fairseq/clib/libnat_cuda",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "binding.cpp",
                      "path": "fairseq/clib/libnat_cuda/binding.cpp",
                      "type": "file",
                      "size": 1772
                    },
                    {
                      "name": "edit_dist.cu",
                      "path": "fairseq/clib/libnat_cuda/edit_dist.cu",
                      "type": "file",
                      "size": 10695
                    },
                    {
                      "name": "edit_dist.h",
                      "path": "fairseq/clib/libnat_cuda/edit_dist.h",
                      "type": "file",
                      "size": 659
                    }
                  ]
                }
              ]
            },
            {
              "name": "criterions",
              "path": "fairseq/criterions",
              "type": "directory",
              "contents": [
                {
                  "name": "__init__.py",
                  "path": "fairseq/criterions/__init__.py",
                  "type": "file",
                  "size": 1061
                },
                {
                  "name": "adaptive_loss.py",
                  "path": "fairseq/criterions/adaptive_loss.py",
                  "type": "file",
                  "size": 4550
                },
                {
                  "name": "composite_loss.py",
                  "path": "fairseq/criterions/composite_loss.py",
                  "type": "file",
                  "size": 3689
                },
                {
                  "name": "cross_entropy.py",
                  "path": "fairseq/criterions/cross_entropy.py",
                  "type": "file",
                  "size": 3280
                },
                {
                  "name": "ctc.py",
                  "path": "fairseq/criterions/ctc.py",
                  "type": "file",
                  "size": 9767
                },
                {
                  "name": "fairseq_criterion.py",
                  "path": "fairseq/criterions/fairseq_criterion.py",
                  "type": "file",
                  "size": 4437
                },
                {
                  "name": "label_smoothed_cross_entropy.py",
                  "path": "fairseq/criterions/label_smoothed_cross_entropy.py",
                  "type": "file",
                  "size": 3941
                },
                {
                  "name": "label_smoothed_cross_entropy_with_alignment.py",
                  "path": "fairseq/criterions/label_smoothed_cross_entropy_with_alignment.py",
                  "type": "file",
                  "size": 4393
                },
                {
                  "name": "legacy_masked_lm.py",
                  "path": "fairseq/criterions/legacy_masked_lm.py",
                  "type": "file",
                  "size": 6769
                },
                {
                  "name": "masked_lm.py",
                  "path": "fairseq/criterions/masked_lm.py",
                  "type": "file",
                  "size": 3159
                },
                {
                  "name": "nat_loss.py",
                  "path": "fairseq/criterions/nat_loss.py",
                  "type": "file",
                  "size": 6238
                },
                {
                  "name": "sentence_prediction.py",
                  "path": "fairseq/criterions/sentence_prediction.py",
                  "type": "file",
                  "size": 3717
                },
                {
                  "name": "sentence_ranking.py",
                  "path": "fairseq/criterions/sentence_ranking.py",
                  "type": "file",
                  "size": 4532
                },
                {
                  "name": "wav2vec_criterion.py",
                  "path": "fairseq/criterions/wav2vec_criterion.py",
                  "type": "file",
                  "size": 6437
                }
              ]
            },
            {
              "name": "data",
              "path": "fairseq/data",
              "type": "directory",
              "contents": [
                {
                  "name": "__init__.py",
                  "path": "fairseq/data/__init__.py",
                  "type": "file",
                  "size": 4115
                },
                {
                  "name": "add_target_dataset.py",
                  "path": "fairseq/data/add_target_dataset.py",
                  "type": "file",
                  "size": 2046
                },
                {
                  "name": "append_token_dataset.py",
                  "path": "fairseq/data/append_token_dataset.py",
                  "type": "file",
                  "size": 1066
                },
                {
                  "name": "audio",
                  "path": "fairseq/data/audio",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/data/audio/__init__.py",
                      "type": "file",
                      "size": 0
                    },
                    {
                      "name": "raw_audio_dataset.py",
                      "path": "fairseq/data/audio/raw_audio_dataset.py",
                      "type": "file",
                      "size": 5341
                    }
                  ]
                },
                {
                  "name": "backtranslation_dataset.py",
                  "path": "fairseq/data/backtranslation_dataset.py",
                  "type": "file",
                  "size": 6235
                },
                {
                  "name": "base_wrapper_dataset.py",
                  "path": "fairseq/data/base_wrapper_dataset.py",
                  "type": "file",
                  "size": 2154
                },
                {
                  "name": "bucket_pad_length_dataset.py",
                  "path": "fairseq/data/bucket_pad_length_dataset.py",
                  "type": "file",
                  "size": 2261
                },
                {
                  "name": "colorize_dataset.py",
                  "path": "fairseq/data/colorize_dataset.py",
                  "type": "file",
                  "size": 844
                },
                {
                  "name": "concat_dataset.py",
                  "path": "fairseq/data/concat_dataset.py",
                  "type": "file",
                  "size": 4619
                },
                {
                  "name": "concat_sentences_dataset.py",
                  "path": "fairseq/data/concat_sentences_dataset.py",
                  "type": "file",
                  "size": 1573
                },
                {
                  "name": "data_utils.py",
                  "path": "fairseq/data/data_utils.py",
                  "type": "file",
                  "size": 17434
                },
                {
                  "name": "data_utils_fast.pyx",
                  "path": "fairseq/data/data_utils_fast.pyx",
                  "type": "file",
                  "size": 3588
                },
                {
                  "name": "denoising_dataset.py",
                  "path": "fairseq/data/denoising_dataset.py",
                  "type": "file",
                  "size": 15236
                },
                {
                  "name": "dictionary.py",
                  "path": "fairseq/data/dictionary.py",
                  "type": "file",
                  "size": 12615
                },
                {
                  "name": "encoders",
                  "path": "fairseq/data/encoders",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/data/encoders/__init__.py",
                      "type": "file",
                      "size": 752
                    },
                    {
                      "name": "byte_bpe.py",
                      "path": "fairseq/data/encoders/byte_bpe.py",
                      "type": "file",
                      "size": 1329
                    },
                    {
                      "name": "byte_utils.py",
                      "path": "fairseq/data/encoders/byte_utils.py",
                      "type": "file",
                      "size": 1644
                    },
                    {
                      "name": "bytes.py",
                      "path": "fairseq/data/encoders/bytes.py",
                      "type": "file",
                      "size": 861
                    },
                    {
                      "name": "characters.py",
                      "path": "fairseq/data/encoders/characters.py",
                      "type": "file",
                      "size": 680
                    },
                    {
                      "name": "fastbpe.py",
                      "path": "fairseq/data/encoders/fastbpe.py",
                      "type": "file",
                      "size": 1101
                    },
                    {
                      "name": "gpt2_bpe.py",
                      "path": "fairseq/data/encoders/gpt2_bpe.py",
                      "type": "file",
                      "size": 1637
                    },
                    {
                      "name": "gpt2_bpe_utils.py",
                      "path": "fairseq/data/encoders/gpt2_bpe_utils.py",
                      "type": "file",
                      "size": 4465
                    },
                    {
                      "name": "hf_bert_bpe.py",
                      "path": "fairseq/data/encoders/hf_bert_bpe.py",
                      "type": "file",
                      "size": 1606
                    },
                    {
                      "name": "hf_byte_bpe.py",
                      "path": "fairseq/data/encoders/hf_byte_bpe.py",
                      "type": "file",
                      "size": 1499
                    },
                    {
                      "name": "moses_tokenizer.py",
                      "path": "fairseq/data/encoders/moses_tokenizer.py",
                      "type": "file",
                      "size": 1938
                    },
                    {
                      "name": "nltk_tokenizer.py",
                      "path": "fairseq/data/encoders/nltk_tokenizer.py",
                      "type": "file",
                      "size": 707
                    },
                    {
                      "name": "sentencepiece_bpe.py",
                      "path": "fairseq/data/encoders/sentencepiece_bpe.py",
                      "type": "file",
                      "size": 1630
                    },
                    {
                      "name": "space_tokenizer.py",
                      "path": "fairseq/data/encoders/space_tokenizer.py",
                      "type": "file",
                      "size": 543
                    },
                    {
                      "name": "subword_nmt_bpe.py",
                      "path": "fairseq/data/encoders/subword_nmt_bpe.py",
                      "type": "file",
                      "size": 1642
                    },
                    {
                      "name": "utils.py",
                      "path": "fairseq/data/encoders/utils.py",
                      "type": "file",
                      "size": 907
                    }
                  ]
                },
                {
                  "name": "fairseq_dataset.py",
                  "path": "fairseq/data/fairseq_dataset.py",
                  "type": "file",
                  "size": 6467
                },
                {
                  "name": "fasta_dataset.py",
                  "path": "fairseq/data/fasta_dataset.py",
                  "type": "file",
                  "size": 3387
                },
                {
                  "name": "id_dataset.py",
                  "path": "fairseq/data/id_dataset.py",
                  "type": "file",
                  "size": 424
                },
                {
                  "name": "indexed_dataset.py",
                  "path": "fairseq/data/indexed_dataset.py",
                  "type": "file",
                  "size": 17020
                },
                {
                  "name": "iterators.py",
                  "path": "fairseq/data/iterators.py",
                  "type": "file",
                  "size": 19581
                },
                {
                  "name": "language_pair_dataset.py",
                  "path": "fairseq/data/language_pair_dataset.py",
                  "type": "file",
                  "size": 18304
                },
                {
                  "name": "legacy",
                  "path": "fairseq/data/legacy",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/data/legacy/__init__.py",
                      "type": "file",
                      "size": 453
                    },
                    {
                      "name": "block_pair_dataset.py",
                      "path": "fairseq/data/legacy/block_pair_dataset.py",
                      "type": "file",
                      "size": 12878
                    },
                    {
                      "name": "masked_lm_dataset.py",
                      "path": "fairseq/data/legacy/masked_lm_dataset.py",
                      "type": "file",
                      "size": 12468
                    },
                    {
                      "name": "masked_lm_dictionary.py",
                      "path": "fairseq/data/legacy/masked_lm_dictionary.py",
                      "type": "file",
                      "size": 1557
                    }
                  ]
                },
                {
                  "name": "list_dataset.py",
                  "path": "fairseq/data/list_dataset.py",
                  "type": "file",
                  "size": 730
                },
                {
                  "name": "lm_context_window_dataset.py",
                  "path": "fairseq/data/lm_context_window_dataset.py",
                  "type": "file",
                  "size": 2910
                },
                {
                  "name": "lru_cache_dataset.py",
                  "path": "fairseq/data/lru_cache_dataset.py",
                  "type": "file",
                  "size": 571
                },
                {
                  "name": "mask_tokens_dataset.py",
                  "path": "fairseq/data/mask_tokens_dataset.py",
                  "type": "file",
                  "size": 6973
                },
                {
                  "name": "monolingual_dataset.py",
                  "path": "fairseq/data/monolingual_dataset.py",
                  "type": "file",
                  "size": 7469
                },
                {
                  "name": "multi_corpus_dataset.py",
                  "path": "fairseq/data/multi_corpus_dataset.py",
                  "type": "file",
                  "size": 5232
                },
                {
                  "name": "multi_corpus_sampled_dataset.py",
                  "path": "fairseq/data/multi_corpus_sampled_dataset.py",
                  "type": "file",
                  "size": 5115
                },
                {
                  "name": "multilingual",
                  "path": "fairseq/data/multilingual",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/data/multilingual/__init__.py",
                      "type": "file",
                      "size": 177
                    },
                    {
                      "name": "multilingual_data_manager.py",
                      "path": "fairseq/data/multilingual/multilingual_data_manager.py",
                      "type": "file",
                      "size": 40077
                    },
                    {
                      "name": "multilingual_utils.py",
                      "path": "fairseq/data/multilingual/multilingual_utils.py",
                      "type": "file",
                      "size": 1623
                    },
                    {
                      "name": "sampled_multi_dataset.py",
                      "path": "fairseq/data/multilingual/sampled_multi_dataset.py",
                      "type": "file",
                      "size": 17170
                    },
                    {
                      "name": "sampled_multi_epoch_dataset.py",
                      "path": "fairseq/data/multilingual/sampled_multi_epoch_dataset.py",
                      "type": "file",
                      "size": 7488
                    },
                    {
                      "name": "sampling_method.py",
                      "path": "fairseq/data/multilingual/sampling_method.py",
                      "type": "file",
                      "size": 1947
                    }
                  ]
                },
                {
                  "name": "nested_dictionary_dataset.py",
                  "path": "fairseq/data/nested_dictionary_dataset.py",
                  "type": "file",
                  "size": 3926
                },
                {
                  "name": "noising.py",
                  "path": "fairseq/data/noising.py",
                  "type": "file",
                  "size": 12184
                },
                {
                  "name": "num_samples_dataset.py",
                  "path": "fairseq/data/num_samples_dataset.py",
                  "type": "file",
                  "size": 405
                },
                {
                  "name": "numel_dataset.py",
                  "path": "fairseq/data/numel_dataset.py",
                  "type": "file",
                  "size": 787
                },
                {
                  "name": "offset_tokens_dataset.py",
                  "path": "fairseq/data/offset_tokens_dataset.py",
                  "type": "file",
                  "size": 445
                },
                {
                  "name": "pad_dataset.py",
                  "path": "fairseq/data/pad_dataset.py",
                  "type": "file",
                  "size": 837
                },
                {
                  "name": "plasma_utils.py",
                  "path": "fairseq/data/plasma_utils.py",
                  "type": "file",
                  "size": 2640
                },
                {
                  "name": "prepend_dataset.py",
                  "path": "fairseq/data/prepend_dataset.py",
                  "type": "file",
                  "size": 953
                },
                {
                  "name": "prepend_token_dataset.py",
                  "path": "fairseq/data/prepend_token_dataset.py",
                  "type": "file",
                  "size": 1067
                },
                {
                  "name": "raw_label_dataset.py",
                  "path": "fairseq/data/raw_label_dataset.py",
                  "type": "file",
                  "size": 547
                },
                {
                  "name": "replace_dataset.py",
                  "path": "fairseq/data/replace_dataset.py",
                  "type": "file",
                  "size": 1394
                },
                {
                  "name": "resampling_dataset.py",
                  "path": "fairseq/data/resampling_dataset.py",
                  "type": "file",
                  "size": 4317
                },
                {
                  "name": "roll_dataset.py",
                  "path": "fairseq/data/roll_dataset.py",
                  "type": "file",
                  "size": 486
                },
                {
                  "name": "round_robin_zip_datasets.py",
                  "path": "fairseq/data/round_robin_zip_datasets.py",
                  "type": "file",
                  "size": 4153
                },
                {
                  "name": "shorten_dataset.py",
                  "path": "fairseq/data/shorten_dataset.py",
                  "type": "file",
                  "size": 2441
                },
                {
                  "name": "sort_dataset.py",
                  "path": "fairseq/data/sort_dataset.py",
                  "type": "file",
                  "size": 622
                },
                {
                  "name": "strip_token_dataset.py",
                  "path": "fairseq/data/strip_token_dataset.py",
                  "type": "file",
                  "size": 648
                },
                {
                  "name": "subsample_dataset.py",
                  "path": "fairseq/data/subsample_dataset.py",
                  "type": "file",
                  "size": 2149
                },
                {
                  "name": "token_block_dataset.py",
                  "path": "fairseq/data/token_block_dataset.py",
                  "type": "file",
                  "size": 5966
                },
                {
                  "name": "token_block_utils_fast.pyx",
                  "path": "fairseq/data/token_block_utils_fast.pyx",
                  "type": "file",
                  "size": 6930
                },
                {
                  "name": "transform_eos_dataset.py",
                  "path": "fairseq/data/transform_eos_dataset.py",
                  "type": "file",
                  "size": 4576
                },
                {
                  "name": "transform_eos_lang_pair_dataset.py",
                  "path": "fairseq/data/transform_eos_lang_pair_dataset.py",
                  "type": "file",
                  "size": 3512
                }
              ]
            },
            {
              "name": "dataclass",
              "path": "fairseq/dataclass",
              "type": "directory",
              "contents": [
                {
                  "name": "__init__.py",
                  "path": "fairseq/dataclass/__init__.py",
                  "type": "file",
                  "size": 273
                },
                {
                  "name": "constants.py",
                  "path": "fairseq/dataclass/constants.py",
                  "type": "file",
                  "size": 537
                },
                {
                  "name": "data_class.py",
                  "path": "fairseq/dataclass/data_class.py",
                  "type": "file",
                  "size": 28868
                },
                {
                  "name": "utils.py",
                  "path": "fairseq/dataclass/utils.py",
                  "type": "file",
                  "size": 7375
                }
              ]
            },
            {
              "name": "distributed_utils.py",
              "path": "fairseq/distributed_utils.py",
              "type": "file",
              "size": 16915
            },
            {
              "name": "file_io.py",
              "path": "fairseq/file_io.py",
              "type": "file",
              "size": 3287
            },
            {
              "name": "file_utils.py",
              "path": "fairseq/file_utils.py",
              "type": "file",
              "size": 11036
            },
            {
              "name": "hub_utils.py",
              "path": "fairseq/hub_utils.py",
              "type": "file",
              "size": 10080
            },
            {
              "name": "incremental_decoding_utils.py",
              "path": "fairseq/incremental_decoding_utils.py",
              "type": "file",
              "size": 1760
            },
            {
              "name": "iterative_refinement_generator.py",
              "path": "fairseq/iterative_refinement_generator.py",
              "type": "file",
              "size": 12517
            },
            {
              "name": "legacy_distributed_data_parallel.py",
              "path": "fairseq/legacy_distributed_data_parallel.py",
              "type": "file",
              "size": 6223
            },
            {
              "name": "logging",
              "path": "fairseq/logging",
              "type": "directory",
              "contents": [
                {
                  "name": "__init__.py",
                  "path": "fairseq/logging/__init__.py",
                  "type": "file",
                  "size": 0
                },
                {
                  "name": "meters.py",
                  "path": "fairseq/logging/meters.py",
                  "type": "file",
                  "size": 7885
                },
                {
                  "name": "metrics.py",
                  "path": "fairseq/logging/metrics.py",
                  "type": "file",
                  "size": 9325
                },
                {
                  "name": "progress_bar.py",
                  "path": "fairseq/logging/progress_bar.py",
                  "type": "file",
                  "size": 11082
                }
              ]
            },
            {
              "name": "model_parallel",
              "path": "fairseq/model_parallel",
              "type": "directory",
              "contents": [
                {
                  "name": "__init__.py",
                  "path": "fairseq/model_parallel/__init__.py",
                  "type": "file",
                  "size": 228
                },
                {
                  "name": "criterions",
                  "path": "fairseq/model_parallel/criterions",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/model_parallel/criterions/__init__.py",
                      "type": "file",
                      "size": 505
                    },
                    {
                      "name": "vocab_parallel_cross_entropy.py",
                      "path": "fairseq/model_parallel/criterions/vocab_parallel_cross_entropy.py",
                      "type": "file",
                      "size": 3003
                    }
                  ]
                },
                {
                  "name": "megatron",
                  "path": "fairseq/model_parallel/megatron",
                  "type": "file",
                  "size": 0
                },
                {
                  "name": "megatron_trainer.py",
                  "path": "fairseq/model_parallel/megatron_trainer.py",
                  "type": "file",
                  "size": 1959
                },
                {
                  "name": "models",
                  "path": "fairseq/model_parallel/models",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/model_parallel/models/__init__.py",
                      "type": "file",
                      "size": 668
                    },
                    {
                      "name": "pipeline_parallel_transformer",
                      "path": "fairseq/model_parallel/models/pipeline_parallel_transformer",
                      "type": "directory",
                      "contents": [
                        {
                          "name": "__init__.py",
                          "path": "fairseq/model_parallel/models/pipeline_parallel_transformer/__init__.py",
                          "type": "file",
                          "size": 207
                        },
                        {
                          "name": "layers.py",
                          "path": "fairseq/model_parallel/models/pipeline_parallel_transformer/layers.py",
                          "type": "file",
                          "size": 22150
                        },
                        {
                          "name": "model.py",
                          "path": "fairseq/model_parallel/models/pipeline_parallel_transformer/model.py",
                          "type": "file",
                          "size": 31005
                        }
                      ]
                    },
                    {
                      "name": "roberta",
                      "path": "fairseq/model_parallel/models/roberta",
                      "type": "directory",
                      "contents": [
                        {
                          "name": "__init__.py",
                          "path": "fairseq/model_parallel/models/roberta/__init__.py",
                          "type": "file",
                          "size": 207
                        },
                        {
                          "name": "model.py",
                          "path": "fairseq/model_parallel/models/roberta/model.py",
                          "type": "file",
                          "size": 10704
                        }
                      ]
                    },
                    {
                      "name": "transformer.py",
                      "path": "fairseq/model_parallel/models/transformer.py",
                      "type": "file",
                      "size": 3708
                    },
                    {
                      "name": "transformer_lm.py",
                      "path": "fairseq/model_parallel/models/transformer_lm.py",
                      "type": "file",
                      "size": 7237
                    }
                  ]
                },
                {
                  "name": "modules",
                  "path": "fairseq/model_parallel/modules",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/model_parallel/modules/__init__.py",
                      "type": "file",
                      "size": 765
                    },
                    {
                      "name": "multihead_attention.py",
                      "path": "fairseq/model_parallel/modules/multihead_attention.py",
                      "type": "file",
                      "size": 12920
                    },
                    {
                      "name": "transformer_layer.py",
                      "path": "fairseq/model_parallel/modules/transformer_layer.py",
                      "type": "file",
                      "size": 2866
                    },
                    {
                      "name": "transformer_sentence_encoder.py",
                      "path": "fairseq/model_parallel/modules/transformer_sentence_encoder.py",
                      "type": "file",
                      "size": 1785
                    },
                    {
                      "name": "transformer_sentence_encoder_layer.py",
                      "path": "fairseq/model_parallel/modules/transformer_sentence_encoder_layer.py",
                      "type": "file",
                      "size": 2356
                    }
                  ]
                }
              ]
            },
            {
              "name": "models",
              "path": "fairseq/models",
              "type": "directory",
              "contents": [
                {
                  "name": "__init__.py",
                  "path": "fairseq/models/__init__.py",
                  "type": "file",
                  "size": 6599
                },
                {
                  "name": "bart",
                  "path": "fairseq/models/bart",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/models/bart/__init__.py",
                      "type": "file",
                      "size": 244
                    },
                    {
                      "name": "hub_interface.py",
                      "path": "fairseq/models/bart/hub_interface.py",
                      "type": "file",
                      "size": 6947
                    },
                    {
                      "name": "model.py",
                      "path": "fairseq/models/bart/model.py",
                      "type": "file",
                      "size": 13648
                    }
                  ]
                },
                {
                  "name": "composite_encoder.py",
                  "path": "fairseq/models/composite_encoder.py",
                  "type": "file",
                  "size": 1898
                },
                {
                  "name": "distributed_fairseq_model.py",
                  "path": "fairseq/models/distributed_fairseq_model.py",
                  "type": "file",
                  "size": 3938
                },
                {
                  "name": "fairseq_decoder.py",
                  "path": "fairseq/models/fairseq_decoder.py",
                  "type": "file",
                  "size": 3064
                },
                {
                  "name": "fairseq_encoder.py",
                  "path": "fairseq/models/fairseq_encoder.py",
                  "type": "file",
                  "size": 2955
                },
                {
                  "name": "fairseq_incremental_decoder.py",
                  "path": "fairseq/models/fairseq_incremental_decoder.py",
                  "type": "file",
                  "size": 4387
                },
                {
                  "name": "fairseq_model.py",
                  "path": "fairseq/models/fairseq_model.py",
                  "type": "file",
                  "size": 19821
                },
                {
                  "name": "fconv.py",
                  "path": "fairseq/models/fconv.py",
                  "type": "file",
                  "size": 27685
                },
                {
                  "name": "fconv_lm.py",
                  "path": "fairseq/models/fconv_lm.py",
                  "type": "file",
                  "size": 4753
                },
                {
                  "name": "fconv_self_att.py",
                  "path": "fairseq/models/fconv_self_att.py",
                  "type": "file",
                  "size": 24306
                },
                {
                  "name": "huggingface",
                  "path": "fairseq/models/huggingface",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/models/huggingface/__init__.py",
                      "type": "file",
                      "size": 709
                    },
                    {
                      "name": "hf_gpt2.py",
                      "path": "fairseq/models/huggingface/hf_gpt2.py",
                      "type": "file",
                      "size": 7034
                    },
                    {
                      "name": "transformers",
                      "path": "fairseq/models/huggingface/transformers",
                      "type": "file",
                      "size": 0
                    }
                  ]
                },
                {
                  "name": "lightconv.py",
                  "path": "fairseq/models/lightconv.py",
                  "type": "file",
                  "size": 36573
                },
                {
                  "name": "lightconv_lm.py",
                  "path": "fairseq/models/lightconv_lm.py",
                  "type": "file",
                  "size": 10288
                },
                {
                  "name": "lstm.py",
                  "path": "fairseq/models/lstm.py",
                  "type": "file",
                  "size": 29625
                },
                {
                  "name": "lstm_lm.py",
                  "path": "fairseq/models/lstm_lm.py",
                  "type": "file",
                  "size": 6311
                },
                {
                  "name": "masked_lm.py",
                  "path": "fairseq/models/masked_lm.py",
                  "type": "file",
                  "size": 15107
                },
                {
                  "name": "model_utils.py",
                  "path": "fairseq/models/model_utils.py",
                  "type": "file",
                  "size": 2335
                },
                {
                  "name": "multilingual_transformer.py",
                  "path": "fairseq/models/multilingual_transformer.py",
                  "type": "file",
                  "size": 8969
                },
                {
                  "name": "nat",
                  "path": "fairseq/models/nat",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/models/nat/__init__.py",
                      "type": "file",
                      "size": 276
                    },
                    {
                      "name": "cmlm_transformer.py",
                      "path": "fairseq/models/nat/cmlm_transformer.py",
                      "type": "file",
                      "size": 6347
                    },
                    {
                      "name": "fairseq_nat_model.py",
                      "path": "fairseq/models/nat/fairseq_nat_model.py",
                      "type": "file",
                      "size": 4959
                    },
                    {
                      "name": "insertion_transformer.py",
                      "path": "fairseq/models/nat/insertion_transformer.py",
                      "type": "file",
                      "size": 10448
                    },
                    {
                      "name": "iterative_nonautoregressive_transformer.py",
                      "path": "fairseq/models/nat/iterative_nonautoregressive_transformer.py",
                      "type": "file",
                      "size": 8427
                    },
                    {
                      "name": "levenshtein_transformer.py",
                      "path": "fairseq/models/nat/levenshtein_transformer.py",
                      "type": "file",
                      "size": 19562
                    },
                    {
                      "name": "levenshtein_utils.py",
                      "path": "fairseq/models/nat/levenshtein_utils.py",
                      "type": "file",
                      "size": 9372
                    },
                    {
                      "name": "nat_crf_transformer.py",
                      "path": "fairseq/models/nat/nat_crf_transformer.py",
                      "type": "file",
                      "size": 4252
                    },
                    {
                      "name": "nonautoregressive_ensembles.py",
                      "path": "fairseq/models/nat/nonautoregressive_ensembles.py",
                      "type": "file",
                      "size": 9020
                    },
                    {
                      "name": "nonautoregressive_transformer.py",
                      "path": "fairseq/models/nat/nonautoregressive_transformer.py",
                      "type": "file",
                      "size": 16114
                    }
                  ]
                },
                {
                  "name": "roberta",
                  "path": "fairseq/models/roberta",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/models/roberta/__init__.py",
                      "type": "file",
                      "size": 317
                    },
                    {
                      "name": "alignment_utils.py",
                      "path": "fairseq/models/roberta/alignment_utils.py",
                      "type": "file",
                      "size": 4074
                    },
                    {
                      "name": "hub_interface.py",
                      "path": "fairseq/models/roberta/hub_interface.py",
                      "type": "file",
                      "size": 8422
                    },
                    {
                      "name": "model.py",
                      "path": "fairseq/models/roberta/model.py",
                      "type": "file",
                      "size": 17545
                    },
                    {
                      "name": "model_camembert.py",
                      "path": "fairseq/models/roberta/model_camembert.py",
                      "type": "file",
                      "size": 1888
                    },
                    {
                      "name": "model_xlmr.py",
                      "path": "fairseq/models/roberta/model_xlmr.py",
                      "type": "file",
                      "size": 1204
                    }
                  ]
                },
                {
                  "name": "transformer.py",
                  "path": "fairseq/models/transformer.py",
                  "type": "file",
                  "size": 42924
                },
                {
                  "name": "transformer_align.py",
                  "path": "fairseq/models/transformer_align.py",
                  "type": "file",
                  "size": 3532
                },
                {
                  "name": "transformer_from_pretrained_xlm.py",
                  "path": "fairseq/models/transformer_from_pretrained_xlm.py",
                  "type": "file",
                  "size": 6085
                },
                {
                  "name": "transformer_lm.py",
                  "path": "fairseq/models/transformer_lm.py",
                  "type": "file",
                  "size": 16839
                },
                {
                  "name": "wav2vec",
                  "path": "fairseq/models/wav2vec",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/models/wav2vec/__init__.py",
                      "type": "file",
                      "size": 277
                    },
                    {
                      "name": "wav2vec.py",
                      "path": "fairseq/models/wav2vec/wav2vec.py",
                      "type": "file",
                      "size": 24032
                    },
                    {
                      "name": "wav2vec2.py",
                      "path": "fairseq/models/wav2vec/wav2vec2.py",
                      "type": "file",
                      "size": 33628
                    },
                    {
                      "name": "wav2vec2_asr.py",
                      "path": "fairseq/models/wav2vec/wav2vec2_asr.py",
                      "type": "file",
                      "size": 22473
                    }
                  ]
                }
              ]
            },
            {
              "name": "modules",
              "path": "fairseq/modules",
              "type": "directory",
              "contents": [
                {
                  "name": "__init__.py",
                  "path": "fairseq/modules/__init__.py",
                  "type": "file",
                  "size": 2655
                },
                {
                  "name": "adaptive_input.py",
                  "path": "fairseq/modules/adaptive_input.py",
                  "type": "file",
                  "size": 2514
                },
                {
                  "name": "adaptive_softmax.py",
                  "path": "fairseq/modules/adaptive_softmax.py",
                  "type": "file",
                  "size": 7945
                },
                {
                  "name": "beamable_mm.py",
                  "path": "fairseq/modules/beamable_mm.py",
                  "type": "file",
                  "size": 1779
                },
                {
                  "name": "character_token_embedder.py",
                  "path": "fairseq/modules/character_token_embedder.py",
                  "type": "file",
                  "size": 6846
                },
                {
                  "name": "conv_tbc.py",
                  "path": "fairseq/modules/conv_tbc.py",
                  "type": "file",
                  "size": 1356
                },
                {
                  "name": "cross_entropy.py",
                  "path": "fairseq/modules/cross_entropy.py",
                  "type": "file",
                  "size": 1650
                },
                {
                  "name": "cuda_utils.cu",
                  "path": "fairseq/modules/cuda_utils.cu",
                  "type": "file",
                  "size": 5817
                },
                {
                  "name": "downsampled_multihead_attention.py",
                  "path": "fairseq/modules/downsampled_multihead_attention.py",
                  "type": "file",
                  "size": 9863
                },
                {
                  "name": "dynamic_convolution.py",
                  "path": "fairseq/modules/dynamic_convolution.py",
                  "type": "file",
                  "size": 11057
                },
                {
                  "name": "dynamic_crf_layer.py",
                  "path": "fairseq/modules/dynamic_crf_layer.py",
                  "type": "file",
                  "size": 7676
                },
                {
                  "name": "dynamicconv_layer",
                  "path": "fairseq/modules/dynamicconv_layer",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/modules/dynamicconv_layer/__init__.py",
                      "type": "file",
                      "size": 234
                    },
                    {
                      "name": "cuda_function_gen.py",
                      "path": "fairseq/modules/dynamicconv_layer/cuda_function_gen.py",
                      "type": "file",
                      "size": 6866
                    },
                    {
                      "name": "dynamicconv_cuda.cpp",
                      "path": "fairseq/modules/dynamicconv_layer/dynamicconv_cuda.cpp",
                      "type": "file",
                      "size": 1478
                    },
                    {
                      "name": "dynamicconv_cuda.cuh",
                      "path": "fairseq/modules/dynamicconv_layer/dynamicconv_cuda.cuh",
                      "type": "file",
                      "size": 1406
                    },
                    {
                      "name": "dynamicconv_cuda_kernel.cu",
                      "path": "fairseq/modules/dynamicconv_layer/dynamicconv_cuda_kernel.cu",
                      "type": "file",
                      "size": 5794
                    },
                    {
                      "name": "dynamicconv_layer.py",
                      "path": "fairseq/modules/dynamicconv_layer/dynamicconv_layer.py",
                      "type": "file",
                      "size": 8719
                    },
                    {
                      "name": "dynamiconv_cpu.cpp",
                      "path": "fairseq/modules/dynamicconv_layer/dynamiconv_cpu.cpp",
                      "type": "file",
                      "size": 841
                    },
                    {
                      "name": "setup.py",
                      "path": "fairseq/modules/dynamicconv_layer/setup.py",
                      "type": "file",
                      "size": 613
                    }
                  ]
                },
                {
                  "name": "fairseq_dropout.py",
                  "path": "fairseq/modules/fairseq_dropout.py",
                  "type": "file",
                  "size": 1687
                },
                {
                  "name": "fp32_group_norm.py",
                  "path": "fairseq/modules/fp32_group_norm.py",
                  "type": "file",
                  "size": 727
                },
                {
                  "name": "gelu.py",
                  "path": "fairseq/modules/gelu.py",
                  "type": "file",
                  "size": 706
                },
                {
                  "name": "grad_multiply.py",
                  "path": "fairseq/modules/grad_multiply.py",
                  "type": "file",
                  "size": 442
                },
                {
                  "name": "gumbel_vector_quantizer.py",
                  "path": "fairseq/modules/gumbel_vector_quantizer.py",
                  "type": "file",
                  "size": 6792
                },
                {
                  "name": "kmeans_vector_quantizer.py",
                  "path": "fairseq/modules/kmeans_vector_quantizer.py",
                  "type": "file",
                  "size": 4248
                },
                {
                  "name": "layer_drop.py",
                  "path": "fairseq/modules/layer_drop.py",
                  "type": "file",
                  "size": 1409
                },
                {
                  "name": "layer_norm.py",
                  "path": "fairseq/modules/layer_norm.py",
                  "type": "file",
                  "size": 1499
                },
                {
                  "name": "learned_positional_embedding.py",
                  "path": "fairseq/modules/learned_positional_embedding.py",
                  "type": "file",
                  "size": 2259
                },
                {
                  "name": "lightconv_layer",
                  "path": "fairseq/modules/lightconv_layer",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/modules/lightconv_layer/__init__.py",
                      "type": "file",
                      "size": 230
                    },
                    {
                      "name": "cuda_function_gen.py",
                      "path": "fairseq/modules/lightconv_layer/cuda_function_gen.py",
                      "type": "file",
                      "size": 9642
                    },
                    {
                      "name": "lightconv_cuda.cpp",
                      "path": "fairseq/modules/lightconv_layer/lightconv_cuda.cpp",
                      "type": "file",
                      "size": 1432
                    },
                    {
                      "name": "lightconv_cuda.cuh",
                      "path": "fairseq/modules/lightconv_layer/lightconv_cuda.cuh",
                      "type": "file",
                      "size": 2165
                    },
                    {
                      "name": "lightconv_cuda_kernel.cu",
                      "path": "fairseq/modules/lightconv_layer/lightconv_cuda_kernel.cu",
                      "type": "file",
                      "size": 10609
                    },
                    {
                      "name": "lightconv_layer.py",
                      "path": "fairseq/modules/lightconv_layer/lightconv_layer.py",
                      "type": "file",
                      "size": 4679
                    },
                    {
                      "name": "setup.py",
                      "path": "fairseq/modules/lightconv_layer/setup.py",
                      "type": "file",
                      "size": 545
                    }
                  ]
                },
                {
                  "name": "lightweight_convolution.py",
                  "path": "fairseq/modules/lightweight_convolution.py",
                  "type": "file",
                  "size": 10496
                },
                {
                  "name": "linearized_convolution.py",
                  "path": "fairseq/modules/linearized_convolution.py",
                  "type": "file",
                  "size": 4261
                },
                {
                  "name": "multihead_attention.py",
                  "path": "fairseq/modules/multihead_attention.py",
                  "type": "file",
                  "size": 19130
                },
                {
                  "name": "positional_embedding.py",
                  "path": "fairseq/modules/positional_embedding.py",
                  "type": "file",
                  "size": 1286
                },
                {
                  "name": "quant_noise.py",
                  "path": "fairseq/modules/quant_noise.py",
                  "type": "file",
                  "size": 3666
                },
                {
                  "name": "quantization",
                  "path": "fairseq/modules/quantization",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/modules/quantization/__init__.py",
                      "type": "file",
                      "size": 0
                    },
                    {
                      "name": "pq",
                      "path": "fairseq/modules/quantization/pq",
                      "type": "directory",
                      "contents": [
                        {
                          "name": "__init__.py",
                          "path": "fairseq/modules/quantization/pq/__init__.py",
                          "type": "file",
                          "size": 234
                        },
                        {
                          "name": "em.py",
                          "path": "fairseq/modules/quantization/pq/em.py",
                          "type": "file",
                          "size": 7333
                        },
                        {
                          "name": "modules",
                          "path": "fairseq/modules/quantization/pq/modules",
                          "type": "directory",
                          "truncated": true
                        },
                        {
                          "name": "pq.py",
                          "path": "fairseq/modules/quantization/pq/pq.py",
                          "type": "file",
                          "size": 4292
                        },
                        {
                          "name": "utils.py",
                          "path": "fairseq/modules/quantization/pq/utils.py",
                          "type": "file",
                          "size": 11605
                        }
                      ]
                    },
                    {
                      "name": "quantization_options.py",
                      "path": "fairseq/modules/quantization/quantization_options.py",
                      "type": "file",
                      "size": 1647
                    },
                    {
                      "name": "scalar",
                      "path": "fairseq/modules/quantization/scalar",
                      "type": "directory",
                      "contents": [
                        {
                          "name": "__init__.py",
                          "path": "fairseq/modules/quantization/scalar/__init__.py",
                          "type": "file",
                          "size": 221
                        },
                        {
                          "name": "modules",
                          "path": "fairseq/modules/quantization/scalar/modules",
                          "type": "directory",
                          "truncated": true
                        },
                        {
                          "name": "ops.py",
                          "path": "fairseq/modules/quantization/scalar/ops.py",
                          "type": "file",
                          "size": 1669
                        },
                        {
                          "name": "utils.py",
                          "path": "fairseq/modules/quantization/scalar/utils.py",
                          "type": "file",
                          "size": 2323
                        }
                      ]
                    }
                  ]
                },
                {
                  "name": "same_pad.py",
                  "path": "fairseq/modules/same_pad.py",
                  "type": "file",
                  "size": 432
                },
                {
                  "name": "scalar_bias.py",
                  "path": "fairseq/modules/scalar_bias.py",
                  "type": "file",
                  "size": 888
                },
                {
                  "name": "sinusoidal_positional_embedding.py",
                  "path": "fairseq/modules/sinusoidal_positional_embedding.py",
                  "type": "file",
                  "size": 3880
                },
                {
                  "name": "sparse_multihead_attention.py",
                  "path": "fairseq/modules/sparse_multihead_attention.py",
                  "type": "file",
                  "size": 4525
                },
                {
                  "name": "sparse_transformer_sentence_encoder.py",
                  "path": "fairseq/modules/sparse_transformer_sentence_encoder.py",
                  "type": "file",
                  "size": 2965
                },
                {
                  "name": "sparse_transformer_sentence_encoder_layer.py",
                  "path": "fairseq/modules/sparse_transformer_sentence_encoder_layer.py",
                  "type": "file",
                  "size": 1490
                },
                {
                  "name": "transformer_layer.py",
                  "path": "fairseq/modules/transformer_layer.py",
                  "type": "file",
                  "size": 16391
                },
                {
                  "name": "transformer_sentence_encoder.py",
                  "path": "fairseq/modules/transformer_sentence_encoder.py",
                  "type": "file",
                  "size": 9734
                },
                {
                  "name": "transformer_sentence_encoder_layer.py",
                  "path": "fairseq/modules/transformer_sentence_encoder_layer.py",
                  "type": "file",
                  "size": 4160
                },
                {
                  "name": "transpose_last.py",
                  "path": "fairseq/modules/transpose_last.py",
                  "type": "file",
                  "size": 550
                },
                {
                  "name": "unfold.py",
                  "path": "fairseq/modules/unfold.py",
                  "type": "file",
                  "size": 570
                },
                {
                  "name": "vggblock.py",
                  "path": "fairseq/modules/vggblock.py",
                  "type": "file",
                  "size": 4057
                }
              ]
            },
            {
              "name": "nan_detector.py",
              "path": "fairseq/nan_detector.py",
              "type": "file",
              "size": 3757
            },
            {
              "name": "optim",
              "path": "fairseq/optim",
              "type": "directory",
              "contents": [
                {
                  "name": "__init__.py",
                  "path": "fairseq/optim/__init__.py",
                  "type": "file",
                  "size": 1551
                },
                {
                  "name": "adadelta.py",
                  "path": "fairseq/optim/adadelta.py",
                  "type": "file",
                  "size": 1835
                },
                {
                  "name": "adafactor.py",
                  "path": "fairseq/optim/adafactor.py",
                  "type": "file",
                  "size": 10523
                },
                {
                  "name": "adagrad.py",
                  "path": "fairseq/optim/adagrad.py",
                  "type": "file",
                  "size": 1278
                },
                {
                  "name": "adam.py",
                  "path": "fairseq/optim/adam.py",
                  "type": "file",
                  "size": 8448
                },
                {
                  "name": "adamax.py",
                  "path": "fairseq/optim/adamax.py",
                  "type": "file",
                  "size": 6096
                },
                {
                  "name": "bmuf.py",
                  "path": "fairseq/optim/bmuf.py",
                  "type": "file",
                  "size": 8426
                },
                {
                  "name": "dynamic_loss_scaler.py",
                  "path": "fairseq/optim/dynamic_loss_scaler.py",
                  "type": "file",
                  "size": 2539
                },
                {
                  "name": "fairseq_optimizer.py",
                  "path": "fairseq/optim/fairseq_optimizer.py",
                  "type": "file",
                  "size": 5092
                },
                {
                  "name": "fp16_optimizer.py",
                  "path": "fairseq/optim/fp16_optimizer.py",
                  "type": "file",
                  "size": 18108
                },
                {
                  "name": "fused_adam.py",
                  "path": "fairseq/optim/fused_adam.py",
                  "type": "file",
                  "size": 13372
                },
                {
                  "name": "fused_lamb.py",
                  "path": "fairseq/optim/fused_lamb.py",
                  "type": "file",
                  "size": 1833
                },
                {
                  "name": "lr_scheduler",
                  "path": "fairseq/optim/lr_scheduler",
                  "type": "directory",
                  "contents": [
                    {
                      "name": "__init__.py",
                      "path": "fairseq/optim/lr_scheduler/__init__.py",
                      "type": "file",
                      "size": 1123
                    },
                    {
                      "name": "cosine_lr_scheduler.py",
                      "path": "fairseq/optim/lr_scheduler/cosine_lr_scheduler.py",
                      "type": "file",
                      "size": 4989
                    },
                    {
                      "name": "fairseq_lr_scheduler.py",
                      "path": "fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py",
                      "type": "file",
                      "size": 1869
                    },
                    {
                      "name": "fixed_schedule.py",
                      "path": "fairseq/optim/lr_scheduler/fixed_schedule.py",
                      "type": "file",
                      "size": 2649
                    },
                    {
                      "name": "inverse_square_root_schedule.py",
                      "path": "fairseq/optim/lr_scheduler/inverse_square_root_schedule.py",
                      "type": "file",
                      "size": 3114
                    },
                    {
                      "name": "polynomial_decay_schedule.py",
                      "path": "fairseq/optim/lr_scheduler/polynomial_decay_schedule.py",
                      "type": "file",
                      "size": 2995
                    },
                    {
                      "name": "reduce_lr_on_plateau.py",
                      "path": "fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py",
                      "type": "file",
                      "size": 4755
                    },
                    {
                      "name": "tri_stage_lr_scheduler.py",
                      "path": "fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py",
                      "type": "file",
                      "size": 5074
                    },
                    {
                      "name": "triangular_lr_scheduler.py",
                      "path": "fairseq/optim/lr_scheduler/triangular_lr_scheduler.py",
                      "type": "file",
                      "size": 2723
                    }
                  ]
                },
                {
                  "name": "nag.py",
                  "path": "fairseq/optim/nag.py",
                  "type": "file",
                  "size": 3583
                },
                {
                  "name": "sgd.py",
                  "path": "fairseq/optim/sgd.py",
                  "type": "file",
                  "size": 1442
                },
                {
                  "name": "shard.py",
                  "path": "fairseq/optim/shard.py",
                  "type": "file",
                  "size": 1076
                }
              ]
            },
            {
              "name": "options.py",
              "path": "fairseq/options.py",
              "type": "file",
              "size": 19581
            },
            {
              "name": "pdb.py",
              "path": "fairseq/pdb.py",
              "type": "file",
              "size": 1089
            },
            {
              "name": "quantization_utils.py",
              "path": "fairseq/quantization_utils.py",
              "type": "file",
              "size": 5440
            },
            {
              "name": "registry.py",
              "path": "fairseq/registry.py",
              "type": "file",
              "size": 3797
            },
            {
              "name": "scoring",
              "path": "fairseq/scoring",
              "type": "directory",
              "contents": [
                {
                  "name": "__init__.py",
                  "path": "fairseq/scoring/__init__.py",
                  "type": "file",
                  "size": 1076
                },
                {
                  "name": "bleu.py",
                  "path": "fairseq/scoring/bleu.py",
                  "type": "file",
                  "size": 4141
                },
                {
                  "name": "wer.py",
                  "path": "fairseq/scoring/wer.py",
                  "type": "file",
                  "size": 844
                }
              ]
            },
            {
              "name": "search.py",
              "path": "fairseq/search.py",
              "type": "file",
              "size": 27939
            },
            {
              "name": "sequence_generator.py",
              "path": "fairseq/sequence_generator.py",
              "type": "file",
              "size": 39636
            },
            {
              "name": "sequence_scorer.py",
              "path": "fairseq/sequence_scorer.py",
              "type": "file",
              "size": 5148
            },
            {
              "name": "tasks",
              "path": "fairseq/tasks",
              "type": "directory",
              "contents": [
                {
                  "name": "__init__.py",
                  "path": "fairseq/tasks/__init__.py",
                  "type": "file",
                  "size": 3326
                },
                {
                  "name": "audio_pretraining.py",
                  "path": "fairseq/tasks/audio_pretraining.py",
                  "type": "file",
                  "size": 4723
                },
                {
                  "name": "cross_lingual_lm.py",
                  "path": "fairseq/tasks/cross_lingual_lm.py",
                  "type": "file",
                  "size": 6188
                },
                {
                  "name": "denoising.py",
                  "path": "fairseq/tasks/denoising.py",
                  "type": "file",
                  "size": 6147
                },
                {
                  "name": "fairseq_task.py",
                  "path": "fairseq/tasks/fairseq_task.py",
                  "type": "file",
                  "size": 20699
                },
                {
                  "name": "language_modeling.py",
                  "path": "fairseq/tasks/language_modeling.py",
                  "type": "file",
                  "size": 11742
                },
                {
                  "name": "legacy_masked_lm.py",
                  "path": "fairseq/tasks/legacy_masked_lm.py",
                  "type": "file",
                  "size": 4894
                },
                {
                  "name": "masked_lm.py",
                  "path": "fairseq/tasks/masked_lm.py",
                  "type": "file",
                  "size": 8345
                },
                {
                  "name": "multilingual_denoising.py",
                  "path": "fairseq/tasks/multilingual_denoising.py",
                  "type": "file",
                  "size": 8285
                },
                {
                  "name": "multilingual_masked_lm.py",
                  "path": "fairseq/tasks/multilingual_masked_lm.py",
                  "type": "file",
                  "size": 11909
                },
                {
                  "name": "multilingual_translation.py",
                  "path": "fairseq/tasks/multilingual_translation.py",
                  "type": "file",
                  "size": 15955
                },
                {
                  "name": "semisupervised_translation.py",
                  "path": "fairseq/tasks/semisupervised_translation.py",
                  "type": "file",
                  "size": 18621
                },
                {
                  "name": "sentence_prediction.py",
                  "path": "fairseq/tasks/sentence_prediction.py",
                  "type": "file",
                  "size": 8862
                },
                {
                  "name": "sentence_ranking.py",
                  "path": "fairseq/tasks/sentence_ranking.py",
                  "type": "file",
                  "size": 7010
                },
                {
                  "name": "translation.py",
                  "path": "fairseq/tasks/translation.py",
                  "type": "file",
                  "size": 17485
                },
                {
                  "name": "translation_from_pretrained_bart.py",
                  "path": "fairseq/tasks/translation_from_pretrained_bart.py",
                  "type": "file",
                  "size": 5179
                },
                {
                  "name": "translation_from_pretrained_xlm.py",
                  "path": "fairseq/tasks/translation_from_pretrained_xlm.py",
                  "type": "file",
                  "size": 1106
                },
                {
                  "name": "translation_lev.py",
                  "path": "fairseq/tasks/translation_lev.py",
                  "type": "file",
                  "size": 7230
                },
                {
                  "name": "translation_multi_simple_epoch.py",
                  "path": "fairseq/tasks/translation_multi_simple_epoch.py",
                  "type": "file",
                  "size": 15730
                }
              ]
            },
            {
              "name": "token_generation_constraints.py",
              "path": "fairseq/token_generation_constraints.py",
              "type": "file",
              "size": 16526
            },
            {
              "name": "tokenizer.py",
              "path": "fairseq/tokenizer.py",
              "type": "file",
              "size": 345
            },
            {
              "name": "trainer.py",
              "path": "fairseq/trainer.py",
              "type": "file",
              "size": 41639
            },
            {
              "name": "utils.py",
              "path": "fairseq/utils.py",
              "type": "file",
              "size": 22015
            }
          ]
        },
        {
          "name": "fairseq_cli",
          "path": "fairseq_cli",
          "type": "directory",
          "contents": [
            {
              "name": "__init__.py",
              "path": "fairseq_cli/__init__.py",
              "type": "file",
              "size": 0
            },
            {
              "name": "eval_lm.py",
              "path": "fairseq_cli/eval_lm.py",
              "type": "file",
              "size": 8969
            },
            {
              "name": "generate.py",
              "path": "fairseq_cli/generate.py",
              "type": "file",
              "size": 12552
            },
            {
              "name": "interactive.py",
              "path": "fairseq_cli/interactive.py",
              "type": "file",
              "size": 10253
            },
            {
              "name": "preprocess.py",
              "path": "fairseq_cli/preprocess.py",
              "type": "file",
              "size": 14099
            },
            {
              "name": "score.py",
              "path": "fairseq_cli/score.py",
              "type": "file",
              "size": 3066
            },
            {
              "name": "train.py",
              "path": "fairseq_cli/train.py",
              "type": "file",
              "size": 12033
            },
            {
              "name": "validate.py",
              "path": "fairseq_cli/validate.py",
              "type": "file",
              "size": 4380
            }
          ]
        },
        {
          "name": "hubconf.py",
          "path": "hubconf.py",
          "type": "file",
          "size": 2019
        },
        {
          "name": "pyproject.toml",
          "path": "pyproject.toml",
          "type": "file",
          "size": 100
        },
        {
          "name": "scripts",
          "path": "scripts",
          "type": "directory",
          "contents": [
            {
              "name": "__init__.py",
              "path": "scripts/__init__.py",
              "type": "file",
              "size": 0
            },
            {
              "name": "average_checkpoints.py",
              "path": "scripts/average_checkpoints.py",
              "type": "file",
              "size": 5957
            },
            {
              "name": "build_sym_alignment.py",
              "path": "scripts/build_sym_alignment.py",
              "type": "file",
              "size": 3806
            },
            {
              "name": "compare_namespaces.py",
              "path": "scripts/compare_namespaces.py",
              "type": "file",
              "size": 1052
            },
            {
              "name": "compound_split_bleu.sh",
              "path": "scripts/compound_split_bleu.sh",
              "type": "file",
              "size": 439
            },
            {
              "name": "constraints",
              "path": "scripts/constraints",
              "type": "directory",
              "contents": [
                {
                  "name": "extract.py",
                  "path": "scripts/constraints/extract.py",
                  "type": "file",
                  "size": 2827
                },
                {
                  "name": "validate.py",
                  "path": "scripts/constraints/validate.py",
                  "type": "file",
                  "size": 930
                }
              ]
            },
            {
              "name": "convert_dictionary.lua",
              "path": "scripts/convert_dictionary.lua",
              "type": "file",
              "size": 787
            },
            {
              "name": "convert_model.lua",
              "path": "scripts/convert_model.lua",
              "type": "file",
              "size": 3423
            },
            {
              "name": "count_docs.py",
              "path": "scripts/count_docs.py",
              "type": "file",
              "size": 1784
            },
            {
              "name": "read_binarized.py",
              "path": "scripts/read_binarized.py",
              "type": "file",
              "size": 1365
            },
            {
              "name": "rm_pt.py",
              "path": "scripts/rm_pt.py",
              "type": "file",
              "size": 4772
            },
            {
              "name": "sacrebleu.sh",
              "path": "scripts/sacrebleu.sh",
              "type": "file",
              "size": 486
            },
            {
              "name": "shard_docs.py",
              "path": "scripts/shard_docs.py",
              "type": "file",
              "size": 1576
            },
            {
              "name": "split_train_valid_docs.py",
              "path": "scripts/split_train_valid_docs.py",
              "type": "file",
              "size": 2561
            },
            {
              "name": "spm_decode.py",
              "path": "scripts/spm_decode.py",
              "type": "file",
              "size": 1509
            },
            {
              "name": "spm_encode.py",
              "path": "scripts/spm_encode.py",
              "type": "file",
              "size": 3411
            },
            {
              "name": "spm_train.py",
              "path": "scripts/spm_train.py",
              "type": "file",
              "size": 431
            }
          ]
        },
        {
          "name": "setup.py",
          "path": "setup.py",
          "type": "file",
          "size": 4434
        },
        {
          "name": "tests",
          "path": "tests",
          "type": "directory",
          "contents": [
            {
              "name": "__init__.py",
              "path": "tests/__init__.py",
              "type": "file",
              "size": 0
            },
            {
              "name": "gpu",
              "path": "tests/gpu",
              "type": "directory",
              "contents": [
                {
                  "name": "__init__.py",
                  "path": "tests/gpu/__init__.py",
                  "type": "file",
                  "size": 0
                },
                {
                  "name": "test_binaries_gpu.py",
                  "path": "tests/gpu/test_binaries_gpu.py",
                  "type": "file",
                  "size": 9922
                },
                {
                  "name": "transformer_quantization_config.yaml",
                  "path": "tests/gpu/transformer_quantization_config.yaml",
                  "type": "file",
                  "size": 766
                }
              ]
            },
            {
              "name": "speech_recognition",
              "path": "tests/speech_recognition",
              "type": "directory",
              "contents": [
                {
                  "name": "__init__.py",
                  "path": "tests/speech_recognition/__init__.py",
                  "type": "file",
                  "size": 0
                },
                {
                  "name": "asr_test_base.py",
                  "path": "tests/speech_recognition/asr_test_base.py",
                  "type": "file",
                  "size": 19503
                },
                {
                  "name": "test_collaters.py",
                  "path": "tests/speech_recognition/test_collaters.py",
                  "type": "file",
                  "size": 2048
                },
                {
                  "name": "test_cross_entropy.py",
                  "path": "tests/speech_recognition/test_cross_entropy.py",
                  "type": "file",
                  "size": 1428
                },
                {
                  "name": "test_data_utils.py",
                  "path": "tests/speech_recognition/test_data_utils.py",
                  "type": "file",
                  "size": 1039
                },
                {
                  "name": "test_vggtransformer.py",
                  "path": "tests/speech_recognition/test_vggtransformer.py",
                  "type": "file",
                  "size": 4578
                }
              ]
            },
            {
              "name": "test_average_checkpoints.py",
              "path": "tests/test_average_checkpoints.py",
              "type": "file",
              "size": 4494
            },
            {
              "name": "test_backtranslation_dataset.py",
              "path": "tests/test_backtranslation_dataset.py",
              "type": "file",
              "size": 4030
            },
            {
              "name": "test_binaries.py",
              "path": "tests/test_binaries.py",
              "type": "file",
              "size": 45107
            },
            {
              "name": "test_bmuf.py",
              "path": "tests/test_bmuf.py",
              "type": "file",
              "size": 5351
            },
            {
              "name": "test_character_token_embedder.py",
              "path": "tests/test_character_token_embedder.py",
              "type": "file",
              "size": 1656
            },
            {
              "name": "test_concat_dataset.py",
              "path": "tests/test_concat_dataset.py",
              "type": "file",
              "size": 1943
            },
            {
              "name": "test_constraints.py",
              "path": "tests/test_constraints.py",
              "type": "file",
              "size": 10242
            },
            {
              "name": "test_convtbc.py",
              "path": "tests/test_convtbc.py",
              "type": "file",
              "size": 1679
            },
            {
              "name": "test_dictionary.py",
              "path": "tests/test_dictionary.py",
              "type": "file",
              "size": 3342
            },
            {
              "name": "test_export.py",
              "path": "tests/test_export.py",
              "type": "file",
              "size": 3511
            },
            {
              "name": "test_file_io.py",
              "path": "tests/test_file_io.py",
              "type": "file",
              "size": 1415
            },
            {
              "name": "test_fp16_optimizer.py",
              "path": "tests/test_fp16_optimizer.py",
              "type": "file",
              "size": 2799
            },
            {
              "name": "test_inference_dropout.py",
              "path": "tests/test_inference_dropout.py",
              "type": "file",
              "size": 3057
            },
            {
              "name": "test_iterators.py",
              "path": "tests/test_iterators.py",
              "type": "file",
              "size": 4680
            },
            {
              "name": "test_label_smoothing.py",
              "path": "tests/test_label_smoothing.py",
              "type": "file",
              "size": 4235
            },
            {
              "name": "test_lstm_jitable.py",
              "path": "tests/test_lstm_jitable.py",
              "type": "file",
              "size": 4007
            },
            {
              "name": "test_memory_efficient_fp16.py",
              "path": "tests/test_memory_efficient_fp16.py",
              "type": "file",
              "size": 2002
            },
            {
              "name": "test_metrics.py",
              "path": "tests/test_metrics.py",
              "type": "file",
              "size": 2638
            },
            {
              "name": "test_multi_corpus_sampled_dataset.py",
              "path": "tests/test_multi_corpus_sampled_dataset.py",
              "type": "file",
              "size": 3105
            },
            {
              "name": "test_multihead_attention.py",
              "path": "tests/test_multihead_attention.py",
              "type": "file",
              "size": 1904
            },
            {
              "name": "test_noising.py",
              "path": "tests/test_noising.py",
              "type": "file",
              "size": 19779
            },
            {
              "name": "test_reproducibility.py",
              "path": "tests/test_reproducibility.py",
              "type": "file",
              "size": 3864
            },
            {
              "name": "test_resampling_dataset.py",
              "path": "tests/test_resampling_dataset.py",
              "type": "file",
              "size": 3366
            },
            {
              "name": "test_sequence_generator.py",
              "path": "tests/test_sequence_generator.py",
              "type": "file",
              "size": 23561
            },
            {
              "name": "test_sequence_scorer.py",
              "path": "tests/test_sequence_scorer.py",
              "type": "file",
              "size": 3949
            },
            {
              "name": "test_sparse_multihead_attention.py",
              "path": "tests/test_sparse_multihead_attention.py",
              "type": "file",
              "size": 2545
            },
            {
              "name": "test_token_block_dataset.py",
              "path": "tests/test_token_block_dataset.py",
              "type": "file",
              "size": 2970
            },
            {
              "name": "test_train.py",
              "path": "tests/test_train.py",
              "type": "file",
              "size": 8428
            },
            {
              "name": "test_utils.py",
              "path": "tests/test_utils.py",
              "type": "file",
              "size": 3067
            },
            {
              "name": "utils.py",
              "path": "tests/utils.py",
              "type": "file",
              "size": 17080
            }
          ]
        },
        {
          "name": "train.py",
          "path": "train.py",
          "type": "file",
          "size": 366
        }
      ]
    },
    "structure_summary": "/\n    \u251c\u2500\u2500 .github/\n    \u2502   \u251c\u2500\u2500 ISSUE_TEMPLATE/\n    \u2502   \u2502   \u251c\u2500\u2500 bug_report.md\n    \u2502   \u2502   \u251c\u2500\u2500 documentation.md\n    \u2502   \u2502   \u251c\u2500\u2500 feature_request.md\n    \u2502   \u2502   \u2514\u2500\u2500 how-to-question.md\n    \u2502   \u251c\u2500\u2500 workflows/\n    \u2502   \u2502   \u2514\u2500\u2500 build.yml\n    \u2502   \u251c\u2500\u2500 ISSUE_TEMPLATE.md\n    \u2502   \u2514\u2500\u2500 PULL_REQUEST_TEMPLATE.md\n    \u251c\u2500\u2500 config/\n    \u2502   \u251c\u2500\u2500 criterion/\n    \u2502   \u2502   \u251c\u2500\u2500 adaptive_loss.yaml\n    \u2502   \u2502   \u2514\u2500\u2500 cross_entropy.yaml\n    \u2502   \u251c\u2500\u2500 lr_scheduler/\n    \u2502   \u2502   \u251c\u2500\u2500 cosine.yaml\n    \u2502   \u2502   \u2514\u2500\u2500 inverse_sqrt.yaml\n    \u2502   \u251c\u2500\u2500 model/\n    \u2502   \u2502   \u251c\u2500\u2500 transformer_lm.yaml\n    \u2502   \u2502   \u251c\u2500\u2500 transformer_lm_baevski_gbw.yaml\n    \u2502   \u2502   \u251c\u2500\u2500 transformer_lm_baevski_wiki103.yaml\n    \u2502   \u2502   \u251c\u2500\u2500 transformer_lm_big.yaml\n    \u2502   \u2502   \u251c\u2500\u2500 transformer_lm_gbw.yaml\n    \u2502   \u2502   \u251c\u2500\u2500 transformer_lm_gpt.yaml\n    \u2502   \u2502   \u251c\u2500\u2500 transformer_lm_gpt2_big.yaml\n    \u2502   \u2502   \u251c\u2500\u2500 transformer_lm_gpt2_medium.yaml\n    \u2502   \u2502   \u251c\u2500\u2500 transformer_lm_gpt2_small.yaml\n    \u2502   \u2502   \u2514\u2500\u2500 transformer_lm_wiki103.yaml\n    \u2502   \u251c\u2500\u2500 optimizer/\n    \u2502   \u2502   \u251c\u2500\u2500 adam.yaml\n    \u2502   \u2502   \u2514\u2500\u2500 nag.yaml\n    \u2502   \u251c\u2500\u2500 params/\n    \u2502   \u2502   \u251c\u2500\u2500 eval_lm_params.yaml\n    \u2502   \u2502   \u2514\u2500\u2500 training_params.yaml\n    \u2502   \u251c\u2500\u2500 task/\n    \u2502   \u2502   \u2514\u2500\u2500 language_modeling.yaml\n    \u2502   \u251c\u2500\u2500 config.yaml\n    \u2502   \u2514\u2500\u2500 config_eval_lm.yaml\n    \u251c\u2500\u2500 docs/\n    \u2502   \u251c\u2500\u2500 _static/\n    \u2502   \u2502   \u2514\u2500\u2500 theme_overrides.css\n    \u2502   \u251c\u2500\u2500 command_line_tools.rst\n    \u2502   ... (19 more files)\n    \u251c\u2500\u2500 examples/\n    \u2502   \u251c\u2500\u2500 backtranslation/\n    \u2502   \u2502   ... (7 more files)\n    \u2502   \u251c\u2500\u2500 bart/\n    \u2502   \u2502   ... (3 more files)\n    \u2502   \u251c\u2500\u2500 byte_level_bpe/\n    \u2502   \u2502   ... (4 more files)\n    \u2502   \u251c\u2500\u2500 camembert/\n    \u2502   \u2502   ... (1 more files)\n    \u2502   \u251c\u2500\u2500 constrained_decoding/\n    \u2502   \u2502   ... (3 more files)\n    \u2502   \u251c\u2500\u2500 conv_seq2seq/\n    \u2502   \u2502   ... (1 more files)\n    \u2502   \u251c\u2500\u2500 cross_lingual_language_model/\n    \u2502   \u2502   ... (1 more files)\n    \u2502   \u251c\u2500\u2500 joint_alignment_translation/\n    \u2502   \u2502   ... (2 more files)\n    \u2502   \u251c\u2500\u2500 language_model/\n    \u2502   \u2502   ... (4 more files)\n    \u2502   \u251c\u2500\u2500 layerdrop/\n    \u2502   \u2502   ... (1 more files)\n    \u2502   \u251c\u2500\u2500 linformer/\n    \u2502   \u2502   \u251c\u2500\u2500 src/\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 models/\n    \u2502   \u2502   \u2502   \u2502   ... (2 more files)\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 modules/\n    \u2502   \u2502   \u2502   \u2502   ... (4 more files)\n    \u2502   \u2502   \u2502   ... (1 more files)\n    \u2502   \u2502   ... (1 more files)\n    \u2502   \u251c\u2500\u2500 mbart/\n    \u2502   \u2502   ... (1 more files)\n    \u2502   \u251c\u2500\u2500 megatron_11b/\n    \u2502   \u2502   ... (2 more files)\n    \u2502   \u251c\u2500\u2500 multilingual/\n    \u2502   \u2502   ... (4 more files)\n    \u2502   \u251c\u2500\u2500 noisychannel/\n    \u2502   \u2502   ... (9 more files)\n    \u2502   \u251c\u2500\u2500 nonautoregressive_translation/\n    \u2502   \u2502   ... (2 more files)\n    \u2502   \u251c\u2500\u2500 paraphraser/\n    \u2502   \u2502   ... (2 more files)\n    \u2502   \u251c\u2500\u2500 pay_less_attention_paper/\n    \u2502   \u2502   ... (1 more files)\n    \u2502   \u251c\u2500\u2500 pointer_generator/\n    \u2502   \u2502   \u251c\u2500\u2500 src/\n    \u2502   \u2502   \u2502   ... (2 more files)\n    \u2502   \u2502   ... (4 more files)\n    \u2502   \u251c\u2500\u2500 quant_noise/\n    \u2502   \u2502   ... (2 more files)\n    \u2502   \u251c\u2500\u2500 roberta/\n    \u2502   \u2502   \u251c\u2500\u2500 commonsense_qa/\n    \u2502   \u2502   \u2502   ... (4 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 wsc/\n    \u2502   \u2502   \u2502   ... (5 more files)\n    \u2502   \u2502   ... (9 more files)\n    \u2502   \u251c\u2500\u2500 scaling_nmt/\n    \u2502   \u2502   ... (1 more files)\n    \u2502   \u251c\u2500\u2500 simultaneous_translation/\n    \u2502   \u2502   \u251c\u2500\u2500 criterions/\n    \u2502   \u2502   \u2502   ... (2 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 docs/\n    \u2502   \u2502   \u2502   ... (2 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 eval/\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 agents/\n    \u2502   \u2502   \u2502   \u2502   ... (5 more files)\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 scorers/\n    \u2502   \u2502   \u2502   \u2502   ... (3 more files)\n    \u2502   \u2502   \u2502   ... (5 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 models/\n    \u2502   \u2502   \u2502   ... (2 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 modules/\n    \u2502   \u2502   \u2502   ... (3 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 utils/\n    \u2502   \u2502   \u2502   ... (3 more files)\n    \u2502   \u2502   ... (2 more files)\n    \u2502   \u251c\u2500\u2500 speech_recognition/\n    \u2502   \u2502   \u251c\u2500\u2500 criterions/\n    \u2502   \u2502   \u2502   ... (3 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 data/\n    \u2502   \u2502   \u2502   ... (5 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 datasets/\n    \u2502   \u2502   \u2502   ... (2 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 models/\n    \u2502   \u2502   \u2502   ... (3 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 tasks/\n    \u2502   \u2502   \u2502   ... (2 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 utils/\n    \u2502   \u2502   \u2502   ... (1 more files)\n    \u2502   \u2502   ... (4 more files)\n    \u2502   \u251c\u2500\u2500 stories/\n    \u2502   \u2502   ... (1 more files)\n    \u2502   \u251c\u2500\u2500 translation/\n    \u2502   \u2502   ... (5 more files)\n    \u2502   \u251c\u2500\u2500 translation_moe/\n    \u2502   \u2502   \u251c\u2500\u2500 src/\n    \u2502   \u2502   \u2502   ... (4 more files)\n    \u2502   \u2502   ... (2 more files)\n    \u2502   \u251c\u2500\u2500 unsupervised_quality_estimation/\n    \u2502   \u2502   ... (4 more files)\n    \u2502   \u251c\u2500\u2500 wav2vec/\n    \u2502   \u2502   ... (5 more files)\n    \u2502   \u251c\u2500\u2500 wmt19/\n    \u2502   \u2502   ... (1 more files)\n    \u2502   \u251c\u2500\u2500 xlmr/\n    \u2502   \u2502   ... (1 more files)\n    \u2502   ... (2 more files)\n    \u251c\u2500\u2500 fairseq/\n    \u2502   \u251c\u2500\u2500 benchmark/\n    \u2502   \u2502   ... (5 more files)\n    \u2502   \u251c\u2500\u2500 clib/\n    \u2502   \u2502   \u251c\u2500\u2500 libbleu/\n    \u2502   \u2502   \u2502   ... (2 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 libnat/\n    \u2502   \u2502   \u2502   ... (1 more files)\n    \u2502   \u2502   \u2514\u2500\u2500 libnat_cuda/\n    \u2502   \u2502       ... (3 more files)\n    \u2502   \u251c\u2500\u2500 criterions/\n    \u2502   \u2502   ... (14 more files)\n    \u2502   \u251c\u2500\u2500 data/\n    \u2502   \u2502   \u251c\u2500\u2500 audio/\n    \u2502   \u2502   \u2502   ... (2 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 encoders/\n    \u2502   \u2502   \u2502   ... (16 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 legacy/\n    \u2502   \u2502   \u2502   ... (4 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 multilingual/\n    \u2502   \u2502   \u2502   ... (6 more files)\n    \u2502   \u2502   ... (48 more files)\n    \u2502   \u251c\u2500\u2500 dataclass/\n    \u2502   \u2502   ... (4 more files)\n    \u2502   \u251c\u2500\u2500 logging/\n    \u2502   \u2502   ... (4 more files)\n    \u2502   \u251c\u2500\u2500 model_parallel/\n    \u2502   \u2502   \u251c\u2500\u2500 criterions/\n    \u2502   \u2502   \u2502   ... (2 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 models/\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 pipeline_parallel_transformer/\n    \u2502   \u2502   \u2502   \u2502   ... (3 more files)\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 roberta/\n    \u2502   \u2502   \u2502   \u2502   ... (2 more files)\n    \u2502   \u2502   \u2502   ... (3 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 modules/\n    \u2502   \u2502   \u2502   ... (5 more files)\n    \u2502   \u2502   ... (3 more files)\n    \u2502   \u251c\u2500\u2500 models/\n    \u2502   \u2502   \u251c\u2500\u2500 bart/\n    \u2502   \u2502   \u2502   ... (3 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 huggingface/\n    \u2502   \u2502   \u2502   ... (3 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 nat/\n    \u2502   \u2502   \u2502   ... (10 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 roberta/\n    \u2502   \u2502   \u2502   ... (6 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 wav2vec/\n    \u2502   \u2502   \u2502   ... (4 more files)\n    \u2502   \u2502   ... (21 more files)\n    \u2502   \u251c\u2500\u2500 modules/\n    \u2502   \u2502   \u251c\u2500\u2500 dynamicconv_layer/\n    \u2502   \u2502   \u2502   ... (8 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 lightconv_layer/\n    \u2502   \u2502   \u2502   ... (7 more files)\n    \u2502   \u2502   \u251c\u2500\u2500 quantization/\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 pq/\n    \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 modules/\n    \u2502   \u2502   \u2502   \u2502   \u2502   ... (directory truncated)\n    \u2502   \u2502   \u2502   \u2502   ... (4 more files)\n    \u2502   \u2502   \u2502   \u251c\u2500\u2500 scalar/\n    \u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 modules/\n    \u2502   \u2502   \u2502   \u2502   \u2502   ... (directory truncated)\n    \u2502   \u2502   \u2502   \u2502   ... (3 more files)\n    \u2502   \u2502   \u2502   ... (2 more files)\n    \u2502   \u2502   ... (37 more files)\n    \u2502   \u251c\u2500\u2500 optim/\n    \u2502   \u2502   \u251c\u2500\u2500 lr_scheduler/\n    \u2502   \u2502   \u2502   ... (9 more files)\n    \u2502   \u2502   ... (15 more files)\n    \u2502   \u251c\u2500\u2500 scoring/\n    \u2502   \u2502   ... (3 more files)\n    \u2502   \u251c\u2500\u2500 tasks/\n    \u2502   \u2502   ... (19 more files)\n    \u2502   ... (22 more files)\n    \u251c\u2500\u2500 fairseq_cli/\n    \u2502   ... (8 more files)\n    \u251c\u2500\u2500 scripts/\n    \u2502   \u251c\u2500\u2500 constraints/\n    \u2502   \u2502   ... (2 more files)\n    \u2502   ... (16 more files)\n    \u251c\u2500\u2500 tests/\n    \u2502   \u251c\u2500\u2500 gpu/\n    \u2502   \u2502   ... (3 more files)\n    \u2502   \u251c\u2500\u2500 speech_recognition/\n    \u2502   \u2502   ... (6 more files)\n    \u2502   ... (31 more files)",
    "readme": "<p align=\"center\">\n  <img src=\"docs/fairseq_logo.png\" width=\"150\">\n  <br />\n  <br />\n  <a href=\"https://github.com/pytorch/fairseq/blob/master/LICENSE\"><img alt=\"MIT License\" src=\"https://img.shields.io/badge/license-MIT-blue.svg\" /></a>\n  <a href=\"https://github.com/pytorch/fairseq/releases\"><img alt=\"Latest Release\" src=\"https://img.shields.io/github/release/pytorch/fairseq.svg\" /></a>\n  <a href=\"https://github.com/pytorch/fairseq/actions?query=workflow:build\"><img alt=\"Build Status\" src=\"https://github.com/pytorch/fairseq/workflows/build/badge.svg\" /></a>\n  <a href=\"https://fairseq.readthedocs.io/en/latest/?badge=latest\"><img alt=\"Documentation Status\" src=\"https://readthedocs.org/projects/fairseq/badge/?version=latest\" /></a>\n</p>\n\n--------------------------------------------------------------------------------\n\nFairseq(-py) is a sequence modeling toolkit that allows researchers and\ndevelopers to train custom models for translation, summarization, language\nmodeling and other text generation tasks.\nWe provide reference implementations of various sequence modeling papers:\n\n<details><summary>List of implemented papers</summary><p>\n\n- **Convolutional Neural Networks (CNN)**\n  - [Language Modeling with Gated Convolutional Networks (Dauphin et al., 2017)](examples/language_model/conv_lm/README.md)\n  - [Convolutional Sequence to Sequence Learning (Gehring et al., 2017)](examples/conv_seq2seq/README.md)\n  - [Classical Structured Prediction Losses for Sequence to Sequence Learning (Edunov et al., 2018)](https://github.com/pytorch/fairseq/tree/classic_seqlevel)\n  - [Hierarchical Neural Story Generation (Fan et al., 2018)](examples/stories/README.md)\n  - [wav2vec: Unsupervised Pre-training for Speech Recognition (Schneider et al., 2019)](examples/wav2vec/README.md)\n- **LightConv and DynamicConv models**\n  - [Pay Less Attention with Lightweight and Dynamic Convolutions (Wu et al., 2019)](examples/pay_less_attention_paper/README.md)\n- **Long Short-Term Memory (LSTM) networks**\n  - Effective Approaches to Attention-based Neural Machine Translation (Luong et al., 2015)\n- **Transformer (self-attention) networks**\n  - Attention Is All You Need (Vaswani et al., 2017)\n  - [Scaling Neural Machine Translation (Ott et al., 2018)](examples/scaling_nmt/README.md)\n  - [Understanding Back-Translation at Scale (Edunov et al., 2018)](examples/backtranslation/README.md)\n  - [Adaptive Input Representations for Neural Language Modeling (Baevski and Auli, 2018)](examples/language_model/transformer_lm/README.md)\n  - [Lexically constrained decoding with dynamic beam allocation (Post & Vilar, 2018)](examples/constrained_decoding/README.md)\n  - [Mixture Models for Diverse Machine Translation: Tricks of the Trade (Shen et al., 2019)](examples/translation_moe/README.md)\n  - [RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al., 2019)](examples/roberta/README.md)\n  - [Facebook FAIR's WMT19 News Translation Task Submission (Ng et al., 2019)](examples/wmt19/README.md)\n  - [Jointly Learning to Align and Translate with Transformer Models (Garg et al., 2019)](examples/joint_alignment_translation/README.md )\n  - [Multilingual Denoising Pre-training for Neural Machine Translation (Liu et at., 2020)](examples/mbart/README.md)\n  - [Neural Machine Translation with Byte-Level Subwords (Wang et al., 2020)](examples/byte_level_bpe/README.md)\n  - [Unsupervised Quality Estimation for Neural Machine Translation (Fomicheva et al., 2020)](examples/unsupervised_quality_estimation/README.md)\n  - [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations (Baevski et al., 2020)](examples/wav2vec/README.md)\n  - [Generating Medical Reports from Patient-Doctor Conversations Using Sequence-to-Sequence Models (Enarvi et al., 2020)](examples/pointer_generator/README.md)\n  - [Linformer: Self-Attention with Linear Complexity (Wang et al., 2020)](examples/linformer/README.md)\n- **Non-autoregressive Transformers**\n  - Non-Autoregressive Neural Machine Translation (Gu et al., 2017)\n  - Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement (Lee et al. 2018)\n  - Insertion Transformer: Flexible Sequence Generation via Insertion Operations (Stern et al. 2019)\n  - Mask-Predict: Parallel Decoding of Conditional Masked Language Models (Ghazvininejad et al., 2019)\n  - [Levenshtein Transformer (Gu et al., 2019)](examples/nonautoregressive_translation/README.md)\n\n</p></details>\n\n### What's New:\n\n- September 2020: [Added Linformer code](examples/linformer/README.md)\n- September 2020: [Added pointer-generator networks](examples/pointer_generator/README.md)\n- August 2020: [Added lexically constrained decoding](examples/constrained_decoding/README.md)\n- August 2020: [wav2vec2 models and code released](examples/wav2vec/README.md)\n- July 2020: [Unsupervised Quality Estimation code released](examples/unsupervised_quality_estimation/README.md)\n- May 2020: [Follow fairseq on Twitter](https://twitter.com/fairseq)\n- April 2020: [Monotonic Multihead Attention code released](examples/simultaneous_translation/README.md)\n- April 2020: [Quant-Noise code released](examples/quant_noise/README.md)\n- April 2020: [Initial model parallel support and 11B parameters unidirectional LM released](examples/megatron_11b/README.md)\n<details><summary>Previous updates</summary><p>\n\n- March 2020: [Byte-level BPE code released](examples/byte_level_bpe/README.md)\n- February 2020: [mBART model and code released](examples/mbart/README.md)\n- February 2020: [Added tutorial for back-translation](https://github.com/pytorch/fairseq/tree/master/examples/backtranslation#training-your-own-model-wmt18-english-german)\n- December 2019: [fairseq 0.9.0 released](https://github.com/pytorch/fairseq/releases/tag/v0.9.0)\n- November 2019: [VizSeq released (a visual analysis toolkit for evaluating fairseq models)](https://facebookresearch.github.io/vizseq/docs/getting_started/fairseq_example)\n- November 2019: [CamemBERT model and code released](examples/camembert/README.md)\n- November 2019: [BART model and code released](examples/bart/README.md)\n- November 2019: [XLM-R models and code released](examples/xlmr/README.md)\n- September 2019: [Nonautoregressive translation code released](examples/nonautoregressive_translation/README.md)\n- August 2019: [WMT'19 models released](examples/wmt19/README.md)\n- July 2019: fairseq relicensed under MIT license\n- July 2019: [RoBERTa models and code released](examples/roberta/README.md)\n- June 2019: [wav2vec models and code released](examples/wav2vec/README.md)\n\n</p></details>\n\n### Features:\n\n- multi-GPU training on one machine or across multiple machines (data and model parallel)\n- fast generation on both CPU and GPU with multiple search algorithms implemented:\n  - beam search\n  - Diverse Beam Search ([Vijayakumar et al., 2016](https://arxiv.org/abs/1610.02424))\n  - sampling (unconstrained, top-k and top-p/nucleus)\n  - lexically constrained decoding ([Post & Vilar, 2018](examples/constrained_decoding/README.md))\n- large mini-batch training even on a single GPU via delayed updates\n- mixed precision training (trains faster with less GPU memory on [NVIDIA tensor cores](https://developer.nvidia.com/tensor-cores))\n- extensible: easily register new models, criterions, tasks, optimizers and learning rate schedulers\n\nWe also provide [pre-trained models for translation and language modeling](#pre-trained-models-and-examples)\nwith a convenient `torch.hub` interface:\n```python\nen2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model')\nen2de.translate('Hello world', beam=5)\n# 'Hallo Welt'\n```\nSee the PyTorch Hub tutorials for [translation](https://pytorch.org/hub/pytorch_fairseq_translation/)\nand [RoBERTa](https://pytorch.org/hub/pytorch_fairseq_roberta/) for more examples.\n\n# Requirements and Installation\n\n* [PyTorch](http://pytorch.org/) version >= 1.4.0\n* Python version >= 3.6\n* For training new models, you'll also need an NVIDIA GPU and [NCCL](https://github.com/NVIDIA/nccl)\n* **To install fairseq** and develop locally:\n```bash\ngit clone https://github.com/pytorch/fairseq\ncd fairseq\npip install --editable ./\n\n# on MacOS:\n# CFLAGS=\"-stdlib=libc++\" pip install --editable ./\n```\n* **For faster training** install NVIDIA's [apex](https://github.com/NVIDIA/apex) library:\n```bash\ngit clone https://github.com/NVIDIA/apex\ncd apex\npip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" \\\n  --global-option=\"--deprecated_fused_adam\" --global-option=\"--xentropy\" \\\n  --global-option=\"--fast_multihead_attn\" ./\n```\n* **For large datasets** install [PyArrow](https://arrow.apache.org/docs/python/install.html#using-pip): `pip install pyarrow`\n* If you use Docker make sure to increase the shared memory size either with\n`--ipc=host` or `--shm-size` as command line options to `nvidia-docker run`.\n\n\n# Getting Started\n\nThe [full documentation](https://fairseq.readthedocs.io/) contains instructions\nfor getting started, training new models and extending fairseq with new model\ntypes and tasks.\n\n# Pre-trained models and examples\n\nWe provide pre-trained models and pre-processed, binarized test sets for several tasks listed below,\nas well as example training and evaluation commands.\n\n- [Translation](examples/translation/README.md): convolutional and transformer models are available\n- [Language Modeling](examples/language_model/README.md): convolutional and transformer models are available\n\nWe also have more detailed READMEs to reproduce results from specific papers:\n- [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations (Baevski et al., 2020)](examples/wav2vec/README.md)\n- [Unsupervised Quality Estimation for Neural Machine Translation (Fomicheva et al., 2020)](examples/unsupervised_quality_estimation/README.md)\n- [Training with Quantization Noise for Extreme Model Compression ({Fan*, Stock*} et al., 2020)](examples/quant_noise/README.md)\n- [Neural Machine Translation with Byte-Level Subwords (Wang et al., 2020)](examples/byte_level_bpe/README.md)\n- [Multilingual Denoising Pre-training for Neural Machine Translation (Liu et at., 2020)](examples/mbart/README.md)\n- [Reducing Transformer Depth on Demand with Structured Dropout (Fan et al., 2019)](examples/layerdrop/README.md)\n- [Jointly Learning to Align and Translate with Transformer Models (Garg et al., 2019)](examples/joint_alignment_translation/README.md)\n- [Levenshtein Transformer (Gu et al., 2019)](examples/nonautoregressive_translation/README.md)\n- [Facebook FAIR's WMT19 News Translation Task Submission (Ng et al., 2019)](examples/wmt19/README.md)\n- [RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al., 2019)](examples/roberta/README.md)\n- [wav2vec: Unsupervised Pre-training for Speech Recognition (Schneider et al., 2019)](examples/wav2vec/README.md)\n- [Mixture Models for Diverse Machine Translation: Tricks of the Trade (Shen et al., 2019)](examples/translation_moe/README.md)\n- [Pay Less Attention with Lightweight and Dynamic Convolutions (Wu et al., 2019)](examples/pay_less_attention_paper/README.md)\n- [Understanding Back-Translation at Scale (Edunov et al., 2018)](examples/backtranslation/README.md)\n- [Classical Structured Prediction Losses for Sequence to Sequence Learning (Edunov et al., 2018)](https://github.com/pytorch/fairseq/tree/classic_seqlevel)\n- [Hierarchical Neural Story Generation (Fan et al., 2018)](examples/stories/README.md)\n- [Scaling Neural Machine Translation (Ott et al., 2018)](examples/scaling_nmt/README.md)\n- [Convolutional Sequence to Sequence Learning (Gehring et al., 2017)](examples/conv_seq2seq/README.md)\n- [Language Modeling with Gated Convolutional Networks (Dauphin et al., 2017)](examples/language_model/conv_lm/README.md)\n\n# Join the fairseq community\n\n* Twitter: https://twitter.com/fairseq\n* Facebook page: https://www.facebook.com/groups/fairseq.users\n* Google group: https://groups.google.com/forum/#!forum/fairseq-users\n\n# License\n\nfairseq(-py) is MIT-licensed.\nThe license applies to the pre-trained models as well.\n\n# Citation\n\nPlease cite as:\n\n```bibtex\n@inproceedings{ott2019fairseq,\n  title = {fairseq: A Fast, Extensible Toolkit for Sequence Modeling},\n  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},\n  booktitle = {Proceedings of NAACL-HLT 2019: Demonstrations},\n  year = {2019},\n}\n```\n",
    "readme_filename": "README.md",
    "github_workflows": {
      "build.yml": "name: build\n\non:\n  # Trigger the workflow on push to master or any pull request\n  push:\n    branches:\n      - master\n  pull_request:\n\njobs:\n  build:\n\n    strategy:\n      max-parallel: 4\n      matrix:\n        platform: [ubuntu-latest, macos-latest]\n        python-version: [3.6, 3.7]\n\n    runs-on: ${{ matrix.platform }}\n\n    steps:\n    - uses: actions/checkout@v1\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v1\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: Conditionally install pytorch\n      if: matrix.platform == 'windows-latest'\n      run: pip3 install torch -f https://download.pytorch.org/whl/torch_stable.html\n    - name: Install locally\n      run: |\n        python -m pip install --upgrade pip\n        python setup.py build_ext --inplace\n        python -m pip install --editable .\n    - name: Lint with flake8\n      run: |\n        pip install flake8\n        # stop the build if there are Python syntax errors or undefined names\n        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics\n        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide\n        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics\n    - name: Run tests\n      run: |\n          python setup.py test\n"
    }
  },
  "llm_calls_before_build": 0,
  "github_workflows_found": [
    "build.yml"
  ],
  "dockerfile_attempt_1": 1,
  "dockerfile": "FROM pytorch/pytorch:1.9.0-cuda11.1-cudnn8-runtime\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    git \\\n    wget \\\n    perl \\\n    cmake \\\n    pkg-config \\\n    build-essential \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Python dependencies\nRUN pip install --no-cache-dir \\\n    numpy \\\n    cython \\\n    sacremoses \\\n    sentencepiece \\\n    pyarrow\n\n# Clone fairseq repository and checkout specific commit\nRUN git clone https://github.com/facebookresearch/fairseq.git /workspace/fairseq\nWORKDIR /workspace/fairseq\nRUN git checkout 85f097141d83d6aac378838b6c0c8f2a0f77154f\n\n# Install fairseq in editable mode\nRUN pip install --editable .",
  "dockerfile_build_success": true,
  "successful_candidate_index": 3,
  "successful_candidate_attempt": 1,
  "successful_candidate_improvement_attempt": 0,
  "llm_calls_total": 5
}