[
  {
    "number": 15614,
    "title": "[BUG] 24.04 cuDF.pandas now errors on mixed dtype comparisons in row-wise functions (didn't in 24.02)",
    "created_at": "2024-04-29T22:45:28Z",
    "closed_at": "2024-04-29T23:16:50Z",
    "labels": [
      "question",
      "0 - Waiting on Author"
    ],
    "url": "https://github.com/rapidsai/cudf/issues/15614",
    "body": "**Describe the bug**\r\nIn the cuDF pandas demo notebooks, we try to run `min()` on mixed dtypes.  It works in pandas, and used to work in cuDF.pandas 24.02.  It fails in 24.04.\r\n**Steps/Code to reproduce bug**\r\n```\r\n%load_ext cudf.pandas\r\nimport pandas as pd\r\n\r\nsmall_df = pd.DataFrame({'a': [0, 1, 2], 'b': [\"x\", \"y\", \"z\"]})\r\nsmall_df = pd.concat([small_df, small_df])\r\n\r\naxis = 0\r\nfor i in range(0, 2):\r\n    small_df.min(axis=axis)\r\n    axis = 1\r\n\r\ncounts = small_df.groupby(\"a\").b.count()\r\n```\r\noutputs\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nFile /opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:889, in _fast_slow_function_call(func, *args, **kwargs)\r\n    888 fast_args, fast_kwargs = _fast_arg(args), _fast_arg(kwargs)\r\n--> 889 result = func(*fast_args, **fast_kwargs)\r\n    890 if result is NotImplemented:\r\n    891     # try slow path\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:30, in call_operator(fn, args, kwargs)\r\n     29 def call_operator(fn, args, kwargs):\r\n---> 30     return fn(*args, **kwargs)\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/nvtx/nvtx.py:116, in annotate.__call__.<locals>.inner(*args, **kwargs)\r\n    115 libnvtx_push_range(self.attributes, self.domain.handle)\r\n--> 116 result = func(*args, **kwargs)\r\n    117 libnvtx_pop_range(self.domain.handle)\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/cudf/core/frame.py:1715, in Frame.min(self, axis, skipna, numeric_only, **kwargs)\r\n   1680 \"\"\"\r\n   1681 Return the minimum of the values in the DataFrame.\r\n   1682 \r\n   (...)\r\n   1713     Parameters currently not supported are `level`, `numeric_only`.\r\n   1714 \"\"\"\r\n-> 1715 return self._reduce(\r\n   1716     \"min\",\r\n   1717     axis=axis,\r\n   1718     skipna=skipna,\r\n   1719     numeric_only=numeric_only,\r\n   1720     **kwargs,\r\n   1721 )\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/nvtx/nvtx.py:116, in annotate.__call__.<locals>.inner(*args, **kwargs)\r\n    115 libnvtx_push_range(self.attributes, self.domain.handle)\r\n--> 116 result = func(*args, **kwargs)\r\n    117 libnvtx_pop_range(self.domain.handle)\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/cudf/core/dataframe.py:6267, in DataFrame._reduce(self, op, axis, numeric_only, **kwargs)\r\n   6266 elif axis == 1:\r\n-> 6267     return source._apply_cupy_method_axis_1(op, **kwargs)\r\n   6268 else:\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/nvtx/nvtx.py:116, in annotate.__call__.<locals>.inner(*args, **kwargs)\r\n    115 libnvtx_push_range(self.attributes, self.domain.handle)\r\n--> 116 result = func(*args, **kwargs)\r\n    117 libnvtx_pop_range(self.domain.handle)\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/cudf/core/dataframe.py:6449, in DataFrame._apply_cupy_method_axis_1(self, method, *args, **kwargs)\r\n   6447 kwargs.pop(\"cast_to_int\", None)\r\n-> 6449 prepared, mask, common_dtype = self._prepare_for_rowwise_op(\r\n   6450     method, skipna, numeric_only\r\n   6451 )\r\n   6452 for col in prepared._data.names:\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/nvtx/nvtx.py:116, in annotate.__call__.<locals>.inner(*args, **kwargs)\r\n    115 libnvtx_push_range(self.attributes, self.domain.handle)\r\n--> 116 result = func(*args, **kwargs)\r\n    117 libnvtx_pop_range(self.domain.handle)\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/cudf/core/dataframe.py:6071, in DataFrame._prepare_for_rowwise_op(self, method, skipna, numeric_only)\r\n   6066 if (\r\n   6067     not numeric_only\r\n   6068     and is_string_dtype(common_dtype)\r\n   6069     and any(not is_string_dtype(dt) for dt in filtered.dtypes)\r\n   6070 ):\r\n-> 6071     raise TypeError(\r\n   6072         f\"Cannot perform row-wise {method} across mixed-dtype columns,\"\r\n   6073         \" try type-casting all the columns to same dtype.\"\r\n   6074     )\r\n   6076 if not skipna and any(col.nullable for col in filtered._columns):\r\n\r\nTypeError: Cannot perform row-wise min across mixed-dtype columns, try type-casting all the columns to same dtype.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\nCell In[2], line 11\r\n      9 axis = 0\r\n     10 for i in range(0, 2):\r\n---> 11     small_df.min(axis=axis)\r\n     12     axis = 1\r\n     14 counts = small_df.groupby(\"a\").b.count()\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:837, in _CallableProxyMixin.__call__(self, *args, **kwargs)\r\n    836 def __call__(self, *args, **kwargs) -> Any:\r\n--> 837     result, _ = _fast_slow_function_call(\r\n    838         # We cannot directly call self here because we need it to be\r\n    839         # converted into either the fast or slow object (by\r\n    840         # _fast_slow_function_call) to avoid infinite recursion.\r\n    841         # TODO: When Python 3.11 is the minimum supported Python version\r\n    842         # this can use operator.call\r\n    843         call_operator,\r\n    844         self,\r\n    845         args,\r\n    846         kwargs,\r\n    847     )\r\n    848     return result\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:902, in _fast_slow_function_call(func, *args, **kwargs)\r\n    900         slow_args, slow_kwargs = _slow_arg(args), _slow_arg(kwargs)\r\n    901         with disable_module_accelerator():\r\n--> 902             result = func(*slow_args, **slow_kwargs)\r\n    903 return _maybe_wrap_result(result, func, *args, **kwargs), fast\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/cudf/pandas/fast_slow_proxy.py:30, in call_operator(fn, args, kwargs)\r\n     29 def call_operator(fn, args, kwargs):\r\n---> 30     return fn(*args, **kwargs)\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:11630, in DataFrame.min(self, axis, skipna, numeric_only, **kwargs)\r\n  11622 @doc(make_doc(\"min\", ndim=2))\r\n  11623 def min(\r\n  11624     self,\r\n   (...)\r\n  11628     **kwargs,\r\n  11629 ):\r\n> 11630     result = super().min(axis, skipna, numeric_only, **kwargs)\r\n  11631     if isinstance(result, Series):\r\n  11632         result = result.__finalize__(self, method=\"min\")\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/pandas/core/generic.py:12385, in NDFrame.min(self, axis, skipna, numeric_only, **kwargs)\r\n  12378 def min(\r\n  12379     self,\r\n  12380     axis: Axis | None = 0,\r\n   (...)\r\n  12383     **kwargs,\r\n  12384 ):\r\n> 12385     return self._stat_function(\r\n  12386         \"min\",\r\n  12387         nanops.nanmin,\r\n  12388         axis,\r\n  12389         skipna,\r\n  12390         numeric_only,\r\n  12391         **kwargs,\r\n  12392     )\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/pandas/core/generic.py:12374, in NDFrame._stat_function(self, name, func, axis, skipna, numeric_only, **kwargs)\r\n  12370 nv.validate_func(name, (), kwargs)\r\n  12372 validate_bool_kwarg(skipna, \"skipna\", none_allowed=False)\r\n> 12374 return self._reduce(\r\n  12375     func, name=name, axis=axis, skipna=skipna, numeric_only=numeric_only\r\n  12376 )\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:11549, in DataFrame._reduce(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\r\n  11545     df = df.T\r\n  11547 # After possibly _get_data and transposing, we are now in the\r\n  11548 #  simple case where we can use BlockManager.reduce\r\n> 11549 res = df._mgr.reduce(blk_func)\r\n  11550 out = df._constructor_from_mgr(res, axes=res.axes).iloc[0]\r\n  11551 if out_dtype is not None and out.dtype != \"boolean\":\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/pandas/core/internals/managers.py:1500, in BlockManager.reduce(self, func)\r\n   1498 res_blocks: list[Block] = []\r\n   1499 for blk in self.blocks:\r\n-> 1500     nbs = blk.reduce(func)\r\n   1501     res_blocks.extend(nbs)\r\n   1503 index = Index([None])  # placeholder\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/pandas/core/internals/blocks.py:404, in Block.reduce(self, func)\r\n    398 @final\r\n    399 def reduce(self, func) -> list[Block]:\r\n    400     # We will apply the function and reshape the result into a single-row\r\n    401     #  Block with the same mgr_locs; squeezing will be done at a higher level\r\n    402     assert self.ndim == 2\r\n--> 404     result = func(self.values)\r\n    406     if self.values.ndim == 1:\r\n    407         res_values = result\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:11468, in DataFrame._reduce.<locals>.blk_func(values, axis)\r\n  11466         return np.array([result])\r\n  11467 else:\r\n> 11468     return op(values, axis=axis, skipna=skipna, **kwds)\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/pandas/core/nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds)\r\n    145         result = alt(values, axis=axis, skipna=skipna, **kwds)\r\n    146 else:\r\n--> 147     result = alt(values, axis=axis, skipna=skipna, **kwds)\r\n    149 return result\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/pandas/core/nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs)\r\n    401 if datetimelike and mask is None:\r\n    402     mask = isna(values)\r\n--> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\r\n    406 if datetimelike:\r\n    407     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/pandas/core/nanops.py:1098, in _nanminmax.<locals>.reduction(values, axis, skipna, mask)\r\n   1093     return _na_for_min_count(values, axis)\r\n   1095 values, mask = _get_values(\r\n   1096     values, skipna, fill_value_typ=fill_value_typ, mask=mask\r\n   1097 )\r\n-> 1098 result = getattr(values, meth)(axis)\r\n   1099 result = _maybe_null_out(result, axis, mask, values.shape)\r\n   1100 return result\r\n\r\nFile /opt/conda/lib/python3.11/site-packages/numpy/core/_methods.py:45, in _amin(a, axis, out, keepdims, initial, where)\r\n     43 def _amin(a, axis=None, out=None, keepdims=False,\r\n     44           initial=_NoValue, where=True):\r\n---> 45     return umr_minimum(a, axis, None, out, keepdims, initial, where)\r\n\r\nTypeError: '<=' not supported between instances of 'int' and 'str'\r\n```\r\n\r\nit used to output a warning:\r\n```\r\n/opt/conda/lib/python3.10/site-packages/cudf/core/dataframe.py:5971: UserWarning: Row-wise operations currently only support int, float and bool dtypes. Non numeric columns are ignored.\r\n  warnings.warn(msg)\r\n```\r\nand then worked:\r\n```\r\na\r\n0    2\r\n1    2\r\n2    2\r\nName: b, dtype: int64\r\n```\r\n\r\n**Expected behavior**\r\n```\r\n>>> counts\r\na\r\n0    2\r\n1    2\r\n2    2\r\nName: b, dtype: int64\r\n```\r\nwhich is what I get in pandas and 24.02 cuDF.pandas\r\n\r\n**Environment overview (please complete the following information)**\r\n - Environment location: [Docker]\r\n - Method of cuDF install: [Docker]\r\n   - If method of install is [Docker], provide `docker pull` & `docker run` commands used:  \r\n   - for 24.02: `docker run --user root --gpus all --rm -it --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 8888:8888 -p 8787:8787 -p 8786:8786 rapidsai/notebooks:24.02-cuda11.8-py3.10 jupyter-lab --notebook-dir=/home/rapids/notebooks --ip=0.0.0.0 --no-browser --NotebookApp.token='' --NotebookApp.allow_origin='*' --allow-root`\r\n   - For 24.04:  `docker run --user root --gpus all --rm -it --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 8888:8888 -p 8787:8787 -p 8786:8786 rapidsai/notebooks:24.04-cuda11.8-py3.10 jupyter-lab --notebook-dir=/home/rapids/notebooks --ip=0.0.0.0 --no-browser --NotebookApp.token='' --NotebookApp.allow_origin='*' --allow-root`\r\n",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/15614/comments",
    "author": "taureandyernv",
    "comments": [
      {
        "user": "beckernick",
        "created_at": "2024-04-29T23:00:26Z",
        "body": "Pandas 2 enforces `numeric_only=False` rather than the prior behavior that filtered down to numeric if things failed.\r\n\r\nSo I believe this is now the expected behavior and we should update our notebooks. @galipremsagar @mroeschke , is that your understanding?"
      },
      {
        "user": "galipremsagar",
        "created_at": "2024-04-29T23:08:40Z",
        "body": "That's right @beckernick, @taureandyernv can you verify if cudf-24.04 matches upto pandas-2.x? Here is what I get for `pandas-2.x`:\r\n\r\n```ipython\r\nIn [1]: import pandas as pd\r\n   ...: \r\n   ...: small_df = pd.DataFrame({'a': [0, 1, 2], 'b': [\"x\", \"y\", \"z\"]})\r\n   ...: small_df = pd.concat([small_df, small_df])\r\n   ...: \r\n   ...: axis = 0\r\n   ...: for i in range(0, 2):\r\n   ...:     small_df.min(axis=axis)\r\n   ...:     axis = 1\r\n   ...: \r\n   ...: counts = small_df.groupby(\"a\").b.count()\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nCell In[1], line 8\r\n      6 axis = 0\r\n      7 for i in range(0, 2):\r\n----> 8     small_df.min(axis=axis)\r\n      9     axis = 1\r\n     11 counts = small_df.groupby(\"a\").b.count()\r\n\r\nFile /nvme/0/pgali/envs/cudfdev/lib/python3.11/site-packages/pandas/core/frame.py:11643, in DataFrame.min(self, axis, skipna, numeric_only, **kwargs)\r\n  11635 @doc(make_doc(\"min\", ndim=2))\r\n  11636 def min(\r\n  11637     self,\r\n   (...)\r\n  11641     **kwargs,\r\n  11642 ):\r\n> 11643     result = super().min(axis, skipna, numeric_only, **kwargs)\r\n  11644     if isinstance(result, Series):\r\n  11645         result = result.__finalize__(self, method=\"min\")\r\n\r\nFile /nvme/0/pgali/envs/cudfdev/lib/python3.11/site-packages/pandas/core/generic.py:12388, in NDFrame.min(self, axis, skipna, numeric_only, **kwargs)\r\n  12381 def min(\r\n  12382     self,\r\n  12383     axis: Axis | None = 0,\r\n   (...)\r\n  12386     **kwargs,\r\n  12387 ):\r\n> 12388     return self._stat_function(\r\n  12389         \"min\",\r\n  12390         nanops.nanmin,\r\n  12391         axis,\r\n  12392         skipna,\r\n  12393         numeric_only,\r\n  12394         **kwargs,\r\n  12395     )\r\n\r\nFile /nvme/0/pgali/envs/cudfdev/lib/python3.11/site-packages/pandas/core/generic.py:12377, in NDFrame._stat_function(self, name, func, axis, skipna, numeric_only, **kwargs)\r\n  12373 nv.validate_func(name, (), kwargs)\r\n  12375 validate_bool_kwarg(skipna, \"skipna\", none_allowed=False)\r\n> 12377 return self._reduce(\r\n  12378     func, name=name, axis=axis, skipna=skipna, numeric_only=numeric_only\r\n  12379 )\r\n\r\nFile /nvme/0/pgali/envs/cudfdev/lib/python3.11/site-packages/pandas/core/frame.py:11562, in DataFrame._reduce(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\r\n  11558     df = df.T\r\n  11560 # After possibly _get_data and transposing, we are now in the\r\n  11561 #  simple case where we can use BlockManager.reduce\r\n> 11562 res = df._mgr.reduce(blk_func)\r\n  11563 out = df._constructor_from_mgr(res, axes=res.axes).iloc[0]\r\n  11564 if out_dtype is not None and out.dtype != \"boolean\":\r\n\r\nFile /nvme/0/pgali/envs/cudfdev/lib/python3.11/site-packages/pandas/core/internals/managers.py:1500, in BlockManager.reduce(self, func)\r\n   1498 res_blocks: list[Block] = []\r\n   1499 for blk in self.blocks:\r\n-> 1500     nbs = blk.reduce(func)\r\n   1501     res_blocks.extend(nbs)\r\n   1503 index = Index([None])  # placeholder\r\n\r\nFile /nvme/0/pgali/envs/cudfdev/lib/python3.11/site-packages/pandas/core/internals/blocks.py:404, in Block.reduce(self, func)\r\n    398 @final\r\n    399 def reduce(self, func) -> list[Block]:\r\n    400     # We will apply the function and reshape the result into a single-row\r\n    401     #  Block with the same mgr_locs; squeezing will be done at a higher level\r\n    402     assert self.ndim == 2\r\n--> 404     result = func(self.values)\r\n    406     if self.values.ndim == 1:\r\n    407         res_values = result\r\n\r\nFile /nvme/0/pgali/envs/cudfdev/lib/python3.11/site-packages/pandas/core/frame.py:11481, in DataFrame._reduce.<locals>.blk_func(values, axis)\r\n  11479         return np.array([result])\r\n  11480 else:\r\n> 11481     return op(values, axis=axis, skipna=skipna, **kwds)\r\n\r\nFile /nvme/0/pgali/envs/cudfdev/lib/python3.11/site-packages/pandas/core/nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds)\r\n    145         result = alt(values, axis=axis, skipna=skipna, **kwds)\r\n    146 else:\r\n--> 147     result = alt(values, axis=axis, skipna=skipna, **kwds)\r\n    149 return result\r\n\r\nFile /nvme/0/pgali/envs/cudfdev/lib/python3.11/site-packages/pandas/core/nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs)\r\n    401 if datetimelike and mask is None:\r\n    402     mask = isna(values)\r\n--> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs)\r\n    406 if datetimelike:\r\n    407     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\r\n\r\nFile /nvme/0/pgali/envs/cudfdev/lib/python3.11/site-packages/pandas/core/nanops.py:1098, in _nanminmax.<locals>.reduction(values, axis, skipna, mask)\r\n   1093     return _na_for_min_count(values, axis)\r\n   1095 values, mask = _get_values(\r\n   1096     values, skipna, fill_value_typ=fill_value_typ, mask=mask\r\n   1097 )\r\n-> 1098 result = getattr(values, meth)(axis)\r\n   1099 result = _maybe_null_out(result, axis, mask, values.shape)\r\n   1100 return result\r\n\r\nFile /nvme/0/pgali/envs/cudfdev/lib/python3.11/site-packages/numpy/core/_methods.py:45, in _amin(a, axis, out, keepdims, initial, where)\r\n     43 def _amin(a, axis=None, out=None, keepdims=False,\r\n     44           initial=_NoValue, where=True):\r\n---> 45     return umr_minimum(a, axis, None, out, keepdims, initial, where)\r\n\r\nTypeError: '<=' not supported between instances of 'int' and 'str'\r\n```"
      },
      {
        "user": "taureandyernv",
        "created_at": "2024-04-29T23:16:50Z",
        "body": "I verified.  We'll update the notebooks accordingly.  Thanks at @beckernick and @galipremsagar "
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why mixed dtype comparisons now error in cuDF.pandas 24.04 when they worked previously",
      "Clarification on whether this is an intentional compatibility change with pandas 2.x behavior",
      "Guidance on handling mixed dtype operations in row-wise functions under new constraints",
      "Documentation of breaking changes in row-wise operation requirements between versions"
    ],
    "_classification": {
      "category": "Requires build environment but hard to be dockerized",
      "timestamp": "2025-04-05 00:00:39"
    }
  },
  {
    "number": 7521,
    "title": "[FEA] enable iteration over cudf series",
    "created_at": "2021-03-05T20:20:43Z",
    "closed_at": "2021-03-05T23:27:26Z",
    "labels": [
      "question",
      "Python"
    ],
    "url": "https://github.com/rapidsai/cudf/issues/7521",
    "body": "Hi cuDF developers,\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI am not sure if this is a feature request or bug, but I would like to be able to iterate over a cuDF series. I am using cuDF 0.19.\r\n\r\nHere is a sample that demonstrates what I mean:\r\n\r\n```\r\nstephey@cgpu19:~$ python\r\nPython 3.8.5 (default, Sep  4 2020, 07:30:14) \r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import dask\r\n>>> import dask_cudf\r\n>>> import cudf\r\n>>> df = dask.datasets.timeseries()\r\n>>> df_id_cpu = df['id']\r\n>>> cpu_loop = [i for i in df_id_cpu]\r\n>>> df_gpu = df.map_partitions(cudf.from_pandas)\r\n>>> df_id_gpu = df_gpu['id']\r\n>>> gpu_loop = [i for i in df_id_gpu]\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"<stdin>\", line 1, in <listcomp>\r\n  File \"/app/miniconda3/lib/python3.8/site-packages/dask/dataframe/core.py\", line 3055, in __iter__\r\n    for row in s:\r\n  File \"/app/miniconda3/lib/python3.8/site-packages/cudf/core/series.py\", line 877, in __iter__\r\n    cudf.utils.utils.raise_iteration_error(obj=self)\r\n  File \"/app/miniconda3/lib/python3.8/site-packages/cudf/utils/utils.py\", line 388, in raise_iteration_error\r\n    raise TypeError(\r\nTypeError: Series object is not iterable. Consider using `.to_arrow()`, `.to_pandas()` or `.values_host` if you wish to iterate over the values.\r\n\r\n```\r\n\r\n**Describe the solution you'd like**\r\nI would like to be able to iterate over a cudf series the same way I can in pandas:\r\n\r\n```\r\n>>> df_gpu = df.map_partitions(cudf.from_pandas)\r\n>>> df_id_gpu = df_gpu['id']\r\n>>> gpu_loop = [i for i in df_id_gpu]\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nOne option is to convert from a cudf series to a cupy array, although this is much slower in my application than using `to_pandas()`.\r\n\r\n**Additional context**\r\nUsing `.to_pandas()` is a workable option, although I'm trying to keep all my work on the GPU if possible. \r\n\r\nPlease let me know if I can answer questions or provide any other information.\r\n\r\nThank you very much,\r\nLaurie\r\n\r\n",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/7521/comments",
    "author": "lastephey",
    "comments": [
      {
        "user": "galipremsagar",
        "created_at": "2021-03-05T22:08:51Z",
        "body": "> **Additional context**\r\n> Using `.to_pandas()` is a workable option, although I'm trying to keep all my work on the GPU if possible.\r\n\r\nIn your example above why do you want to be iterating over a GPU-backed series object? Also, we see that you are trying to convert a `Series` object to a list for which the best way to do it is via `to_pandas().tolist()`. The reason iterating over a GPU-backed series object is disabled is because it is quite slower when compared to iterating over a CPU-backed series object. \r\n\r\nMaybe it would be helpful for us to help you with your next operation if you can provide what you want to do with the iterable?"
      },
      {
        "user": "lastephey",
        "created_at": "2021-03-05T22:45:36Z",
        "body": "Thank you for the information-- this is helpful. Now I understand why iterating in this way would be slow/disabled, but then it might be nice to have a more informative error message. \r\n\r\nI'm trying to do something like:\r\n\r\n```\r\nimage = cp.zeros((10,10))\r\nfor i, j in zip(df_id_gpu, df_id_gpu):\r\n    image[i, j] += 1.0\r\n```\r\n\r\nwhere I use the values in the cudf series `df_id_gpu` to populate an image. \r\n\r\nWhat's the best strategy in this situation? Thank you. "
      },
      {
        "user": "galipremsagar",
        "created_at": "2021-03-05T23:00:48Z",
        "body": "You can achieve that operation by keeping all the data on GPU memory:\r\n\r\n```python\r\n>>> import cudf\r\n>>> import cupy as cp\r\n>>> df_id_gpu = cudf.Series([0, 1, 2, 3, 4, 5])\r\n>>> image = cp.zeros((10,10))\r\n>>> df_id_gpu\r\n0    0\r\n1    1\r\n2    2\r\n3    3\r\n4    4\r\n5    5\r\ndtype: int64\r\n>>> image\r\narray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\r\n>>> df_id_gpu.values\r\narray([0, 1, 2, 3, 4, 5])\r\n>>> image[df_id_gpu.values, df_id_gpu.values] += 1\r\n>>> image\r\narray([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\r\n```"
      },
      {
        "user": "lastephey",
        "created_at": "2021-03-05T23:27:26Z",
        "body": "Thank you very much for this solution-- this strategy is exactly what I wanted to know. \r\n\r\nI appreciate your time. I'll go ahead and close. "
      },
      {
        "user": "mohandeepzumen",
        "created_at": "2022-06-07T05:25:24Z",
        "body": "I'm doing a different operation where i have a spell check method and each of the word in the cell has to go through this spellCheck method. I'm not able to iterate through every cell. Tried doing .topandas().tolist(), but the performance remains the same. Is there a way i can iterate through each cell in a series?"
      },
      {
        "user": "shwina",
        "created_at": "2022-06-07T15:51:36Z",
        "body": "@mohandeepzumen can you show us what your `spellcheck` method looks like?"
      },
      {
        "user": "mohandeepzumen",
        "created_at": "2022-06-10T09:38:35Z",
        "body": "def spellCheck(word,model):\r\n    if word in model.words:\r\n        pass\r\n    else:\r\n        w = model.get_nearest_neighbors(word, k=1)[0][1]\r\n\r\nthe model here refers to a fasttext model trained on a corpus of text."
      }
    ],
    "satisfaction_conditions": [
      "Enable GPU-native iteration or equivalent bulk operations for cuDF Series",
      "Provide guidance for GPU-optimized alternatives to element-wise iteration",
      "Avoid CPU data transfer during operations",
      "Support common pandas-like patterns with GPU-native equivalents",
      "Maintain performance comparable to CPU methods when using alternatives"
    ],
    "_classification": {
      "category": "Requires build environment but hard to be dockerized",
      "timestamp": "2025-04-05 00:02:01"
    }
  }
]