[
  {
    "number": 14395,
    "title": "[QST]use cudf.concat slower than pandas.concat",
    "created_at": "2023-11-10T10:37:20Z",
    "closed_at": "2023-11-10T14:15:25Z",
    "labels": [
      "question",
      "Performance"
    ],
    "url": "https://github.com/rapidsai/cudf/issues/14395",
    "body": "** cudf.concat slower than pandas.concat**\r\n## here is my code:\r\n```\r\nimport os, time, pandas as pd, numpy as np\r\nimport cudf\r\nfrom tqdm import tqdm\r\n\r\nos.environ['CUDA_VISIBLE_DEVICES']='1'\r\ndef pd_concat_test(df):\r\n    st = 10\r\n    tdf = df[:st].copy()\r\n    n = len(df) - st\r\n    ta = time.time()\r\n    for i in tqdm(range(st, len(df))):\r\n        tdf = pd.concat([tdf, df[i:i+1]])\r\n    tb = time.time()\r\n\r\n    print(f'pd concat {n} times cost {tb-ta :.2f} s.')\r\n\r\n\r\ndef cupd_concat_test(cdf):\r\n    st = 10\r\n    tdf = cdf[:st].copy()\r\n    n = len(cdf) - st\r\n    ta = time.time()\r\n    for i in tqdm(range(st, len(cdf))):\r\n        tdf = cudf.concat([tdf, cdf[i:i+1]])\r\n    tb = time.time()\r\n\r\n    print(f'cudf concat {n} times cost {tb-ta :.2f} s.')\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    \r\n    in_csv = 'target.csv'\r\n    \r\n    df = pd.read_csv(in_csv)\r\n    cdf = cudf.read_csv(in_csv)\r\n    print(df.head(5))\r\n    cupd_concat_test(cdf)\r\n    pd_concat_test(df)\r\n```\r\n## here's output:\r\n```\r\n       timestamp     open     high      low    close    volume  quote_volume\r\n0  1577836800000  7189.43  7190.52  7170.15  7171.55  2449.049   17576407.75\r\n1  1577840400000  7171.55  7225.00  7171.10  7210.24  3865.038   27838016.40\r\n2  1577844000000  7210.24  7239.30  7206.46  7237.99  3228.365   23324787.16\r\n3  1577847600000  7237.41  7239.74  7215.00  7221.65  2513.307   18161803.91\r\n4  1577851200000  7221.65  7225.41  7211.22  7213.86  1176.666    8493621.94\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33398/33398 [01:01<00:00, 542.44it/s]\r\ncudf concat 33398 times cost 61.57 s.\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 33398/33398 [00:14<00:00, 2279.08it/s]\r\npd concat 33398 times cost 14.65 s.\r\n```\r\n## here's my env: \r\n* python3.10.4\r\n*  nvcc -V\r\n```\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2021 NVIDIA Corporation\r\nBuilt on Thu_Nov_18_09:45:30_PST_2021\r\nCuda compilation tools, release 11.5, V11.5.119\r\nBuild cuda_11.5.r11.5/compiler.30672275_0\r\n```\r\n* pip list |grep cu\r\n```\r\ncubinlinker-cu11          0.3.0.post1\r\ncucim                     23.10.0\r\ncuda-python               11.8.3\r\ncudf-cu11                 23.10.1\r\ncugraph-cu11              23.10.0\r\ncuml-cu11                 23.10.0\r\ncuproj-cu11               23.10.0\r\ncupy-cuda11x              12.2.0\r\ncuspatial-cu11            23.10.0\r\ncuxfilter-cu11            23.10.0\r\ndask-cuda                 23.10.0\r\ndask-cudf-cu11            23.10.1\r\ndocutils                  0.20\r\nexecuting                 1.2.0\r\nptxcompiler-cu11          0.7.0.post1\r\npylibcugraph-cu11         23.10.0\r\npylibraft-cu11            23.10.0\r\nraft-dask-cu11            23.10.0\r\nrmm-cu11                  23.10.0\r\ntorch                     1.12.0+cu113\r\nucx-py-cu11               0.34.0\r\n```",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/14395/comments",
    "author": "haoran1062",
    "comments": [
      {
        "user": "shwina",
        "created_at": "2023-11-10T11:44:14Z",
        "body": "Hi @haoran1062 -- thank you for reporting! Please let me know if the below answers your question:\r\n\r\n## Why is it slow?\r\n\r\nGPUs are generally faster because they operate on data in parallel. If you have very small operations (e.g., involving a single row), there is little or no parallelism that the GPU can take advantage of. \r\n\r\n## Operate on larger chunks of data to see the benefit from GPUs\r\n\r\nEach `concat` operation in your example appends a single row to a dataframe. In general, you will not see the benefit of the GPU for very small operations like these. You may even see some slowdown for very small operations compared to the CPU.\r\n\r\nLet's modify the example to use `concat` with larger chunks. In the snippet below, each concat appends a dataframe of size `10_000` to ultimately produce a dataframe of size `10_000_000`. The speedup from using the GPU should be more obvious:\r\n\r\n```\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 999/999 [00:02<00:00, 441.12it/s]\r\ncudf concat 999 times cost 2.27 s.\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 999/999 [00:34<00:00, 28.90it/s]\r\npd concat 999 times cost 34.57 s.\r\n```\r\n\r\nThe code:\r\n\r\n```python\r\nimport os, time, pandas as pd, numpy as np\r\nimport cudf\r\nfrom tqdm import tqdm\r\n\r\nos.environ['CUDA_VISIBLE_DEVICES']='1'\r\ndef pd_concat_test(df):\r\n    chunk_size = 10_000\r\n    tdf = df[:chunk_size].copy()\r\n    n = len(df) - chunk_size\r\n    ta = time.time()\r\n    rng = range(chunk_size, len(df), chunk_size)\r\n    for i, chunk_start in enumerate(tqdm(rng)):\r\n        chunk_end = chunk_start + chunk_size        \r\n        tdf = pd.concat([tdf, df[chunk_start:chunk_end]])\r\n    tb = time.time()\r\n\r\n    print(f'pd concat {i+1} times cost {tb-ta :.2f} s.')\r\n    return tdf\r\n\r\n\r\ndef cupd_concat_test(cdf):\r\n    chunk_size = 10_000\r\n    tdf = cdf[:chunk_size].copy()\r\n    n = len(cdf) - chunk_size\r\n    ta = time.time()\r\n    rng = range(chunk_size, len(cdf), chunk_size)\r\n    for i, chunk_start in enumerate(tqdm(rng)):\r\n        chunk_end = chunk_start + chunk_size\r\n        tdf = cudf.concat([tdf, cdf[chunk_start:chunk_end]])\r\n    tb = time.time()\r\n\r\n    print(f'cudf concat {i+1} times cost {tb-ta :.2f} s.')\r\n    return tdf\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    cdf = cudf.datasets.randomdata(10_000_000)\r\n    df = cdf.to_pandas()\r\n    print(\"Heads:\")\r\n    print(cdf.head())\r\n    print(df.head())\r\n\r\n    print(\"Tails:\")\r\n    print(cdf.tail())\r\n    print(df.tail())\r\n    cdf = cupd_concat_test(cdf)\r\n    df = pd_concat_test(df)\r\n    print(\"Heads:\")\r\n    print(cdf.head())\r\n    print(df.head())\r\n\r\n    print(\"Tails:\")\r\n    print(cdf.tail())\r\n    print(df.tail())\r\n\r\n```\r\n\r\n"
      },
      {
        "user": "haoran1062",
        "created_at": "2023-11-10T12:13:17Z",
        "body": "@shwina thanks for your answer. I tested it according to your suggestions and the results are really good. \r\n```\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1282/1282 [00:17<00:00, 71.86it/s]\r\ncudf concat 1282 times cost 17.84 s.\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1282/1282 [02:49<00:00,  7.58it/s]\r\npd concat 1282 times cost 169.24 s.\r\n```\r\nbut I do really have that question Do you have any suitable suggestions how to speed up add columns one by one with high frequency operation"
      },
      {
        "user": "shwina",
        "created_at": "2023-11-10T12:17:23Z",
        "body": "Thanks! I'll close this issue out, but please feel free to reopen if you have any further questions. "
      },
      {
        "user": "haoran1062",
        "created_at": "2023-11-10T12:17:59Z",
        "body": "@shwina Do you have any suitable suggestions about how to speed up add rows one by one with high frequency operation\uff1f"
      },
      {
        "user": "shwina",
        "created_at": "2023-11-10T12:20:58Z",
        "body": "Sorry, I missed your question at the end.\r\n\r\n> Do you have any suitable suggestions how to speed up add columns one by one with high frequency operation\uff1f\r\n\r\nDo you mean rows, and not columns?\r\n\r\nCan you provide a bit more information about your use case: where is the data coming from? "
      },
      {
        "user": "haoran1062",
        "created_at": "2023-11-10T12:28:13Z",
        "body": "> Sorry, I missed your question at the end.\r\n> \r\n> > Do you have any suitable suggestions how to speed up add columns one by one with high frequency operation\uff1f\r\n> \r\n> Do you mean rows, and not columns?\r\n> \r\n> Can you provide a bit more information about your use case: where is the data coming from?\r\n\r\nmy bad, add one rows one by one .\r\nthe data is market data, which have timestamp, open, high, low, close, volume, and other data.\r\n"
      },
      {
        "user": "shwina",
        "created_at": "2023-11-10T14:06:27Z",
        "body": "Thanks! I think the way to do this is to collect your data in batches before appending it to the DataFrame. Here's how I would do it at a high level:\r\n\r\n```python\r\nimport cudf\r\nimport numpy as np\r\n\r\n\r\ndef producer():\r\n    for i in range(1_000_000):\r\n        ts = np.datetime64(\"now\") + np.timedelta64(i, \"s\")\r\n        yield (ts, np.random.rand(), np.random.rand(), np.random.rand(), np.random.rand(), np.random.rand())\r\n\r\n        \r\nif __name__ == \"__main__\":\r\n    batch_size = 100_000\r\n    \r\n    df = cudf.DataFrame()\r\n\r\n    records = np.recarray(batch_size, dtype=[(\"ts\", \"datetime64[ms]\"), (\"a\", \"float64\"), (\"b\", \"float64\"), (\"c\", \"float64\"), (\"d\", \"float64\"), (\"e\", \"float64\")])\r\n\r\n    for i, record in enumerate(producer()):\r\n        print(i)\r\n        # add the record to the batch\r\n        records[i % batch_size] = record\r\n        if i > 0 and (i % batch_size == 0):\r\n            # add the records to the DataFrame\r\n            df = cudf.concat([df, cudf.DataFrame.from_records(records)])\r\n    print(df.head())\r\n        \r\n```\r\n\r\nPlease forgive any minor mistakes there might be in the code above.\n\n---\n\nNote that the code above actually won't be much faster than pandas, since most of the time is spent populating the records rather than on any pandas operations."
      },
      {
        "user": "haoran1062",
        "created_at": "2023-11-10T14:15:26Z",
        "body": "> Note that the code above actually won't be much faster than pandas, since most of the time is spent populating the records rather than on any pandas operations.\r\n\r\nThanks a lot! I'll try your suggestion and thanks again for your great project! have a nice day~"
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why row-by-row concatenation is slower in cuDF compared to pandas",
      "Guidance on batch processing strategies for GPU-optimized concatenation",
      "Recommendations for handling high-frequency incremental updates in GPU DataFrames",
      "Clear comparison of CPU/GPU tradeoffs for different operation sizes"
    ],
    "_classification": {
      "category": "Can be dockerized without any issue",
      "timestamp": "2025-04-05 00:00:49"
    }
  },
  {
    "number": 6070,
    "title": "[BUG] .str.stod() no longer works on a String column",
    "created_at": "2020-08-22T02:44:33Z",
    "closed_at": "2020-08-24T03:14:12Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/rapidsai/cudf/issues/6070",
    "body": "**Describe the bug**\r\nI used `.stod()` to convert a string column to a decimal. However, this has stopped working on nightly 0.15.\r\n\r\n**Steps/Code to reproduce bug**\r\nMinimal example:\r\n\r\n```\r\ndf = cudf.DataFrame([['0.01'], ['0.02']], columns=['string_column'])\r\ndf['string_column'].str.stod()\r\n```\r\n\r\n**Expected behavior**\r\nA columns converted to decimal type.\r\n\r\n**Environment overview (please complete the following information)**\r\n - Environment location: Docker\r\n - Method of cuDF install: Docker\r\n   - If method of install is [Docker], provide `docker pull` & `docker run` commands used\r\n\r\n   - pull: `docker pull rapidsai/rapidsai-nightly:cuda10.2-runtime-ubuntu18.04-py3.7`\r\n   - run: \r\n\r\n```\r\ndocker run --gpus all -it -p 8888:8888 -p 8787:8787 -p 8786:8786 --name kdd_rapids \\\r\n\trapidsai/rapidsai-nightly:cuda10.2-runtime-ubuntu18.04-py3.7\r\n```\r\n\r\n**Environment details**\r\nPlease run and paste the output of the `cudf/print_env.sh` script here, to gather any other relevant environment details\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/6070/comments",
    "author": "drabastomek",
    "comments": [
      {
        "user": "galipremsagar",
        "created_at": "2020-08-22T17:55:17Z",
        "body": "This behavior was changed with integration of `nvstrings` into `cudf`. We have removed `stod` access via `.str` StringMethods, but instead you can attain the same type-cast by doing `.astype`:\r\n\r\n\r\n```python\r\n>>> import cudf\r\n>>> df = cudf.DataFrame([['0.01'], ['0.02']], columns=['string_column'])\r\n>>> df['string_column'].astype('float64')\r\n0    0.01\r\n1    0.02\r\nName: string_column, dtype: float64\r\n```\r\n\r\nLet us know if this helps?"
      },
      {
        "user": "argenisleon",
        "created_at": "2020-08-22T18:41:31Z",
        "body": "@drabastomek  maybe this could help\r\n```python\r\ndf = cudf.DataFrame([['0.01'], ['0.02']], columns=['string_column'])\r\ncudf.Series(cudf.core.column.string.str_cast.stod(df[\"string_column\"]._column))\r\n```"
      },
      {
        "user": "drabastomek",
        "created_at": "2020-08-23T01:27:03Z",
        "body": "Thanks all! I used the casting and it worked fine! I just had the code that was using `.stod()` before and couldn't find it anymore. Any plans on bring it back or the `.stod()` will no longer be included in strings functions?"
      },
      {
        "user": "galipremsagar",
        "created_at": "2020-08-24T02:56:14Z",
        "body": "`.stod` was not exposed via `.str.stod` as we recommend to use `astype` API because, though underlying we call the identical code-path(`stod`) but we have added additional validation if all the string values to be type-casted are capable/valid of being type-casted to float(in this case). "
      },
      {
        "user": "drabastomek",
        "created_at": "2020-08-24T03:14:12Z",
        "body": "Makes sense! Thanks! Closing this bug."
      }
    ],
    "satisfaction_conditions": [
      "Provides a working method to convert string columns to numeric types in cuDF",
      "Explains the API change rationale for string-to-float conversions",
      "Avoids dependency on deprecated/nonexistent string methods like .str.stod()"
    ],
    "_classification": {
      "category": "Can be dockerized without any issue",
      "timestamp": "2025-04-05 00:02:43"
    }
  },
  {
    "number": 5445,
    "title": "[QST] Lots of package conflicts when installing cuDF on Ubuntu machine",
    "created_at": "2020-06-11T04:30:03Z",
    "closed_at": "2020-08-27T18:56:15Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/rapidsai/cudf/issues/5445",
    "body": "I am trying to install the RAPIDS cuDF package on my Ubuntu machine using conda.\r\n\r\nRunning the command\r\n\r\n    conda install -c nvidia -c rapidsai -c numba -c conda-forge -c defaults cudf\r\n\r\nor\r\n\r\n    conda install -c rapidsai -c nvidia -c numba -c conda-forge cudf=0.13 python=3.7 cudatoolkit=10.2\r\n\r\nboth gives the following messages\r\n\r\n```\r\nCollecting package metadata (current_repodata.json): done\r\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\r\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\r\nSolving environment: | \r\nFound conflicts! Looking for incompatible packages.\r\nThis can take several minutes.  Press CTRL-C to abort.\r\n```\r\n\r\nThis took a really long time, before attempting to estimate conflicts 172 packages \r\n\r\n\r\n> Examining conflict for dask-core pickleshare backcall python_abi osqp mkl_random cloudpickle cvxpy-base psutil libtiff fastparquet python-snappy pillow fsspec pexpect pytz et_xmlfile heapdict wcwidth qt traitlets mkl-service pyqt libxml2 setuptools numba cython beautifulsoup4 multiprocess cycler sip pyyaml fastcache fontconfig pyopenssl cudf cx_oracle prompt_toolkit gstreamer numexpr msgpack-python wrapt markupsafe llvmlite future sortedcontainers urllib3 numpy-base jedi distributed pycparser protobuf pytables dill hmmlearn mysql-connector-python locket chardet xz ipython_genutils joblib gst-plugins-base matplotlib sqlalchemy python jdcal xlrd mock click matplotlib-base peewee ptyprocess zstd openpyxl jinja2 ipython tblib decorator wheel nose pysocks cytoolz partd numpy scikit-learn pyparsing h5py tornado python-dateutil pygments ecos soupsieve cffi blosc parso ppft mkl_fft dask kiwisolver cvxopt patsy zict cryptography pytorch ninja pox typing_extensions pathos packaging multitasking statsmodels certifi bottleneck requests yfinance bokeh pymysql pip sExamining conflict for dask-core pickleshare backcall python_abi osqp mkl_random cloudpickle cvxpy-base psutil libtiff fastparquet python-snappy pillow fsspec pexpect pytz et_xmlfile heapdict wcwidth qt traitlets mkl-service pyqt libxml2 setuptools numba cython beautifulsoup4 multiprocess cycler sip pyyaml fastcache fontconfig pyopenssl cudf cx_oracle prompt_toolkit gstreamer numexpr msgpack-python wrapt markupsafe llvmlite future sortedcontainers urllib3 numpy-base jedi distributed pycparser protobuf pytables dill hmmlearn mysql-connector-python locket chardet xz ipython_genutils joblib gst-plugins-base matplotlib sqlalchemy python jdcal xlrd mock click matplotlib-base peewee ptyprocess zstd openpyxl jinja2 ipython tblib decorator wheel nose pysocks cytoolz partd numpy scikit-learn pyparsing h5py tornado python-dateutil pygments ecos soupsieve cffi blosc parso ppft mkl_fft dask kiwisolver cvxopt patsy zict cryptography pytorch ninja pox typing_extensions pathos packaging multitasking statsmodels certifi bottleneck requests yfinance bokeh pymysql pip sExamining conflict for dask-core pickleshare backcall python_abi osqp mkl_random cloudpickle cvxpy-base psutil libtiff libpng fastparquet python-snappy pillow freetype fsspec pexpect pytz et_xmlfile heapdict wcwidth qt glib traitlets mkl-service pyqt libxml2 setuptools numba cython beautifulsoup4 multiprocess cycler sip pyyaml fastcache fontconfig pyopenssl cudf cx_oracle prompt_toolkit gstreamer numexpr msgpack-python wrapt markupsafe llvmlite future sortedcontainers urllib3 numpy-base jedi distributed pycparser protobuf pytables dill hmmlearn mysql-connector-python locket chardet ipython_genutils joblib gst-plugins-base matplotlib sqlalchemy python jdcal xlrd mock click matplotlib-base peewee ptyprocess zstd openpyxl jinja2 ipython tblib decorator wheel nose pysocks cytoolz partd libprotobuf numpy scikit-learn pyparsing h5py tornado dbus python-dateutil pygments ecos soupsieve cffi blosc parso ppft mkl_fft zlib dask kiwisolver cvxopt hdf5 patsy zict cryptography pytorch ninja pox typing_extensions pathos packaging multitasking statsmodels certifi botExamining conflict for dask-core pickleshare backcall python_abi osqp mkl_random cloudpickle cvxpy-base psutil libtiff libpng fastparquet python-snappy pillow freetype fsspec pexpect pytz et_xmlfile heapdict wcwidth qt glib traitlets mkl-service pyqt libxml2 setuptools numba cython beautifulsoup4 multiprocess cycler sip pyyaml fastcache fontconfig pyopenssl cudf cx_oracle prompt_toolkit gstreamer numexpr msgpack-python wrapt markupsafe llvmlite future sortedcontainers urllib3 numpy-base jedi distributed pycparser protobuf pytables dill hmmlearn mysql-connector-python locket chardet ipython_genutils joblib gst-plugins-base matplotlib sqlalchemy python jdcal xlrd mock click matplotlib-base peewee ptyprocess zstd openpyxl jinja2 ipython tblib decorator wheel nose pysocks cytoolz partd libprotobuf numpy scikit-learn pyparsing h5py tornado dbus python-dateutil pygments ecos soupsieve cffi blosc parso ppft mkl_fft zlib dask kiwisolver cvxopt hdf5 patsy zict cryptography pytorch ninja pox typing_extensions pathos packaging multitasking statsmodels certifi botExamining conflict for dask-core pickleshare backcall python_abi osqp mkl_random cloudpickle cvxpy-base psutil fastparquet python-snappy pillow fsspec pexpect pytz et_xmlfile heapdict wcwidth qt traitlets mkl-service pyqt numba setuptools cython beautifulsoup4 multiprocess cycler sip pyyaml fastcache pyopenssl cudf cx_oracle prompt_toolkit numexpr msgpack-python wrapt markupsafe llvmlite future sortedcontainers urllib3 numpy-base jedi distributed pycparser protobuf pytables dill hmmlearn mysql-connector-python locket chardet ipython_genutils joblib matplotlib sqlalchemy python sqlite jdcal xlrd mock click matplotlib-base peewee ptyprocess openpyxl jinja2 ipython tblib decorator wheel nose pysocks cytoolz partd numpy scikit-learn pyparsing h5py tornado python-dateutil pygments ecos soupsieve cffi parso ppft mkl_fft dask kiwisolver cvxopt patsy zict cryptography pytorch ninja pox typing_extensions pathos packaging multitasking statsmodels certifi bottleneck requests yfinance bokeh pymysql pip scipy cvxpy arch scs toolz pandas idna six olefile thrift:   2Examining conflict for dask-core pickleshare backcall python_abi osqp mkl_random cloudpickle cvxpy-base psutil fastparquet python-snappy pillow fsspec pexpect pytz et_xmlfile heapdict wcwidth qt traitlets mkl-service pyqt numba setuptools cython beautifulsoup4 multiprocess cycler sip pyyaml fastcache pyopenssl cudf cx_oracle prompt_toolkit numexpr msgpack-python wrapt markupsafe llvmlite future sortedcontainers urllib3 numpy-base jedi distributed pycparser protobuf pytables dill hmmlearn mysql-connector-python locket chardet ipython_genutils joblib matplotlib sqlalchemy python sqlite jdcal xlrd mock click matplotlib-base peewee ptyprocess openpyxl jinja2 ipython tblib decorator wheel nose pysocks cytoolz partd numpy scikit-learn pyparsing h5py tornado python-dateutil pygments ecos soupsieve cffi parso ppft mkl_fft dask kiwisolver cvxopt patsy zict cryptography pytorch ninja pox typing_extensions pathos packaging multitasking statsmodels certifi bottleneck requests yfinance bokeh pymysql pip scipy cvxpy arch scs toolz pandas idna six olefile thrift:   2Examining conflict for dask-core pickleshare backcall python_abi osqp mkl_random cloudpickle cvxpy-base psutil fastparquet python-snappy pillow fsspec pexpect pytz et_xmlfile heapdict wcwidth qt traitlets mkl-service pyqt numba setuptools cython beautifulsoup4 multiprocess cycler sip pyyaml readline fastcache pyopenssl cudf cx_oracle prompt_toolkit numexpr msgpack-python wrapt markupsafe llvmlite future sortedcontainers urllib3 numpy-base jedi distributed pycparser protobuf pytables dill hmmlearn mysql-connector-python locket chardet ipython_genutils joblib matplotlib sqlalchemy python jdcal xlrd mock click matplotlib-base peewee ptyprocess openpyxl jinja2 ipython tblib decorator wheel nose pysocks cytoolz partd numpy scikit-learn pyparsing h5py tornado python-dateutil pygments ecos soupsieve cffi parso ppft mkl_fft dask kiwisolver cvxopt patsy zict cryptography pytorch ninja pox typing_extensions pathos packaging multitasking statsmodels certifi bottleneck requests yfinance bokeh pymysql pip scipy cvxpy arch scs toolz pandas idna six olefile thrift:  Examining conflict for dask-core pickleshare backcall python_abi osqp mkl_random cloudpickle cvxpy-base psutil fastparquet python-snappy pillow fsspec pexpect pytz et_xmlfile heapdict wcwidth qt traitlets mkl-service pyqt numba setuptools cython beautifulsoup4 multiprocess cycler sip pyyaml readline fastcache pyopenssl cudf cx_oracle prompt_toolkit numexpr msgpack-python wrapt markupsafe llvmlite future sortedcontainers urllib3 numpy-base jedi distributed pycparser protobuf pytables dill hmmlearn mysql-connector-python locket chardet ipython_genutils joblib matplotlib sqlalchemy python jdcal xlrd mock click matplotlib-base peewee ptyprocess openpyxl jinja2 ipython tblib decorator wheel nose pysocks cytoolz partd numpy scikit-learn pyparsing h5py tornado python-dateutil pygments ecos soupsieve cffi parso ppft mkl_fft dask kiwisolver cvxopt patsy zict cryptography pytorch ninja pox typing_extensions pathos packaging multitasking statsmodels certifi bottleneck requests yfinance bokeh pymysql pip scipy cvxpy arch scs toolz pandas idna six olefile thrift:  Examining conflict for dask-core pickleshare backcall python_abi openssl osqp mkl_random cloudpickle cvxpy-base psutil fastparquet python-snappy pillow fsspec pexpect pytz et_xmlfile heapdict wcwidth qt traitlets mkl-service pyqt numba setuptools cython beautifulsoup4 multiprocess cycler sip pyyaml fastcache pyopenssl cudf cx_oracle prompt_toolkit numexpr msgpack-python wrapt markupsafe llvmlite future sortedcontainers urllib3 numpy-base jedi distributed pycparser protobuf pytables dill hmmlearn mysql-connector-python locket chardet ipython_genutils joblib matplotlib sqlalchemy python jdcal xlrd mock click matplotlib-base peewee ptyprocess openpyxl jinja2 ipython tblib decorator wheel nose pysocks cytoolz partd numpy scikit-learn pyparsing h5py tornado python-dateutil pygments ecos soupsieve cffi parso ppft mkl_fft mysql-connector-c dask kiwisolver cvxopt patsy zict cryptography pytorch ninja pox typing_extensions pathos packaging multitasking statsmodels certifi bottleneck requests yfinance bokeh pymysql pip scipy cvxpy arch scs toolz pandas idna six Examining conflict for dask-core pickleshare backcall python_abi openssl osqp mkl_random cloudpickle cvxpy-base psutil fastparquet python-snappy pillow fsspec pexpect pytz et_xmlfile heapdict wcwidth qt traitlets mkl-service pyqt numba setuptools cython beautifulsoup4 multiprocess cycler sip pyyaml fastcache pyopenssl cudf cx_oracle prompt_toolkit numexpr msgpack-python wrapt markupsafe llvmlite future sortedcontainers urllib3 numpy-base jedi distributed pycparser protobuf pytables dill hmmlearn mysql-connector-python locket chardet ipython_genutils joblib matplotlib sqlalchemy python jdcal xlrd mock click matplotlib-base peewee ptyprocess openpyxl jinja2 ipython tblib decorator wheel nose pysocks cytoolz partd numpy scikit-learn pyparsing h5py tornado python-dateutil pygments ecos soupsieve cffi parso ppft mkl_fft mysql-connector-c dask kiwisolver cvxopt patsy zict cryptography pytorch ninja pox typing_extensions pathos packaging multitasking statsmodels certifi bottleneck requests yfinance bokeh pymysql pip scipy cvxpy arch scs toolz pandas idna six olefile thrift:\r\n\r\nand finding lots of conflicts, such as the following  \r\n\r\n```\r\nPackage typing_extensions conflicts for:\r\nanaconda/linux-64::bokeh==2.0.2=py37_0 -> typing_extensions[version='>=3.7.4']\r\ndefaults/noarch::dask==2.9.2=py_0 -> bokeh[version='>=1.0.0'] -> typing_extensions[version='>=3.7.4']\r\n\r\nPackage cryptography-vectors conflicts for:\r\ndefaults/linux-64::pymysql==0.9.3=py37_0 -> cryptography -> cryptography-vectors[version='2.3.*|2.3.1.*']\r\nanaconda/linux-64::urllib3==1.25.8=py37_0 -> cryptography[version='>=1.3.4'] -> cryptography-vectors[version='2.3.*|2.3.1.*']\r\n\r\nPackage hdf5 conflicts for:\r\nanaconda/linux-64::pytables==3.5.2=py37h71ec239_1 -> hdf5[version='>=1.10.4,<1.10.5.0a0']\r\nanaconda/linux-64::h5py==2.9.0=py37h7918eee_0 -> hdf5[version='>=1.10.4,<1.10.5.0a0']The following specifications were found to be incompatible with your CUDA driver:\r\n\r\n  - feature:/linux-64::__cuda==10.2=0\r\n  - feature:|@/linux-64::__cuda==10.2=0\r\n\r\nYour installed CUDA driver is: 10.2\r\n```\r\n\r\n`conda list cudf` shows that cuDF is still not installed. \r\n\r\nIs there a better `conda` command to run to install cuDF?\r\n\r\n**System Environment**\r\n\r\n- Nvidia driver 440.33.01 \r\n- CUDA Version 10.2.89\r\n- cudatoolkit 10.2.89 \r\n- Python 3.7.4\r\n- conda 4.8.3\r\n- Ubuntu 18.04\r\n- Nvidia 2080 Ti\r\n",
    "comments_url": "https://api.github.com/repos/rapidsai/cudf/issues/5445/comments",
    "author": "athenawisdoms",
    "comments": [
      {
        "user": "kkraus14",
        "created_at": "2020-06-11T04:51:15Z",
        "body": "@athenawisdoms could you dump the output of `conda list` here? Alternatively, if creating a new environment is an option I'd suggest taking that route and doing:\r\n\r\n```\r\nconda create --name rapids -c rapidsai -c nvidia -c conda-forge -c defaults python=3.7 cudatoolkit=10.2 cudf=0.14\r\n```\r\n\r\nNOTE: 0.14 just released so upgraded cudf to 0.14 in the command, but feel free to roll it back if needed."
      },
      {
        "user": "athenawisdoms",
        "created_at": "2020-06-11T14:24:19Z",
        "body": "@kkraus14 Thanks your suggestion to createa a new environment works!\r\n\r\nHowever, I'll still like to install cudf to my existing environment. Here's the `conda list` output as requested. Wonder if you can identify the problem...\r\n\r\n```\r\n# Name                    Version                   Build  Channel\r\n_libgcc_mutex             0.1                        main    conda-forge\r\narch                      4.9.1           np116py37h14c3975_0    bashtage\r\nbackcall                  0.1.0                    py37_0    anaconda\r\nbeautifulsoup4            4.8.2                    py37_0    anaconda\r\nblas                      1.0                         mkl  \r\nblosc                     1.16.3               hd408876_0    anaconda\r\nbokeh                     2.0.2                    py37_0    anaconda\r\nbottleneck                1.3.1            py37hdd07704_0    anaconda\r\nbzip2                     1.0.8                h7b6447c_0    anaconda\r\nca-certificates           2020.4.5.2           hecda079_0    conda-forge\r\ncertifi                   2020.4.5.2       py37hc8dfbb8_0    conda-forge\r\ncffi                      1.14.0           py37h2e261b9_0    anaconda\r\nchardet                   3.0.4                 py37_1003    anaconda\r\nclick                     7.0                      py37_0    anaconda\r\ncloudpickle               1.4.1                      py_0    anaconda\r\ncryptography              2.9.2            py37h1ba5d50_0    anaconda\r\ncudatoolkit               10.2.89              hfd86e86_1    anaconda\r\ncvxopt                    1.2.0            py37hfa32c7d_0    anaconda\r\ncvxpy                     1.0.24           py37he1b5a44_0    conda-forge\r\ncvxpy-base                1.0.24           py37he1b5a44_0    conda-forge\r\ncx_oracle                 7.0.0            py37h7b6447c_0    anaconda\r\ncycler                    0.10.0                   py37_0    anaconda\r\ncython                    0.29.13          py37he6710b0_0    anaconda\r\ncytoolz                   0.10.1           py37h7b6447c_0    anaconda\r\ndask                      2.9.2                      py_0  \r\ndask-core                 2.9.2                      py_0  \r\ndbus                      1.13.6               h746ee38_0    anaconda\r\ndecorator                 4.4.0                    py37_1    anaconda\r\ndill                      0.3.1.1                  py37_0    anaconda\r\ndistributed               2.16.0                   py37_0    anaconda\r\necos                      2.0.7           py37h3010b51_1000    conda-forge\r\net_xmlfile                1.0.1                    py37_0    anaconda\r\nexpat                     2.2.6                he6710b0_0    anaconda\r\nfastcache                 1.1.0            py37h516909a_0    conda-forge\r\nfastparquet               0.4.0            py37h03ebfcd_0    conda-forge\r\nfontconfig                2.13.0               h9420a91_0    anaconda\r\nfreetype                  2.9.1                h8a8886c_1    anaconda\r\nfsspec                    0.7.1                      py_0    anaconda\r\nfuture                    0.17.1                py37_1000    conda-forge\r\nglib                      2.56.2               hd408876_0    anaconda\r\nglpk                      4.65                 h3ceedfd_2    anaconda\r\ngmp                       6.1.2                h6c8ec71_1  \r\ngsl                       2.4                  h14c3975_4    anaconda\r\ngst-plugins-base          1.14.0               hbbd80ab_1    anaconda\r\ngstreamer                 1.14.0               hb453b48_1    anaconda\r\nh5py                      2.9.0            py37h7918eee_0    anaconda\r\nhdf5                      1.10.4               hb1b8bf9_0    anaconda\r\nheapdict                  1.0.1                      py_0    anaconda\r\nhmmlearn                  0.2.3            py37hc1659b7_1    conda-forge\r\nicu                       58.2                 h9c2bf20_1  \r\nidna                      2.8                      py37_0    anaconda\r\nintel-openmp              2019.4                      243    anaconda\r\nipython                   7.7.0            py37h39e3cac_0    anaconda\r\nipython_genutils          0.2.0                    py37_0    anaconda\r\njdcal                     1.4.1                      py_0    conda-forge\r\njedi                      0.15.1                   py37_0    conda-forge\r\njinja2                    2.11.2                     py_0    anaconda\r\njoblib                    0.13.2                   py37_0    anaconda\r\njpeg                      9b                   h024ee3a_2  \r\nkiwisolver                1.1.0            py37he6710b0_0    anaconda\r\nlibedit                   3.1.20181209         hc058e9b_0    anaconda\r\nlibffi                    3.2.1                hd88cf55_4  \r\nlibgcc-ng                 9.1.0                hdf63c60_0    anaconda\r\nlibgfortran-ng            7.3.0                hdf63c60_0    anaconda\r\nlibpng                    1.6.37               hbc83047_0    anaconda\r\nlibprotobuf               3.6.0                hdbcaa40_0    anaconda\r\nlibstdcxx-ng              9.1.0                hdf63c60_0    anaconda\r\nlibtiff                   4.1.0                h2733197_0    anaconda\r\nlibuuid                   1.0.3                h1bed415_2    anaconda\r\nlibxcb                    1.13                 h1bed415_1    anaconda\r\nlibxml2                   2.9.9                hea5a465_1    anaconda\r\nllvmlite                  0.32.1           py37hd408876_0    anaconda\r\nlocket                    0.2.0                    py37_1    anaconda\r\nlz4-c                     1.8.1.2              h14c3975_0    anaconda\r\nlzo                       2.10                 h49e0be7_2  \r\nmarkupsafe                1.1.1            py37h7b6447c_0    anaconda\r\nmatplotlib                3.1.1            py37h5429711_0    anaconda\r\nmatplotlib-base           3.1.3            py37hef1b27d_0  \r\nmetis                     5.1.0                hf484d3e_4    anaconda\r\nmkl                       2019.4                      243    anaconda\r\nmkl-service               2.0.2            py37h7b6447c_0    anaconda\r\nmkl_fft                   1.0.12           py37ha843d7b_0    anaconda\r\nmkl_random                1.0.2            py37hd81dba3_0    anaconda\r\nmock                      3.0.5                    py37_0    conda-forge\r\nmsgpack-python            1.0.0            py37hfd86e86_1    anaconda\r\nmultiprocess              0.70.9           py37h516909a_0    conda-forge\r\nmultitasking              0.0.9                      py_0    ranaroussi\r\nmysql-connector-c         6.1.11               h597af5e_0  \r\nmysql-connector-python    8.0.18           py37h9c95fcb_1    anaconda\r\nncurses                   6.1                  he6710b0_1    anaconda\r\nninja                     1.9.0            py37hfd86e86_0    anaconda\r\nnose                      1.3.7                    py37_2    conda-forge\r\nnumba                     0.49.1           py37h0573a6f_0    anaconda\r\nnumexpr                   2.7.0            py37h9e4a6bb_0    anaconda\r\nnumpy                     1.16.4           py37h7e9f1db_0    anaconda\r\nnumpy-base                1.16.4           py37hde5b4d6_0    anaconda\r\nolefile                   0.46                     py37_0    anaconda\r\nopenblas                  0.3.3             h9ac9557_1001    conda-forge\r\nopenpyxl                  2.6.2                      py_0    conda-forge\r\nopenssl                   1.1.1g               h516909a_0    conda-forge\r\nosqp                      0.5.0            py37hb3f55d8_0    conda-forge\r\npackaging                 20.3                       py_0    anaconda\r\npandas                    1.0.3            py37h0573a6f_0    anaconda\r\nparso                     0.5.1                      py_0    conda-forge\r\npartd                     1.1.0                      py_0    anaconda\r\npathos                    0.2.5                      py_0    conda-forge\r\npatsy                     0.5.1                    py37_0    anaconda\r\npcre                      8.43                 he6710b0_0    anaconda\r\npeewee                    3.9.2            py37h6b74fdf_0    conda-forge\r\npexpect                   4.7.0                    py37_0    conda-forge\r\npickleshare               0.7.5                    py37_0    anaconda\r\npillow                    7.1.2            py37hb39fc2d_0    anaconda\r\npip                       19.1.1                   py37_0    conda-forge\r\npox                       0.2.7                      py_0    conda-forge\r\nppft                      1.6.6.1                  py37_0    conda-forge\r\nprompt_toolkit            2.0.9                    py37_0    anaconda\r\nprotobuf                  3.6.0            py37hf484d3e_0    anaconda\r\npsutil                    5.7.0            py37h7b6447c_0    anaconda\r\nptyprocess                0.6.0                    py37_0    conda-forge\r\npycparser                 2.20                       py_0    anaconda\r\npygments                  2.4.2                      py_0    conda-forge\r\npymysql                   0.9.3                    py37_0  \r\npyopenssl                 19.1.0                   py37_0    anaconda\r\npyparsing                 2.4.2                      py_0    conda-forge\r\npyqt                      5.9.2            py37h05f1152_2    anaconda\r\npysocks                   1.7.1                    py37_0    anaconda\r\npytables                  3.5.2            py37h71ec239_1    anaconda\r\npython                    3.7.3                h0371630_0    anaconda\r\npython-dateutil           2.8.0                    py37_0    anaconda\r\npython-snappy             0.5.4            py37he6710b0_0  \r\npython_abi                3.7                     1_cp37m    conda-forge\r\npytorch                   1.5.0           py3.7_cuda10.2.89_cudnn7.6.5_0    pytorch\r\npytz                      2019.1                     py_0    conda-forge\r\npyyaml                    5.3.1            py37h7b6447c_0    anaconda\r\nqt                        5.9.7                h5867ecd_1    anaconda\r\nrarfile                   3.1                      pypi_0    pypi\r\nreadline                  7.0                  h7b6447c_5    anaconda\r\nrequests                  2.22.0                   py37_1  \r\nscikit-learn              0.22.1           py37hd81dba3_0  \r\nscipy                     1.4.1            py37h0b6359f_0  \r\nscs                       2.0.2           py37h0290663_1000    conda-forge\r\nsetuptools                41.0.1                   py37_0    conda-forge\r\nsip                       4.19.8           py37hf484d3e_0    anaconda\r\nsix                       1.12.0                   py37_0    anaconda\r\nsnappy                    1.1.7                hbae5bb6_3  \r\nsortedcontainers          2.1.0                    py37_0    anaconda\r\nsoupsieve                 2.0.1                      py_0    anaconda\r\nsqlalchemy                1.3.7            py37h7b6447c_0    anaconda\r\nsqlite                    3.28.0               h7b6447c_0    anaconda\r\nstatsmodels               0.10.1           py37hdd07704_0    anaconda\r\nsuitesparse               5.2.0                h9e4a6bb_0    anaconda\r\ntbb                       2019.4               hfd86e86_0    anaconda\r\ntblib                     1.6.0                      py_0    anaconda\r\nthrift                    0.11.0           py37hf484d3e_0  \r\ntk                        8.6.8                hbc83047_0    anaconda\r\ntoolz                     0.10.0                     py_0    anaconda\r\ntornado                   6.0.3            py37h7b6447c_0    anaconda\r\ntraitlets                 4.3.2                    py37_0    conda-forge\r\ntyping_extensions         3.7.4.1                  py37_0    anaconda\r\nunrar                     0.4                      pypi_0    pypi\r\nurllib3                   1.25.8                   py37_0    anaconda\r\nwcwidth                   0.1.7                    py37_0    anaconda\r\nwheel                     0.33.4                   py37_0    conda-forge\r\nwrapt                     1.11.2           py37h7b6447c_0  \r\nxlrd                      1.2.0                    py37_0    anaconda\r\nxz                        5.2.4                h14c3975_4    anaconda\r\nyaml                      0.1.7                h96e3832_1    anaconda\r\nyfinance                  0.1.54                     py_0    ranaroussi\r\nzict                      2.0.0                      py_0    anaconda\r\nzlib                      1.2.11               h7b6447c_3    anaconda\r\nzstd                      1.3.7                h0b5b093_0    anaconda\r\n```"
      },
      {
        "user": "kkraus14",
        "created_at": "2020-08-27T18:56:15Z",
        "body": "The things that stick out to me from your environment are `pandas`, `dask`, `dask-core`, and `distributed`.\r\n\r\nWe currently require `pandas >=0.25.3,<1.0.0a0`, `dask >=2.15.0`, `dask-core >=2.15.0`, `distributed >=2.15.0`.\r\n\r\nThere's also likely a lot of conflicts coming from trying to move from defaults to conda-forge in your environment where you could try:\r\n```\r\nconda install -c nvidia -c rapidsai -c numba -c defaults -c conda-forge \"cudf\" \"pandas\" \"dask\" \"distributed\"\r\n```\n\n---\n\nClosing as answered."
      }
    ],
    "satisfaction_conditions": [
      "Resolves version conflicts with critical dependencies like pandas, dask, dask-core, and distributed",
      "Maintains compatibility with existing CUDA 10.2 environment and NVIDIA drivers",
      "Works within the existing conda environment without requiring a fresh environment",
      "Handles channel priority conflicts between conda-forge and defaults",
      "Preserves compatibility with other installed packages like cx_oracle, pytorch, and matplotlib"
    ],
    "_classification": {
      "category": "Can be dockerized without any issue",
      "timestamp": "2025-04-05 00:03:18"
    }
  }
]