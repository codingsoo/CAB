[
  {
    "number": 6443,
    "title": "Order Guarantees with the Async API",
    "created_at": "2025-02-18T17:09:07Z",
    "closed_at": "2025-02-19T09:56:35Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/6443",
    "body": "Hey,\nI\u2019m wondering if the following example guarantees execution order:\n```\nRBucket<String> bucket = redisson.getBucket(\"key\");\n\nbucket.setAsync(\"value\"); // Fire SET without waiting\nRFuture<String> future = bucket.getAsync(); \n\nfuture.thenAccept(System.out::println); \n```\nDoes SET always execute before GET, even though SET wasn\u2019t explicitly awaited?\n\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/6443/comments",
    "author": "barshaul",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2025-02-19T08:58:52Z",
        "body": "Hi,\n\nNo, due to the asynchronous nature of the connections handling. \n\nTo achieve that you can create a Redisson instance with `\u0441onnectionPoolSize = 1`."
      },
      {
        "user": "barshaul",
        "created_at": "2025-02-19T09:56:35Z",
        "body": "Ack, that answers my question. Thanks! "
      },
      {
        "user": "mrniko",
        "created_at": "2025-02-19T10:50:04Z",
        "body": "@barshaul \n\nTo achieve that you can create a Redisson instance with `\u0441onnectionPoolSize = 1`"
      }
    ]
  },
  {
    "number": 6315,
    "title": "Redisson is shutdown",
    "created_at": "2024-12-04T02:54:58Z",
    "closed_at": "2024-12-04T09:40:48Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/6315",
    "body": "### Redisson Version\r\n3.13.2\r\n\r\n### What is the Actual behavior?\r\nan error is reported by refreshing the local cache through Redis when the k8s pod is destroyed\r\n\r\n### Redisson configuration\r\n\r\n\r\n    @Bean\r\n    public StringRedisTemplate stringRedisTemplateMenu() {\r\n        StringRedisTemplate template = new StringRedisTemplate();\r\n        template.setConnectionFactory(redissonMenuConnectionFactory());\r\n        return template;\r\n    }\r\n    @Bean\r\n    public RedisConnectionFactory redissonMenuConnectionFactory() {\r\n        return new RedissonConnectionFactory(redissonMenu());\r\n    }\r\n    @Bean(destroyMethod = \"shutdown\")\r\n    public RedissonClient redissonMenu() {\r\n        if (StringUtils.isBlank(redissonMenuProperties.getSingleServerConfig().getPassword())) {\r\n            redissonMenuProperties.getSingleServerConfig().setPassword(null);\r\n        }\r\n        Config config = null;\r\n        try {\r\n            config = Config.fromJSON(JSON.toJSONString(redissonMenuProperties));\r\n        } catch (Exception e) {\r\n            log.error(\"spring.redisson-menu \u914d\u7f6e\u5f02\u5e38:{}\", e.getMessage(), e);\r\n            throw new BaseBizException(BaseErrorEnum.UNKNOW_SYSTEM_ERROR, \"spring.redisson-menu \u914d\u7f6e\u8bfb\u53d6\u5f02\u5e38\");\r\n        }\r\n        config.setCodec(new org.redisson.client.codec.StringCodec());\r\n        return Redisson.create(config);\r\n    }\r\n\r\n### Additional information\r\n`nested exception is org.redisson.RedissonShutdownException: Redisson is shutdown org.springframework.dao.InvalidDataAccessApiUsageException: Redisson is shutdown; nested exception is org.redisson.RedissonShutdownException: Redisson is shutdown\\n\\tat org.redisson.spring.data.connection.RedissonExceptionConverter.convert(RedissonExceptionConverter.java:48)\\n\\tat org.redisson.spring.data.connection.RedissonExceptionConverter.convert(RedissonExceptionConverter.java:35)\\n\\tat org.springframework.data.redis.PassThroughExceptionTranslationStrategy.translate(PassThroughExceptionTranslationStrategy.java:44)\\n\\tat org.redisson.spring.data.connection.RedissonConnection.transform(RedissonConnection.java:217)\\n\\tat org.redisson.spring.data.connection.RedissonConnection.syncFuture(RedissonConnection.java:212)\\n\\tat org.redisson.spring.data.connection.RedissonConnection.sync(RedissonConnection.java:378)\\n\\tat org.redisson.spring.data.connection.RedissonConnection.read(RedissonConnection.java:759)\\n\\tat org.redisson.spring.data.connection.RedissonConnection.get(RedissonConnection.java:493)\\n\\tat org.springframework.data.redis.connection.DefaultStringRedisConnection.get(DefaultStringRedisConnection.java:404)\\n\\tat org.springframework.data.redis.core.DefaultValueOperations$1.inRedis(DefaultValueOperations.java:57)\\n\\tat org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:60)\\n\\tat org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:228)\\n\\tat org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:188)\\n\\tat org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:96)\\n\\tat org.springframework.data.redis.core.DefaultValueOperations.get(DefaultValueOperations.java:53)\\n ...`\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/6315/comments",
    "author": "LHH7049",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2024-12-04T06:30:24Z",
        "body": "This is an expected behavior since pod is shutdown."
      },
      {
        "user": "LHH7049",
        "created_at": "2024-12-04T09:40:48Z",
        "body": "> This is an expected behavior since pod is shutdown.\r\n\r\nfine, thanks"
      }
    ]
  },
  {
    "number": 5830,
    "title": "Issue with Kryo5Codec in combination with org.springframework.cache.support.NullValue",
    "created_at": "2024-04-30T10:11:54Z",
    "closed_at": "2024-12-23T11:00:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/5830",
    "body": "Hi,\r\n\r\nI'm currently having an issue with the Spring Cache implementation in combination with Redisson. \r\nThe JCacheCache class provided by Redisson extends `org.springframework.cache.support.AbstractValueAdaptingCache`. In the method `protected Object fromStoreValue(@Nullable Object storeValue)` of the class AbstractValueAdaptingCache, there is an if condition, that check if the storeValue is equal to NullValue.INSTANCE using ==. \r\n\r\n```\r\nprotected Object fromStoreValue(@Nullable Object storeValue) {\r\n\tif (this.allowNullValues && storeValue == NullValue.INSTANCE) {\r\n\t\treturn null;\r\n\t}\r\n\treturn storeValue;\r\n}\r\n```\r\n\r\nThis condition evaluated to false in my case, because the instance of storeValue was not the same instance as NullValue.INSTANCE. Reason is the deserialisation, that was done by Kryo. It seems, that Kryo changes the constructor to \"public\" using reflections and creates a new instance by calling the constructor. It does not call the \"readResolve()\" method of NullValue class, which would return NullValue.INSTANCE.\r\nIs this a known issue? The only solution I came up with is extending the Kryo5Codec and adding a custom Serializer for NullValue.class. Is there another way to fix this issue?\r\n\r\nBest regards",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/5830/comments",
    "author": "MrKanister2000",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2024-04-30T12:12:56Z",
        "body": "> The JCacheCache class provided by Redisson\r\n\r\nSorry, Redisson doesn't implement such class"
      },
      {
        "user": "MrKanister2000",
        "created_at": "2024-04-30T13:07:27Z",
        "body": "> Sorry, Redisson doesn't implement such class\r\n\r\nYep sry, my bad. I got confused with the class names. JCacheCache is part of the Spring package. \r\nNevertheless, the `org.redisson.jcache.JCache` class returns a new instance of NullValue from the cache, because of the Kryo deserialization issue I described. Any hint how to fix this?\r\n"
      },
      {
        "user": "mrniko",
        "created_at": "2024-04-30T13:18:30Z",
        "body": "Can you add the code below into org.redisson.codec.Kryo5Codec#createKryo method and say if it works?\r\n\r\n```java\r\nif (com.esotericsoftware.kryo.util.Util.isClassAvailable(\"org.springframework.cache.support.NullValue\")) {\r\n   kryo.addDefaultSerializer(Class.forName(\"org.springframework.cache.support.NullValue\"), new JavaSerializer());\r\n}\r\n```"
      },
      {
        "user": "MrKanister2000",
        "created_at": "2024-04-30T14:06:05Z",
        "body": "Yes, it works, thanks. Do you see any trade-offs (like performance) when using the JavaSerializer?\r\n\r\nMy first solution was extending the Kryo5Codec class:\r\n\r\n```\r\npublic class MyKryo5Codec extends Kryo5Codec {\r\n\r\n    @Override\r\n    protected Kryo createKryo(ClassLoader classLoader) {\r\n        Kryo kryo = super.createKryo(classLoader);\r\n\r\n        kryo.addDefaultSerializer(NullValue.class, new NullValueSerializer(kryo, NullValue.class));\r\n\r\n        return kryo;\r\n    }\r\n}\r\n```\r\n\r\nand creating a custom NullValueSerializer:\r\n\r\n```\r\npublic class NullValueSerializer extends FieldSerializer<NullValue> {\r\n\r\n    public NullValueSerializer(Kryo kryo, Class type) {\r\n        super(kryo, type);\r\n    }\r\n\r\n    @Override\r\n    public NullValue read(Kryo kryo, Input input, Class type) {\r\n        return (NullValue) NullValue.INSTANCE;\r\n    }\r\n}\r\n```\r\n\r\nBut your solution has a way smaller footprint than mine."
      },
      {
        "user": "mrniko",
        "created_at": "2024-05-01T05:08:01Z",
        "body": "Thanks for testing. In your example Spring become a required dependency because of explicit NullValue class definition which I would like to avoid. It would be great if you rewrite it without explicit NullValue definition."
      }
    ]
  },
  {
    "number": 5298,
    "title": "How to successfully use Live Objects ?",
    "created_at": "2023-09-08T21:31:58Z",
    "closed_at": "2023-09-13T08:13:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/5298",
    "body": "I'm having difficulty with two different parts of the Live Objects feature of Redisson:\r\n\r\n1. Storing a nested `Map<String, String>` as a field of an '@REntity`\r\n2. Using a condition to `find()` instances that I know are stored.\r\n\r\nHere's my live object class (I'm using Lombok, hence the @Getter, etc annotations):\r\n```java\r\n@RequiredArgsConstructor\r\n@NoArgsConstructor(access = PROTECTED)\r\n@REntity(codec = StringCodec.class)\r\npublic class Manifest {\r\n\r\n\t@RId(generator = UUIDGenerator.class)\r\n\t@Getter\r\n\tprivate String id;\r\n\r\n\t@RIndex\r\n\t@Getter\r\n\tprivate String jobId;\r\n\r\n\t@RIndex\r\n\t@Getter\r\n\tprivate String rootFolder;\r\n\r\n\t@RCascade(ALL)  // Not sure this is needed, it doesn't seem to make any difference\r\n\tprivate Map<String, String> entries = new HashMap<>();\r\n\r\n\r\n\tpublic void add(String path, String hash) {\r\n\t\tentries.put(path, hash);\r\n\t}\r\n\r\n\t@Transient\r\n\tpublic int getSize() {\r\n\t\treturn entries.size();\r\n\t}\r\n\r\n}\r\n```\r\n\r\nI'm using this code to initially create and store the live object:\r\n```java\r\n\tRLiveObjectService liveObjects = redisson.getLiveObjectService();\r\n\tvar manifest = new Manifest(jobID, rootPath);\r\n\tmanifest = liveObjects.persist(manifest);\r\n\tliveObjects.asLiveObject(manifest).expire(Duration.ofMinutes(60));\r\n```\r\n\r\nElsewhere I use this code to get the object by ID and add data to its `entries` map:\r\n```java\r\n\tManifest manifest = liveObjects.get(Manifest.class, id);\r\n\tmanifest.add(path, hash);\r\n```\r\n\r\nSomewhere else, I use this code to find the object:\r\n```java\r\n\tpublic static Condition jobIDEquals(String jobID) {\r\n\t\treturn Conditions.eq(\"jobId\", jobID);\r\n\t}\r\n\r\n\tCollection<Manifest> manifests = liveObjects.find(Manifest.class, jobIDEquals(jobID));\r\n```\r\n\r\nWith the code above, the two problems are:\r\n1. The `manifests` collection is empty, even though I can inspect my Redis server (using RedisInsight) and see the hashes stored there with matching `jobId` values.\r\n2. If I load one of the objects directly by its `id`, the `entries` Map is always empty, _even after_ having added values to it. I see in RedisInsight that the value of `entries` is `org.redisson.RedissonReference@7623beea`, but there is no other key in Redis that corresponds to that reference.\r\n\r\nWhat am I doing wrong?",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/5298/comments",
    "author": "eric-creekside",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2023-09-09T04:47:34Z",
        "body": "You need to define getters and constructors explicitly"
      },
      {
        "user": "eric-creekside",
        "created_at": "2023-09-10T21:59:48Z",
        "body": "That solved some of the problems, thanks. I strongly suggest you make this clear in the documentation and examples that Live Objects can not use getters/setters/constructors that are generated by byte-code tools. Lombok is very popular and commonly used. It could save other users a lot of time knowing to avoid using it in their `@REntity` objects.\n\n---\n\nAs I tested more, I was still seeing the situation where values I had added to my nested `entries` `Map<>` were not getting persisted, so when a later process loaded the objects with `find()`, `entries` was empty. I discovered that my `Manifest.add()` method had to use the getter to reference `entities`. Specifically, this code did *not* work:\r\n```java\r\n\tpublic void add(String path, String hash) {\r\n\t\tentries.put(path, hash);\r\n\t}\r\n```\r\nbut this code does work:\r\n```java\r\n\tpublic void add(String path, String hash) {\r\n\t\tgetEntries().put(path, hash);\r\n\t}\r\n```\r\n\r\nI think this is another opportunity to improve the documentation and examples by making it clear that collection fields of the live object have to be de-referenced from the proxy in order to have their contents persisted.\r\n\r\nIf possible, it would be good to also detect that situation at runtime and log a warning."
      },
      {
        "user": "mrniko",
        "created_at": "2023-09-13T08:13:57Z",
        "body": "Follow statement added to the documentation: `Getters/setters/constructors can't be generated by byte-code tools like Lombok. Additional methods should use getters and not fields. `"
      }
    ]
  },
  {
    "number": 4890,
    "title": "Switching from Redis 4 to 6, will Redisson have compatibility issues?",
    "created_at": "2023-02-22T13:23:12Z",
    "closed_at": "2023-02-23T07:23:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4890",
    "body": "Hi team, \r\n\r\nWe are going to upgrade Redis 4 to Redis 6. I would like to ask team if there will be compatibility issues between Redission and Redis 6 after upgrading 4 to 6. Or do you know of any known Redission incompatibilities due to Redis 6 upgrades?\r\nAccording to redission documentation, Redission supports Redis 4 and 6. Does this mean that we don't need to modify any client code? \r\n\r\nMany thanks for your support!",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4890/comments",
    "author": "yunbozhang-msft",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2023-02-23T07:23:49Z",
        "body": "Hi,\r\n\r\nRedisson is fully compatible with 3.x up to 7.0.x version. No code modification is needed."
      },
      {
        "user": "yunbozhang-msft",
        "created_at": "2023-02-28T05:22:03Z",
        "body": "Thank you!"
      }
    ]
  },
  {
    "number": 4768,
    "title": "Classfile version 61 (Java17) change intended?",
    "created_at": "2022-12-29T15:48:50Z",
    "closed_at": "2023-01-06T07:28:19Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4768",
    "body": "Is it an intended or accidental change to publish redisson compiled with java17 target and thus break everyone not yet lucky enough to be on 17?\r\nIf so, wouldn't a change like this be good to be documented as incompatible in the release notes?\r\n\r\nAlso i was expecting such a drastic thing to be a major, rather than a minor change (in terms of SemVer).",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4768/comments",
    "author": "uweschaefer",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2022-12-30T05:34:28Z",
        "body": "Can you point on that class? All classes of 3.19.0 version compiled with java 8 target. Checked it with javap\r\n\r\n```\r\npublic class org.redisson.Redisson implements org.redisson.api.RedissonClient\r\n  minor version: 0\r\n  major version: 52\r\n```\r\n"
      },
      {
        "user": "uweschaefer",
        "created_at": "2023-01-09T17:54:44Z",
        "body": "my bad. I rechecked all classes from 3.18,19.0 and 19.1... Don't know what i saw... :blush: "
      }
    ]
  },
  {
    "number": 4674,
    "title": "Expire RRateLimiter",
    "created_at": "2022-11-15T08:22:44Z",
    "closed_at": "2022-11-17T07:52:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4674",
    "body": "I want to delete RRateLimiter hash from redis, post rate interval is over. e.g. I set rate interval of 10 sec then hash must be removed post 10 sec.\r\nIs there any built in api for this functinality exists? ",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4674/comments",
    "author": "pat246",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2022-11-17T07:52:56Z",
        "body": "You need to use `expire()` method"
      },
      {
        "user": "pat246",
        "created_at": "2022-11-17T12:41:16Z",
        "body": "Thanks.\r\nActually we are using redisson 3.12.x version, hence I was unable to call `expire()` method. However as workaround I've tried to expire using `RMap`  with expiry value of \"rate interval\" as below\r\n\r\n\r\n`RRateLimiter limiter = redisson.getRateLimiter(name);`\r\n`RMap<Object, Object> keyMap = redisson.getMap(name);`\r\n`keyMap.expire(10, TimeUnit.SECONDS); // 10 sec is rate interval of limitter`"
      }
    ]
  },
  {
    "number": 4670,
    "title": "How to set cache properties for Hibernate scond level cache?",
    "created_at": "2022-11-13T08:38:42Z",
    "closed_at": "2022-12-12T06:04:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4670",
    "body": "I'm working on a Java spring project where I have multiple entities to be cached using `@Cache` annotation, ex:\r\n`@Cache(usage = CacheConcurrencyStrategy.READ_WRITE ,region = \"cache1\")`\r\n\r\nI have set ` spring.jpa.properties.hibernate.cache.region.factory_class` to be RedissonRegionFactory\r\n\r\nAs I'm using Redis cache as Hibernate second Level cache, I want a way to customize the properties of each cache region in a Java class, by properties I mean the TTL and maxEntriesLocalHeap.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4670/comments",
    "author": "AseelAbushhadeh",
    "comments": [
      {
        "user": "OdaybatLFC",
        "created_at": "2022-11-15T08:48:17Z",
        "body": "Hello @AseelAbushhadeh , what I have done in my project is configure each cached entity with my own configuration class. I am also open to hear if there is another way of achieving this."
      },
      {
        "user": "mrniko",
        "created_at": "2022-11-17T07:51:33Z",
        "body": "@OdaybatLFC \r\n\r\nWhy can't you use spring.jpa.properties.hibernate.cache... settings?\r\n\r\n```java\r\nspring.jpa.properties.hibernate.cache.redisson.entity.expiration.time_to_live=\r\nspring.jpa.properties.hibernate.cache.redisson.entity.expiration.max_idle_time=\r\nspring.jpa.properties.hibernate.cache.redisson.collection.expiration.time_to_live=\r\nspring.jpa.properties.hibernate.cache.redisson.collection.expiration.max_idle_time=\r\n```"
      },
      {
        "user": "AseelAbushhadeh",
        "created_at": "2022-11-17T10:37:03Z",
        "body": "thanks for the suggestion, I can use it but this will apply to all caches, I want to customize the properties for each entity cache individually.\r\n\r\n> @OdaybatLFC\r\n> \r\n> Why can't you use spring.jpa.properties.hibernate.cache... settings?\r\n> \r\n> ```java\r\n> spring.jpa.properties.hibernate.cache.redisson.entity.expiration.time_to_live=\r\n> spring.jpa.properties.hibernate.cache.redisson.entity.expiration.max_idle_time=\r\n> spring.jpa.properties.hibernate.cache.redisson.collection.expiration.time_to_live=\r\n> spring.jpa.properties.hibernate.cache.redisson.collection.expiration.max_idle_time=\r\n> ```\r\n\r\n"
      },
      {
        "user": "mrniko",
        "created_at": "2022-11-17T11:24:26Z",
        "body": "You can specify region name as well.\r\n```\r\nspring.jpa.properties.hibernate.cache.redisson.my_object.eviction.max_entries=\r\nspring.jpa.properties.hibernate.cache.redisson.my_object.expiration.time_to_live=\r\nspring.jpa.properties.hibernate.cache.redisson.my_object.expiration.max_idle_time=\r\n\r\nspring.jpa.properties.hibernate.cache.redisson.my_collection.expiration.time_to_live=\r\nspring.jpa.properties.hibernate.cache.redisson.my_collection.expiration.max_idle_time=\r\n```"
      },
      {
        "user": "AseelAbushhadeh",
        "created_at": "2022-11-17T12:16:45Z",
        "body": "> You can specify region name as well.\r\n> \r\n> ```\r\n> spring.jpa.properties.hibernate.cache.redisson.my_object.eviction.max_entries=\r\n> spring.jpa.properties.hibernate.cache.redisson.my_object.expiration.time_to_live=\r\n> spring.jpa.properties.hibernate.cache.redisson.my_object.expiration.max_idle_time=\r\n> \r\n> spring.jpa.properties.hibernate.cache.redisson.my_collection.expiration.time_to_live=\r\n> spring.jpa.properties.hibernate.cache.redisson.my_collection.expiration.max_idle_time=\r\n> ```\r\n\r\nThanks it works!! \r\nHoping I can find a way to do that in a java class."
      }
    ]
  },
  {
    "number": 4284,
    "title": "What difference from `readAllEntrySet` and `getAll` in `RMap`",
    "created_at": "2022-05-10T12:57:00Z",
    "closed_at": "2022-05-10T13:15:01Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4284",
    "body": "Hi~ Community:\r\n    When I want to use `hmget` command in redis, I found `rMap.getAll(\"\")`, it returns all fields, so what difference from `readAllEntrySet` and `getAll` in `RMap`?\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4284/comments",
    "author": "xdshent",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2022-05-10T13:01:52Z",
        "body": "`getAll` methods allows to load map by specified keys. Whereas `readAllEntrySet` loads all map entries."
      },
      {
        "user": "xdshent",
        "created_at": "2022-05-10T13:14:57Z",
        "body": "> `getAll` methods allows to load map by specified keys. Whereas `readAllEntrySet` loads all map entries.\r\n\r\nthx! @mrniko "
      }
    ]
  },
  {
    "number": 4281,
    "title": "Redis is changed to access with password, and trylock takes more time",
    "created_at": "2022-05-10T09:47:28Z",
    "closed_at": "2022-05-12T06:58:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4281",
    "body": "Redis used to access without password, and then upgraded to access with password. It was found that trylock took more than one second\u3002\r\nredisson version is 3.16.0\r\nThe configuration is as follows\uff1a\r\n`config.useClusterServers()\r\n                    .setPassword(password)\r\n                    .setScanInterval(2000)\r\n                    .addNodeAddress(xxxxx);\r\n            return Redisson.create(config);`\r\nso, I tried to reduce the reission version to 3.11.6, and the time consumption decreased significantly\r\nI don't know what caused this. Is it the wrong way to use the new version?\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4281/comments",
    "author": "XTUxiongda",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2022-05-10T10:02:24Z",
        "body": "It was caused by introduction of WAIT command to sync with slaves. It seems that sync takes much time in your case."
      },
      {
        "user": "XTUxiongda",
        "created_at": "2022-05-10T10:27:39Z",
        "body": "> It was caused by introduction of WAIT command to sync with slaves. It seems that sync takes much time in your case.\r\nIs there any way to solve it? I found this problem after version 3.14.1. Or can I only use the old version, and the new version all has this problem?\r\n\n\n---\n\nAnd My waittime input parameter is 0\r\n"
      },
      {
        "user": "mrniko",
        "created_at": "2022-05-10T12:59:24Z",
        "body": "Could you set `TRACE` logging level for `org.redisson` package and share output?"
      },
      {
        "user": "XTUxiongda",
        "created_at": "2022-05-12T01:13:05Z",
        "body": "[basic-porter-tadata-xxx.xx.xx.xx-0000] 2022-05-10 21:30:16.221 TRACE 20100 [redisson-netty-2-4] [CommandEncoder.java:112] channel: [id: 0x5eda2625, L:/xxx.xx.xx.xx:58206 - R:xxx.xx.xx.xx/xxx.xx.xx.xx:7002] message: *2\r\n$7\r\nCLUSTER\r\n$5\r\nNODES\r\n\r\n[basic-porter-tadata-xxx.xx.xx.xx-0000] 2022-05-10 21:30:16.235 TRACE 20100 [redisson-netty-2-4] [CommandDecoder.java:113] reply: $775\r\na45ecb9201e0bf48665ed7e5a9846cbe6d753165 xxx.xx.xx.xx:7006@17006 slave f5d943dbd5806937e204ee35ea5f6aa65e46a6ca 0 1652189413455 6 connected\r\nf5d943dbd5806937e204ee35ea5f6aa65e46a6ca xxx.xx.xx.xx:7003@17003 master - 0 1652189414000 3 connected 10923-16383\r\n40e866c9d83596f7d50ff09ee92370f580c9add9 xxx.xx.xx.xx:7001@17001 master - 0 1652189415465 1 connected 0-5460\r\nf226329e04bda39971a532552f18a32bb2c1b7a8 xxx.xx.xx.xx:7005@17005 slave ced813a2fd0db10432dbc999befd3709ac2234a2 0 1652189414460 5 connected\r\neccdd6be867c3fc36a27f2c1cc105c98c2d08879 xxx.xx.xx.xx:7004@17004 slave 40e866c9d83596f7d50ff09ee92370f580c9add9 0 1652189414000 1 connected\r\nced813a2fd0db10432dbc999befd3709ac2234a2 xxx.xx.xx.xx:7002@17002 myself,master - 0 1652189413000 2 connected 5461-10922\r\n\r\n, channel: [id: 0x5eda2625, L:/xxx.xx.xx.xx:58206 - R:xxx.xx.xx.xx/xxx.xx.xx.xx:7002], command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@44c15e70(incomplete)], command=(CLUSTER NODES), params=[], codec=null]\r\n[basic-porter-tadata-xxx.xx.xx.xx-0000] 2022-05-10 21:30:16.236 DEBUG 20100 [redisson-netty-2-4] [ClusterConnectionManager.java:466] cluster nodes state got from xxx.xx.xx.xx/xxx.xx.xx.xx:7002:\r\na45ecb9201e0bf48665ed7e5a9846cbe6d753165 xxx.xx.xx.xx:7006@17006 slave f5d943dbd5806937e204ee35ea5f6aa65e46a6ca 0 1652189413455 6 connected\r\nf5d943dbd5806937e204ee35ea5f6aa65e46a6ca xxx.xx.xx.xx:7003@17003 master - 0 1652189414000 3 connected 10923-16383\r\n40e866c9d83596f7d50ff09ee92370f580c9add9 xxx.xx.xx.xx:7001@17001 master - 0 1652189415465 1 connected 0-5460\r\nf226329e04bda39971a532552f18a32bb2c1b7a8 xxx.xx.xx.xx:7005@17005 slave ced813a2fd0db10432dbc999befd3709ac2234a2 0 1652189414460 5 connected\r\neccdd6be867c3fc36a27f2c1cc105c98c2d08879 xxx.xx.xx.xx:7004@17004 slave 40e866c9d83596f7d50ff09ee92370f580c9add9 0 1652189414000 1 connected\r\nced813a2fd0db10432dbc999befd3709ac2234a2 xxx.xx.xx.xx:7002@17002 myself,master - 0 1652189413000 2 connected 5461-10922\r\n\r\n[basic-porter-tadata-xxx.xx.xx.xx-0000] 2022-05-10 21:30:17.313 DEBUG 20100 [http-nio-8080-exec-3] [ClusterConnectionManager.java:751] slot 2875 for sync_tadata_lock\r\n[basic-porter-tadata-xxx.xx.xx.xx-0000] 2022-05-10 21:30:17.314 DEBUG 20100 [http-nio-8080-exec-3] [ClusterConnectionManager.java:751] slot 2875 for sync_tadata_lock\r\n[basic-porter-tadata-xxx.xx.xx.xx-0000] 2022-05-10 21:30:17.314 TRACE 20100 [redisson-netty-2-5] [CommandEncoder.java:112] channel: [id: 0x1dd4250d, L:/xxx.xx.xx.xx:58207 - R:xxx.xx.xx.xx/xxx.xx.xx.xx:7001] message: *6\r\n$4\r\nEVAL\r\n$339\r\nif (redis.call('exists', KEYS[1]) == 0) then redis.call('hincrby', KEYS[1], ARGV[2], 1); redis.call('pexpire', KEYS[1], ARGV[1]); return nil; end; if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then redis.call('hincrby', KEYS[1], ARGV[2], 1); redis.call('pexpire', KEYS[1], ARGV[1]); return nil; end; return redis.call('pttl', KEYS[1]);\r\n$1\r\n1\r\n$16\r\nsync_tadata_lock\r\n$6\r\n600000\r\n$40\r\n8f9cbb23-40dd-4457-a13a-6f8041461ba5:194\r\n\r\n[basic-porter-tadata-xxx.xx.xx.xx-0000] 2022-05-10 21:30:17.315 TRACE 20100 [redisson-netty-2-5] [CommandEncoder.java:112] channel: [id: 0x1dd4250d, L:/xxx.xx.xx.xx:58207 - R:xxx.xx.xx.xx/xxx.xx.xx.xx:7001] message: *6\r\n$4\r\nEVAL\r\n$339\r\nif (redis.call('exists', KEYS[1]) == 0) then redis.call('hincrby', KEYS[1], ARGV[2], 1); redis.call('pexpire', KEYS[1], ARGV[1]); return nil; end; if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then redis.call('hincrby', KEYS[1], ARGV[2], 1); redis.call('pexpire', KEYS[1], ARGV[1]); return nil; end; return redis.call('pttl', KEYS[1]);\r\n$1\r\n1\r\n$16\r\nsync_tadata_lock\r\n$6\r\n600000\r\n$40\r\n8f9cbb23-40dd-4457-a13a-6f8041461ba5:194\r\n*3\r\n$4\r\nWAIT\r\n$1\r\n1\r\n$4\r\n1000\r\n\r\n[basic-porter-tadata-xxx.xx.xx.xx-0000] 2022-05-10 21:30:17.332 TRACE 20100 [redisson-netty-2-5] [CommandDecoder.java:113] reply: $-1\r\n, channel: [id: 0x1dd4250d, L:/xxx.xx.xx.xx:58207 - R:xxx.xx.xx.xx/xxx.xx.xx.xx:7001], command: CommandsData [commands=[CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@5dfb7633(incomplete)], command=(EVAL), params=[if (redis.call('exists', KEYS[1]) == 0) then redis.call('hincrby', KEYS[1], ARGV[2], 1); redis.call(..., 1, sync_tadata_lock, 600000, 8f9cbb23-40dd-4457-a13a-6f8041461ba5:194], codec=org.redisson.client.codec.LongCodec], CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@ee60138(incomplete)], command=(WAIT), params=[1, 1000], codec=org.redisson.client.codec.StringCodec]]]\r\n[basic-porter-tadata-xxx.xx.xx.xx-0000] 2022-05-10 21:30:18.255 TRACE 20100 [redisson-netty-2-4] [CommandEncoder.java:112] channel: [id: 0x5eda2625, L:/xxx.xx.xx.xx:58206 - R:xxx.xx.xx.xx/xxx.xx.xx.xx:7002] message: *2\r\n$7\r\nCLUSTER\r\n$5\r\nNODES\r\n\r\n[basic-porter-tadata-xxx.xx.xx.xx-0000] 2022-05-10 21:30:18.271 TRACE 20100 [redisson-netty-2-4] [CommandDecoder.java:113] reply: $775\r\na45ecb9201e0bf48665ed7e5a9846cbe6d753165 xxx.xx.xx.xx:7006@17006 slave f5d943dbd5806937e204ee35ea5f6aa65e46a6ca 0 1652189416468 6 connected\r\nf5d943dbd5806937e204ee35ea5f6aa65e46a6ca xxx.xx.xx.xx:7003@17003 master - 0 1652189414000 3 connected 10923-16383\r\n40e866c9d83596f7d50ff09ee92370f580c9add9 xxx.xx.xx.xx:7001@17001 master - 0 1652189415465 1 connected 0-5460\r\nf226329e04bda39971a532552f18a32bb2c1b7a8 xxx.xx.xx.xx:7005@17005 slave ced813a2fd0db10432dbc999befd3709ac2234a2 0 1652189416000 5 connected\r\neccdd6be867c3fc36a27f2c1cc105c98c2d08879 xxx.xx.xx.xx:7004@17004 slave 40e866c9d83596f7d50ff09ee92370f580c9add9 0 1652189417471 1 connected\r\nced813a2fd0db10432dbc999befd3709ac2234a2 xxx.xx.xx.xx:7002@17002 myself,master - 0 1652189415000 2 connected 5461-10922\r\n\r\n, channel: [id: 0x5eda2625, L:/xxx.xx.xx.xx:58206 - R:xxx.xx.xx.xx/xxx.xx.xx.xx:7002], command: CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@3c593bb7(incomplete)], command=(CLUSTER NODES), params=[], codec=null]\r\n[basic-porter-tadata-xxx.xx.xx.xx-0000] 2022-05-10 21:30:18.272 DEBUG 20100 [redisson-netty-2-4] [ClusterConnectionManager.java:466] cluster nodes state got from xxx.xx.xx.xx/xxx.xx.xx.xx:7002:\r\na45ecb9201e0bf48665ed7e5a9846cbe6d753165 xxx.xx.xx.xx:7006@17006 slave f5d943dbd5806937e204ee35ea5f6aa65e46a6ca 0 1652189416468 6 connected\r\nf5d943dbd5806937e204ee35ea5f6aa65e46a6ca xxx.xx.xx.xx:7003@17003 master - 0 1652189414000 3 connected 10923-16383\r\n40e866c9d83596f7d50ff09ee92370f580c9add9 xxx.xx.xx.xx:7001@17001 master - 0 1652189415465 1 connected 0-5460\r\nf226329e04bda39971a532552f18a32bb2c1b7a8 xxx.xx.xx.xx:7005@17005 slave ced813a2fd0db10432dbc999befd3709ac2234a2 0 1652189416000 5 connected\r\neccdd6be867c3fc36a27f2c1cc105c98c2d08879 xxx.xx.xx.xx:7004@17004 slave 40e866c9d83596f7d50ff09ee92370f580c9add9 0 1652189417471 1 connected\r\nced813a2fd0db10432dbc999befd3709ac2234a2 xxx.xx.xx.xx:7002@17002 myself,master - 0 1652189415000 2 connected 5461-10922\r\n\r\n[basic-porter-tadata-xxx.xx.xx.xx-0000] 2022-05-10 21:30:18.826 TRACE 20100 [redisson-netty-2-5] [CommandDecoder.java:113] reply: :0\r\n, channel: [id: 0x1dd4250d, L:/xxx.xx.xx.xx:58207 - R:xxx.xx.xx.xx/xxx.xx.xx.xx:7001], command: CommandsData [commands=[CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@5dfb7633(success)], command=(EVAL), params=[if (redis.call('exists', KEYS[1]) == 0) then redis.call('hincrby', KEYS[1], ARGV[2], 1); redis.call(..., 1, sync_tadata_lock, 600000, 8f9cbb23-40dd-4457-a13a-6f8041461ba5:194], codec=org.redisson.client.codec.LongCodec], CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@ee60138(incomplete)], command=(WAIT), params=[1, 1000], codec=org.redisson.client.codec.StringCodec]]]\r\n[basic-porter-tadata-xxx.xx.xx.xx-0000] 2022-05-10 21:30:18.827 DEBUG 20100 [redisson-netty-2-5] [RedisExecutor.java:522] connection released for command null and params null from slot NodeSource [slot=null, addr=null, redisClient=null, redirect=null, entry=MasterSlaveEntry [masterEntry=[freeSubscribeConnectionsAmount=1, freeSubscribeConnectionsCounter=value:50:queue:0, freeConnectionsAmount=24, freeConnectionsCounter=value:64:queue:0, freezeReason=null, client=[addr=redis://xxx.xx.xx.xx:7001], nodeType=MASTER, firstFail=0]]] using connection RedisConnection@1915911582 [redisClient=[addr=redis://xxx.xx.xx.xx:7001], channel=[id: 0x1dd4250d, L:/xxx.xx.xx.xx:58207 - R:xxx.xx.xx.xx/xxx.xx.xx.xx:7001], currentCommand=null]\r\n\r\n\n\n---\n\n@mrniko can you help me on this queston? thank you very much. i really want to know the reason."
      },
      {
        "user": "mrniko",
        "created_at": "2022-05-12T06:13:29Z",
        "body": "I reproduce your case only if masterauth is not set for slave nodes."
      },
      {
        "user": "XTUxiongda",
        "created_at": "2022-05-12T06:49:45Z",
        "body": "> I reproduce your case only if masterauth is not set for slave nodes.\r\n\r\nthank you very much !  That's why. "
      }
    ]
  },
  {
    "number": 4065,
    "title": "How to use 'zAdd'?",
    "created_at": "2022-01-10T09:22:53Z",
    "closed_at": "2022-01-11T07:26:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4065",
    "body": "How to use 'RedisZSetCommands.zAdd(byte[] key, double score, byte[] value)'?\r\nnot implemented\uff1f",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4065/comments",
    "author": "Jabwin",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2022-01-10T10:55:47Z",
        "body": "It's implemented in all versions. Starting from Spring Data Redis 2.5.0 it's routed to `zAdd(byte[] key, double score, byte[] value, ZAddArgs args)` method. Which is also implemented."
      }
    ]
  },
  {
    "number": 4046,
    "title": "Reads only happening from Master Node for Redis Cache in Elastic Cache replicated mode",
    "created_at": "2021-12-23T11:38:40Z",
    "closed_at": "2021-12-26T08:32:43Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/4046",
    "body": "We are using the clustered connection in aws for redis, but the read is always happening from the primary node.\r\n\r\nThe versions we are using:\r\n\r\nRedis engine in aws  : 4.0.10\r\n\r\nClient:\r\n                       <dependency>\r\n\t\t\t\t<groupId>org.redisson</groupId>\r\n\t\t\t\t<artifactId>redisson</artifactId>\r\n\t\t\t\t<version>3.16.6</version>\r\n\t\t\t</dependency>\r\n\r\n\r\nConfig:\r\nURL: aws cluster url\r\nfinal int poolSize = Runtime.getRuntime().availableProcessors() * 2 + 2;\r\n\t\tConfig config = new Config();\r\n\t\tconfig\r\n\t\t\t.useClusterServers()\r\n\t\t\t.setScanInterval(2000)\r\n\t\t\t.addNodeAddress(redisUrl)\r\n\t\t\t.setMasterConnectionPoolSize(poolSize)\r\n\t\t\t.setMasterConnectionMinimumIdleSize(poolSize)\r\n\t\t\t.setSlaveConnectionPoolSize(poolSize)\r\n\t\t\t.setSlaveConnectionMinimumIdleSize(poolSize)\r\n\t\t\t\t.setReadMode(ReadMode.SLAVE);\r\n\r\n\t\tconfig.setCodec(codec);\r\n\t\tredissonClient = Redisson.create(config);\r\n\r\n\r\nCache read:\r\n\r\n                final RMap<String, Config> cache = this.redissonClient.getMap(CONFIG_CACHE);\r\n\t\tif (cache.isEmpty()) {\r\n\t\t\tlog.info(\"found Config cache empty... reloading from database\");\r\n\t\t\treloadPartnerConfig();\r\n\t\t}\r\n\t\treturn cache.get(apiKey);\r\n\r\n\r\n@mrniko  Could you check this once you have some time. I am sure you can provide a relevant answer very fast.\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/4046/comments",
    "author": "rjvharidas",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-12-23T17:32:02Z",
        "body": "please share log with `trace` logging level for `org.redisson` package.\n\n---\n\nEVAL script uses write command so it's executed on master. You can use RMapCache.getWithTTLOnly() if idleTimeout is not defined."
      },
      {
        "user": "rjvharidas",
        "created_at": "2021-12-26T08:32:43Z",
        "body": "Thanks @mrniko , we have moved to  RMapCache.getWithTTLOnly() and now i can see the data is loading from read replica."
      },
      {
        "user": "formanojhr",
        "created_at": "2023-04-26T03:45:11Z",
        "body": "@mrniko is this issue also in cluster mode? for read replicas. I assume yes."
      }
    ]
  },
  {
    "number": 3989,
    "title": " ERR Error running script (call to f_0fd7cdd6c1224471b29d6f7fc503462f3b252f12): @user_script:1: user_script:1: bad argument #2 to 'unpack' (data string too short",
    "created_at": "2021-11-26T18:24:24Z",
    "closed_at": "2021-11-30T06:09:02Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3989",
    "body": "I am unable to understand this error. Please help.\r\n` Execution exception[[RedisException: ERR Error running script (call to f_0fd7cdd6c1224471b29d6f7fc503462f3b252f12): @user_script:1: user_script:1: bad argument #2 to 'unpack' (data string too short) . channel: [id: 0xd4089e92, L:/10.212.134.41:60921 - R:core-dev-redis.6cbkbd.0001.aps1.cache.amazonaws.com/192.168.2.46:6379] command: (EVAL), params: [local result = {}; local idleKeys = {}; local res; if (#ARGV == 4) then  res = redis.call('hscan', K..., 3, ALLUS_XXX, redisson__timeout__set:{ALLUS_XXX}, redisson__idle__set:{ALLUS_XXX}, 1637948919729, 0, 10]]]\\\r\n`\r\n\r\nI am trying to read using `getMapCache(ALLUS_XXX)`\r\n\r\nalso, in redis cli if I do `hgetall ALLUS_XXX`.  This is the output\r\n\r\n```\r\n 1) \"3\"\r\n 2) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"3\\\",\\\"ax\\\":\\\"21\\\",\\\"bp\\\":331.27,\\\"ap\\\":331.3,\\\"bs\\\":2,\\\"as\\\":1,\\\"t\\\":\\\"1637948895747\\\",\\\"q\\\":\\\"42893371\\\",\\\"z\\\":3}\"\r\n 3) \"2\"\r\n 4) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"2\\\",\\\"ax\\\":\\\"19\\\",\\\"bp\\\":330.03,\\\"ap\\\":330.13,\\\"bs\\\":2,\\\"as\\\":3,\\\"t\\\":\\\"1637949585689\\\",\\\"q\\\":\\\"46053648\\\",\\\"z\\\":3}\"\r\n 5) \"12\"\r\n 6) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"12\\\",\\\"ax\\\":\\\"11\\\",\\\"bp\\\":329.91,\\\"ap\\\":330.25,\\\"bs\\\":1,\\\"as\\\":12,\\\"t\\\":\\\"1637949676507\\\",\\\"q\\\":\\\"46258127\\\",\\\"z\\\":3}\"\r\n 7) \"9\"\r\n 8) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"9\\\",\\\"ax\\\":\\\"15\\\",\\\"bp\\\":330.43,\\\"ap\\\":330.44,\\\"bs\\\":3,\\\"as\\\":3,\\\"t\\\":\\\"1637949113455\\\",\\\"q\\\":\\\"43838492\\\",\\\"z\\\":3}\"\r\n 9) \"15\"\r\n10) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"15\\\",\\\"ax\\\":\\\"12\\\",\\\"bp\\\":330.34,\\\"ap\\\":330.37,\\\"bs\\\":2,\\\"as\\\":4,\\\"t\\\":\\\"1637949549028\\\",\\\"q\\\":\\\"45809932\\\",\\\"z\\\":3}\"\r\n11) \"10\"\r\n12) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"10\\\",\\\"ax\\\":\\\"12\\\",\\\"bp\\\":330.26,\\\"ap\\\":330.37,\\\"bs\\\":1,\\\"as\\\":2,\\\"t\\\":\\\"1637949585833\\\",\\\"q\\\":\\\"46055016\\\",\\\"z\\\":3}\"\r\n13) \"18\"\r\n14) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"18\\\",\\\"ax\\\":\\\"11\\\",\\\"bp\\\":330.15,\\\"ap\\\":330.25,\\\"bs\\\":2,\\\"as\\\":12,\\\"t\\\":\\\"1637949683953\\\",\\\"q\\\":\\\"46258667\\\",\\\"z\\\":3}\"\r\n15) \"1\"\r\n16) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"1\\\",\\\"ax\\\":\\\"17\\\",\\\"bp\\\":330.21,\\\"ap\\\":330.31,\\\"bs\\\":4,\\\"as\\\":1,\\\"t\\\":\\\"1637949583379\\\",\\\"q\\\":\\\"46033150\\\",\\\"z\\\":3}\"\r\n17) \"11\"\r\n18) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"11\\\",\\\"ax\\\":\\\"12\\\",\\\"bp\\\":329.91,\\\"ap\\\":330.2,\\\"bs\\\":4,\\\"as\\\":1,\\\"t\\\":\\\"1637949688637\\\",\\\"q\\\":\\\"46259504\\\",\\\"z\\\":3}\"\r\n19) \"7\"\r\n20) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"7\\\",\\\"ax\\\":\\\"11\\\",\\\"bp\\\":330.15,\\\"ap\\\":330.25,\\\"bs\\\":2,\\\"as\\\":12,\\\"t\\\":\\\"1637949684316\\\",\\\"q\\\":\\\"46258719\\\",\\\"z\\\":3}\"\r\n21) \"20\"\r\n22) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"20\\\",\\\"ax\\\":\\\"12\\\",\\\"bp\\\":330.11,\\\"ap\\\":330.26,\\\"bs\\\":1,\\\"as\\\":1,\\\"t\\\":\\\"1637949586232\\\",\\\"q\\\":\\\"46058248\\\",\\\"z\\\":3}\"\r\n23) \"19\"\r\n24) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"19\\\",\\\"ax\\\":\\\"11\\\",\\\"bp\\\":329.91,\\\"ap\\\":330.25,\\\"bs\\\":2,\\\"as\\\":12,\\\"t\\\":\\\"1637949676537\\\",\\\"q\\\":\\\"46258138\\\",\\\"z\\\":3}\"\r\n25) \"8\"\r\n26) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"8\\\",\\\"ax\\\":\\\"11\\\",\\\"bp\\\":330.06,\\\"ap\\\":330.25,\\\"bs\\\":1,\\\"as\\\":12,\\\"t\\\":\\\"1637949685035\\\",\\\"q\\\":\\\"46258880\\\",\\\"z\\\":3}\"\r\n27) \"17\"\r\n28) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"17\\\",\\\"ax\\\":\\\"17\\\",\\\"bp\\\":329.37,\\\"ap\\\":330.16,\\\"bs\\\":2,\\\"as\\\":2,\\\"t\\\":\\\"1637949606270\\\",\\\"q\\\":\\\"46241118\\\",\\\"z\\\":3}\"\r\n29) \"21\"\r\n30) \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"21\\\",\\\"ax\\\":\\\"12\\\",\\\"bp\\\":330.9,\\\"ap\\\":331.09,\\\"bs\\\":1,\\\"as\\\":1,\\\"t\\\":\\\"1637949581667\\\",\\\"q\\\":\\\"46012327\\\",\\\"z\\\":3}\"\r\n```\r\n\r\n\r\nThis is easlily reproducible,\r\n1. ` HMSET ALLUS_XXX 1 \"{\\\"ev\\\":\\\"Q\\\",\\\"sym\\\":\\\"XXX\\\",\\\"bx\\\":\\\"1\\\",\\\"ax\\\":\\\"20\\\",\\\"bp\\\":157.2,\\\"ap\\\":157.21,\\\"bs\\\":5,\\\"as\\\":1,\\\"t\\\":\\\"1637949207844\\\",\\\"q\\\":\\\"60303179\\\",\\\"z\\\":3}\"`\r\n2. Now try to access this using redisson `getMapCache(\"ALLUS_XXX\").readAllEntrySet()`",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3989/comments",
    "author": "ashwinreal",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-11-27T05:38:02Z",
        "body": "use the same codec for data store and reading"
      },
      {
        "user": "ashwinreal",
        "created_at": "2021-11-27T08:21:47Z",
        "body": "> use the same codec for data store and reading\r\n\r\nWhat is the codec when we add keys using redis-cli  and want to read using redisson  @mrniko ?  I tried a few at random did not work"
      },
      {
        "user": "SplotyCode",
        "created_at": "2021-11-27T09:15:05Z",
        "body": "Have you tried StringCodec?"
      },
      {
        "user": "ashwinreal",
        "created_at": "2021-11-28T16:16:26Z",
        "body": " @mrniko  @SplotyCode i have tried both\r\n` redisService.client.getMapCache(key, StringCodec.INSTANCE ).readAllEntrySet()\r\n      redisService.client.getMapCache(key, ByteArrayCodec.INSTANCE ).readAllEntrySet()\r\n`\n\n---\n\nI feel this should not be hard to do , there should be a codec already defined for this ... all I am trying to do is `HMSET test_key 1 \"123\"\r\n` \r\nand then read this using redission. Somehow I am not getting any of the codecs to work for this use case . \r\nDo I need to define a custom codec for this ? Pls suggest @mrniko @SplotyCode \n\n---\n\n@mrniko @SplotyCode I am really stuck here . Any suggestions pls ?"
      },
      {
        "user": "mrniko",
        "created_at": "2021-11-29T05:48:07Z",
        "body": "you can insert/update RMapCache entries only through its API or try RMap object"
      },
      {
        "user": "ashwinreal",
        "created_at": "2021-11-30T18:27:34Z",
        "body": "yes, this works \r\n`client.getMap(key, StringCodec.INSTANCE).readAllEntrySet`\r\nThanks @mrniko "
      },
      {
        "user": "chanhengseang3",
        "created_at": "2024-06-25T06:29:38Z",
        "body": "I got this error after added StringCodec.INSTANCE\r\n`redissonClient.getBoundedBlockingQueue(\"key\", StringCodec.INSTANCE)`\r\n```\r\ncom.esotericsoftware.kryo.KryoException: Encountered unregistered class ID: 65\r\n\tat com.esotericsoftware.kryo.util.DefaultClassResolver.readClass(DefaultClassResolver.java:159)\r\n\tat com.esotericsoftware.kryo.Kryo.readClass(Kryo.java:758)\r\n\tat com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:869)\r\n\tat org.redisson.codec.Kryo5Codec$4.decode(Kryo5Codec.java:144)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:433)\r\n\tat org.redisson.client.handler.CommandDecoder.decodeList(CommandDecoder.java:490)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:442)\r\n\tat org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:216)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:144)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:120)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:529)\r\n\tat io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:290)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:444)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:412)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:440)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:420)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\n```"
      }
    ]
  },
  {
    "number": 3925,
    "title": "Redisson client injects weird characters at the beginning of strings",
    "created_at": "2021-10-29T12:01:41Z",
    "closed_at": "2021-10-29T12:28:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3925",
    "body": "I'm using Redisson client to publish String messages on a topic, but for some reasons, the published messages always contain some weird characters at the beginning:\r\n\r\neg: when I publish the string \"{\"event\":\"notification\"}\" at the redis level I end up with this: \"\\x04>\\x18{\"event\":\"notification\"}\"\r\n\r\n1) \"pmessage\"\r\n2) \"*\"\r\n3) \"active_project_users:1\"\r\n4) \"\\x04>\\x18{\\\"event\\\":\\\"notification\\\"}\"\r\n\r\nAny idea how I can make those weird chars go away?\r\n\r\nMy java code looks like this:\r\n\r\n private void publish(String channel, String message) {       \r\n        RTopic topic = redissonClient.getTopic(channel);\r\n        topic.publish(\"{\\\"event\\\":\\\"notification\\\"}\");\r\n    }\r\nI'm using redis:3.2 & radisson-spring-boot-starter 3.16.1\r\n\r\nThanks",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3925/comments",
    "author": "ghevge",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-10-29T12:28:17Z",
        "body": "default codec is MarshallingCodec. You need to define StringCodec if you want data stored as plain text."
      }
    ]
  },
  {
    "number": 3787,
    "title": "spring cache and jackson InvalidDefinitionException",
    "created_at": "2021-08-20T08:22:15Z",
    "closed_at": "2021-08-20T08:48:08Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3787",
    "body": "ERROR o.r.client.handler.CommandDecoder - Unable to decode data. channel: [id: 0x72310cd6, L:/127.0.0.1:14072 - R:127.0.0.1/127.0.0.1:6379], reply: ReplayingDecoderByteBuf(ridx=128, widx=128), command: (HGET), params: [role, PooledUnsafeDirectByteBuf(ridx: 0, widx: 8, cap: 256)]\r\ncom.fasterxml.jackson.databind.exc.InvalidDefinitionException: Cannot construct instance of `org.springframework.security.core.authority.SimpleGrantedAuthority` (no Creators, like default constructor, exist): cannot deserialize from Object value (no delegate- or property-based Creator)\r\n at [Source: (io.netty.buffer.ByteBufInputStream); line: 1, column: 104] (through reference chain: java.util.ArrayList[0])\r\n\tat com.fasterxml.jackson.databind.exc.InvalidDefinitionException.from(InvalidDefinitionException.java:67)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.reportBadDefinition(DeserializationContext.java:1764)\r\n\tat com.fasterxml.jackson.databind.DatabindContext.reportBadDefinition(DatabindContext.java:400)\r\n\tat com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1209)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1415)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:362)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:230)\r\n\tat com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:197)\r\n\tat com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:139)\r\n\tat com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:107)\r\n\tat com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:208)\r\n\tat com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:771)\r\n\tat com.fasterxml.jackson.databind.deser.std.CollectionDeserializer._deserializeFromArray(CollectionDeserializer.java:357)\r\n\tat com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:244)\r\n\tat com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:28)\r\n\tat com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer._deserialize(AsArrayTypeDeserializer.java:120)\r\n\tat com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer.deserializeTypedFromArray(AsArrayTypeDeserializer.java:53)\r\n\tat com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromAny(AsPropertyTypeDeserializer.java:206)\r\n\tat com.fasterxml.jackson.databind.deser.std.UntypedObjectDeserializer$Vanilla.deserializeWithType(UntypedObjectDeserializer.java:771)\r\n\tat com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:74)\r\n\tat com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:322)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4593)\r\n\tat com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3585)\r\n\tat org.redisson.codec.JsonJacksonCodec$2.decode(JsonJacksonCodec.java:99)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:366)\r\n\tat org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:183)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:122)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:107)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:507)\r\n\tat io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n2021-08-20 16:02:53 [XNIO-1 task-1] ERROR me.zhengjie.config.RedisConfig - Redis occur handleCacheGetError\uff1akey -> [auth:1]\r\norg.redisson.client.RedisException: Unexpected exception while processing command\r\n\r\n\r\n\r\n\r\n\r\nI found key auth:1 is [\"java.util.ArrayList\",{\"@class\":\"org.springframework.security.core.authority.SimpleGrantedAuthority\",\"role\":\"admin\"}]].\r\n\r\nI think the problem is jackson turn this value to List<GrantedAuthority>.\r\nBut I don't know how to solve it exactly.\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3787/comments",
    "author": "EF03",
    "comments": [
      {
        "user": "EF03",
        "created_at": "2021-08-20T08:24:29Z",
        "body": "```\r\n@Bean\r\npublic CacheManager cacheManager(RedissonClient redissonClient) {\r\n    List<RedissonProperties.CacheGroup> cacheGroup = redissonProperties.getCacheGroup();\r\n    Map<String, CacheConfig> config = new HashMap<>(16);\r\n    for (RedissonProperties.CacheGroup group : cacheGroup) {\r\n        CacheConfig cacheConfig = new CacheConfig(group.getTtl(), group.getMaxIdleTime());\r\n        cacheConfig.setMaxSize(group.getMaxSize());\r\n        config.put(group.getGroupId(), cacheConfig);\r\n    }\r\n    return new RedissonSpringCacheManager(redissonClient, config, JsonJacksonCodec.INSTANCE);\r\n}\r\n```\r\n"
      },
      {
        "user": "mrniko",
        "created_at": "2021-08-20T08:28:10Z",
        "body": "try to use `MarshallingCodec` or `Kryo5Codec`"
      },
      {
        "user": "EF03",
        "created_at": "2021-08-20T08:48:08Z",
        "body": "I try MarshallingCodec it cloud work. thanks ^^"
      }
    ]
  },
  {
    "number": 3777,
    "title": "Topic listener removal",
    "created_at": "2021-08-14T20:32:10Z",
    "closed_at": "2021-08-15T05:17:18Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3777",
    "body": "Is it necessary to explicitly remove a Topic listener before shutdown, or does shutdown remove it anyway?\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3777/comments",
    "author": "asarkar",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-08-15T04:53:12Z",
        "body": "No, it's not necessary."
      },
      {
        "user": "asarkar",
        "created_at": "2021-08-15T05:17:18Z",
        "body": "@mrniko Rephrasing as \u201cshutdown removes all local listeners, no need to do it explicitly\u201d, closing this ticket. Thank you."
      },
      {
        "user": "mrniko",
        "created_at": "2021-08-15T06:00:25Z",
        "body": "it doesn't remove listeners, just shutdown network connection to Redis."
      },
      {
        "user": "asarkar",
        "created_at": "2021-08-15T20:49:11Z",
        "body": "I\u2019m confused, isn\u2019t that the same thing? Unless the server keeps a count of the listeners.\n\n---\n\nFor the record, I've verified that the count is local to the JVM."
      }
    ]
  },
  {
    "number": 3754,
    "title": "Is there any guideline for upgrading the middle value of a version",
    "created_at": "2021-08-02T05:14:11Z",
    "closed_at": "2021-08-05T07:43:14Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3754",
    "body": "Will it be an incompatible version when I upgrade from 3.11.x to 3.15.x?\r\nIs there any reason or guideline for the version value?",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3754/comments",
    "author": "ieiayaobb",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-08-02T08:28:20Z",
        "body": "There is no such guideline. No API breaking changes were made since 3.11.0 version."
      },
      {
        "user": "ieiayaobb",
        "created_at": "2021-08-05T07:43:14Z",
        "body": "I see, thanks.\r\nClose this PR"
      }
    ]
  },
  {
    "number": 3737,
    "title": "data consistency",
    "created_at": "2021-07-22T02:24:09Z",
    "closed_at": "2021-07-27T04:56:25Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3737",
    "body": "\u5206\u5e03\u5f0f\u9501\uff0c\u4ee5redlock\u4e3a\u4f8b\r\n\u5ba2\u6237\u7aef\u4e24\u53f0\uff1a\u5ba2\u6237\u7aefa\uff0c\u5ba2\u6237\u7aefb\r\n\u5ba2\u6237\u7aef\u6267\u884c\u79d2\u6740\u64cd\u4f5c\uff0c\u76f4\u63a5\u64cd\u4f5credis\uff0c\r\n1\u3001\u9996\u5148\u5ba2\u6237\u7aefa\uff0c\u5ba2\u6237\u7aefb\u540c\u65f6\u62a2\u9501\uff0c\r\n2\u3001\u6700\u7ec8\u5ba2\u6237\u7aefa\u83b7\u53d6\u9501\uff0c\u7136\u540e\u6267\u884c\u4e1a\u52a1\u5904\u7406\uff08\u4e0d\u9700\u8981\u7f51\u7edc\uff09\r\n3\u3001\u8fd9\u65f6\u5ba2\u6237\u7aefa \u7f51\u7edc\u901a\u4fe1\u6545\u969c\uff0c\u81f4\u4f7f\u5ba2\u6237\u7aefb\u83b7\u53d6\u5230\u9501\u4e86\uff0c\u5ba2\u6237\u7aefb\u6b63\u5e38\u64cd\u4f5c\uff0c\u4fee\u6539\u72b6\u6001\u6570\u636e\uff08redis \u6570\u636e\uff09\r\n4\u3001\u4e4b\u540e\u63a5\u7740\u5ba2\u6237\u7aefa\u7f51\u7edc\u6b63\u5e38\u4e86\uff0c\u4e5f\u76f4\u63a5\u4fee\u6539\u72b6\u6001\u6570\u636e\uff0c\uff08\u4fee\u6b63\u72b6\u6001\u5728lock \u4e4b\u540e\uff0c\u4f46\u662f\u663e\u7136\u6b64\u65f6\u5ba2\u6237\u7aefa\u5904\u4e8e\u65e0\u9501\u72b6\u6001\uff09\r\n\r\n\u8fd9\u6837\u6570\u636e\u4e00\u81f4\u6027\u4e0d\u5c31\u6ca1\u6709\u4fdd\u8bc1\u4e86\u5417\uff1f\r\n\r\n1\u3001a.lock\r\n2\u3001\u4e1a\u52a1\u903b\u8f91\r\n3\u3001\u4fee\u6b63\u72b6\u6001\r\n4\u3001a.unlock\r\n\r\n\u8d70\u7684\u7b2c\u4e8c\u6b65\uff0c\u7b2c\u4e09\u6b65\u5ba2\u6237\u7aef\u5904\u4e8e\u65e0\u9501\u72b6\u6001\u7684\uff0c\r\n\u4e00\u79cd\u60f3\u6cd51\u3001\u540e\u53f0watchdog \u7ebf\u7a0b\uff0c\u68c0\u6d4b\u5230\u8d85\u65f6\u540e\u963b\u585e\u4e1a\u52a1\u7ebf\u7a0b \uff08\u4f46\u662f\u597d\u50cf\u6ca1\u627e\u5230\u963b\u585e\u975e\u5f53\u524d\u7ebf\u7a0b\u7684api)\r\n\u53e6\u4e00\u79cd\u60f3\u6cd52\u3001\u5728unlock \u65f6\uff0c\u5047\u5982redis \u5f53\u524d\u6301\u9501\u7ebf\u7a0b\u975e\u81ea\u5df1\u65f6\uff0c\u629b\u5f02\u5e38\uff08\u8c8c\u4f3c\u662f\u8fd9\u4e48\u5904\u7406\u7684\uff0c\u4e0d\u8fc7\uff0c\u8fd9\u6837\u5904\u7406\u7684\u8bdd\uff0c\u90a3\u4e0d\u662f\u6b63\u786e\u64cd\u4f5c\r\n\u5e94\u5f53\u6355\u83b7unlock \u4e0b\u7684\u5f02\u5e38\uff0c\u7136\u540e\u5bf9\u4fee\u6539\u72b6\u6001\u7684\u64cd\u4f5c\u505a\u8865\u507f\u4e86\uff0c\u4e5f\u597d\u50cf\u4e0d\u592a\u5bf9\uff09\u3002",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3737/comments",
    "author": "TangXianJun1",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-07-23T05:59:16Z",
        "body": "you need to define big enough `leaseTimeout` value during lock acquisition. So Redis state can survive absence of client during this period of time."
      },
      {
        "user": "TangXianJun1",
        "created_at": "2021-07-30T03:20:10Z",
        "body": "define big enough leaseTimeout can solves most situations\uff0coptimistic locking can be used in extreme cases.\r\nhave studeied ,This is what happens with distributed locks today\r\nfinally thanks for your comments."
      }
    ]
  },
  {
    "number": 3684,
    "title": "Connecting to AWS Elasticache cluster using cluster endpoint",
    "created_at": "2021-06-25T15:02:17Z",
    "closed_at": "2021-06-25T18:05:31Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3684",
    "body": "Hello,\r\nAWS EC exposes 2 ways of connecting to multi-node cluster.\r\nIt gives us a cluster-endpoint AND it also gives us endpoints for each node.\r\nNow, in redisson I see that there's a cluster connection config which requires each of the node endpoint address alongwith replicase i think.\r\nAnd then there's singleServerConfig.\r\n\r\nI was wondering what's the best way to handle this? If I use single server config with cluster endpoint, will it be okay?\r\n\r\nOr I always need to use cluster connection config with all node endpoints registered.",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3684/comments",
    "author": "mayurgoenka",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-06-25T15:17:29Z",
        "body": "you can use endpoint with AWS EC"
      },
      {
        "user": "mayurgoenka",
        "created_at": "2021-06-25T18:05:31Z",
        "body": "thanks @mrniko for confirmation."
      }
    ]
  },
  {
    "number": 3654,
    "title": "Is order of Operations in a RBatch guaranteed?",
    "created_at": "2021-06-11T06:09:58Z",
    "closed_at": "2021-06-14T07:58:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3654",
    "body": "Sorry if this is obvious, but i did not find any documentstion about this:\r\n\r\nIf i am using **RBatch** and create let's say a Bucket from it, and call setAsync on the bucket 100 times before executing the batch, is the order of the operations in the batch guaranteed to be the order in which\r\n```\r\nsetAsync(Object)\r\n```\r\nhas been called?\r\n\r\nIn other words, is there any way i could end up with anything but the last value i set to the bucket after the RBatch is executed? For instance if the Marshalling of the 99th value took some time?\r\n\r\nBucket is just an example here, i am also using RMaps the same way.",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3654/comments",
    "author": "uweschaefer",
    "comments": [
      {
        "user": "uweschaefer",
        "created_at": "2021-06-27T18:51:10Z",
        "body": "Thanks for answering, @mrniko \r\n\r\nis there an example somewhere? i fail to understand how RLock helps me in this case.\r\nOr did you refer to RedissonFairLock ?\r\n\r\nthx\r\n\r\nPS: One important thing i realized i failed to mention:\r\n\r\nall setAsync(Object) calls **come from the same Thread**.\r\njust like `stringList.stream().forEach(myStringBucket::setAsync);`"
      },
      {
        "user": "mrniko",
        "created_at": "2021-06-29T07:46:43Z",
        "body": "In batch list of operations is always ordered. But RBatch object isn't thread-safe."
      },
      {
        "user": "uweschaefer",
        "created_at": "2021-06-29T09:15:21Z",
        "body": "Thanks, this is very good news."
      }
    ]
  },
  {
    "number": 3626,
    "title": "Will RLOS indexed based querying work in cluster enabled Redis?",
    "created_at": "2021-05-28T05:46:43Z",
    "closed_at": "2021-05-28T05:49:18Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3626",
    "body": "When we use cluster enabled Redis like AWS EC, it's possible that objects gets stored on different shards. Will the indexed based querying still work here?",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3626/comments",
    "author": "mayurgoenka",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-05-28T05:49:13Z",
        "body": "Sharded index supported only in PRO version."
      },
      {
        "user": "mayurgoenka",
        "created_at": "2021-05-28T05:51:10Z",
        "body": "I really appreciate the quick turnaround. You are doing a great job @mrniko. Thanks a lot!"
      },
      {
        "user": "mrniko",
        "created_at": "2021-05-28T06:02:53Z",
        "body": "@mayurgoenka \r\n\r\nThank you!"
      },
      {
        "user": "mayurgoenka",
        "created_at": "2021-06-02T13:15:33Z",
        "body": "Hi @mrniko , \r\nI see that the index is created in the following fashion:\r\n`\"redisson_live_object_index:{com.org.application.MyLiveObject}:index_field:<some_hash>\"`\r\n\r\nI see that we are using hash tag : `{com.org.application.MyLiveObject}` for storing all indices belonging to same class inside same keyslot.\r\n\r\nIn my use case, m trying to store billions of objects of the same class MyLiveObject and there are multiple indices as well. It's obvious that this won't fit in the same keyslot and will need sharding.\r\n\r\nYour comment, \"Sharded index supported only in PRO version.\", does this mean that the index itself will also get sharded across nodes and above use case will still work in PRO version? Same hashtag `{com.org.application.MyLiveObject}` won't be used in PRO version for indices?\r\n\r\nSorry for the repeated query, but just want to make sure before I finalise my design.\r\n\r\nHope my query is clear."
      },
      {
        "user": "mrniko",
        "created_at": "2021-06-02T13:30:41Z",
        "body": "Hi @mayurgoenka, \r\n\r\n> does this mean that the index itself will also get sharded across nodes and above use case will still work in PRO version\r\n\r\nIn this case name will be different to distribute evenly across all Redis master nodes.\r\n\r\n> Same hashtag {com.org.application.MyLiveObject} won't be used in PRO version for indices?\r\n\r\nThis name still will be present in key, but without braces.\r\n"
      },
      {
        "user": "mayurgoenka",
        "created_at": "2021-06-02T13:42:13Z",
        "body": "Thank you @mrniko , this means that I can safely use RLOS for huge data in redis clustered mode.\r\n\r\n\r\nAnother query is, are there any plans for supporting batch operations and transactions with RLOS objects? "
      },
      {
        "user": "mrniko",
        "created_at": "2021-06-02T14:03:16Z",
        "body": "What kind of batch / transaction operations over RLOS do you need? Could you describe some use cases?"
      },
      {
        "user": "mayurgoenka",
        "created_at": "2021-06-02T14:45:49Z",
        "body": "Suppose I want to merge 1000s of Live objects into redis cache, like a batch update OR batch insert. I see that we do have rlos.persist(list) but I not sure if its using pipelining inside or not? Also, rlos.merge(list) is what I was primarily looking for. \r\nThese operations are mainly required for warming up the cache in my use case.\r\n\r\n\r\nTransactions could be required when I want to update 2 different Live objects together or not do them at all. Live objects here can be of same class or different classes.\r\nI need this in my use case because there's a parent-child type of relationship in my application, where if I delete the parent object, child object also needs to get deleted."
      },
      {
        "user": "mrniko",
        "created_at": "2021-06-08T10:27:07Z",
        "body": "`org.redisson.api.RLiveObjectService#persist(T...)` method stores object in a batch. `merge()` method for multiple object isn't implemented yet.\r\n\r\nAs for transactions, I can recommend you to use RLock object."
      },
      {
        "user": "mayurgoenka",
        "created_at": "2021-06-09T05:58:26Z",
        "body": "yes, thank you for the response @mrniko , appreciate it."
      }
    ]
  },
  {
    "number": 3569,
    "title": "Simple key value read and write example",
    "created_at": "2021-04-23T06:54:37Z",
    "closed_at": "2021-04-27T05:59:20Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3569",
    "body": "Hi Team,\r\n            Can you share a sample on how to read/write a simple key value  using RedissonReactiveClient\r\n\r\nkey: String\r\nvalue:  java object\r\n\r\nReactive way of writing and reading will be great help.",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3569/comments",
    "author": "ShanmugamC",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-04-23T12:45:46Z",
        "body": "Use `RedissonReactiveClient.getBucket()` method."
      },
      {
        "user": "ShanmugamC",
        "created_at": "2021-04-23T15:44:50Z",
        "body": "@mrniko Thanks a lot for your quick help !"
      }
    ]
  },
  {
    "number": 3546,
    "title": "Object not added in RSet",
    "created_at": "2021-04-12T08:04:23Z",
    "closed_at": "2021-04-13T05:43:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3546",
    "body": "In the below code, we are facing intermittent issues where` System.out.println(\"Your Ids: \"+ids1)` is not printed when we add something and RedissionSet reference doesn't contain anything even after adding objects to it.\r\n```\r\nfinal Set<String> homeIds = platformCache.getSet(Home.fetchProductCacheKey(productId));\r\n\r\nList<String> getIds = callToDb.getProductId(productId);\r\n\r\nfor(String ids : getIds) {\r\nhomeIds.add(ids);\r\n}\r\n\r\nfor(String ids1: homeIds) { // This for loop is not run since homeids were empty sometimes.\r\nSystem.out.println(\"Your Ids: \"+ids1);\r\n}\r\n\r\n```\r\n\r\nAre we doing anything wrong? Any help will be appreciated.",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3546/comments",
    "author": "vipul1231",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-04-12T08:53:19Z",
        "body": "Try ReadMode.MASTER setting"
      },
      {
        "user": "vipul1231",
        "created_at": "2021-04-12T10:10:54Z",
        "body": "I believe this setting will move reading data to master node ?. This will increase traffic to my master node. Please correct me if I am wrong."
      },
      {
        "user": "mrniko",
        "created_at": "2021-04-12T12:43:20Z",
        "body": "This issue happens due to replication lag between slave/master nodes."
      },
      {
        "user": "vipul1231",
        "created_at": "2021-04-13T05:43:13Z",
        "body": "Ok thanks. Closing this issue."
      }
    ]
  },
  {
    "number": 3544,
    "title": "Why ExpirationEntry use LinkedHashMap to save threadId",
    "created_at": "2021-04-09T09:28:20Z",
    "closed_at": "2021-04-13T02:50:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3544",
    "body": "Reddison watchDog strategy use timerTask to increase key expiration time while set the lock success\r\n\r\n    private void renewExpiration() {\r\n        ExpirationEntry ee = EXPIRATION_RENEWAL_MAP.get(getEntryName());\r\n        if (ee == null) {\r\n            return;\r\n        }\r\n        \r\n        Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() {\r\n            @Override\r\n            public void run(Timeout timeout) throws Exception {\r\n                ExpirationEntry ent = EXPIRATION_RENEWAL_MAP.get(getEntryName());\r\n                if (ent == null) {\r\n                    return;\r\n                }\r\n                Long threadId = ent.getFirstThreadId();\r\n                if (threadId == null) {\r\n                    return;\r\n                }\r\n                \r\n                RFuture<Boolean> future = renewExpirationAsync(threadId);\r\n                ......\r\n       }\r\n   }\r\n\r\n  First use **entryName** to get ExpirationEntry object. For the same entryName, other threads can't get the key because locked(ps: same thread can get and counter++)\uff0cso why use LinkedHashMap to save thread if there only have one thread?\r\n\r\n`public static class ExpirationEntry {\r\n\r\n        private final Map<Long, Integer> threadIds = new LinkedHashMap<>();\r\n        private volatile Timeout timeout;\r\n\r\n        public ExpirationEntry() {\r\n            super();\r\n        }\r\n\r\n        public synchronized void addThreadId(long threadId) {\r\n            Integer counter = threadIds.get(threadId);\r\n            if (counter == null) {\r\n                counter = 1;\r\n            } else {\r\n                counter++;\r\n            }\r\n            threadIds.put(threadId, counter);\r\n        }\r\n}`",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3544/comments",
    "author": "yukerui",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-04-12T13:14:20Z",
        "body": "in case of readwrite lock there are might be multiple read locks."
      },
      {
        "user": "yukerui",
        "created_at": "2021-04-13T02:50:36Z",
        "body": "> in case of readwrite lock there are might be multiple read locks.\r\n\r\nUnderstood, thank you for your reply"
      }
    ]
  },
  {
    "number": 3493,
    "title": "Transaction in Redis Live Object Service",
    "created_at": "2021-03-16T21:14:11Z",
    "closed_at": "2021-03-18T06:56:07Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3493",
    "body": "Hi,\r\n\r\nIs it possible to perform transaction on Redis Live Object?\r\nI want write a new instance of MyClass - only if new instance is newer than previous one. \r\nI need method similar to 'merge' in RMap. \r\n\r\n    @REntity\r\n    public class MyClass {\r\n\r\n        @RId\r\n        private String key;\r\n\r\n        @RIndex\r\n        public Date createDate;\r\n\r\n        @RIndex\r\n        public String externalValue;\r\n     }\r\n\r\nSo I need to compare dates of old and new objects and then save new object only if it newer. It has be executed in one transaction. In other thread someone can update fields in this object.",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3493/comments",
    "author": "bbartekb",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-03-17T08:46:35Z",
        "body": "Wrap this function with RLock object with name based on object id."
      },
      {
        "user": "bbartekb",
        "created_at": "2021-03-17T21:33:02Z",
        "body": "Thank you for your response!\r\n\r\nIt works for me with tryLock()\r\n\r\n    public void updateLiveObjectEntry(MyClass myObject) {\r\n        RLiveObjectService rLiveObjectService = getRedissonConnection().getClient().getLiveObjectService();\r\n        RLock lock = getRedissonConnection().getClient().getLock(myObject.getKey());\r\n\r\n        try {\r\n            lock.tryLock(10, TimeUnit.SECONDS);\r\n            if (myObject.getCreateDate().after(rLiveObjectService.get(MyClass.class, myObject.getKey()).getCreateDate())) {\r\n                rLiveObjectService.merge(myObject);\r\n            }\r\n        } catch (InterruptedException e) {\r\n        } finally {\r\n            lock.unlock();\r\n        }\r\n    }\r\n    \r\nIs my solution correct? \r\nI think this lock is not connected with my LiveObject, so myObject entry is not locked. It will be work if in all usage I use method updateLiveObjectEntry().\r\n    "
      },
      {
        "user": "mrniko",
        "created_at": "2021-03-18T05:31:12Z",
        "body": "you can use follow lock name: `String lockName = MyClass.class.getName() + \":\" + myObject.getKey()`. If you have any doubts about the key uniqueness with different Object classes."
      }
    ]
  },
  {
    "number": 3398,
    "title": "org.redisson.api.RAtomicLong#expireAt(long)  Cause the value to be deleted  ",
    "created_at": "2021-02-03T07:55:21Z",
    "closed_at": "2021-02-03T07:59:08Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3398",
    "body": "Redisson:3.15.0\r\nredis:4.0.9\r\n\r\norg.redisson.api.RAtomicLong#expireAt(long)\r\nCannot find the key of aKey after execution\r\n\r\nWhy is this ?\r\n\r\njava code\r\n```\r\n        Config config = new Config();\r\n        config.useSingleServer()\r\n                .setAddress(\"redis://127.0.0.1:6379\")\r\n                .setDatabase(0);\r\n        RedissonClient redissonClient = Redisson.create(config);\r\n\r\n        String aKey = \"aKey\";\r\n        RAtomicLong aAtomic = redissonClient.getAtomicLong(aKey);\r\n        long aValue0 = aAtomic.get();\r\n        LOG.info(\"aKey-value0[{}]\", aValue0);\r\n\r\n        aAtomic.incrementAndGet();\r\n        long aValue1 = aAtomic.get();\r\n        LOG.info(\"aKey-value1[{}]\", aValue1);\r\n        aAtomic.expireAt(1000 * 60 * 60);\r\n\r\n        long aValue2 = aAtomic.get();\r\n        LOG.info(\"aKey-value2[{}]\", aValue2);\r\n\r\n        LOG.info(\"---------------------------------------------------------\");\r\n\r\n        String bKey = \"bKey\";\r\n        RAtomicLong bAtomic = redissonClient.getAtomicLong(bKey);\r\n        long bValue0 = bAtomic.get();\r\n        LOG.info(\"bKey-value0[{}]\", bValue0);\r\n\r\n        bAtomic.incrementAndGet();\r\n        bAtomic.expire(10, TimeUnit.HOURS);\r\n\r\n        long bValue1 = bAtomic.get();\r\n        LOG.info(\"bKey-value1[{}]\", bValue1);\r\n\r\n        LOG.info(\"---------------------------------------------------------\");\r\n\r\n        String cKey = \"cKey\";\r\n        RAtomicLong cAtomic = redissonClient.getAtomicLong(cKey);\r\n        long cValue0 = cAtomic.get();\r\n        LOG.info(\"cKey-value0[{}]\", cValue0);\r\n\r\n        cAtomic.incrementAndGet();\r\n\r\n        long cValue1 = cAtomic.get();\r\n        LOG.info(\"cKey-value1[{}]\", cValue1);\r\n\r\n        redissonClient.shutdown();\r\n```\r\nlog...\r\n```\r\n15:45:35.913 [main] INFO org.redisson.Version - Redisson 3.15.0\r\n15:45:36.804 [redisson-netty-2-17] INFO org.redisson.connection.pool.MasterPubSubConnectionPool - 1 connections initialized for /127.0.0.1:6379\r\n15:45:36.817 [redisson-netty-2-17] INFO org.redisson.connection.pool.MasterConnectionPool - 24 connections initialized for /127.0.0.1:6379\r\n15:45:36.877 [main] INFO RedissonClient - aKey-value0[0]\r\n15:45:36.880 [main] INFO RedissonClient - aKey-value1[1]\r\n15:45:36.881 [main] INFO RedissonClient - aKey-value2[0]\r\n15:45:36.881 [main] INFO RedissonClient - ---------------------------------------------------------\r\n15:45:36.882 [main] INFO RedissonClient - bKey-value0[0]\r\n15:45:36.886 [main] INFO RedissonClient - bKey-value1[1]\r\n15:45:36.887 [main] INFO RedissonClient - ---------------------------------------------------------\r\n15:45:36.887 [main] INFO RedissonClient - cKey-value0[0]\r\n15:45:36.889 [main] INFO RedissonClient - cKey-value1[1]\r\n```\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3398/comments",
    "author": "NoSugarIce",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-02-03T07:59:08Z",
        "body": "Because `expireAt()` method accepts date in milliseconds."
      },
      {
        "user": "NoSugarIce",
        "created_at": "2021-02-03T08:10:28Z",
        "body": "> Because `expireAt()` method accepts date in milliseconds.\r\n\r\n@mrniko Thanks, I realized the problem when I saw the code comments a few minutes after issuing the question ."
      }
    ]
  },
  {
    "number": 3390,
    "title": "RBatch response order with cluster env ?",
    "created_at": "2021-01-28T16:31:38Z",
    "closed_at": "2021-02-05T06:19:16Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3390",
    "body": "> In cluster environment batch executed in map\\reduce way. It aggregates commands for each node and sends them simultaneously, then result got from each node added to common result list.\r\n\r\n```\r\n\r\n    /**\r\n     * Executes all operations accumulated during async methods invocations.\r\n     * <p>\r\n     * If cluster configuration used then operations are grouped by slot ids\r\n     * and may be executed on different servers. Thus command execution order could be changed\r\n     *\r\n     * @return List with result object for each command\r\n     * @throws RedisException in case of any error\r\n     *\r\n     */\r\n    BatchResult<?> execute() throws RedisException;\r\n```\r\n\r\nRead above tips, I was not sure about responses order for origin commands.\r\nCould you help me make sure about this?\r\n\r\n1.When commands send group by slots, but I want know responses order is right with original commands?\r\n\r\n\r\nthx~ ",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3390/comments",
    "author": "waylink",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-01-29T07:03:15Z",
        "body": "You'll always get correct response, but in cluster environment result in BatchResult can have different order."
      },
      {
        "user": "waylink",
        "created_at": "2021-01-29T07:12:57Z",
        "body": "> You'll always get correct response, but in cluster environment result in BatchResult can have different order.\r\n\r\n~~in cluster env result in batchResult have different order.~~\r\n\r\nHow to understand ?  in cluster env"
      },
      {
        "user": "mrniko",
        "created_at": "2021-01-31T09:37:01Z",
        "body": "result has different order since single request spliced into different requests and executed concurrently on different Redis nodes. If keys of such commands don't belong to the same master node."
      },
      {
        "user": "waylink",
        "created_at": "2021-01-31T10:13:27Z",
        "body": "> result has different order since single request spliced into different requests and executed concurrently on different Redis nodes. If keys of such commands don't belong to the same master node.\r\n\r\nall right.\r\n\r\nInvoker always get correct response in cluster env.\r\n\r\nOnly warning : BatchResult[] has different order for execute in cluster env."
      },
      {
        "user": "mrniko",
        "created_at": "2021-02-05T06:19:14Z",
        "body": "It's better to attach handler to each command executed in RBatch rather than use result list:\r\n\r\n```java\r\n\t\tRBatch batch = client.createBatch(batchOptions);\r\n\t\tfor (int i = 0; i < 10; i++) {\r\n\t\t\tString key = \"\" + i;\r\n                        RFuture<Object> t = batch.getBucket(key).getAsync();\r\n                        t.whenComplete((res, ex) -> {\r\n                \r\n                       });\r\n\t\t}\r\n\t\tbatch.execute();\r\n```"
      }
    ]
  },
  {
    "number": 3374,
    "title": "time_to_live and max_idle_time doesn't work in redisson as 2 level cache in hibernate",
    "created_at": "2021-01-22T10:31:32Z",
    "closed_at": "2021-01-23T05:12:18Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3374",
    "body": "Hello everybody,\r\nI try to use Redisson  as second level cache in my jpa spring boot application it works fine i see that it cache entities in redis it just i need to set a time to live and time to idle on cache entries i use this configuration below but it doesn't work:\r\n\r\n`spring.jpa.properties.hibernate.cache.use_second_level_cache=true\r\nspring.cache.type=redis\r\n\r\nhibernate.cache.redisson.entity.expiration.time_to_live=1000\r\nhibernate.cache.redisson.entity.expiration.max_idle_time=1000\r\nhibernate.cache.redisson.collection.expiration.time_to_live=1000\r\nhibernate.cache.redisson.collection.expiration.max_idle_time=1000\r\n\r\nspring.jpa.properties.hibernate.cache.region.factory_class=org.redisson.hibernate.RedissonRegionFactory\r\nspring.jpa.properties.hibernate.cache.redisson.config=redisson/redisson-dev.yaml\r\nspring.jpa.properties.hibernate.cache.redisson.fallback=true\r\nspring.jpa.properties.javax.persistence.sharedCache.mode=ENABLE_SELECTIVE\r\n\r\nserver.port=8888\r\nspring.datasource.url=jdbc:h2:mem:testdb\r\nspring.datasource.driverClassName=org.h2.Driver\r\nspring.datasource.username=sa\r\nspring.datasource.password=\r\n\r\nspring.jpa.database-plateform=org.hibernate.dialect.H2Dialect\r\nspring.jpa.hibernate.ddl-auto=update\r\nspring.h2.console.enabled=true\r\nlogging.level.org.hibernate.SQL=DEBUG\r\nlogging.level.org.hibernate.type=TRACE\r\n`\r\n\r\ni use  redisson-hibernate-53  as dependancy\r\n\r\nAny help on this will help ,thank you.\r\n  \r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3374/comments",
    "author": "yeagerrrr",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2021-01-22T12:07:55Z",
        "body": "I think spring config file doesn't pickup custom hibernate settings used by Redisson. Try to define them in hibernate config xml file"
      },
      {
        "user": "yeagerrrr",
        "created_at": "2021-01-22T12:32:22Z",
        "body": "it works !!!!!\r\ni just use : \r\n\r\nspring.jpa.properties.hibernate.cache.redisson.entity.expiration.time_to_live=1000\r\nspring.jpa.properties.hibernate.cache.redisson.entity.expiration.max_idle_time=1000\r\nspring.jpa.properties.hibernate.cache.redisson.collection.expiration.time_to_live=1000\r\nspring.jpa.properties.hibernate.cache.redisson.collection.expiration.max_idle_time=1000\r\n\r\nintead of : \r\n\r\nhibernate.cache.redisson.entity.expiration.time_to_live=1000\r\nhibernate.cache.redisson.entity.expiration.max_idle_time=1000\r\nhibernate.cache.redisson.collection.expiration.time_to_live=1000\r\nhibernate.cache.redisson.collection.expiration.max_idle_time=1000\r\n\r\n@mrniko thank you very much for your answer \ud83d\udc4d "
      },
      {
        "user": "mrniko",
        "created_at": "2021-01-23T05:12:18Z",
        "body": "I'm closing this"
      }
    ]
  },
  {
    "number": 3187,
    "title": "Behavior of locks vs conditions like network partition",
    "created_at": "2020-11-04T14:00:54Z",
    "closed_at": "2020-11-05T11:44:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3187",
    "body": "Hello everyone,\r\n\r\nCouldn't find my answer in docs or by looking briefly at the implementation, so posting the question here.\r\n\r\nLet's assume a system, where X instances of the same application are working concurrently on processing some data. In general, the instances can work concurrently, but some specific data items must not be processed at the same time by more than one instance, as this would produce race condition.\r\n\r\nTo synchronize application instances and avoid race conditions, we've set up a Redis instance, and we use Redisson's locking mechanism to achieve exclusive execution. In general, the workflow for an instance looks like this:\r\n(take a lock A) -> (process data) -> (release lock A)\r\n\r\nThen, obviously, the other instances, that want to process the conflicting data item, need to wait for lock A to be released. Processing an item can take anywhere between several seconds and several days. so a lock might be held for a long time (and we use this auto-renewal feature for locks to have the lock prolonged as needed behind the scenes by Redisson).\r\n\r\nMy question is - what happens if an instance, that is currently holding the lock, loses connectivity to Redis (and therefore the lock times out and is then taken by another instance), and then after some time it regains the connectivity? Will it finish processing the data without holding the lock, and then fail on releasing the lock? Or maybe something else would happen?\r\n\r\nI'd really appreciate your feedback on this.\r\n\r\nBest Regards,\r\nPawe\u0142",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3187/comments",
    "author": "pnaw94",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-11-04T15:44:25Z",
        "body": "> Will it finish processing the data without holding the lock, and then fail on releasing the lock?\r\n\r\nIt will finish without holding lock if connectionWatchdogTimeout occured by that moment."
      },
      {
        "user": "pnaw94",
        "created_at": "2020-11-05T11:44:58Z",
        "body": "@mrniko thanks for the answer! I think that's all I need at that point."
      }
    ]
  },
  {
    "number": 3108,
    "title": "RMap's values(pattern) doesn't seem to work on a simple test",
    "created_at": "2020-10-07T13:18:25Z",
    "closed_at": "2020-11-11T08:12:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/3108",
    "body": "The following simple test doesn't seem to work:\r\n```@Test\r\n    public void test() {\r\n\r\n        String mapName = UUID.randomUUID().toString();\r\n        RMap<String, String> map = redissonClient.getMap(mapName, JsonJacksonCodec.INSTANCE);\r\n\r\n        try {\r\n            map.put(\"prefix_1_1_\", \"1\");\r\n            map.put(\"prefix_1_2_\", \"2\");\r\n            map.put(\"prefix_2_3_\", \"3\");\r\n            map.put(\"prefix_2_4_\", \"4\");\r\n\r\n            Collection<String> entries = map.values(\"prefix*\");\r\n\r\n            assertThat(entries).hasSize(4);\r\n        } finally {\r\n            redissonClient.getMap(mapName).delete();\r\n        }\r\n    }\r\n```\r\nVersion of redisson is 3.13.4\r\nI'm pretty sure I'm missing something here so didn't post it as a bug",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/3108/comments",
    "author": "peterlitvak",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-10-07T14:33:27Z",
        "body": "You need to use StringCodec for map keys."
      },
      {
        "user": "peterlitvak",
        "created_at": "2020-10-07T14:42:31Z",
        "body": "Does it mean I need to create my own codec with JsonJacksoCodec for the values (since I need values to be JSON encoded objects) and StringCodec for the keys?"
      },
      {
        "user": "mrniko",
        "created_at": "2020-10-07T14:43:39Z",
        "body": "You can use CompositeCodec to use StringCodec for keys and JsonJacksonCodec for values"
      },
      {
        "user": "peterlitvak",
        "created_at": "2020-10-07T14:44:19Z",
        "body": "Thank you!"
      }
    ]
  },
  {
    "number": 2897,
    "title": "Strange characters on value when read data in other language",
    "created_at": "2020-07-06T18:45:50Z",
    "closed_at": "2020-07-07T11:43:46Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2897",
    "body": "Hey there!\r\n\r\nI was wondering if it's possible to perform a simple operation like we do on Redis StackExchange (c#) client:\r\n\r\n```\r\nIDatabase db = redis.GetDatabase();\r\nstring value = \"abcdefg\";\r\nvar expires = 1000;\r\ndb.StringSet(\"mykey\", value, expires);\r\n...\r\nstring value = db.StringGet(\"mykey\");\r\nConsole.WriteLine(value); // writes: \"abcdefg\r\n```\r\n\r\nRight now I'm using a Map but I would like to make it simple as this example on C#. \r\n\r\n```\r\n    override fun put(collection: String, key: String, value: String, expiresInSeconds: Long) {\r\n        logger.info(\"Storing key $key into collection $collection\")\r\n        val cacheMap = getMapCache(collection)\r\n\r\n        cacheMap.put(key, value, 3600, TimeUnit.SECONDS)\r\n    }\r\n\r\n    private fun getMapCache(collection: String) = redissonClient.getMapCache<String, String>(\"any\", StringCodec())\r\n```\r\n\r\nWhen I try to retrieve values fro other clients like C# or Python, I got some strange characters on value like `????????\ufffd\u0003??????myvalue`.\r\n\r\nIs there any option to clear/remove those characters on Redisson and store it as plain string?\r\n\r\nIs there any option to store it simple as we do in C#?",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2897/comments",
    "author": "daviddelucca",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-07-07T04:37:33Z",
        "body": "Here is how you can do the same with Redisson:\r\n\r\n```java\r\nRBucket b = redisson.getBucket(\"mykey\", StringCodec.INSTANCE);\r\nb.set(\"value\", 1, TimeUnit.SECONDS);\r\n\r\nb.get(); // = \"value\"\r\n```\r\n\r\n> When I try to retrieve values fro other clients like C# or Python, I got some strange characters on value like ????????\ufffd\ufffd??????myvalue.\r\n\r\nBecause default Redisson codec is `MarshallingCodec`"
      },
      {
        "user": "daviddelucca",
        "created_at": "2020-07-07T09:12:38Z",
        "body": "Is possible to remove those characters or create a custom codec?\r\n\r\n"
      },
      {
        "user": "mrniko",
        "created_at": "2020-07-07T11:20:56Z",
        "body": "You can use StringCodec instead"
      },
      {
        "user": "daviddelucca",
        "created_at": "2020-07-07T11:43:54Z",
        "body": "Thank you very much!"
      }
    ]
  },
  {
    "number": 2888,
    "title": "Set Redisson config using AWS ElastiCache as Clustered Mode",
    "created_at": "2020-07-02T23:45:55Z",
    "closed_at": "2020-07-03T17:05:54Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2888",
    "body": "Hey there!\r\n\r\nWhat is the proper way to configure Redisson when you have a AWS ElastiCache Redis running as Clustered Mode? I have tried to set using it as follows:\r\n\r\n```\r\n    val nodeAddress = \"redis://test-rest-encryption-0001-001.p0vefj.0001.use1.cache.amazonaws.com:6379\" \r\n    val config = Config()\r\n    val configCluster = config.useClusterServers().addNodeAddress(nodeAddress)\r\n    val client = Redisson.create(config)\r\n```\r\n\r\nNode endpoint: test-rest-encryption-0001-001.p0vefj.0001.use1.cache.amazonaws.com\r\nConfiguration endpoint: test-rest-encryption.p0vefj.clustercfg.use1.cache.amazonaws.com\r\n\r\nFor `nodeAddress`, I have tried to use configuration endpoint and node endpoint but fails in both case (connection timed out):\r\n\r\n```\r\n21:04:39.542 [main] WARN  o.r.cluster.ClusterConnectionManager - connection timed out: test-rest-encryption-0001-001.p0vefj.0001.use1.cache.amazonaws.com/172.31.19.41:6379\r\nException in thread \"main\" org.redisson.client.RedisConnectionException: Can't connect to servers!\r\n\tat org.redisson.cluster.ClusterConnectionManager.<init>(ClusterConnectionManager.java:144)\r\n\tat org.redisson.config.ConfigSupport.createConnectionManager(ConfigSupport.java:237)\r\n\tat org.redisson.Redisson.<init>(Redisson.java:117)\r\n\tat org.redisson.Redisson.create(Redisson.java:156)\r\n\tat aus.web.SessionManagerApplicationKt.main(SessionManagerApplication.kt:23)\r\nCaused by: io.netty.channel.ConnectTimeoutException: connection timed out: test-rest-encryption-0001-001.p0vefj.0001.use1.cache.amazonaws.com/172.31.19.41:6379\r\n\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:261)\r\n\tat io.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98)\r\n\tat io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:170)\r\n\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n```\r\n\r\nAm I missing something?\r\n\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2888/comments",
    "author": "daviddelucca",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-07-03T05:28:56Z",
        "body": "Is your application located in the same security group?"
      },
      {
        "user": "daviddelucca",
        "created_at": "2020-07-03T16:44:10Z",
        "body": "Yes, it\u2019s in the same SG!\r\n\r\nDo you usually use configuration endpoint or node endpoint? I have read in docs about to use node endpoint but it throws the same exception \ud83d\ude1e\r\n\r\n\r\n\n\n---\n\n@mrniko I have figured part of the problem: the client throws an exception if I try to connect to cluster with option `Encryption in-transit` enabled. Does this client support Encryption in-transit and Encryption at-rest?\r\n\r\nI'm using version 3.5.6"
      },
      {
        "user": "mrniko",
        "created_at": "2020-07-03T17:04:01Z",
        "body": "use rediss:// prefix for SSL connection. And select latest Redisson version for new projects."
      },
      {
        "user": "daviddelucca",
        "created_at": "2020-07-03T17:05:54Z",
        "body": "Solved! It was the prefix!\r\n"
      }
    ]
  },
  {
    "number": 2844,
    "title": "Is it possible to access to the data maintained or written by Redisson in Nodejs? And would it be a bad practice?",
    "created_at": "2020-06-17T04:51:15Z",
    "closed_at": "2020-06-29T06:23:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2844",
    "body": "Hi, I have using Redisson for not a long time, and I realize that I need my old project to access to Redis and retrieve data that is maintained by the current Java code which use Redisson. \r\nBut Redisson is not just a redis client but a In-Memory Data Grid, therefore it's quite different and not compatible friendly for nodejs program for it only has pure redis client tools to use. \r\nSo the idea I have is:\r\n1. Write a Java Redisson program as a proxy and serve data for nodejs program. \r\n2. Figure out how Redisson save data, for sorted set, and Bucket, and write a package for nodejs to decode data from Redis. \r\n3. Give up Redisson and use pure redis client, like Redis. \r\n\r\nIs there any other solutions? Or is there any nodejs middleware for Redisson? Would that be difficult to write one for Redisson(I haven't read much source code of Redisson yet)? \r\nThanks. ",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2844/comments",
    "author": "XLCYun",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-06-17T04:54:52Z",
        "body": "> But Redisson is not just a redis client but a In-Memory Data Grid, therefore it's quite different and not compatible friendly for nodejs program for it only has pure redis client tools to use.\r\n\r\nIt's still remains redis client and compatible with others as long as they store the data in the same format."
      },
      {
        "user": "XLCYun",
        "created_at": "2020-06-17T05:43:41Z",
        "body": "> > But Redisson is not just a redis client but a In-Memory Data Grid, therefore it's quite different and not compatible friendly for nodejs program for it only has pure redis client tools to use.\r\n> \r\n> It's still remains redis client and compatible with others as long as they store the data in the same format.\r\n\r\nHi, thanks for you reply. I see that Redisson use `Marshalling` Codec as default codec, and it store `true` as `\"\\x04P\"` and `false` as `\"\\x04Q\"`, and String `\"A\"` as `\"\\x04>\\x01A\"`.\r\nI think these prefixes are added by `MarshallingCodec`, so are you saying I should write a nodejs program to decode these value if it's possible, or I should write a Codec on my own? \r\nAm I going to the right direction and which one should be preferred by your opinion? Thanks. "
      },
      {
        "user": "mrniko",
        "created_at": "2020-06-17T07:17:20Z",
        "body": "You can use json codec, for example."
      },
      {
        "user": "XLCYun",
        "created_at": "2020-06-29T06:23:55Z",
        "body": "Locks maintained by Redisson might be bit tricky to cooperate with in Node.js. Use `JsonJacksonCodec` or other codec is easy for sharing data between different program written in different language. Issue closed, thanks for the help @mrniko . "
      }
    ]
  },
  {
    "number": 2842,
    "title": "How to retrieve DelayedQueue by name using getDelayedQueue",
    "created_at": "2020-06-17T02:39:53Z",
    "closed_at": "2020-06-17T14:42:38Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2842",
    "body": "Want to understand how to retrieve delayed queue (RDelayedQueue) by name using getDelayedQueue method on org.redisson.api.RedissonClient. \r\n\r\nDoes it require to call redissonClient.getDelayedQueue(destinationQueue) every time before queuing a message as below or retrieve queue once and use it for every message queuing ?\r\n\r\nRDelayedQueue..offer(message, delayInMillisFromCurrent, TimeUnit.MILLISECONDS);",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2842/comments",
    "author": "anilkonduru",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-06-17T04:52:10Z",
        "body": "No, you can store RDelayedQueue instance and use it."
      },
      {
        "user": "anilkonduru",
        "created_at": "2020-06-17T14:42:38Z",
        "body": "@mrniko Thanks, that helps."
      }
    ]
  },
  {
    "number": 2782,
    "title": "How to configure scheduling times? ",
    "created_at": "2020-05-19T03:56:55Z",
    "closed_at": "2020-05-19T05:29:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2782",
    "body": "When using the periodic scheduling method\uff08e.g. RScheduledExecutorService.scheduleAtFixedRate\uff09, I want to stop scheduling after a specified number of times. What should I do?\r\nThanks!",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2782/comments",
    "author": "hgqapp",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-05-19T05:29:49Z",
        "body": "You can implement this logic right in the task.\r\n\r\n```java\r\nclass RunnableTask implements Runnable {\r\n\r\n    @RInject\r\n    private RedissonClient redissonClient;\r\n\r\n    @RInject\r\n    private String taskId;\r\n\r\n    public void run() {\r\n         if (redissonClient.getAtomicLong(\"\").incrementAndGet() == 10) {\r\n              redissonClient.getExecutorService(\"\").cancelTask(taskId);\r\n         }\r\n    }\r\n}\r\n```"
      },
      {
        "user": "hgqapp",
        "created_at": "2020-05-19T06:04:34Z",
        "body": "@mrniko Thanks, your answer is very useful to me."
      }
    ]
  },
  {
    "number": 2766,
    "title": "RScoredSortedSet.entryRange() can't get entry list under redis cluster\uff1f ",
    "created_at": "2020-05-13T14:38:36Z",
    "closed_at": "2020-05-13T17:16:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2766",
    "body": "### Redisson version\uff1a3.7.5\r\n### **I created a redis cluster of three masters and three slaves in the virtual machine.**\r\n\r\n192.168.10.139 master  0-5460\r\n192.168.10.140 master  5461-10922\r\n192.168.10.141 master  10923-16383\r\n192.168.10.142 slave\r\n192.168.10.143 slave \r\n192.168.10.144 slave\r\n\r\n### **I want to test whether the scoresortedset supports clustering.So I wrote a unit test class**\r\n\r\n\r\n\r\n@Before\r\n    public void setUp(){\r\n        Config config = new Config();\r\n        config.useClusterServers()\r\n                .setPassword(\"123456\")\r\n                .setScanInterval(2000) // \u96c6\u7fa4\u72b6\u6001\u626b\u63cf\u95f4\u9694\u65f6\u95f4\uff0c\u5355\u4f4d\u662f\u6beb\u79d2\r\n                .addNodeAddress(\"redis://192.168.10.139:6379\", \"redis://192.168.10.140:6379\")\r\n                .addNodeAddress(\"redis://192.168.10.141:6379\", \"redis://192.168.10.142:6379\")\r\n                .addNodeAddress(\"redis://192.168.10.143:6379\", \"redis://192.168.10.144:6379\");\r\n        redissonClient = Redisson.create(config);\r\n    }\r\n\r\n@Test\r\n    public void redisClusterTest(){\r\n        RScoredSortedSet<String> set = redissonClient.getScoredSortedSet(\"xuyikai\");\r\n        for(int i=1;i<=10;i++){\r\n            boolean isAdd = set.tryAdd(i, \"key\uff1a\" + i);\r\n            log.info(\"isAdd:{}\",isAdd);\r\n        }\r\n        log.info(\"set size:{}\",set.size());\r\n        Collection<ScoredEntry<String>> scoredEntries = set.entryRange(0,10);\r\n        for (ScoredEntry<String> entry : scoredEntries) {\r\n            String key = entry.getValue();\r\n            Double score = entry.getScore();\r\n            log.info(\"key:{},score:{}\",key,score);\r\n        }\r\n    }\r\n\r\n### **I found that the key and score can be inserted normally in the scoreportedset, but when I try to read the size of the current scoreportedset, I find that the return value is 0.**\r\n### **This is the output\uff1a**\r\n\r\n\r\n2020-05-13 22:29:17,531 [main] INFO  org.redisson.Version# logVersion : 41 - Redisson 3.7.5\r\n2020-05-13 22:29:18,230 [main] INFO  o.r.cluster.ClusterConnectionManager# <init> : 120 - Redis cluster nodes configuration got from 192.168.10.139/192.168.10.139:6379:\r\n3d1cc11809e1e057a0f4347df55ac5497035bc59 192.168.10.142:6379@16379 slave e1d330c89353464f871e4fe37ed2bb744e26d9f1 0 1589380157345 4 connected\r\ned84d533c89be5b453349be85ea62236b7e388fd 192.168.10.140:6379@16379 master - 0 1589380157553 2 connected 5461-10922\r\ne1d330c89353464f871e4fe37ed2bb744e26d9f1 192.168.10.141:6379@16379 master - 0 1589380156277 3 connected 10923-16383\r\nc699c611bb722a38588acd51a561755598fbdda7 192.168.10.139:6379@16379 myself,master - 0 1589380156000 1 connected 0-5460\r\n68a78c982c84cc39fb0a500be9007cf08df2d1eb 192.168.10.143:6379@16379 slave c699c611bb722a38588acd51a561755598fbdda7 0 1589380157000 5 connected\r\n0bf30336b5397e3172bbc39827375bfbadbd500e 192.168.10.144:6379@16379 slave ed84d533c89be5b453349be85ea62236b7e388fd 0 1589380157764 6 connected\r\n\r\n2020-05-13 22:29:18,252 [redisson-netty-1-2] INFO  o.r.cluster.ClusterConnectionManager# operationComplete : 244 - slaves: [redis://192.168.10.143:6379] added for slot ranges: [[0-5460]]\r\n2020-05-13 22:29:18,256 [redisson-netty-1-5] INFO  o.r.cluster.ClusterConnectionManager# operationComplete : 244 - slaves: [redis://192.168.10.144:6379] added for slot ranges: [[5461-10922]]\r\n2020-05-13 22:29:18,275 [redisson-netty-1-7] INFO  o.r.cluster.ClusterConnectionManager# operationComplete : 244 - slaves: [redis://192.168.10.142:6379] added for slot ranges: [[10923-16383]]\r\n2020-05-13 22:29:18,291 [redisson-netty-1-5] INFO  o.r.c.p.MasterPubSubConnectionPool# operationComplete : 144 - 1 connections initialized for 192.168.10.141/192.168.10.141:6379\r\n2020-05-13 22:29:18,298 [redisson-netty-1-12] INFO  o.r.c.pool.PubSubConnectionPool# operationComplete : 144 - 1 connections initialized for 192.168.10.144/192.168.10.144:6379\r\n2020-05-13 22:29:18,299 [redisson-netty-1-2] INFO  o.r.c.pool.PubSubConnectionPool# operationComplete : 144 - 1 connections initialized for 192.168.10.142/192.168.10.142:6379\r\n2020-05-13 22:29:18,299 [redisson-netty-1-11] INFO  o.r.c.p.MasterPubSubConnectionPool# operationComplete : 144 - 1 connections initialized for 192.168.10.140/192.168.10.140:6379\r\n2020-05-13 22:29:18,343 [redisson-netty-1-8] INFO  o.r.c.pool.PubSubConnectionPool# operationComplete : 144 - 1 connections initialized for 192.168.10.143/192.168.10.143:6379\r\n2020-05-13 22:29:18,345 [redisson-netty-1-9] INFO  o.r.c.pool.MasterConnectionPool# operationComplete : 144 - 32 connections initialized for 192.168.10.140/192.168.10.140:6379\r\n2020-05-13 22:29:18,345 [redisson-netty-1-1] INFO  o.r.c.pool.MasterConnectionPool# operationComplete : 144 - 32 connections initialized for 192.168.10.139/192.168.10.139:6379\r\n2020-05-13 22:29:18,346 [redisson-netty-1-10] INFO  o.r.c.p.MasterPubSubConnectionPool# operationComplete : 144 - 1 connections initialized for 192.168.10.139/192.168.10.139:6379\r\n2020-05-13 22:29:18,348 [redisson-netty-1-10] INFO  o.r.cluster.ClusterConnectionManager# operationComplete : 267 - master: redis://192.168.10.139:6379 added for slot ranges: [[0-5460]]\r\n2020-05-13 22:29:18,352 [redisson-netty-1-2] INFO  o.r.c.pool.SlaveConnectionPool# operationComplete : 144 - 32 connections initialized for 192.168.10.144/192.168.10.144:6379\r\n2020-05-13 22:29:18,352 [redisson-netty-1-3] INFO  o.r.c.pool.SlaveConnectionPool# operationComplete : 144 - 32 connections initialized for 192.168.10.142/192.168.10.142:6379\r\n2020-05-13 22:29:18,352 [redisson-netty-1-5] INFO  o.r.c.pool.MasterConnectionPool# operationComplete : 144 - 32 connections initialized for 192.168.10.141/192.168.10.141:6379\r\n2020-05-13 22:29:18,352 [redisson-netty-1-9] INFO  o.r.cluster.ClusterConnectionManager# operationComplete : 267 - master: redis://192.168.10.140:6379 added for slot ranges: [[5461-10922]]\r\n2020-05-13 22:29:18,354 [redisson-netty-1-5] INFO  o.r.cluster.ClusterConnectionManager# operationComplete : 267 - master: redis://192.168.10.141:6379 added for slot ranges: [[10923-16383]]\r\n2020-05-13 22:29:18,357 [redisson-netty-1-7] INFO  o.r.c.pool.SlaveConnectionPool# operationComplete : 144 - 32 connections initialized for 192.168.10.143/192.168.10.143:6379\r\n2020-05-13 22:29:18,371 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true\r\n2020-05-13 22:29:18,372 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true\r\n2020-05-13 22:29:18,373 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true\r\n2020-05-13 22:29:18,374 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true\r\n2020-05-13 22:29:18,375 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true\r\n2020-05-13 22:29:18,376 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true\r\n2020-05-13 22:29:18,377 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true\r\n2020-05-13 22:29:18,378 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true\r\n2020-05-13 22:29:18,379 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true\r\n2020-05-13 22:29:18,381 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 65 - isAdd:true\r\n2020-05-13 22:29:18,382 [main] INFO  com.mbkj.mall.RedisClusterTest# redisClusterTest : 68 - set size:0\r\n\r\n### **I tried distributed lock under this condition. It seems that there is no problem, so I am confused about the above problems**\r\n### **I hope you can answer my question, thank you**\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2766/comments",
    "author": "xuyikai1",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-05-13T17:16:13Z",
        "body": "Seems there is a replication lag between master and slave. You may try to use `readMode=Master` to avoid this. RLock is always use Redis master."
      },
      {
        "user": "xuyikai1",
        "created_at": "2020-05-14T08:17:45Z",
        "body": "Thank you for your answer. As you said, it solved the problem"
      }
    ]
  },
  {
    "number": 2538,
    "title": "\u6570\u636e\u7c7b\u578b\u95ee\u9898",
    "created_at": "2020-01-13T07:40:33Z",
    "closed_at": "2020-01-13T08:12:31Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2538",
    "body": "\u6211\u7528spring\u4e2d\u7684@cacheable\u65f6\uff0c\u4ece\u6570\u636e\u5e93\u4e2d\u53d6\u51fa\u6765\u51c6\u5907\u5e8f\u5217\u5316\u5b58\u5230redis\u4e2d\u7684\u6570\u636e\u662fByte\u7c7b\u578b\uff0c\u4f46\u662f\u518d\u4eceredis\u4e2d\u67e5\u51fa\u6765\u8fd4\u56de\u7684\u5374\u662fInteger\uff0c\u8fd9\u4e2a\u662f\u9700\u8981\u4fee\u6539redisson\u7684\u6570\u636e\u5e8f\u5217\u5316\u65b9\u5f0f\u5417\uff1f\u6211\u8bd5\u4e86\u4e00\u4e0b\u5305\u88c5\u7c7bShort\u3001Byte\u90fd\u4f1a\u53d8\u6210Integer\uff0cCharacter\u4f1a\u53d8\u6210String\uff0cFloat\u4f1a\u53d8\u6210Double\u3002",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2538/comments",
    "author": "MarionSong",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-01-13T08:06:07Z",
        "body": "Which codec do you use?"
      },
      {
        "user": "MarionSong",
        "created_at": "2020-01-13T08:10:45Z",
        "body": "JsonJacksonCodec"
      },
      {
        "user": "mrniko",
        "created_at": "2020-01-13T08:12:31Z",
        "body": "Switch to FST, KryoCodec or SerializationCodec"
      },
      {
        "user": "MarionSong",
        "created_at": "2020-01-13T09:01:23Z",
        "body": "thank you \uff0cI switch to SerializationCodec"
      }
    ]
  },
  {
    "number": 2532,
    "title": "\u5173\u4e8eredisson\u7684watchdog\u91cd\u8fde\u673a\u5236",
    "created_at": "2020-01-09T09:03:59Z",
    "closed_at": "2020-01-10T08:44:45Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2532",
    "body": "\u6700\u8fd1\u5c06redisson\u7248\u672c\u5347\u5230\u4e863.11.5\uff0c\u7136\u540e\u6d4b\u8bd5\u4e86\u4e00\u4e0bredisson\u7684\u91cd\u8fde\u673a\u5236\uff0c\u7136\u540e\u51fa\u73b0\u4e86\u4e00\u4e2a\u5947\u602a\u7684\u73b0\u8c61\u3002\u5728Linux\u4e0a\u90e8\u7f72redis\u96c6\u7fa4\uff0c\u7136\u540e\u5728\u672c\u5730Windows\u4e0a\u8fdb\u884c\u8fde\u63a5\u6d4b\u8bd5\u3002\u5982\u679c\u4f7f\u7528\u5728Linux\u4e0a\u4f7f\u7528iptables\u5207\u65ad\u8fde\u63a5\uff0c\u5728\u8fde\u63a5\u6062\u590d\u540e\u4e0d\u53ef\u7528\u8fde\u63a5\u4f1a\u91cd\u8fde\uff1b\u4f46\u5982\u679c\u5728Windows\u4e0a\u4f7f\u7528IP\u5b89\u5168\u7b56\u7565\u6765\u5207\u65ad\u8fde\u63a5\uff0c\u5728\u8fde\u63a5\u6062\u590d\u540e\uff0c\u4e0d\u53ef\u7528\u8fde\u63a5\u6ca1\u6709\u91cd\u8fde\u3002\u8bf7\u95ee\u4e00\u4e0b\uff0c\u8fd9\u4e24\u79cd\u65b9\u5f0f\u4e4b\u95f4\u6709\u4ec0\u4e48\u4e0d\u4e00\u6837\u7684\u5730\u65b9\u5417\uff1f",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2532/comments",
    "author": "ShosinnFuYW",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-01-10T07:08:24Z",
        "body": "Did you try to set `setPingConnectionInterval` setting to handle such cases?"
      },
      {
        "user": "ShosinnFuYW",
        "created_at": "2020-01-10T08:44:37Z",
        "body": "> \r\n> \r\n> Did you try to set `setPingConnectionInterval` setting to handle such cases?\r\nThank you,it works fine!\r\n"
      }
    ]
  },
  {
    "number": 2524,
    "title": "Deserialization the object from redis to RList throws InvocationTargetException",
    "created_at": "2020-01-07T09:19:40Z",
    "closed_at": "2020-01-07T09:21:26Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2524",
    "body": "Deserialization the object from redis to RList throws InvocationTargetException\r\n\r\nredisson:3.12.0\r\nfst:2.56\r\n1.8.0_152\r\n\r\nstacktrace:\r\n\r\n`\r\nCaused by: java.lang.reflect.InvocationTargetException: null\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n\tat org.redisson.command.RedisExecutor.getCodec(RedisExecutor.java:681)\r\n\t... 109 common frames omitted\r\nCaused by: java.lang.NoSuchMethodError: org.nustaq.serialization.FSTConfiguration.getJsonFieldNames()Lorg/nustaq/serialization/coders/FSTJsonFieldNames;\r\n\tat org.redisson.codec.FstCodec.copy(FstCodec.java:201)\r\n\tat org.redisson.codec.FstCodec.<init>(FstCodec.java:190)\r\n\t... 114 common frames omitted\r\n`\r\n\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2524/comments",
    "author": "fengzhenxing",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2020-01-07T09:21:26Z",
        "body": "`java.lang.NoSuchMethodError: org.nustaq.serialization.FSTConfiguration.getJsonFieldNames`\r\n\r\nmake sure you have latest version of fst codec in classpath"
      },
      {
        "user": "fengzhenxing",
        "created_at": "2020-01-07T09:26:47Z",
        "body": "@mrniko yes. The lastest fst codec version is 2.57.Thanks"
      },
      {
        "user": "mrniko",
        "created_at": "2020-01-07T09:28:20Z",
        "body": "Unable to reproduce it."
      },
      {
        "user": "fengzhenxing",
        "created_at": "2020-01-07T09:29:40Z",
        "body": "@mrniko I add the lastest fst codec version,then throws NPE.\r\n\r\nstacktrace:\r\n\r\n`\r\njava.io.IOException: java.lang.NullPointerException\r\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:247)\r\n\tat org.redisson.codec.FstCodec$1.decode(FstCodec.java:250)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:368)\r\n\tat org.redisson.client.handler.CommandDecoder.decodeCommand(CommandDecoder.java:196)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:134)\r\n\tat org.redisson.client.handler.CommandDecoder.decode(CommandDecoder.java:104)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:493)\r\n\tat io.netty.handler.codec.ReplayingDecoder.callDecode(ReplayingDecoder.java:366)\r\n\tat io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:271)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:355)\r\n\tat io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:377)\r\n\tat io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)\r\n\tat io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)\r\n\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:714)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)\r\n\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)\r\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\r\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\r\n\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\r\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.NullPointerException: null\r\n\tat org.nustaq.serialization.FSTObjectInput.readObjectWithHeader(FSTObjectInput.java:357)\r\n\tat org.nustaq.serialization.FSTObjectInput.readObjectInternal(FSTObjectInput.java:331)\r\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:311)\r\n\tat org.nustaq.serialization.FSTObjectInput.readObject(FSTObjectInput.java:245)\r\n\t... 24 common frames omitted\r\n`"
      },
      {
        "user": "mrniko",
        "created_at": "2020-01-07T09:30:35Z",
        "body": "is there code example to reproduce it?"
      },
      {
        "user": "fengzhenxing",
        "created_at": "2020-01-07T09:35:01Z",
        "body": "Here is some example code:\r\n\r\n`\r\nRList<ExampleObject> serviceUserList = redisson.getList(key);\r\n`\r\nif I add  new properties in ExampleObject,then throws NPE. The properties of exampleObject stored in redis is not equals"
      },
      {
        "user": "mrniko",
        "created_at": "2020-01-07T09:36:56Z",
        "body": "> if I add new properties in ExampleObject,then throws NPE. The properties of exampleObject stored in redis is not equals\r\n\r\nConsider to use JacksonCodec for this purpose."
      },
      {
        "user": "fengzhenxing",
        "created_at": "2020-01-07T09:38:19Z",
        "body": "yes,I replace the type of codec so it works.\r\n\r\n"
      }
    ]
  },
  {
    "number": 2488,
    "title": "java.lang.ClassNotFoundException: org.springframework.data.redis.connection.RedisStreamCommands ",
    "created_at": "2019-12-18T02:04:35Z",
    "closed_at": "2019-12-18T07:28:00Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/2488",
    "body": "Hello \r\n         I just submitted two questions that didn't work. The reason is that I pressed the wrong key(ctrl + enter on windows). I'm sorry to be embarrassed. My problem is that I use springboot version 2.1.11.RELEASE and the redisson-spring-boot-starter version is 3.11.  .6, the error is the same as the title. I checked issue 2478 and suggested that he downgrade to redisson-spring-data-21. If it is redisson-spring-boot-starter, what version should he downgrade to?",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/2488/comments",
    "author": "LayJustDoIt",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2019-12-18T07:27:57Z",
        "body": "You need to downgrade to redisson-spring-data-21 only"
      },
      {
        "user": "LayJustDoIt",
        "created_at": "2019-12-19T11:30:55Z",
        "body": "> You need to downgrade to redisson-spring-data-21 only\r\n\r\nYes, I tried to downgrade to this version and the program runs normally, thank you for your suggestions"
      }
    ]
  },
  {
    "number": 1860,
    "title": "Why does RMapCache is designed to use Hash instead of simple key-value structure?",
    "created_at": "2019-01-16T02:58:44Z",
    "closed_at": "2019-01-17T11:58:34Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/1860",
    "body": "\r\nI am curious why RMapCache is designed to use Hash instead of simple key-value structure? Simple key-value can use TTL while Hash cannot. What benefit does RMapCache get when using Hash compared with using key-value?\r\n",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/1860/comments",
    "author": "a2232189",
    "comments": [
      {
        "user": "jackygurui",
        "created_at": "2019-01-16T22:32:35Z",
        "body": "`Simple key-value can use TTL while Hash cannot.` I think you have just answered your own question here. \r\n\r\nThere are use cases where string structure would be more suitable than hash and vice versa, RMapCache is here to bridge the gap between them. "
      },
      {
        "user": "a2232189",
        "created_at": "2019-01-17T02:44:40Z",
        "body": "Some want to save the data in redis with TTL and some want to save the data in redis forever, so you choose to use a never-out-ouf-date strcture `HASH` to save all data, and run a schedule task to delete those data that are set with TTL. Am my understand right?\r\n\r\nIf my conclusion above is right, I think that you choose to use `hash` instead of simple key-value is because the maintainability. Since it's easier to maintain the code if the data structure is only `hash`, compared with the thought that when user choose to save data with TTL, Redisson use `simple key-value` and when ser choose to save data forever (without TTL), Redisson use `Hash`.\n\n---\n\n> I think that you choose to use `hash` instead of simple key-value is because the maintainability. Since it's easier to maintain the code if the data structure is only `hash`, compared with the thought that when user choose to save data with TTL, Redisson use `simple key-value` and when ser choose to save data forever (without TTL), Redisson use `Hash`.\r\n\r\nAm my conclusion right here?"
      },
      {
        "user": "jackygurui",
        "created_at": "2019-01-17T11:27:21Z",
        "body": "Redisson doesn't choose data types between string and hash on user's behalf. If the user wants to use string, he/she can use RBucket, if he/she wants to use hash, then there is RMap for the job. Other map objects Redisson offers are complementary to provide extra functionalities that vanila hash doesn't do. \r\n\r\nUsers decide which data type they need, Redisson provides every possibilities for them. I hope I have answered your question."
      },
      {
        "user": "a2232189",
        "created_at": "2019-01-17T11:58:34Z",
        "body": "Didn't know `RBucket`  before. thanks."
      }
    ]
  },
  {
    "number": 1706,
    "title": "What is the best practice for setting local caches ttl against Redis caches?",
    "created_at": "2018-10-30T07:35:33Z",
    "closed_at": "2018-10-31T12:15:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/1706",
    "body": "Is it correct if Redis cache ttl is the same as timeToLiveInMillis for local cache?\r\n\r\nMY_CACHE: \r\n ttl: 300000\r\n maxIdleTime: 300000\r\n maxSize: 1000\r\n \r\n localCacheOptions:\r\n    evictionPolicy: \"LRU\"\r\n    reconnectionStrategy: \"CLEAR\"\r\n    syncStrategy: \"INVALIDATE\"\r\n    writeMode: \"WRITE_THROUGH\"\r\n    cacheSize: 1000\r\n    timeToLiveInMillis: 300000\r\n    maxIdleInMillis: 300000",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/1706/comments",
    "author": "bkoroliuk-amplify",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2018-10-30T08:12:59Z",
        "body": "Do you use RMapCache and RLocalCachedMapCache under the same name?"
      },
      {
        "user": "bkoroliuk-amplify",
        "created_at": "2018-10-30T08:54:09Z",
        "body": "> Do you use RMapCache and RLocalCachedMapCache under the same name?\r\n\r\nyes"
      },
      {
        "user": "mrniko",
        "created_at": "2018-10-30T08:55:39Z",
        "body": "That's a bad idea, since compatibility between these objects is not guaranteed."
      },
      {
        "user": "bkoroliuk-amplify",
        "created_at": "2018-10-30T08:58:34Z",
        "body": "What about this setup? (max ttl for local caches)\r\n```\r\nMY_CACHE:\r\nttl: 300000\r\nmaxIdleTime: 300000\r\nmaxSize: 1000\r\n\r\nlocalCacheOptions:\r\nevictionPolicy: \"LRU\"\r\nreconnectionStrategy: \"CLEAR\"\r\nsyncStrategy: \"INVALIDATE\"\r\nwriteMode: \"WRITE_THROUGH\"\r\ncacheSize: 1000\r\ntimeToLiveInMillis: 0\r\nmaxIdleInMillis: 0\r\n```\r\n"
      },
      {
        "user": "mrniko",
        "created_at": "2018-10-30T09:04:48Z",
        "body": "That config looks correct. What is your concerns about it?"
      },
      {
        "user": "bkoroliuk-amplify",
        "created_at": "2018-10-31T12:15:57Z",
        "body": "@mrniko No concerns, thank you"
      },
      {
        "user": "mrniko",
        "created_at": "2018-10-31T12:16:26Z",
        "body": "@bkoroliuk-amplify \r\n\r\nYou're welcome!"
      }
    ]
  },
  {
    "number": 1687,
    "title": "Default values for local cache in RedissonSpringLocalCachedCacheManager",
    "created_at": "2018-10-23T14:46:37Z",
    "closed_at": "2018-10-24T17:45:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/redisson/redisson/issues/1687",
    "body": "What are default values for the mentioned below properties?\r\nAre these values from LocalCachedMapOptions::defaults()?\r\nI see that local caches work, but only ttl, idle and maxSize are defined.\r\n```\r\n localCacheOptions:\r\n    evictionPolicy: \"LRU\"\r\n    reconnectionStrategy: \"CLEAR\"\r\n    syncStrategy: \"UPDATE\"\r\n    writeMode: \"WRITE_THROUGH\"\r\n    cacheSize: 1000\r\n    timeToLiveInMillis: 300000\r\n    maxIdleInMillis: 300000\r\n```",
    "comments_url": "https://api.github.com/repos/redisson/redisson/issues/1687/comments",
    "author": "bkoroliuk-amplify",
    "comments": [
      {
        "user": "mrniko",
        "created_at": "2018-10-24T14:39:26Z",
        "body": "> What are default values for the mentioned below properties?\r\n\r\nevictionPolicy = NONE,\r\nreconnectionStrategy = NONE,\r\nsyncStrategy = INVALIDATE\r\nwriteMode = WRITE_THROUGH\r\ncacheSize = 0\r\ntimeToLiveInMillis = 0\r\nmaxIdleInMillis = 0\r\n\r\n> Are these values from LocalCachedMapOptions::defaults()?\r\n\r\nNo, seems config instance had been changed further in code."
      }
    ]
  }
]