[
  {
    "number": 169,
    "title": "Missing subunit in output model",
    "created_at": "2025-02-11T13:10:52Z",
    "closed_at": "2025-02-13T15:24:43Z",
    "labels": [],
    "url": "https://github.com/martinpacesa/BindCraft/issues/169",
    "body": "Hello,\n\nIm currently trying to design binders for a complex composed of 3 subunits. To accelerate processing I delete one subunit and trim away parts of the structure of the remaining 2 subunits that are far away from the hotspot and do not interfere with binding of the binder. I successfully managed to design binders for one complex (4ic0) but for a homologous complex (6qgt) I can't get it to work. For some reason one subunit gets skipped during the process. So the output structure only contains subunit G (where the hotspot is on) but subunit B is missing, which probably causes binder design to the interface where subunit B should sit.\nSo far I tried using different trimmed structures as input and also the not trimmed structure (apart from deleting the 3rd subunit) and renaming the chains (don't now if the name of the chain even effects anything).\u00a0\n\nI am using these settings:\u00a0\nadvanved filters =default_4stage_multimer_hardtarget.json\nfilters = slightly adjusted version of the peptide_filters.json\nHowever all these settings worked fine on the first complex.\n\nDo you have an idea what causes this issue?\nKind regards",
    "comments_url": "https://api.github.com/repos/martinpacesa/BindCraft/issues/169/comments",
    "author": "da-schaefer",
    "comments": [
      {
        "user": "martinpacesa",
        "created_at": "2025-02-13T11:24:13Z",
        "body": "So if a subunit is missing, it probably was not specified in the 'chains = \"A,B,C\"' of the target_settings file. The chain names there correspond to what chains are taken into account during design so it does matter. Can you double check that it matches to what is in your pdb file?"
      }
    ],
    "satisfaction_conditions": [
      "Identifies why a subunit is excluded during processing despite being present in the input structure",
      "Explains how chain naming conventions in input files affect subunit recognition",
      "Clarifies how configuration files (like target_settings) control subunit inclusion"
    ]
  },
  {
    "number": 156,
    "title": "Just PyRosetta or also RosettaDL/Rosetta Licenses Needed",
    "created_at": "2025-01-27T23:09:44Z",
    "closed_at": "2025-01-28T10:35:32Z",
    "labels": [],
    "url": "https://github.com/martinpacesa/BindCraft/issues/156",
    "body": "Thanks for creating this amazing software.\nI can\u2019t find any exact guidance on which  modules are used precisely by BindCraft for commercial use - is it just PyRosetta, PyRosetta + Rosetta, or even PyRosetta + Rosetta + RosettaDL? They all seem to be licensed separately by UW and any guidance on which are actually needed is much appreciated.",
    "comments_url": "https://api.github.com/repos/martinpacesa/BindCraft/issues/156/comments",
    "author": "LRParser",
    "comments": [
      {
        "user": "martinpacesa",
        "created_at": "2025-01-28T07:26:26Z",
        "body": "PyRosetta is only licensed to Rosetta license holders so you would need both. RosettaDL is not used."
      },
      {
        "user": "LRParser",
        "created_at": "2025-01-28T10:35:32Z",
        "body": "Thank you!"
      }
    ],
    "satisfaction_conditions": [
      "Clarifies which specific modules require licenses for commercial use of BindCraft",
      "Identifies unused modules to prevent unnecessary licensing",
      "Confirms dependency relationships between modules"
    ]
  },
  {
    "number": 116,
    "title": "RMSD weight",
    "created_at": "2024-12-02T06:08:26Z",
    "closed_at": "2024-12-02T08:19:49Z",
    "labels": [],
    "url": "https://github.com/martinpacesa/BindCraft/issues/116",
    "body": "First of all, thank you for your excellent work. The community thrives because of you. When I was looking at your code, I was very interested in your filtering strategy, because we can't always find a suitable standard to filter the structures generated by AFD or RF+MPNN, so I carefully checked your weight file. I found that your weights for hotspot_RMSDhe Binder_RMSD are positive and usually large. Generally speaking, if the RMSD of the target structure in a trajectory is large, doesn't it mean that the prediction is not very reliable? The weight treatment in the code is a simple addition, so if the RMSD is large, will this cause the ranking of unreliable trajectories to rise?",
    "comments_url": "https://api.github.com/repos/martinpacesa/BindCraft/issues/116/comments",
    "author": "astomer2",
    "comments": [
      {
        "user": "martinpacesa",
        "created_at": "2024-12-02T06:23:57Z",
        "body": "Thank you for the kind works! I think you were looking at the filter json file, those are not weights but hard cutoffs of the value to filter against. In the case of RMSD it is the Calpha RMSD in Angstrom. \"higher\": false flag indicates that the value for the passing design should NOT be higher than that. In the case of Binder_RMSD it is to make sure that the binder in bound and unbound form does not have a radically different structure"
      },
      {
        "user": "astomer2",
        "created_at": "2024-12-02T08:12:11Z",
        "body": "Thanks for your quick reply, this means we are just doing a cutoffs of an attribute, right? Different binders apply different cutoffs ."
      },
      {
        "user": "martinpacesa",
        "created_at": "2024-12-02T08:15:16Z",
        "body": "You can apply different cutoffs if you wish, but these have been pretty generalisable so far for a variety of different targets"
      },
      {
        "user": "astomer2",
        "created_at": "2024-12-02T08:19:47Z",
        "body": "Ok, thanks for your reply, I will close this issue"
      }
    ],
    "satisfaction_conditions": [
      "Clarify the distinction between filter cutoffs and weighting systems in the filtering strategy",
      "Explain how RMSD values are used to assess structural reliability",
      "Confirm adaptability of filtering criteria for different use cases"
    ]
  },
  {
    "number": 95,
    "title": "Difference between peptide_filters.json and filters_peptides.json",
    "created_at": "2024-11-10T01:58:34Z",
    "closed_at": "2024-11-10T10:21:26Z",
    "labels": [],
    "url": "https://github.com/martinpacesa/BindCraft/issues/95",
    "body": "Hi, there are two files with a similar name in the settings_filters directory called `peptide_filters.json` (the last commit was \"v1.2.0\") and `filters_peptides.json` (the last commit was Add files via upload\") where the only difference between them is the `peptide_filters.json` has `null` values for `Average_PackStat`, `1_PackStat`, and `2_PackStat` threshold values and `filters_peptides.json` has `0.35`. ",
    "comments_url": "https://api.github.com/repos/martinpacesa/BindCraft/issues/95/comments",
    "author": "ahmedselim2017",
    "comments": [
      {
        "user": "martinpacesa",
        "created_at": "2024-11-10T09:22:12Z",
        "body": "Whoops, that's a leftover from previous version, will be removed"
      },
      {
        "user": "ahmedselim2017",
        "created_at": "2024-11-11T19:16:55Z",
        "body": "Thanks!"
      }
    ],
    "satisfaction_conditions": [
      "Clarifies the purpose and relationship between the two similarly named files",
      "Explains which file is considered authoritative/current",
      "Addresses potential configuration conflicts from duplicate files",
      "Confirms maintenance status of legacy files"
    ]
  },
  {
    "number": 83,
    "title": "Colab Pro+ runtime advice",
    "created_at": "2024-10-30T21:57:18Z",
    "closed_at": "2024-11-05T23:16:30Z",
    "labels": [],
    "url": "https://github.com/martinpacesa/BindCraft/issues/83",
    "body": "Hi Bindcraft team, congratulations for this wonderful pipeline and for opening it up to the community.\r\n\r\nI decided to use this on a ColabPro+ account with a ~100aa target sequence. The following observations may be of interest to others who want to use Colab for executing Bindcraft. In the 24 hr runtime on a A100 GPU, about 270 compute units were utilized. 79 trajectories were run and 43 designs passed all filters. I assume this (the timeframe) is along expected lines? \r\n\r\nMy issue now is that since ColabPro+ times out after the 24h runtime, the code has now stopped. Is there any way I can resume from the current position and if not, what would be the best way to proceed? I think everything was running fine and I do not want to lose out on the progress made so far. ",
    "comments_url": "https://api.github.com/repos/martinpacesa/BindCraft/issues/83/comments",
    "author": "athavalechem",
    "comments": [
      {
        "user": "martinpacesa",
        "created_at": "2024-10-30T22:36:59Z",
        "body": "Hello, yes you can just continue generating into the same folder, it will keep adding designs"
      },
      {
        "user": "finexzhi",
        "created_at": "2024-10-31T13:57:10Z",
        "body": "I think the question is that the 24h runtime limit will interrupt the calculation in the middle. You can stop the runtime after the end of one run and restart a new 24h runtime (reset the clock). In this way, you will not be worried about the interruption of a run."
      },
      {
        "user": "martinpacesa",
        "created_at": "2024-10-31T16:13:33Z",
        "body": "I don't think it matters. Yes you will lose one trajectory by restarting but it's no big deal."
      },
      {
        "user": "athavalechem",
        "created_at": "2024-11-01T17:09:23Z",
        "body": "Update: A new runtime can be started with all the folder paths identical and new binder designs will simply be added without overwriting anything. No problems there. The trajectory which was interrupted is lost but that is totally fine. I got the 100 designs now.\r\nI am curious about your thoughts on the following things:\r\nThis target (~100aa, mostly helices) took ~48 hrs on ColabPro+ A100 GPU with ~560 compute units. 160 trajectories were tested to generate 101 designs passing all filters (4 stage, all settings were default values).\r\nQuestions:\r\n1) Is this the typical time or is it too slow/fast? Are things faster on a local installation?\r\n2) Does the ratio of trajectories/designs give a sense of how easy the target was and how good the designs may be?\r\n3) Roughly, how are these times expected to change for targets with comparable 'complexity' but that are larger - let's say 300 aa, 800aa, 1400aa?\r\n\r\n\r\n\r\n"
      },
      {
        "user": "martinpacesa",
        "created_at": "2024-11-03T11:33:26Z",
        "body": "1. So the Colab version is certainly much slower than a local installation. It also depends on which GPU you are using. A100 is I think the fastest you can get on colab and is certainly one of the better ones you can have locally as well. H100s are about 5x faster but much more expensive to buy.\r\n2. This is hard to say. We had hard targets and easy targets and generally whatever passed filters also worked in the wetlab, not necessarily better or worse. But in terms of in silico success, your target is definitely amongst the best, we rarely have to sample so little (least we did was 200, most we had to do was 3500).\r\n3. anywhere from 5 minutes to 3 hours per trajectory. Maximum we could test was 500 amino acids at that time. We can now do bigger things with larger GPU memory but the run time in some cases can be half a day per trajectory."
      },
      {
        "user": "athavalechem",
        "created_at": "2024-11-05T23:16:23Z",
        "body": "Thanks for all the insights - this is super useful!"
      }
    ],
    "satisfaction_conditions": [
      "Clarification on how to resume interrupted workflows without losing progress",
      "Performance benchmarks comparing Colab vs local installations",
      "Interpretation of trajectory/design ratios for target difficulty assessment",
      "Scalability expectations for larger protein targets"
    ]
  },
  {
    "number": 78,
    "title": "shutil.copy(best_model_pdb, design_paths[\"Rejected\"])",
    "created_at": "2024-10-27T03:24:26Z",
    "closed_at": "2024-10-30T16:48:15Z",
    "labels": [],
    "url": "https://github.com/martinpacesa/BindCraft/issues/78",
    "body": "\r\n\r\n I got this error message after running my program. What could be causing it, and how should I fix it? Really looking forward to your help!\r\n\r\n\r\n\r\n\r\nFixing interface residues: B43,B63,B66,B69,B70,B73,B74,B77,B78,B80,B81,B82,B85\r\nBase AF2 filters not passed for /home/BindCraft/example/PDL1_l91_s345674_mpnn1, skipping interface scoring\r\nUnmet filter conditions for /home/BindCraft/example/PDL1_l91_s345674_mpnn2\r\nTraceback (most recent call last):\r\n  File \"/home/BindCraft/./bindcraft.py\", line 411, in <module>\r\n    shutil.copy(best_model_pdb, design_paths[\"Rejected\"])\r\n  File \"/home/anaconda3/envs/BindCraft/lib/python3.10/shutil.py\", line 417, in copy\r\n    copyfile(src, dst, follow_symlinks=follow_symlinks)\r\n  File \"/home/anaconda3/envs/BindCraft/lib/python3.10/shutil.py\", line 254, in copyfile\r\n    with open(src, 'rb') as fsrc:\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/BindCraft/example/PDL1_l91_s345674_mpnn2_model2.pdb'\r\n",
    "comments_url": "https://api.github.com/repos/martinpacesa/BindCraft/issues/78/comments",
    "author": "EHHDD2024",
    "comments": [
      {
        "user": "martinpacesa",
        "created_at": "2024-10-27T17:45:38Z",
        "body": "Try updating the bindcraft.py file from the latest repo now."
      },
      {
        "user": "EHHDD2024",
        "created_at": "2024-11-01T01:44:06Z",
        "body": "> Try updating the bindcraft.py file from the latest repo now.\r\n\r\nThank you so much! After updating bindcraft.py, it's now running smoothly. But I'm facing another issue now: why does bindcraft.py utilize all the GPUs when I run it? Is there a way to specify and use only a few GPUs?"
      },
      {
        "user": "martinpacesa",
        "created_at": "2024-11-01T05:55:32Z",
        "body": "It shouldn't. What if you add this line to bindcraft.py:\n\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'"
      }
    ],
    "satisfaction_conditions": [
      "The solution must ensure the script handles missing files or invalid paths gracefully before attempting file operations",
      "The solution should maintain script functionality while preventing silent failures for unmet dependencies"
    ]
  },
  {
    "number": 72,
    "title": "Is there a way to restart where a previous run left off?",
    "created_at": "2024-10-23T16:56:48Z",
    "closed_at": "2024-10-25T12:50:15Z",
    "labels": [],
    "url": "https://github.com/martinpacesa/BindCraft/issues/72",
    "body": "Let's say I ran the program and asked for 10 binders, and Bindcraft ended after 10.  Is there a way to go back and then ask for 100, but to start from where the previous one left off?  ",
    "comments_url": "https://api.github.com/repos/martinpacesa/BindCraft/issues/72/comments",
    "author": "TimCraigCGPS",
    "comments": [
      {
        "user": "martinpacesa",
        "created_at": "2024-10-23T16:59:20Z",
        "body": "Yes, you can just keep outputting to the same folder"
      },
      {
        "user": "TimCraigCGPS",
        "created_at": "2024-10-25T12:50:16Z",
        "body": "Awesome, thanks!"
      }
    ],
    "satisfaction_conditions": [
      "The solution must allow resuming progress from a previous run's output",
      "The program must automatically detect and preserve existing output",
      "No additional parameters or setup should be required for continuation"
    ]
  },
  {
    "number": 55,
    "title": "Is this compatible with Mac GPU?",
    "created_at": "2024-10-16T07:59:27Z",
    "closed_at": "2024-10-16T08:04:25Z",
    "labels": [],
    "url": "https://github.com/martinpacesa/BindCraft/issues/55",
    "body": "Is this compatible with Mac GPU?",
    "comments_url": "https://api.github.com/repos/martinpacesa/BindCraft/issues/55/comments",
    "author": "titocali1",
    "comments": [
      {
        "user": "martinpacesa",
        "created_at": "2024-10-16T08:03:10Z",
        "body": "No, only Nvidia CUDA compatible GPUs"
      }
    ],
    "satisfaction_conditions": [
      "Clarifies compatibility with Mac GPUs",
      "Specifies supported GPU types/architectures"
    ]
  },
  {
    "number": 41,
    "title": "Is that OK to use AlphaFold generated PDB as a template",
    "created_at": "2024-10-10T23:59:01Z",
    "closed_at": "2024-10-11T13:38:24Z",
    "labels": [],
    "url": "https://github.com/martinpacesa/BindCraft/issues/41",
    "body": "My target does not have a published PDB. Thus I used AlphaFold to generate a PDB as the template.\r\n\r\nHowever, after I ran the software, I continued to see the buffer error messages:\r\nBuffer 9:\r\n\t\tSize: 1.22GiB\r\n\t\tXLA Label: fusion\r\n\t\tShape: bf16[4,1130,1130,128]\r\n\t\t==========================\r\n\r\n\tBuffer 10:\r\n\t\tSize: 623.49MiB\r\n\t\tOperator: op_name=\"jit(_model)/jit(main)/transpose(jvp(jit(apply)))/jit(apply_fn)/alphafold/alphafold_iteration/evoformer/__layer_stack_no_state/while/body/checkpoint/rematted_computation/extra_msa_stack/triangle_multiplication_outgoing/projection/...a, ah->...h/dot_general[dimension_numbers=(((2,), (0,)), ((), ())) precision=None preferred_element_type=bfloat16]\" source_file=\"/content/colabdesign/af/alphafold/model/common_modules.py\" source_line=118\r\n\t\tXLA Label: custom-call\r\n\t\tShape: bf16[1276900,256]\r\n\t\t==========================\r\n\r\n\tBuffer 11:\r\n\t\tSize: 623.49MiB\r\n\t\tOperator: op_name=\"jit(_model)/jit(main)/transpose(jvp(jit(apply)))/jit(apply_fn)/alphafold/alphafold_iteration/evoformer/__layer_stack_no_state/while/body/checkpoint/rematted_computation/extra_msa_stack/triangle_multiplication_outgoing/div\" source_file=\"/content/colabdesign/af/alphafold/model/modules.py\" source_line=1038 deduplicated_name=\"input_transpose_fusion.31\"\r\n\t\tXLA Label: fusion\r\n\t\tShape: bf16[256,1130,1130]\r\n\t\t==========================\r\n\r\n\tBuffer 12:\r\n\t\tSize: 623.49MiB\r\n\t\tXLA Label: fusion\r\n\t\tShape: f32[1130,1130,128]\r\n\t\t==========================\r\n\r\n\tBuffer 13:\r\n\t\tSize: 623.49MiB\r\n\t\tOperator: op_name=\"jit(_model)/jit(main)/transpose(jvp(jit(apply)))/jit(apply_fn)/alphafold/alphafold_iteration/evoformer/__layer_stack_no_state/while/body/checkpoint/rematted_computation/extra_msa_stack/add\" source_file=\"/content/colabdesign/af/alphafold/model/modules.py\" source_line=73\r\n\t\tXLA Label: fusion\r\n\t\tShape: f32[1130,1130,128]\r\n\t\t==========================\r\n\r\n\tBuffer 14:\r\n\t\tSize: 623.49MiB\r\n\t\tOperator: op_name=\"jit(_model)/jit(main)/transpose(jvp(jit(apply)))/jit(apply_fn)/alphafold/alphafold_iteration/evoformer/__layer_stack_no_state_1/while/body/checkpoint/rematted_computation/evoformer_iteration/msa_row_attention_with_pair_bias/feat_2d_norm/feat_2d_norm/jit(_var)/sub\" source_file=\"/usr/local/lib/python3.10/dist-packages/haiku/_src/layer_norm.py\" source_line=166\r\n\t\tXLA Label: fusion\r\n\t\tShape: f32[1130,1130,128]\r\n\t\t==========================\r\n\r\n\tBuffer 15:\r\n\t\tSize: 623.49MiB\r\n\t\tEntry Parameter Subshape: f32[1130,1130,128]\r\n\t\t==========================",
    "comments_url": "https://api.github.com/repos/martinpacesa/BindCraft/issues/41/comments",
    "author": "finexzhi",
    "comments": [
      {
        "user": "martinpacesa",
        "created_at": "2024-10-11T10:31:10Z",
        "body": "How big is the pdb you are inputting in amino acids? It is probably too big for your GPU memory, you may have to try it"
      },
      {
        "user": "finexzhi",
        "created_at": "2024-10-11T11:54:34Z",
        "body": "Thanks, Martin. You are giving the right direction to solve this problem.\r\nThe protein is about 1000 amino acids. But I have defined the hot spot residues to be the first 100 amino acids.\r\nI thought the software will only take it as a 100-aa-long target. But I could be wrong.\r\n"
      },
      {
        "user": "martinpacesa",
        "created_at": "2024-10-11T12:05:12Z",
        "body": "It takes the whole pdb you provide as input"
      },
      {
        "user": "finexzhi",
        "created_at": "2024-10-11T12:27:02Z",
        "body": "Thanks, Martin. That is very important information to me. :)\r\nI have used the notepad to modify the original PDB to a new one containing a smaller part of before.\r\nNow it is working. Thank you. "
      }
    ],
    "satisfaction_conditions": [
      "Clarifies whether the entire input PDB structure is processed by the software or only selected parts",
      "Identifies memory constraints related to input size as a root cause of buffer errors",
      "Provides guidance on input preparation requirements for the software"
    ]
  },
  {
    "number": 40,
    "title": "How to resume the computation in the colab?",
    "created_at": "2024-10-10T13:10:09Z",
    "closed_at": "2024-10-11T13:38:37Z",
    "labels": [],
    "url": "https://github.com/martinpacesa/BindCraft/issues/40",
    "body": "I ran the computation to the 4th stage of \"run BindCraft\" . However, it was stopped because my computer went to sleep.\r\n\r\nAs such, I could not run the next step \"consolidate and rank designs\".\r\n\r\nIs that anyway to resume the computation from where I left? Or I have to start over.\r\n\r\nThanks!\r\n\r\nI am using colab pro+.",
    "comments_url": "https://api.github.com/repos/martinpacesa/BindCraft/issues/40/comments",
    "author": "finexzhi",
    "comments": [
      {
        "user": "martinpacesa",
        "created_at": "2024-10-10T16:08:52Z",
        "body": "Since the data is saved on your google drive, you can just start it again and as long as it points to the same output folder it will continue doing the designs. Note, the cosolidate and rank designs part will only start automatically once sufficient number of designs have passed the filters (100 by defualt). This can take a long time depending on your target size, generally you need to generate like 500-3000 trajectories to get 100 that pass the filters. However, if less is okay for you, then you can stop the design loop cell and just run consolidate and rank designs. You can also continue any time and consolidate again, the pipeline is designed in a way that you can always generate more designs and it does not \"break\" anything."
      },
      {
        "user": "finexzhi",
        "created_at": "2024-10-10T16:30:44Z",
        "body": "Thanks for the clarification. It is very clear now that the newly found hits were stored under the project folder. We can always run the software to search the sequence universe to find potentially better hits. I know this could be a random process. But when I start a new round of run, how can the software know which space it has already searched?"
      },
      {
        "user": "martinpacesa",
        "created_at": "2024-10-10T16:32:50Z",
        "body": "Based on the filename, that's why we include the binder length and seed number which is what in an oversimplified manner \"roughly\" determines the search space."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how the software tracks and avoids redundant search space exploration",
      "Clarification of state persistence between sessions",
      "Guidance on manual intervention for partial progress consolidation",
      "Assurance of incremental design generation compatibility"
    ]
  },
  {
    "number": 36,
    "title": "any recommended workstation or laptop to run BindCraft",
    "created_at": "2024-10-09T17:00:01Z",
    "closed_at": "2024-10-09T17:26:57Z",
    "labels": [],
    "url": "https://github.com/martinpacesa/BindCraft/issues/36",
    "body": "I see some workstations but built with only 12-16GB of GPU.\r\nThanks!",
    "comments_url": "https://api.github.com/repos/martinpacesa/BindCraft/issues/36/comments",
    "author": "finexzhi",
    "comments": [
      {
        "user": "martinpacesa",
        "created_at": "2024-10-09T17:08:26Z",
        "body": "I guess the answer is, if it runs for your target then it's okay :D however, the big downside of BindCraft is that the GPU memory requirements scale quickly with target+binder size, so with 16 Gb you might only be able to design for 350 amino acids, that's binder+target combined, which is very small in most applications. For most of the time we got away with 32 Gb GPUs but there are some targets that cannot be trimmed efficiently to that size. There is always the option of running it on colab pro subscription with A100 gpus, since the design data is saved on your google drive, you can just keep running it again and again"
      },
      {
        "user": "finexzhi",
        "created_at": "2024-10-09T17:25:48Z",
        "body": "Thanks, Martin. Good point and suggestions. :)\r\nSubscription of google Colab pro is definitely the best pathway for me now. \r\n"
      }
    ],
    "satisfaction_conditions": [
      "Supports handling larger target/binder sizes beyond 350 amino acids combined",
      "Provides access to GPU memory that scales with project requirements",
      "Offers a cost-effective alternative to purchasing high-end local hardware"
    ]
  },
  {
    "number": 31,
    "title": "multiple target chains",
    "created_at": "2024-10-08T17:15:58Z",
    "closed_at": "2024-10-08T18:46:13Z",
    "labels": [],
    "url": "https://github.com/martinpacesa/BindCraft/issues/31",
    "body": "Hi\r\n\r\nfor the target_settings json. How can we specifiy multiple chains?\r\n\r\nIn PDL1 its only 1 chain:\r\n\r\n> {\r\n>     \"design_path\": \"/content/drive/My Drive/BindCraft/PDL1/\",\r\n>     \"binder_name\": \"PDL1\",\r\n>     \"starting_pdb\": \"/content/bindcraft/example/PDL1.pdb\",\r\n>     **\"chains\": \"A\",**\r\n>     \"target_hotspot_residues\": \"56\",\r\n>     \"lengths\": [65, 150],\r\n>     \"number_of_final_designs\": 100\r\n> }\r\n\r\nIf my pdb is a complex, how can I specifiy that my target is chain B, C and D in json file?\r\n\r\nThank you in advance for your help,\r\nJF\r\n",
    "comments_url": "https://api.github.com/repos/martinpacesa/BindCraft/issues/31/comments",
    "author": "jflucier",
    "comments": [
      {
        "user": "martinpacesa",
        "created_at": "2024-10-08T17:18:57Z",
        "body": "\"chains\": \"A,B,C,D\","
      }
    ],
    "satisfaction_conditions": [
      "Explanation of how to format multiple chain identifiers in the JSON configuration",
      "Validation that the solution works for protein complexes"
    ]
  },
  {
    "number": 4,
    "title": "ValueError: RGBA values should be within 0-1 range",
    "created_at": "2024-10-02T22:13:42Z",
    "closed_at": "2024-10-03T06:36:50Z",
    "labels": [],
    "url": "https://github.com/martinpacesa/BindCraft/issues/4",
    "body": "Hey, \r\nsorry, but I ran into another issue when running the provided example. Stage 4 finishes, but then I get the following: \r\n\r\nTrajectory successful, final pLDDT: 0.74\r\nTraceback (most recent call last):\r\n  File \"/home/joe/Software/BindCraft/bindcraft.py\", line 108, in <module>\r\n    trajectory = binder_hallucination(design_name, target_settings[\"starting_pdb\"], target_settings[\"chains\"],\r\n  File \"/home/joe/Software/BindCraft/functions/colabdesign_utils.py\", line 227, in binder_hallucination\r\n    plots = af_model.animate(dpi=150)\r\n  File \"/home/joe/miniforge3/envs/BindCraft/lib/python3.9/site-packages/colabdesign/af/utils.py\", line 118, in animate\r\n    return make_animation(**sub_traj, pos_ref=pos_ref, length=self._lengths,\r\n  File \"/home/joe/miniforge3/envs/BindCraft/lib/python3.9/site-packages/colabdesign/shared/plot.py\", line 303, in make_animation\r\n    ims[-1].append(plot_pseudo_3D(pos[k], c=plddt[k], Ls=Ls, cmin=0.5, cmax=0.9, **flags))\r\n  File \"/home/joe/miniforge3/envs/BindCraft/lib/python3.9/site-packages/colabdesign/shared/plot.py\", line 177, in plot_pseudo_3D\r\n    lines = mcoll.LineCollection(seg_xy[order], colors=colors[order], linewidths=linewidths,\r\n  File \"/home/joe/miniforge3/envs/BindCraft/lib/python3.9/site-packages/matplotlib/collections.py\", line 1393, in __init__\r\n    super().__init__(\r\n  File \"/home/joe/miniforge3/envs/BindCraft/lib/python3.9/site-packages/matplotlib/collections.py\", line 206, in __init__\r\n    self._internal_update(kwargs)\r\n  File \"/home/joe/miniforge3/envs/BindCraft/lib/python3.9/site-packages/matplotlib/artist.py\", line 1216, in _internal_update\r\n    return self._update_props(\r\n  File \"/home/joe/miniforge3/envs/BindCraft/lib/python3.9/site-packages/matplotlib/artist.py\", line 1192, in _update_props\r\n    ret.append(func(v))\r\n  File \"/home/joe/miniforge3/envs/BindCraft/lib/python3.9/site-packages/matplotlib/collections.py\", line 1463, in set_color\r\n    self.set_edgecolor(c)\r\n  File \"/home/joe/miniforge3/envs/BindCraft/lib/python3.9/site-packages/matplotlib/collections.py\", line 834, in set_edgecolor\r\n    self._set_edgecolor(c)\r\n  File \"/home/joe/miniforge3/envs/BindCraft/lib/python3.9/site-packages/matplotlib/collections.py\", line 813, in _set_edgecolor\r\n    self._edgecolors = mcolors.to_rgba_array(c, self._alpha)\r\n  File \"/home/joe/miniforge3/envs/BindCraft/lib/python3.9/site-packages/matplotlib/colors.py\", line 476, in to_rgba_array\r\n    raise ValueError(\"RGBA values should be within 0-1 range\")\r\nValueError: RGBA values should be within 0-1 range\r\n\r\nDid anyone else encounter this?",
    "comments_url": "https://api.github.com/repos/martinpacesa/BindCraft/issues/4/comments",
    "author": "joerloeffler",
    "comments": [
      {
        "user": "sokrypton",
        "created_at": "2024-10-03T04:30:42Z",
        "body": "Can you try downgrade matplotlib?\r\n```pip install matplotlib==3.7.1```"
      },
      {
        "user": "joerloeffler",
        "created_at": "2024-10-03T06:04:03Z",
        "body": "Thank you for pointing this out! with the downgrade the code runs! Thank you @sokrypton "
      }
    ],
    "satisfaction_conditions": [
      "Resolves matplotlib version incompatibility causing RGBA value errors",
      "Ensures color normalization stays within 0-1 range for visualization components",
      "Maintains compatibility with existing ColabDesign plotting dependencies"
    ]
  }
]