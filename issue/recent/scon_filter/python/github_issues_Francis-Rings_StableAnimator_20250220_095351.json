[
  {
    "number": 45,
    "title": "the file \"inference\" cannot be opened",
    "created_at": "2024-12-17T02:33:53Z",
    "closed_at": "2024-12-17T03:17:36Z",
    "labels": [],
    "url": "https://github.com/Francis-Rings/StableAnimator/issues/45",
    "body": null,
    "comments_url": "https://api.github.com/repos/Francis-Rings/StableAnimator/issues/45/comments",
    "author": "sunjing1123",
    "comments": [
      {
        "user": "Francis-Rings",
        "created_at": "2024-12-17T02:51:36Z",
        "body": "Hi, I just downloaded the `inference.zip` file from the Hugging Face model and unzipped it locally. I was able to open the unzipped files successfully and have checked all the contents to ensure that no files are corrupted.\n\n---\n\nPlease check you have successfully downloaded the entire `inference.zip` file from the Hugging Face model."
      },
      {
        "user": "sunjing1123",
        "created_at": "2024-12-17T03:32:01Z",
        "body": "Hi, yes, I've tried it and succeeded . thanks a lot \r\n"
      }
    ],
    "satisfaction_conditions": [
      "Confirmation that the downloaded file is complete and uncorrupted",
      "Verification of proper unzipping/local file accessibility"
    ]
  },
  {
    "number": 29,
    "title": "Training failed with error _pickle.UnpicklingError: pickle data was truncated",
    "created_at": "2024-12-13T03:47:00Z",
    "closed_at": "2024-12-16T02:59:49Z",
    "labels": [],
    "url": "https://github.com/Francis-Rings/StableAnimator/issues/29",
    "body": "I tried to run the training scripts but it failed with error\r\n    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\nsubprocess.CalledProcessError: Command '['/home/yaqing/miniconda3/envs/stableanimator/bin/python', 'train.py', '--pretrained_model_name_or_path=stabilityai/stable-video-diffusion-img2vid-xt', '--output_dir=/home/yaqing/ai/StableAnimator/checkpoints/Animation', '--data_root_path=/home/yaqing/ai/StableAnimator/animation_data', '--rec_data_path=/home/yaqing/ai/StableAnimator/animation_data/video_rec_path.txt', '--vec_data_path=/home/yaqing/ai/StableAnimator/animation_data/video_vec_path.txt', '--validation_image_folder=/home/yaqing/ai/StableAnimator/validation/ground_truth', '--validation_control_folder=/home/yaqing/ai/StableAnimator/validation/poses', '--validation_image=/home/yaqing/ai/StableAnimator/validation/reference.png', '--num_workers=8', '--lr_warmup_steps=500', '--sample_n_frames=16', '--learning_rate=1e-5', '--per_gpu_batch_size=1', '--num_train_epochs=6000', '--mixed_precision=fp16', '--gradient_accumulation_steps=1', '--checkpointing_steps=2000', '--validation_steps=500', '--gradient_checkpointing', '--checkpoints_total_limit=5000', '--resume_from_checkpoint=latest']' died with <Signals.SIGKILL: 9>.\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/yaqing/miniconda3/envs/stableanimator/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\r\n    exitcode = _main(fd, parent_sentinel)\r\n  File \"/home/yaqing/miniconda3/envs/stableanimator/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\r\n    self = reduction.pickle.load(from_parent)\r\n_pickle.UnpicklingError: pickle data was truncated\r\nAny idea what may be wrong?\r\n",
    "comments_url": "https://api.github.com/repos/Francis-Rings/StableAnimator/issues/29/comments",
    "author": "Yaqing2023",
    "comments": [
      {
        "user": "Francis-Rings",
        "created_at": "2024-12-13T05:17:46Z",
        "body": "Hi, I\u2019ve never encountered this issue before. Based on the error message, it might be related to `spawn`. You could try modifying the multiprocessing method at Line 822 in `train.py`."
      },
      {
        "user": "Yaqing2023",
        "created_at": "2024-12-13T06:06:04Z",
        "body": "yes I tried to change spawn to fork, the error is gone; also in the shell script  it has CUDA_VISIBLE_DEVICES=3,2,1,0, i suppose you have 4 GPU for training. this needs to be updated for actual GPU numbers user has?\r\nbut i still can not run the training on my single GPU machine with 16G memory, even though i have only 2 sub-dir to train 00001 and 00002. It still runs OOM"
      },
      {
        "user": "Francis-Rings",
        "created_at": "2024-12-13T06:12:07Z",
        "body": "> yes I tried to change spawn to fork, the error is gone; also in the shell script it has CUDA_VISIBLE_DEVICES=3,2,1,0, i suppose you have 4 GPU for training. this needs to be updated for actual GPU numbers user has? but i still can not run the training on my single GPU machine with 16G memory, even though i have only 2 sub-dir to train 00001 and 00002. It still runs OOM\r\n\r\nI use 4 NVIDIA A100 80GB GPUs to train StableAnimator. The CUDA_VISIBLE_DEVICES variable specifies which GPUs are available for use. For example, if your machine has a single GPU, you should set CUDA_VISIBLE_DEVICES=0. Furthermore, I recommend using GPUs with at least 40GB of VRAM for training StableAnimator."
      }
    ],
    "satisfaction_conditions": [
      "Solution must address memory constraints for single-GPU training with 16GB VRAM",
      "Must provide configuration adjustments for single-GPU environments",
      "Should maintain compatibility with multiprocessing 'fork' method",
      "Must explain resource requirements for stable training"
    ]
  },
  {
    "number": 16,
    "title": "How much VRAM does it need",
    "created_at": "2024-12-10T18:36:50Z",
    "closed_at": "2024-12-11T09:10:09Z",
    "labels": [],
    "url": "https://github.com/Francis-Rings/StableAnimator/issues/16",
    "body": null,
    "comments_url": "https://api.github.com/repos/Francis-Rings/StableAnimator/issues/16/comments",
    "author": "nitinmukesh",
    "comments": [
      {
        "user": "Francis-Rings",
        "created_at": "2024-12-11T01:20:36Z",
        "body": "Hi, StableAnimator currently supports animating reference images in two resolutions: 512x512 and 576x1024. For a 15-second demo video (512x512 resolution at 30 fps), the 16-frame basic model requires 8GB of VRAM and takes approximately 5 minutes to complete on a 4090 GPU. When the reference image resolution is 576x1024, the same model requires around 10GB of VRAM to animate."
      },
      {
        "user": "nitinmukesh",
        "created_at": "2024-12-11T09:10:09Z",
        "body": "You are awesome.\r\n\r\nTested 512 x 512, only need ~6 GB. 576 x 1024 need ~8+ GB.\r\nIf some sort of quantization is applied 576x1024 will work on 8 GB. "
      }
    ],
    "satisfaction_conditions": [
      "Clear VRAM requirements for different resolutions and frame configurations",
      "Identification of optimization techniques to reduce VRAM consumption",
      "Correlation between input parameters (resolution, frame count) and resource requirements"
    ]
  }
]