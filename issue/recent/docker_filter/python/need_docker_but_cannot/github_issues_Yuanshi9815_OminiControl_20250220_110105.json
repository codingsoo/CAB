[
  {
    "number": 77,
    "title": "OOM on 48G gpu",
    "created_at": "2025-01-16T00:16:03Z",
    "closed_at": "2025-01-17T01:27:48Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/77",
    "body": "I'm currently trying to train it using the a6000 ada gpus, I set the strategy to FSDP but it still reports OOM\r\nDo we have to use 80gb memory for training?",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/77/comments",
    "author": "PeterYYZhang",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2025-01-16T07:05:55Z",
        "body": "Hi @PeterYYZhang,\r\n\r\nJust FYI - you should be able to run the 512x512 config on 48GB GPUs by enabling `gradient_checkpointing: true ` in your config.\r\n\r\n:D"
      },
      {
        "user": "PeterYYZhang",
        "created_at": "2025-01-17T01:27:43Z",
        "body": "Thanks @Yuanshi9815! Now it works!!"
      },
      {
        "user": "rishabh063",
        "created_at": "2025-01-28T15:01:15Z",
        "body": "hey i am getting oom on 48gb vram even when gradient checkpoint is true"
      }
    ],
    "satisfaction_conditions": [
      "Memory optimization technique that works on 48GB GPUs",
      "Solution must address OOM errors during training",
      "Approach should maintain model trainability"
    ],
    "_classification": {
      "category": "Requires build environment but hard to be dockerized",
      "timestamp": "2025-04-05 01:52:53"
    }
  }
]