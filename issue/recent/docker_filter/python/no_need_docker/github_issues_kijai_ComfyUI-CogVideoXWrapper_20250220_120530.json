[
  {
    "number": 97,
    "title": "1Torch was not compiled with flash attention",
    "created_at": "2024-09-25T06:30:07Z",
    "closed_at": "2024-10-01T02:07:44Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/97",
    "body": "I know this most likely has nothing to do with Cog, but I'm getting the following:\r\n```ComfyUI\\comfy\\ldm\\modules\\attention.py:407: UserWarning: 1Torch was not compiled with flash attention.```\r\nIt still runs okay, I'm just wondering if this is compromising my quality or speed or anything.\r\n\r\nThanks in advance for any help.",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/97/comments",
    "author": "Vektor369",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-25T06:35:05Z",
        "body": "It's normal for Windows currently as flash_attn isn't supported by the prebuilt torch installs. CogVideoX itself doesn't benefit from it either, as far as I know."
      }
    ],
    "satisfaction_conditions": [
      "Clarifies whether the missing flash attention support impacts output quality or inference speed",
      "Confirms if this is an expected environment limitation rather than a configuration error",
      "Addresses relevance to their specific use case (CogVideoX)"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-05 01:50:45"
    }
  },
  {
    "number": 85,
    "title": "Question about decoder",
    "created_at": "2024-09-21T21:39:28Z",
    "closed_at": "2024-09-22T09:47:04Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/85",
    "body": "Apologies if this is a stupid question, I have pretty much zero knowledge about how video models work compared to image models.\r\n\r\nIs the way the sampler and decoder currently work somehow similar to generating images in batches with SA or Flux? If so, would it be theoretically possible to unbatch the latents or specify which frame(s) to send to the decoder by index?\r\n\r\nOr am I totally off the mark and the decoder already handles this already, and doesn't decode all frames at once.\r\n\r\nThe reason I got curious about this is because with Fun-xB models (I assume probably caused by the models themselves, not the wrapper) I noticed that it will output extra/duplicated frames at the beginning of image sequence (ie: it outputs 16 frames when selecting 13 frames as length), so I was wondering if it was possible to remove those before sending to the decoder, thus somehow saving on a bit of resources along the way when decoding.\r\n\r\nI tried a few different nodes to separate latents from batch/select by index but obviously it doesn't work ;)",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/85/comments",
    "author": "thelemuet",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-21T21:54:28Z",
        "body": "CogVideoX uses a 3D VAE, meaning it also compresses the images temporally: 4 images into one latent. This causes the disparancies you noticed with the frame counts. The decoding is done 2 \"frames\" at the time by design, it can't be less. If memory for decoding is a concern, the VAE tiling works pretty well with the tile size set to half of the dimensions."
      },
      {
        "user": "thelemuet",
        "created_at": "2024-09-21T22:33:20Z",
        "body": "Ah, makes completes sense, thank you for the explanation.\r\n\r\nFunnily enough, another reason I was messing with the latents is because yesterday I had issues with the VAE tiling resulting in very obvious seams. As an alternative I was splitting the latents with some padding using the core \"crop latent\" node before sending to the decoder, then stitching the images back after that myself. Clearly the latent shape was wrong, cropping the Width was cropping the Height and cropping the Height did nothing, but it did actually work even if not as intended hehe,\r\n\r\nBut looks like there are no more visible seams with VAE tiling after updating today, so thank you, definitely much more convenient ;)"
      },
      {
        "user": "kijai",
        "created_at": "2024-09-21T23:23:00Z",
        "body": "> Ah, makes completes sense, thank you for the explanation.\n> \n> Funnily enough, another reason I was messing with the latents is because yesterday I had issues with the VAE tiling resulting in very obvious seams. As an alternative I was splitting the latents with some padding using the core \"crop latent\" node before sending to the decoder, then stitching the images back after that myself. Clearly the latent shape was wrong, cropping the Width was cropping the Height and cropping the Height did nothing, but it did actually work even if not as intended hehe,\n> \n> But looks like there are no more visible seams with VAE tiling after updating today, so thank you, definitely much more convenient ;)\n\nYes they defaults were just awful before, I got the values from the initial code before these new models and as I never really used it myself, I didn't realise they should be completely different. 96x96 tiles made no sense in pixel space especially, half of the image dimension seems fine now and no seams with 0.2 overlap."
      }
    ],
    "satisfaction_conditions": [
      "Explanation of why frame count discrepancies occur during decoding",
      "Clarification of whether frame selection before decoding is possible within the model's constraints",
      "Identification of resource-efficient alternatives to full-frame decoding",
      "Compatibility with the model's inherent temporal compression mechanism"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-05 01:51:00"
    }
  },
  {
    "number": 77,
    "title": "Error occurred when executing DownloadAndLoadCogVideoModel",
    "created_at": "2024-09-20T16:59:48Z",
    "closed_at": "2024-09-20T17:45:45Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/77",
    "body": "When I tried CogVideoX-5b-I2V, I encountered this problem. Does anyone know how to solve it\uff1f\r\n![Uploading PixPin_2024-09-21_00-55-09.jpg\u2026]()\r\n",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/77/comments",
    "author": "TryingToDoBetter25",
    "comments": [
      {
        "user": "TryingToDoBetter25",
        "created_at": "2024-09-20T17:01:37Z",
        "body": "Traceback (most recent call last):\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\ComfyUI\\execution.py\", line 152, in recursive_execute\r\n    output_data, output_ui = get_output_data(obj, input_data_all)\r\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\ComfyUI\\execution.py\", line 82, in get_output_data\r\n    return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\ComfyUI\\execution.py\", line 75, in map_node_over_list\r\n    results.append(getattr(obj, func)(**slice_dict(input_data_all, i)))\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 98, in loadmodel\r\n    transformer = CogVideoXTransformer3DModel.from_pretrained(base_path, subfolder=\"transformer\")\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\python_embeded\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\r\n    return fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\python_embeded\\Lib\\site-packages\\diffusers\\models\\modeling_utils.py\", line 774, in from_pretrained\r\n    accelerate.load_checkpoint_and_dispatch(\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\python_embeded\\Lib\\site-packages\\accelerate\\big_modeling.py\", line 613, in load_checkpoint_and_dispatch\r\n    load_checkpoint_in_model(\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\python_embeded\\Lib\\site-packages\\accelerate\\utils\\modeling.py\", line 1821, in load_checkpoint_in_model\r\n    set_module_tensor_to_device(\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\python_embeded\\Lib\\site-packages\\accelerate\\utils\\modeling.py\", line 341, in set_module_tensor_to_device\r\n    raise ValueError(f\"{module} does not have a parameter or a buffer named {tensor_name}.\")\r\nValueError: CogVideoXPatchEmbed(\r\n  (proj): Conv2d(32, 3072, kernel_size=(2, 2), stride=(2, 2))\r\n  (text_proj): Linear(in_features=4096, out_features=3072, bias=True)\r\n) does not have a parameter or a buffer named pos_embedding.\r\n"
      },
      {
        "user": "kijai",
        "created_at": "2024-09-20T17:25:44Z",
        "body": "Did you update diffusers to 0.30.3?"
      },
      {
        "user": "TryingToDoBetter25",
        "created_at": "2024-09-20T17:45:37Z",
        "body": "> Did you update diffusers to 0.30.3?\r\n\r\nI reinstalled it and it ran successfully. Thank you very much"
      }
    ],
    "satisfaction_conditions": [
      "Ensures compatibility between the CogVideoX model and its dependencies",
      "Provides a method to verify/update critical dependencies like diffusers"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-05 01:51:43"
    }
  },
  {
    "number": 21,
    "title": "\"Prompt outputs failed validation: Value not in list\"",
    "created_at": "2024-08-28T07:19:18Z",
    "closed_at": "2024-08-28T15:51:50Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/21",
    "body": "I've updated ComfyUI, and I installed the latest CogVideoXWrapper through ComfyUI manager via this Git's URL. I've loaded the \"cogvideox_5b_example_01.json\" workflow, and pointed the Load Clip node to my existing model (t5xxl_fp8_e4m3fn.safetensors).\r\n\r\nAfter hitting queue prompt, I get this error:\r\n\r\nPrompt outputs failed validation: Value not in list: format: 'video/nvenc_h264-mp4' not in ['image/gif', 'image/webp', 'video/ProRes', 'video/av1-webm', 'video/h264-mp4', 'video/h265-mp4', 'video/webm']\r\nVHS_VideoCombine:\r\n    - Value not in list: format: 'video/nvenc_h264-mp4' not in ['image/gif', 'image/webp', 'video/ProRes', 'video/av1-webm', 'video/h264-mp4', 'video/h265-mp4', 'video/webm']",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/21/comments",
    "author": "Gyramuur",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-08-28T12:49:51Z",
        "body": "This is because I forgot the nvenc format selected on the video combine node, it's not supported by all platforms. Just change to some other encode format or recreate the video combine node to get past that."
      },
      {
        "user": "Gyramuur",
        "created_at": "2024-08-28T15:51:50Z",
        "body": "That fixed it, thanks. :) Now getting a separate error but I'll open a different issue."
      }
    ],
    "satisfaction_conditions": [
      "Identifies the root cause of the unsupported video format error",
      "Provides a method to select a supported video encoding format",
      "Explains platform compatibility considerations for video formats",
      "Guides reconfiguration of workflow nodes without requiring code changes"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-05 01:52:29"
    }
  }
]