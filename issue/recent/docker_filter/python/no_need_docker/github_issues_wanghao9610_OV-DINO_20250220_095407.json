[
  {
    "number": 36,
    "title": "Curiosity about how to solve different labels towards same objects among different dataset.",
    "created_at": "2024-08-30T10:16:47Z",
    "closed_at": "2024-09-04T02:42:20Z",
    "labels": [],
    "url": "https://github.com/wanghao9610/OV-DINO/issues/36",
    "body": "I'm curious about one factor of pre-trained datasets. Are there any of the following in your pre-training dataset\uff1a The label descriptions of the same target object are different in different datasets.  For instance, COCO describes birds with the label \"bird\", but Obj365 describes birds with the label \"wild bird\". How do you solve this kind of problem in the pre-trained process?  During the inference process, if the model \"eats\" a picture with birds for example, how will it predict the object birds? Will the model predict it as \"bird\" or \"wild bird\"?",
    "comments_url": "https://api.github.com/repos/wanghao9610/OV-DINO/issues/36/comments",
    "author": "Cloud65000",
    "comments": [
      {
        "user": "wanghao9610",
        "created_at": "2024-08-31T14:00:31Z",
        "body": "In pre-training, we keep the name as the original. Actually, the ambiguity is not important for pre-training, different people may call the same thing with different names, while the two names are the same thing."
      },
      {
        "user": "Cloud65000",
        "created_at": "2024-09-03T02:25:14Z",
        "body": "I see. I guess we can keep the name as the original because BERT will help us generate similar embeddings for those different descriptions of the same object."
      }
    ],
    "satisfaction_conditions": [
      "Explains how semantic similarity of labels is handled during pre-training",
      "Clarifies how the model generalizes across label variations for the same concept"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-05 02:04:02"
    }
  },
  {
    "number": 13,
    "title": "\u5fae\u8c03\u65f6\u7684\u8bad\u7ec3\u8fc7\u7a0b\u56fe",
    "created_at": "2024-08-08T13:28:47Z",
    "closed_at": "2024-08-09T07:33:16Z",
    "labels": [],
    "url": "https://github.com/wanghao9610/OV-DINO/issues/13",
    "body": "\u60a8\u597d\uff0c\u60f3\u8bf7\u95ee\u4e00\u4e0b\u5728coco\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u65f6\uff0c\u6709\u6ca1\u6709\u652f\u6301\u67e5\u770b\u8bad\u7ec3\u8fc7\u7a0b\u7684\u53c2\u6570\uff08tensorboard\u7c7b\u4f3c\u7684\uff09\uff1f",
    "comments_url": "https://api.github.com/repos/wanghao9610/OV-DINO/issues/13/comments",
    "author": "Zwh195",
    "comments": [
      {
        "user": "wanghao9610",
        "created_at": "2024-08-09T02:29:29Z",
        "body": "\u9ed8\u8ba4\u662f\u652f\u6301tensorboard\u7684\u3002\u4f60\u53ef\u4ee5\u67e5\u770b\u4e00\u4e0b\u4f60\u7684\u8bad\u7ec3\u8f93\u51fa\u8def\u5f84\u4e2d\u662f\u5426\u6709 events.out.tfevents.* \u7684\u6587\u4ef6\uff0c\u5982\u679c\u6709\u5219\u8bf4\u660e\u5df2\u7ecf\u6709tensorboard\u7684\u65e5\u5fd7\u4e86\u3002\u8fdb\u5165\u5230\u8bad\u7ec3\u8f93\u51fa\u8def\u5f84\u4e2d\uff0c\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4\uff1a\r\n```bash\r\ntensorboard --logdir=./\r\n```\r\n\u5728\u8fd9\u4e4b\u524d\uff0c\u4f60\u53ef\u80fd\u9700\u8981\u5148\u5b89\u88c5\u4e00\u4e0btensorboard\u3002\u53c2\u8003\uff1apip install tensorboard \u3002"
      },
      {
        "user": "Zwh195",
        "created_at": "2024-08-09T07:33:14Z",
        "body": "\u597d\u7684\u597d\u7684\uff0c\u8c22\u8c22\u60a8\uff01"
      }
    ],
    "satisfaction_conditions": [
      "Confirmation of built-in support for real-time training process visualization",
      "Clear instructions for verifying visualization tool availability",
      "Guidance for accessing training metrics without additional configuration"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-05 02:04:10"
    }
  },
  {
    "number": 3,
    "title": "how to take image feature as prompt ?",
    "created_at": "2024-08-02T03:23:45Z",
    "closed_at": "2024-08-02T04:13:51Z",
    "labels": [],
    "url": "https://github.com/wanghao9610/OV-DINO/issues/3",
    "body": "use CLIP image encode is ok ?",
    "comments_url": "https://api.github.com/repos/wanghao9610/OV-DINO/issues/3/comments",
    "author": "Apm5",
    "comments": [
      {
        "user": "wanghao9610",
        "created_at": "2024-08-02T03:47:10Z",
        "body": "OV-DINO doesn't support taking image feature as prompt, only category name text prompt is available as open-vocabulary setting."
      }
    ],
    "satisfaction_conditions": [
      "Clarifies whether the target model (OV-DINO) supports image features as input prompts",
      "Identifies supported input types for open-vocabulary prompts in OV-DINO",
      "Explains limitations of OV-DINO's prompt handling capabilities"
    ],
    "_classification": {
      "category": "Does not need build environment",
      "timestamp": "2025-04-05 02:04:15"
    }
  }
]