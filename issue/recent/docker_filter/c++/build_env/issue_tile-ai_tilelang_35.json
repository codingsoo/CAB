{
  "number": 35,
  "title": "Copy issue when tensor dim is 1",
  "created_at": "2025-01-23T15:30:32Z",
  "closed_at": "2025-01-26T05:36:20Z",
  "labels": [
    "bug"
  ],
  "url": "https://github.com/tile-ai/tilelang/issues/35",
  "body": "Assume we have Q tensor shape with [bs, 1, head, dim].\nAnd we allocate a shared memory Q_shared [block_M, dim].\n\nhow to copy Q_shared[0, :] = Q[bid, 0, hid, :]?\n\n```\n# type: ignore\n\nimport torch\nimport torch.nn.functional as F\nimport tilelang\nfrom tilelang import Profiler\nfrom tilelang.autotuner import *\nimport tilelang.language as T\nimport itertools\nimport argparse\nfrom functools import partial\n\ndef flashdecoding(batch, heads, seqlen_q, seqlen_kv, dim, is_casual, num_split, tune=False):\n    scale = (1.0 / dim) ** 0.5 * 1.44269504  # log2(e)\n    shape_q = [batch, seqlen_q, heads, dim]\n    shape_kv = [batch, seqlen_kv, heads, dim]\n    part_shape = [batch, seqlen_q, heads, num_split, dim]\n    dtype = \"float16\"\n    accum_dtype = \"float\"\n\n    def kernel_func(block_M, block_N):\n        \n        @T.macro\n        def flash_attn_split(\n            Q: T.Buffer(shape_q, dtype),\n            K: T.Buffer(shape_kv, dtype),\n            V: T.Buffer(shape_kv, dtype),\n            glse: T.Buffer([batch, heads, num_split, seqlen_q], dtype),\n            Output_partial: T.Buffer(part_shape, dtype),\n        ):\n            print(\"flash_attn_split\")\n            with T.Kernel(T.ceildiv(seqlen_q, block_M), heads * batch, num_split, threads=128 * 2) as (bx, by, bz):\n                Q_shared = T.alloc_shared([block_M, dim], dtype)\n                K_shared = T.alloc_shared([block_N, dim], dtype)\n                V_shared = T.alloc_shared([block_N, dim], dtype)\n                O_shared = T.alloc_shared([block_M, dim], dtype)\n                acc_s = T.alloc_fragment([block_M, block_N], accum_dtype)\n                acc_s_cast = T.alloc_fragment([block_M, block_N], dtype)\n                acc_o = T.alloc_fragment([block_M, dim], accum_dtype)\n                scores_max = T.alloc_fragment([block_M], accum_dtype)\n                scores_max_prev = T.alloc_fragment([block_M], accum_dtype)\n                scores_scale = T.alloc_fragment([block_M], accum_dtype)\n                scores_sum = T.alloc_fragment([block_M], accum_dtype)\n                logsum = T.alloc_fragment([block_M], accum_dtype)\n\n                mid = bx\n                hid = by % heads\n                bid = by // heads\n                sid = bz\n\n                # T.annotate_layout({Q_shared: tl.layout.make_swizzled_layout(Q_shared)})\n                T.copy(Q[bid, 0, hid, :], Q_shared[0, :])\n                # T.fill(acc_o, 0)\n                # T.fill(logsum, 0)\n                # T.fill(scores_max, -T.infinity(accum_dtype))\n\n                # loop_range = (\n                #     T.min(T.ceildiv(seqlen_kv, block_N), T.ceildiv((mid + 1) * block_M, block_N)) \n                #     if is_casual else T.ceildiv((seqlen_kv // num_split), block_N)\n                # )\n\n                # for k in T.Pipelined(loop_range, num_stages=2):\n                #     MMA0(K, Q_shared, K_shared, acc_s, k, mid, hid, bid, sid)\n        \n        @T.prim_func\n        def main(\n                Q: T.Buffer(shape_q, dtype),\n                K: T.Buffer(shape_kv, dtype),\n                V: T.Buffer(shape_kv, dtype),\n                glse: T.Buffer([batch, heads, num_split, seqlen_q], dtype),\n                Output_partial: T.Buffer(part_shape, dtype), # [batch, seqlen_q, heads, num_split, dim]\n                Output: T.Buffer(shape_q, dtype),\n        ):\n            print(\"hello\")\n            flash_attn_split(Q, K, V, glse, Output_partial)\n\n        return main\n\n    def kernel(block_M, block_N):\n        return kernel_func(block_M, block_N)\n\n    return kernel\n\ndef ref_program(Q, K, V, casual):\n    assert casual is False\n    dim = Q.size(-1)\n    scores = torch.einsum('bqhd,bkhd->bhqk', Q, K)\n    scores = scores / torch.sqrt(torch.tensor(dim, dtype=scores.dtype))\n    attention_weights = F.softmax(scores, dim=-1)\n    output = torch.einsum('bhqk,bkhd->bqhd', attention_weights, V)\n    return output\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--batch', type=int, default=1, help='batch size')\n    parser.add_argument('--heads', type=int, default=32, help='heads')\n    parser.add_argument('--seqlen_kv', type=int, default=4096, help='sequence length')\n    parser.add_argument('--dim', type=int, default=128, help='dim')\n    parser.add_argument('--is_casual', action='store_true', help='causal')\n    parser.add_argument('--tune', action='store_true', help='tune configs')\n    args = parser.parse_args()\n\n    batch, heads, seqlen_kv, dim, is_casual = args.batch, args.heads, args.seqlen_kv, args.dim, args.is_casual\n    seqlen_q   = 1\n    num_splits = 4\n\n    program = flashdecoding(\n                batch, heads, seqlen_q, seqlen_kv, dim, is_casual, num_splits, tune=args.tune)(\n                block_M=128, block_N=128)\n    jit_kernel = tilelang.JITKernel(program, out_idx=[5], target=\"cuda\")\n\n    q = torch.randn(batch, seqlen_q, heads, dim, dtype=torch.float16, device='cuda')\n    k = torch.randn(batch, seqlen_kv, heads, dim, dtype=torch.float16, device='cuda')\n    v = torch.randn(batch, seqlen_kv, heads, dim, dtype=torch.float16, device='cuda')\n    glse = torch.empty(batch, heads, num_splits, seqlen_q, dtype=torch.float16, device='cuda')\n    output_partial = torch.empty(batch, seqlen_q, heads, num_splits, dim, dtype=torch.float16, device='cuda')\n\n    out_ref = ref_program(q, k, v, is_casual)\n    out_flash = jit_kernel(q, k, v, glse, output_partial)\n\n    print(f\"out_ref vs out_flash: {(out_ref - out_flash).abs().mean().item()}\")\n\n```\n\nI got error:\n> Traceback (most recent call last):\n  File \"/home/shijiecao/Projects/BitAttn/tilelang/mha_kvcache.py\", line 187, in <module>\n    jit_kernel = tilelang.JITKernel(program, out_idx=[5], target=\"cuda\")\n  File \"/home/shijiecao/miniconda3/envs/bit/lib/python3.10/site-packages/tilelang/jit/kernel.py\", line 75, in __init__\n    adapter = self._compile_and_create_adapter(func)\n  File \"/home/shijiecao/miniconda3/envs/bit/lib/python3.10/site-packages/tilelang/jit/kernel.py\", line 120, in _compile_and_create_adapter\n    rt_mod, params = tilelang.lower(tilelang_func, target=target)\n  File \"/home/shijiecao/miniconda3/envs/bit/lib/python3.10/site-packages/tilelang/engine/lower.py\", line 223, in lower\n    device_mod = tvm._ffi.get_global_func(\"target.build.tilelang_cuda\")(device_mod, target)\n  File \"/home/shijiecao/miniconda3/envs/bit/lib/python3.10/site-packages/tilelang/3rdparty/tvm/python/tvm/_ffi/_ctypes/packed_func.py\", line 239, in __call__\n    raise_last_ffi_error()\n  File \"/home/shijiecao/miniconda3/envs/bit/lib/python3.10/site-packages/tilelang/3rdparty/tvm/python/tvm/_ffi/base.py\", line 481, in raise_last_ffi_error\n    raise py_err\nValueError: Traceback (most recent call last):\n  31: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::IRModule, tvm::Target)>::AssignTypedLambda<tvm::runtime::Module (*)(tvm::IRModule, tvm::Target)>(tvm::runtime::Module (*)(tvm::IRModule, tvm::Target), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  30: tvm::codegen::BuildTileLangCUDA(tvm::IRModule, tvm::Target)\n  29: tvm::codegen::CodeGenTileLangCUDA::AddFunction(tvm::tir::PrimFunc const&)\n  28: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)\n  27: non-virtual thunk to tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::DeclBufferNode const*)\n  26: non-virtual thunk to tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::DeclBufferNode const*)\n  25: tvm::codegen::CodeGenTileLangCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)\n  24: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)\n  23: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)\n  22: tvm::codegen::CodeGenTileLangCUDA::VisitStmt_(tvm::tir::AllocateNode const*)\n  21: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)\n  20: tvm::codegen::CodeGenTileLangCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)\n  19: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)\n  18: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)\n  17: tvm::codegen::CodeGenTileLangCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)\n  16: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)\n  15: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)\n  14: tvm::codegen::CodeGenTileLangCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)\n  13: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)\n  12: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)\n  11: tvm::codegen::CodeGenTileLangCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)\n  10: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)\n  9: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)\n  8: tvm::codegen::CodeGenTileLangCUDA::VisitStmt_(tvm::tir::AttrStmtNode const*)\n  7: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::AttrStmtNode const*)\n  6: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)\n  5: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::IfThenElseNode const*)\n  4: tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)\n  3: tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*)\n  2: tvm::codegen::CodeGenC::PrintExpr[abi:cxx11](tvm::PrimExpr const&)\n  1: tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&, std::ostream&)\n  0: tvm::codegen::CodeGenTileLangCUDA::VisitExpr_(tvm::tir::RampNode const*, std::ostream&)\n  File \"/root/TileLang/src/target/codegen_cuda.cc\", line 1257\nValueError: Check failed: lanes <= 4 (8 vs. 4) : Ramp of more than 4 lanes is not allowed.",
  "comments_url": "https://api.github.com/repos/tile-ai/tilelang/issues/35/comments",
  "author": "DD-DuDa",
  "comments": [
    {
      "user": "LeiWang1999",
      "created_at": "2025-01-23T15:32:26Z",
      "body": "@DD-DuDa Thanks for your reporting, would you mind provide the entire scripts to help us reproduce?"
    },
    {
      "user": "DD-DuDa",
      "created_at": "2025-01-23T15:44:02Z",
      "body": "Yeah, I've edited and provided the whole code."
    },
    {
      "user": "LeiWang1999",
      "created_at": "2025-01-23T16:09:44Z",
      "body": "likely due to some bugs of liveness, for example, consider the following simplified program you provide:\n\n```python\n@T.prim_func\ndef main(\n        Q: T.Buffer(shape_q, dtype),\n        K: T.Buffer(shape_kv, dtype),\n        V: T.Buffer(shape_kv, dtype),\n        glse: T.Buffer([batch, heads, num_split, seqlen_q], dtype),\n        Output_partial: T.Buffer(part_shape, dtype), # [batch, seqlen_q, heads, num_split, dim]\n        Output: T.Buffer(shape_q, dtype),\n):\n    with T.Kernel(T.ceildiv(seqlen_q, block_M), heads * batch, num_split, threads=128 * 2) as (bx, by, bz):\n        Q_shared = T.alloc_shared([block_M, dim], dtype)\n\n        hid = by % heads\n        bid = by // heads\n\n        T.copy(Q[bid, 0, hid, :], Q_shared[0, :])\n        for d in T.serial(dim):\n            Q_shared[0, d] = Q[bid, 0, hid, d]\n```\n\nWhen you generate the kernel code using `print(jit_kernel.get_kernel_source())`, the output is as follows:\n```python\nextern \"C\" __global__ void __launch_bounds__(256) main_kernel(half_t* __restrict__ Q) {\n  extern __shared__ __align__(1024) half_t Q_shared[];\n  if (((int)threadIdx.x) < 16) {\n    *(uint4*)(Q_shared + (((int)threadIdx.x) * 8)) = *(uint4*)(Q + ((((int)blockIdx.y) * 128) + (((int)threadIdx.x) * 8)));\n  }\n  for (int d = 1; d < 128; ++d) {\n    Q_shared[d] = Q[((((int)blockIdx.y) * 128) + d)];\n  }\n}\n```\n\nIn this generated code, the first copy block behaves as expected and aligns with the intended functionality.\nSo, it\u2019s possible that the issue may resolve itself if you uncomment certain parts of the program.\n\n---\n\nbut it's also important for us to discover where the bug locates\n\n---\n\nOne debug trick is that we can insert debug print at `tilelang/engine/lower.py` to see the lowered ir module: \n\n```python\ndevice_mod = tir.transform.Filter(is_device_call)(mod)\ndevice_mod = tir.transform.LowerDeviceStorageAccessInfo()(device_mod)\ndevice_mod = tir.transform.LowerIntrin()(device_mod)\ndevice_mod = tir.transform.Simplify()(device_mod)\nprint(device_mod)\nif target.kind.name == \"cuda\":\n    # Debug comments to get the code\n    # code = tvm._ffi.get_global_func(\"target.build.tl_debug_codegen\")(device_mod, target)\n    device_mod = tvm._ffi.get_global_func(\"target.build.tilelang_cuda\")(device_mod, target)\n```\n\n\nfor the frist program:\n```python\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main_kernel(Q: T.handle(\"float16\", \"global\")):\n        Q_1 = T.decl_buffer((16777216,), \"float16\", data=Q)\n        Q_shared = T.handle(\"float16\", \"shared.dyn\")\n        Q_shared_1 = T.decl_buffer((131072,), \"float16\", data=Q_shared, scope=\"shared.dyn\")\n        bx = T.launch_thread(\"blockIdx.x\", 32)\n        Q_shared = T.allocate([131072], \"float16\", \"shared.dyn\")\n        by = T.launch_thread(\"blockIdx.y\", 32)\n        bz = T.launch_thread(\"blockIdx.z\", 4)\n        v = T.launch_thread(\"threadIdx.x\", 256)\n        v_1 = T.launch_thread(\"threadIdx.y\", 1)\n        v_2 = T.launch_thread(\"threadIdx.z\", 1)\n        if v < 16:\n            Q_shared_1[v * 64:v * 64 + 72:9] = Q_1[by * 128 + v * 8:by * 128 + v * 8 + 8]\n```\n\nfor the last program:\n```python\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main_kernel(Q: T.handle(\"float16\", \"global\")):\n        Q_1 = T.decl_buffer((16777216,), \"float16\", data=Q)\n        Q_shared = T.handle(\"float16\", \"shared.dyn\")\n        Q_shared_1 = T.decl_buffer((16384,), \"float16\", data=Q_shared, scope=\"shared.dyn\")\n        bx = T.launch_thread(\"blockIdx.x\", 32)\n        Q_shared = T.allocate([16384], \"float16\", \"shared.dyn\")\n        by = T.launch_thread(\"blockIdx.y\", 32)\n        bz = T.launch_thread(\"blockIdx.z\", 4)\n        v = T.launch_thread(\"threadIdx.x\", 256)\n        v_1 = T.launch_thread(\"threadIdx.y\", 1)\n        v_2 = T.launch_thread(\"threadIdx.z\", 1)\n        if v < 16:\n            Q_shared_1[v * 8:v * 8 + 8] = Q_1[by * 128 + v * 8:by * 128 + v * 8 + 8]\n        for d in range(128):\n            Q_shared_1[d] = Q_1[by * 128 + d]\n```\n\n---\n\nThe problem behinds `tir.transform.VectorizeLoop`.\n\n```python\nprint(\"Before vectorize loop \\n\", mod)\nmod = tir.transform.VectorizeLoop()(mod)\nprint(\"After vectorize loop \\n\", mod)\n```\n\n```python\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(Q: T.Buffer((1, 4096, 32, 128), \"float16\"), K: T.Buffer((1, 4096, 32, 128), \"float16\"), V: T.Buffer((1, 4096, 32, 128), \"float16\"), glse: T.Buffer((1, 32, 4, 4096), \"float16\"), Output_partial: T.Buffer((1, 4096, 32, 4, 128), \"float16\"), Output: T.Buffer((1, 4096, 32, 128), \"float16\")):\n        if v < 16:\n            i = T.int32()\n            T.attr(i, \"pragma_unroll_explicit\", T.bool(False))\n            for i in T.vectorized(8):\n                Q_shared = T.allocate([16384], \"float16\", \"shared.dyn\")\n                Q_shared_1 = T.Buffer((16384,), \"float16\", data=Q_shared, scope=\"shared.dyn\")\n                Q_1 = T.Buffer((16777216,), \"float16\", data=Q.data)\n                Q_shared_1[v * 8 + i] = Q_1[by * 128 + v * 8 + i]\n\nAfter vectorize loop \n # from tvm.script import ir as I\n# from tvm.script import tir as T\n\n@I.ir_module\nclass Module:\n    @T.prim_func\n    def main(Q: T.Buffer((1, 4096, 32, 128), \"float16\"), K: T.Buffer((1, 4096, 32, 128), \"float16\"), V: T.Buffer((1, 4096, 32, 128), \"float16\"), glse: T.Buffer((1, 32, 4, 4096), \"float16\"), Output_partial: T.Buffer((1, 4096, 32, 4, 128), \"float16\"), Output: T.Buffer((1, 4096, 32, 128), \"float16\")):\n        if v < 16:\n            i = T.int32()\n            T.attr(i, \"pragma_unroll_explicit\", T.bool(False))\n            Q_shared = T.allocate([131072], \"float16\", \"shared.dyn\")\n            Q_shared_1 = T.Buffer((131072,), \"float16\", data=Q_shared, scope=\"shared.dyn\")\n            Q_1 = T.Buffer((16777216,), \"float16\", data=Q.data)\n            Q_shared_1[v * 64:v * 64 + 72:9] = Q_1[by * 128 + v * 8:by * 128 + v * 8 + 8]\n```"
    },
    {
      "user": "DD-DuDa",
      "created_at": "2025-01-23T22:26:35Z",
      "body": "Got it! I learned a lot for that. Thank you!"
    },
    {
      "user": "LeiWang1999",
      "created_at": "2025-01-25T12:09:22Z",
      "body": "closed as has been resolved :)"
    }
  ],
  "satisfaction_conditions": [
    "Explanation of why vectorized memory operations are failing with dimension constraints",
    "Guidance on avoiding invalid vectorization patterns when copying tensors with singleton dimensions",
    "Diagnostic approach for identifying vectorization issues in compiler transformations",
    "Compatibility with TileLang's shared memory allocation constraints"
  ],
  "_classification": {
    "category": "Can be dockerized without any issue",
    "timestamp": "2025-04-05 01:51:19"
  },
  "git_commit_info": {
    "sha": "a7f66d4f1bd319e56ce090ba096f5c803c1bfbc7",
    "date": "2025-01-23T13:03:10Z",
    "message": "[Refactor] Simplify interface via replacing argument thread binding of intrinsics with `KernelFrame.Current` (#34)\n\n* installation script fix\n\n* readme typo fix\n\n* doc fix for dequantize gemm\n\n* [Doc] remove CODE_OF_CONDUCT.md and SECURITY.md; update references in CONTRIBUTING.md\n\n* [Doc] add unit tests for AnnotateDeviceRegions transform; remove SUPPORT.md\n\n* update license\n\n* [Enhancement] add tensor supply handling for unsigned integers; improve error message for execution backend assertion\n\n* [Refactor] improve code readability by reformatting function signatures and assertions\n\n* [Refactor] replace torch.manual_seed with tilelang.testing.set_random_seed for consistency in random seed handling\n\n* [Refactor] unify thread binding variable naming across kernel and example files\n\n* [Refactor] remove unused thread binding parameter from matrix multiplication functions\n\n* [Refactor] remove unused thread binding parameter from matrix multiplication functions\n\n* [Refactor] enable main testing function in tilelang kernel gemm test\n\n* bug fix",
    "author": "Lei Wang"
  },
  "repository_info": {
    "structure_summary": ".\n./.git\n./.git/branches\n./.git/description\n./.git/hooks\n./.git/hooks/applypatch-msg.sample\n./.git/hooks/commit-msg.sample\n./.git/hooks/post-update.sample\n./.git/hooks/pre-applypatch.sample\n./.git/hooks/pre-commit.sample\n./.git/hooks/pre-merge-commit.sample\n./.git/hooks/pre-push.sample\n./.git/hooks/pre-receive.sample\n./.git/hooks/push-to-checkout.sample\n./.git/hooks/update.sample\n./.git/hooks/fsmonitor-watchman.sample\n./.git/hooks/pre-rebase.sample\n./.git/hooks/prepare-commit-msg.sample\n./.git/hooks/sendemail-validate.sample\n./.git/info\n./.git/info/exclude\n./.git/config\n./.git/objects\n./.git/objects/pack\n./.git/objects/pack/pack-48143939b914cafc1fea0830944bb6a52ef147ff.pack\n./.git/objects/pack/pack-48143939b914cafc1fea0830944bb6a52ef147ff.rev\n./.git/objects/pack/pack-48143939b914cafc1fea0830944bb6a52ef147ff.idx\n./.git/objects/info\n./.git/HEAD\n./.git/refs\n./.git/refs/heads\n./.git/refs/heads/main\n./.git/refs/tags\n./.git/refs/remotes\n./.git/refs/remotes/origin\n./.git/refs/remotes/origin/HEAD\n./.git/packed-refs\n./.git/logs\n./.git/logs/refs\n./.git/logs/refs/remotes\n./.git/logs/refs/remotes/origin\n./.git/logs/refs/remotes/origin/HEAD\n./.git/logs/refs/heads\n./.git/logs/refs/heads/main\n./.git/logs/HEAD\n./.git/index\n./.clang-tidy\n./.gitattributes\n./.github\n./.github/workflows\n./.github/workflows/dependabot.yml\n./.github/workflows/ci.yml\n./.github/workflows/publish_docs.yml\n./3rdparty\n./3rdparty/.gitignore\n./3rdparty/composable_kernel\n./3rdparty/cutlass\n./3rdparty/tvm\n./CONTRIBUTING.md\n./THIRDPARTYNOTICES.txt\n./docker\n./docker/Dockerfile.cu120\n./docker/README.md\n./docs\n./docs/README.md\n./docs/_static\n./docs/_static/img\n./docs/_static/img/logo-row.svg\n./docs/make.bat\n./docs/.gitignore\n./docs/CNAME\n./docs/Makefile\n./docs/conf.py\n./docs/get_started\n./docs/get_started/Installation.rst\n./docs/get_started/language_ref.rst\n./docs/index.rst\n./docs/privacy.rst\n./docs/requirements.txt\n./examples\n./examples/convolution\n./examples/convolution/README.md\n./examples/convolution/example_convolution.py\n./examples/dequantize_gemm\n./examples/dequantize_gemm/README.md\n./examples/dequantize_gemm/example_dequant_gemm.py\n./examples/dequantize_gemm/example_dequant_gemm_fine_grained.py\n./examples/dequantize_gemm/example_dequant_gemm_fp4_hopper.py\n./examples/flash_attention\n./examples/flash_attention/README.md\n./examples/flash_attention/example_mha.py\n./examples/gemm\n./examples/gemm/README.md\n./examples/gemm/example_gemm.py\n./examples/gemm/example_gemm_intrinsics.py\n./examples/gemm/example_gemm_schedule.py\n./examples/linear_attention\n./examples/linear_attention/README.md\n./examples/linear_attention/example_mamba_chunk_scan.py\n./examples/linear_attention/example_mamba_chunk_state.py\n./examples/quickstart.py\n./images\n./images/MatmulExample.png\n./images/MatmulExample.svg\n./images/logo-row.svg\n./images/mha_performance_h100.png\n./images/op_benchmark_a100_wq_gemv.png\n./images/op_benchmark_consistent_gemm_fp16.png\n./images/op_benchmark_h100.png\n./images/op_benchmark_mi300_fp16_gemm_normalized_latency.png\n./maint\n./maint/scripts\n./maint/scripts/apply_mit_license.sh\n./maint/scripts/check_mit_license.sh\n./maint/scripts/local_distribution.sh\n./maint/scripts/mit_liscense1.txt\n./maint/scripts/mit_liscense2.txt\n./maint/scripts/pypi_distribution.sh\n./src\n./src/layout\n./src/layout/gemm_layouts.cc\n./src/layout/layout.cc\n./src/layout/layout.h\n./src/layout/swizzle.cc\n./src/layout/swizzle.h\n./src/layout/utils.cc\n./src/layout/utils.h\n./src/op\n./src/op/builtin.cc\n./src/op/builtin.h\n./src/op/bulk_copy.cc\n./src/op/bulk_copy.h\n./src/op/elem.cc\n./src/op/elem.h\n./src/op/gemm.cc\n./src/op/gemm.h\n./src/op/op.cc\n./src/op/op.h\n./src/op/parallel.cc\n./src/op/parallel.h\n./src/op/reduce.cc\n./src/op/reduce.h\n./src/runtime\n./src/runtime/runtime.cc\n./src/runtime/runtime.h\n./src/target\n./src/target/codegen_cpp.h\n./src/target/codegen_cpp.cc\n./src/target/codegen_cuda.cc\n./src/target/codegen_cuda.h\n./src/target/codegen_hip.cc\n./src/target/codegen_hip.h\n./src/target/cuda.h\n./src/target/rt_mod_cpp.cc\n./src/target/rt_mod_cuda.cc\n./src/target/rt_mod_hip.cc\n./src/target/utils.cc\n./src/target/utils.h\n./src/tl_templates\n./src/tl_templates/cpu\n./src/tl_templates/cpu/common.h\n./src/tl_templates/cpu/gemm.h\n./src/tl_templates/cuda\n./src/tl_templates/cuda/common.h\n./src/tl_templates/cuda/copy.h\n./src/tl_templates/cuda/copy_sm90.h\n./src/tl_templates/cuda/gemm.h\n./src/tl_templates/cuda/gemm_sm70.h\n./src/tl_templates/cuda/gemm_sm80.h\n./src/tl_templates/cuda/gemm_sm90.h\n./src/tl_templates/cuda/ldsm.h\n./src/tl_templates/cuda/reduce.h\n./src/tl_templates/cuda/threadblock_swizzle.h\n./src/tl_templates/hip\n./src/tl_templates/hip/common.h\n./src/tl_templates/hip/copy.h\n./src/tl_templates/hip/gemm.h\n./src/tl_templates/hip/ldsm.h\n./src/tl_templates/hip/reduce.h\n./src/tl_templates/hip/threadblock_swizzle.h\n./src/transform\n./src/transform/annotate_device_regions.cc\n./src/transform/cluster_planning.cc\n./src/transform/common\n./src/transform/common/loop_fusion_utils.h\n./src/transform/common/loop_vectorization_utils.h\n./src/transform/frontend_legalize.cc\n./src/transform/legalize_vectorized_loop.cc\n./src/transform/make_packed_api.cc\n./src/transform/multi_version_buffer_rewriter.cc\n./src/transform/inject_fence_proxy.cc\n./src/transform/inject_pipeline.cc\n./src/transform/layout_inference.cc\n./src/transform/legalize_safe_memory_access.cc\n./src/transform/loop_partition.cc\n./src/transform/loop_partition.h\n./src/transform/loop_vectorize.cc\n./src/transform/loop_vectorize.h\n./src/transform/lower_hopper_intrin.cc\n./src/transform/lower_tile_op.cc\n./src/transform/pipeline_planning.cc\n./src/transform/simplify.cc\n./src/transform/thread_partial_sync.cc\n./src/transform/warp_specialized_rewriter.cc\n./src/ir.cc\n./testing\n./testing/.gitkeep\n./testing/cpp\n./testing/cpp/.gitkeep\n./testing/python\n./testing/python/amd\n./testing/python/amd/test_tilelang_gemm_mfma_intrinsic.py\n./testing/python/amd/test_tilelang_test_amd.py\n./testing/python/cpu\n./testing/python/cpu/test_tilelang_cpu_gemm.py\n./testing/python/dynamic\n./testing/python/dynamic/test_tilelang_dynamic_symbolic.py\n./testing/python/ir\n./testing/python/ir/test_ir_kernel_frame.py\n./testing/python/jit\n./testing/python/jit/test_tilelang_jit_gemm.py\n./testing/python/kernel\n./testing/python/kernel/test_tilelang_kernel_dequantize_gemm.py\n./testing/python/kernel/test_tilelang_kernel_gemm.py\n./testing/python/kernel/test_tilelang_kernel_gemm_mma_intrinsic.py\n./testing/python/kernel/test_tilelang_kernel_gemm_simt.py\n./testing/python/kernel/test_tilelang_kernel_int4_mma_matmul.py\n./testing/python/primitives\n./testing/python/primitives/test_tilelang_primitives_mma.py\n./testing/python/transform\n./testing/python/transform/test_tilelang_transform_Inject_software_pipeline.py\n./testing/python/transform/test_tilelang_transform_annotate_device_regions.py\n./testing/python/transform/test_tilelang_transform_frontend_legalize.py\n./testing/python/transform/test_tilelang_transform_make_packed_api.py\n./testing/python/transform/test_tilelang_transform_simplify.py\n./tilelang\n./tilelang/autotuner\n./tilelang/autotuner/__init__.py\n./tilelang/common\n./tilelang/common/__init__.py\n./tilelang/common/transform_kind.py\n./tilelang/contrib\n./tilelang/contrib/__init__.py\n./tilelang/contrib/hipcc.py\n./tilelang/contrib/nvcc.py\n./tilelang/engine\n./tilelang/engine/__init__.py\n./tilelang/engine/lower.py\n./tilelang/intrinsics\n./tilelang/intrinsics/__init__.py\n./tilelang/intrinsics/mfma_layout.py\n./tilelang/intrinsics/mfma_macro_generator.py\n./tilelang/intrinsics/mma_layout.py\n./tilelang/intrinsics/mma_macro_generator.py\n./tilelang/intrinsics/utils.py\n./tilelang/jit\n./tilelang/jit/adapter\n./tilelang/jit/adapter/__init__.py\n./tilelang/jit/adapter/base.py\n./tilelang/jit/adapter/ctypes.py\n./tilelang/jit/adapter/dl_pack.py\n./tilelang/jit/adapter/torch_cpp.py\n./tilelang/jit/__init__.py\n./tilelang/jit/core.py\n./tilelang/jit/env.py\n./tilelang/jit/kernel.py\n./tilelang/language\n./tilelang/language/ast\n./tilelang/language/ast/__init__.py\n./tilelang/language/ast/_ffi_api.py\n./tilelang/language/ast/ir.py\n./tilelang/language/parser\n./tilelang/language/parser/__init__.py\n./tilelang/language/parser/operation.py\n./tilelang/language/parser/entry.py\n./tilelang/language/parser/parser.py\n./tilelang/language/__init__.py\n./tilelang/language/allocate.py\n./tilelang/language/copy.py\n./tilelang/language/customize.py\n./tilelang/language/fill.py\n./tilelang/language/gemm.py\n./tilelang/language/kernel.py\n./tilelang/language/parallel.py\n./tilelang/language/pipeline.py\n./tilelang/language/reduce.py\n./tilelang/layout\n./tilelang/layout/__init__.py\n./tilelang/layout/fragment.py\n./tilelang/layout/layout.py\n./tilelang/layout/swizzle.py\n./tilelang/primitives\n./tilelang/primitives/gemm\n./tilelang/primitives/gemm/__init__.py\n./tilelang/primitives/gemm/base.py\n./tilelang/primitives/gemm/gemm_mma.py\n./tilelang/primitives/__init__.py\n./tilelang/profiler\n./tilelang/profiler/__init__.py\n./tilelang/testing\n./tilelang/testing/__init__.py\n./tilelang/transform\n./tilelang/transform/__init__.py\n./tilelang/transform/_ffi_api.py\n./tilelang/transform/simplify.py\n./tilelang/utils\n./tilelang/utils/__init__.py\n./tilelang/utils/language.py\n./tilelang/utils/target.py\n./tilelang/utils/tensor.py\n./tilelang/__init__.py\n./tilelang/_ffi_api.py\n./tilelang/env.py\n./tilelang/libinfo.py\n./tilelang/version.py\n./.gitignore\n./.gitmodules\n./CMakeLists.txt\n./LICENSE\n./MANIFEST.in\n./README.md\n./VERSION\n./benchmark\n./benchmark/benchmark_matmul.py\n./format.sh\n./install_cpu.sh\n./install_cuda.sh\n./install_rocm.sh\n./pyproject.toml\n./requirements-dev.txt\n./requirements-test.txt\n./requirements.txt\n./setup.py\n",
    "readme": "\n--- ./docker/README.md ---\nTo ease the process of installing all the dependencies, we provide a Dockerfile and a simple guideline to build a Docker image with all of above installed. The Docker image is built on top of Ubuntu 20.04, and it contains all the dependencies required to run the experiments. We only provide the Dockerfile for NVIDIA GPU, and the Dockerfile for AMD GPU will be provided upon request.\n\n```bash\ngit clone --recursive https://github.com/tile-ai/tilelang TileLang\ncd TileLang/docker\n# build the image, this may take a while (around 10+ minutes on our test machine)\ndocker build -t tilelang_cuda -f Dockerfile.cu120 .\n# run the container\ndocker run -it --cap-add=SYS_ADMIN --network=host --gpus all --cap-add=SYS_PTRACE --shm-size=4G --security-opt seccomp=unconfined --security-opt apparmor=unconfined --name tilelang_test tilelang_cuda bash\n```\n\n\n\n--- ./docs/README.md ---\n# Tile Language Documentation\n\nThe documentation was built upon [Sphinx](https://www.sphinx-doc.org/en/master/).\n\n## Dependencies\n\nRun the following command in this directory to install dependencies first:\n\n```bash\npip3 install -r requirements.txt\n```\n\n## Build the Documentation\n\nThen you can build the documentation by running:\n\n```bash\nmake html\n```\n\n## View the Documentation\n\nRun the following command to start a simple HTTP server:\n\n```bash\ncd _build/html\npython3 -m http.server\n```\n\nThen you can view the documentation in your browser at `http://localhost:8000` (the port can be customized by appending ` -p PORT_NUMBER` in the python command above).\n\n\n\n--- ./examples/convolution/README.md ---\n# Convolution\n\n\n",
    "readme_filenames": [
      "./docker/README.md",
      "./docs/README.md",
      "./examples/convolution/README.md"
    ],
    "dockerfile": "\n--- ./docker/Dockerfile.cu120 ---\nFROM nvcr.io/nvidia/pytorch:23.01-py3 \n\nWORKDIR /root\n\nRUN echo \"LC_ALL=en_US.UTF-8\" >> /etc/environment\n\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n  build-essential git wget \\\n  libgtest-dev libprotobuf-dev protobuf-compiler libgflags-dev libsqlite3-dev llvm-dev \\\n  && apt-get clean autoclean && rm -rf /var/lib/apt/lists/{apt,dpkg,cache,log} /tmp/* /var/tmp/*\n\nRUN wget https://repo.anaconda.com/miniconda/Miniconda3-py310_23.5.2-0-Linux-x86_64.sh -O install_miniconda.sh && \\\n  bash install_miniconda.sh -b -p /opt/conda && rm install_miniconda.sh\n\nENV PATH=\"/opt/conda/bin:${PATH}\"\n\nENV LIBGL_ALWAYS_INDIRECT=1\n\nRUN conda install pip cmake && conda clean --all\n\nRUN apt-get install -y python3 python3-dev python3-setuptools gcc libtinfo-dev zlib1g-dev build-essential cmake libedit-dev libxml2-dev\n\nRUN git clone https://github.com/tile-ai/tilelang.git --recursive -b main TileLang \\\n  && cd TileLang && ./install.sh\n\nCMD bash\n\n\n\n--- ./docker/README.md ---\nTo ease the process of installing all the dependencies, we provide a Dockerfile and a simple guideline to build a Docker image with all of above installed. The Docker image is built on top of Ubuntu 20.04, and it contains all the dependencies required to run the experiments. We only provide the Dockerfile for NVIDIA GPU, and the Dockerfile for AMD GPU will be provided upon request.\n\n```bash\ngit clone --recursive https://github.com/tile-ai/tilelang TileLang\ncd TileLang/docker\n# build the image, this may take a while (around 10+ minutes on our test machine)\ndocker build -t tilelang_cuda -f Dockerfile.cu120 .\n# run the container\ndocker run -it --cap-add=SYS_ADMIN --network=host --gpus all --cap-add=SYS_PTRACE --shm-size=4G --security-opt seccomp=unconfined --security-opt apparmor=unconfined --name tilelang_test tilelang_cuda bash\n```\n\n\n",
    "dockerfile_paths": [
      "./docker/Dockerfile.cu120",
      "./docker/README.md"
    ],
    "github_workflows": {
      ".github/workflows/dependabot.yml": "name: Dependent Bot Action\n\non:\n  pull_request:\n    branches: [main]\n  workflow_dispatch:\n\njobs:\n  bot-task:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v2\n\n    - name: Set up Python\n      uses: actions/setup-python@v2\n      with:\n        python-version: '3.x'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n",
      ".github/workflows/ci.yml": "name: CI\n\non: [pull_request]\n\njobs:\n  format-check:\n    runs-on: self-hosted\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n      with:\n        fetch-depth: 0\n\n    - name: Set up Python\n      uses: actions/setup-python@v2\n      with:\n        python-version: '3.9'\n\n    - name: Create virtual environment\n      run: python -m venv bitblas_ci\n\n    - name: Activate virtual environment and install dependencies\n      run: |\n        source bitblas_ci/bin/activate\n        python -m pip install --upgrade pip\n        if [ -f requirements-dev.txt ]; then python -m pip install -r requirements-dev.txt; fi\n\n    - name: Update submodules recursively\n      run: git submodule update --init --recursive\n\n    - name: Run format check\n      run: |\n        source bitblas_ci/bin/activate\n        ./format.sh\n\n  build-test:\n    runs-on: self-hosted\n    needs: format-check\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v2\n      with:\n        fetch-depth: 0\n\n    - name: Set up Python\n      uses: actions/setup-python@v2\n      with:\n        python-version: '3.9'\n\n    - name: Create virtual environment\n      run: python -m venv bitblas_ci\n\n    - name: Activate virtual environment and install dependencies\n      run: |\n        source bitblas_ci/bin/activate\n        python -m pip install --upgrade pip\n        if [ -f requirements-test.txt ]; then python -m pip install -r requirements-test.txt; fi\n\n    - name: Install project in wheel mode\n      run: |\n        source bitblas_ci/bin/activate\n        python -m pip install .\n\n    - name: Run tests\n      run: |\n        source bitblas_ci/bin/activate\n        cd testing/python\n        python -m pytest\n",
      ".github/workflows/publish_docs.yml": "name: documentation\n\non:\n  pull_request:\n    types:\n      - closed\n\npermissions:\n  contents: write\n\njobs:\n  docs:\n    if: ${{ github.event.pull_request.merged == true && github.event.pull_request.base.ref == 'main' }}\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        working-directory: ./docs\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n      - name: Sphinx build\n        run: |\n          make html\n          cp CNAME _build/html\n      - name: Deploy to GitHub Pages\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          publish_branch: gh-pages\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: docs/_build/html\n          force_orphan: true\n"
    }
  },
  "llm_calls_before_build": 10,
  "github_workflows_found": [
    ".github/workflows/dependabot.yml",
    ".github/workflows/ci.yml",
    ".github/workflows/publish_docs.yml"
  ],
  "dockerfile": "FROM nvcr.io/nvidia/pytorch:23.01-py3\n\nWORKDIR /root\n\nENV DEBIAN_FRONTEND=noninteractive \\\n    LC_ALL=en_US.UTF-8 \\\n    LANG=en_US.UTF-8 \\\n    PATH=\"/opt/conda/bin:${PATH}\"\n\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    build-essential git cmake wget locales \\\n    libgtest-dev libprotobuf-dev protobuf-compiler libgflags-dev llvm-dev \\\n    python3-dev python3-setuptools zlib1g-dev libtinfo-dev libedit-dev libxml2-dev \\\n    && apt-get clean autoclean \\\n    && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* \\\n    && localedef -i en_US -c -f UTF-8 -A /usr/share/locale/locale.alias en_US.UTF-8\n\nRUN git clone https://github.com/tile-ai/tilelang.git --recursive TileLang \\\n    && cd TileLang \\\n    && git checkout a7f66d4f1bd319e56ce090ba096f5c803c1bfbc7 \\\n    && git submodule update --init --recursive\n\nRUN pip3 install -r /root/TileLang/requirements.txt \\\n    -r /root/TileLang/requirements-dev.txt \\\n    && cd /root/TileLang && ./install_cuda.sh\n\nWORKDIR /root/TileLang",
  "dockerfile_source": "Repository at Dockerfile",
  "dockerfile_attempt_1": 1,
  "dockerfile_build_success": true,
  "llm_calls_total": 20
}